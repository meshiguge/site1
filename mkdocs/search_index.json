{
    "docs": [
        {
            "location": "/", 
            "text": "Keras:\u57fa\u4e8eTheano\u548cTensorFlow\u7684\u6df1\u5ea6\u5b66\u4e60\u5e93\n\n\n\u8fd9\u5c31\u662fKeras\n\n\nKeras\u662f\u4e00\u4e2a\u9ad8\u5c42\u795e\u7ecf\u7f51\u7edc\u5e93\uff0cKeras\u7531\u7eafPython\u7f16\u5199\u800c\u6210\u5e76\u57faTensorflow\u6216Theano\u3002Keras\n\u4e3a\u652f\u6301\u5feb\u901f\u5b9e\u9a8c\u800c\u751f\uff0c\u80fd\u591f\u628a\u4f60\u7684idea\u8fc5\u901f\u8f6c\u6362\u4e3a\u7ed3\u679c\uff0c\u5982\u679c\u4f60\u6709\u5982\u4e0b\u9700\u6c42\uff0c\u8bf7\u9009\u62e9Keras\uff1a\n\n\n\n\n\u7b80\u6613\u548c\u5feb\u901f\u7684\u539f\u578b\u8bbe\u8ba1\uff08keras\u5177\u6709\u9ad8\u5ea6\u6a21\u5757\u5316\uff0c\u6781\u7b80\uff0c\u548c\u53ef\u6269\u5145\u7279\u6027\uff09\n\n\n\u652f\u6301CNN\u548cRNN\uff0c\u6216\u4e8c\u8005\u7684\u7ed3\u5408\n\n\n\u652f\u6301\u4efb\u610f\u7684\u94fe\u63a5\u65b9\u6848\uff08\u5305\u62ec\u591a\u8f93\u5165\u548c\u591a\u8f93\u51fa\u8bad\u7ec3\uff09\n\n\n\u65e0\u7f1dCPU\u548cGPU\u5207\u6362\n\n\n\n\nKeras\u9002\u7528\u7684Python\u7248\u672c\u662f\uff1aPython 2.7-3.5\n\n\nKeras\u7684\u8bbe\u8ba1\u539f\u5219\u662f\n\n\n\n\n\n\n\u6a21\u5757\u6027\uff1a\u6a21\u578b\u53ef\u7406\u89e3\u4e3a\u4e00\u4e2a\u72ec\u7acb\u7684\u5e8f\u5217\u6216\u56fe\uff0c\u5b8c\u5168\u53ef\u914d\u7f6e\u7684\u6a21\u5757\u4ee5\u6700\u5c11\u7684\u4ee3\u4ef7\u81ea\u7531\u7ec4\u5408\u5728\u4e00\u8d77\u3002\u5177\u4f53\u800c\u8a00\uff0c\u7f51\u7edc\u5c42\u3001\u635f\u5931\u51fd\u6570\u3001\u4f18\u5316\u5668\u3001\u521d\u59cb\u5316\u7b56\u7565\u3001\u6fc0\u6d3b\u51fd\u6570\u3001\u6b63\u5219\u5316\u65b9\u6cd5\u90fd\u662f\u72ec\u7acb\u7684\u6a21\u5757\uff0c\u4f60\u53ef\u4ee5\u4f7f\u7528\u5b83\u4eec\u6765\u6784\u5efa\u81ea\u5df1\u7684\u6a21\u578b\u3002\n\n\n\n\n\n\n\u6781\u7b80\u4e3b\u4e49\uff1a\u6bcf\u4e2a\u6a21\u5757\u90fd\u5e94\u8be5\u5c3d\u91cf\u7684\u7b80\u6d01\u3002\u6bcf\u4e00\u6bb5\u4ee3\u7801\u90fd\u5e94\u8be5\u5728\u521d\u6b21\u9605\u8bfb\u65f6\u90fd\u663e\u5f97\u76f4\u89c2\u6613\u61c2\u3002\u6ca1\u6709\u9ed1\u9b54\u6cd5\uff0c\u56e0\u4e3a\u5b83\u5c06\u7ed9\u8fed\u4ee3\u548c\u521b\u65b0\u5e26\u6765\u9ebb\u70e6\u3002\n\n\n\n\n\n\n\u6613\u6269\u5c55\u6027\uff1a\u6dfb\u52a0\u65b0\u6a21\u5757\u8d85\u7ea7\u7b80\u5355\u7684\u5bb9\u6613\uff0c\u53ea\u9700\u8981\u4eff\u7167\u73b0\u6709\u7684\u6a21\u5757\u7f16\u5199\u65b0\u7684\u7c7b\u6216\u51fd\u6570\u5373\u53ef\u3002\u521b\u5efa\u65b0\u6a21\u5757\u7684\u4fbf\u5229\u6027\u4f7f\u5f97Keras\u66f4\u9002\u5408\u4e8e\u5148\u8fdb\u7684\u7814\u7a76\u5de5\u4f5c\u3002\n\n\n\n\n\n\n\u4e0ePython\u534f\u4f5c\uff1aKeras\u6ca1\u6709\u5355\u72ec\u7684\u6a21\u578b\u914d\u7f6e\u6587\u4ef6\u7c7b\u578b\uff08\u4f5c\u4e3a\u5bf9\u6bd4\uff0ccaffe\u6709\uff09\uff0c\u6a21\u578b\u7531python\u4ee3\u7801\u63cf\u8ff0\uff0c\u4f7f\u5176\u66f4\u7d27\u51d1\u548c\u66f4\u6613debug\uff0c\u5e76\u63d0\u4f9b\u4e86\u6269\u5c55\u7684\u4fbf\u5229\u6027\u3002\n\n\n\n\n\n\nKeras\u4ece2015\u5e743\u6708\u5f00\u59cb\u542f\u52a8\uff0c\u7ecf\u8fc7\u4e00\u5e74\u591a\u7684\u5f00\u53d1\uff0c\u76ee\u524dKeras\u8fdb\u5165\u4e861.0\u7684\u65f6\u4ee3\u3002Keras 1.0\u4f9d\u7136\u9075\u5faa\u76f8\u540c\u7684\u8bbe\u8ba1\u539f\u5219\uff0c\u4f46\u4e0e\u4e4b\u524d\u7684\u7248\u672c\u76f8\u6bd4\u6709\u5f88\u5927\u7684\u4e0d\u540c\u3002\u5982\u679c\u4f60\u66fe\u7ecf\u4f7f\u7528\u8fc7\u6b64\u524d\u7684\u5176\u4ed6\u7248\u672cKeras\u3002\u4f60\u6216\u8bb8\u4f1a\u5173\u5fc31.0\u7684\u65b0\u7279\u6027\u3002\n\n\n\n\n\n\n\u6cdb\u578b\u6a21\u578b\uff1a\u7b80\u5355\u548c\u5f3a\u5927\u7684\u65b0\u6a21\u5757\uff0c\u7528\u4e8e\u652f\u6301\u590d\u6742\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7684\u642d\u5efa\u3002\n\n\n\n\n\n\n\u66f4\u4f18\u79c0\u7684\u6027\u80fd\uff1a\u73b0\u5728\uff0cKeras\u6a21\u578b\u7684\u7f16\u8bd1\u65f6\u95f4\u5f97\u5230\u7f29\u77ed\u3002\u6240\u6709\u7684RNN\u73b0\u5728\u90fd\u53ef\u4ee5\u7528\u4e24\u79cd\u65b9\u5f0f\u5b9e\u73b0\uff0c\u4ee5\u4f9b\u7528\u6237\u5728\u4e0d\u540c\u914d\u7f6e\u4efb\u52a1\u548c\u914d\u7f6e\u73af\u5883\u4e0b\u53d6\u5f97\u6700\u5927\u6027\u80fd\u3002\u73b0\u5728\uff0c\u57fa\u4e8eTheano\u7684RNN\u4e5f\u53ef\u4ee5\u88ab\u5c55\u5f00\uff0c\u4ee5\u83b7\u5f97\u5927\u698225%\u7684\u52a0\u901f\u8ba1\u7b97\u3002\n\n\n\n\n\n\n\u6d4b\u91cf\u6307\u6807\uff1a\u73b0\u5728\uff0c\u4f60\u53ef\u4ee5\u63d0\u4f9b\u4e00\u7cfb\u5217\u7684\u6d4b\u91cf\u6307\u6807\u6765\u5728Keras\u7684\u4efb\u4f55\u76d1\u6d4b\u70b9\u89c2\u5bdf\u6a21\u578b\u6027\u80fd\u3002\n\n\n\n\n\n\n\u66f4\u4f18\u7684\u7528\u6237\u4f53\u9a8c\uff1a\u6211\u4eec\u9762\u5411\u4f7f\u7528\u8005\u91cd\u65b0\u7f16\u5199\u4e86\u4ee3\u7801\uff0c\u4f7f\u5f97\u51fd\u6570API\u66f4\u7b80\u5355\u6613\u8bb0\uff0c\u540c\u65f6\u63d0\u4f9b\u66f4\u6709\u6548\u7684\u51fa\u9519\u4fe1\u606f\u3002\n\n\n\n\n\n\n\u65b0\u7248\u672c\u7684Keras\u63d0\u4f9b\u4e86Lambda\u5c42\uff0c\u4ee5\u5b9e\u73b0\u4e00\u4e9b\u7b80\u5355\u7684\u8ba1\u7b97\u4efb\u52a1\u3002\n\n\n\n\n\n\n...\n\n\n\n\n\n\n\u5982\u679c\u4f60\u5df2\u7ecf\u57fa\u4e8eKeras0.3\u7f16\u5199\u4e86\u81ea\u5df1\u7684\u5c42\uff0c\u90a3\u4e48\u5728\u5347\u7ea7\u540e\uff0c\u4f60\u9700\u8981\u4e3a\u81ea\u5df1\u7684\u4ee3\u7801\u505a\u4ee5\u4e0b\u8c03\u6574\uff0c\u4ee5\u5728Keras1.0\u4e0a\u7ee7\u7eed\u8fd0\u884c\u3002\u8bf7\u53c2\u8003\n\u7f16\u5199\u81ea\u5df1\u7684\u5c42\n\n\n\n\n\u5173\u4e8eKeras-cn\n\n\n\u672c\u6587\u6863\u662fKeras\u6587\u6863\u7684\u4e2d\u6587\u7248\uff0c\u5305\u62ec\nkeras.io\n\u7684\u5168\u90e8\u5185\u5bb9\uff0c\u4ee5\u53ca\u66f4\u591a\u7684\u4f8b\u5b50\u3001\u89e3\u91ca\u548c\u5efa\u8bae\n\n\n\u73b0\u5728\uff0ckeras-cn\u7684\u7248\u672c\u53f7\u5c06\u7b80\u5355\u7684\u8ddf\u968f\u6700\u65b0\u7684keras release\u7248\u672c\n\n\n\u7531\u4e8e\u4f5c\u8005\u6c34\u5e73\u548c\u7814\u7a76\u65b9\u5411\u6240\u9650\uff0c\u65e0\u6cd5\u5bf9\u6240\u6709\u6a21\u5757\u90fd\u975e\u5e38\u7cbe\u901a\uff0c\u56e0\u6b64\u6587\u6863\u4e2d\u4e0d\u53ef\u907f\u514d\u7684\u4f1a\u51fa\u73b0\u5404\u79cd\u9519\u8bef\u3001\u758f\u6f0f\u548c\u4e0d\u8db3\u4e4b\u5904\u3002\u5982\u679c\u60a8\u5728\u4f7f\u7528\u8fc7\u7a0b\u4e2d\u6709\u4efb\u4f55\u610f\u89c1\u3001\u5efa\u8bae\u548c\u7591\u95ee\uff0c\u6b22\u8fce\u53d1\u9001\u90ae\u4ef6\u5230moyan_work@foxmail.com\u4e0e\u6211\u53d6\u5f97\u8054\u7cfb\u3002\n\n\n\u60a8\u5bf9\u6587\u6863\u7684\u4efb\u4f55\u8d21\u732e\uff0c\u5305\u62ec\u6587\u6863\u7684\u7ffb\u8bd1\u3001\u67e5\u7f3a\u8865\u6f0f\u3001\u6982\u5ff5\u89e3\u91ca\u3001\u53d1\u73b0\u548c\u4fee\u6539\u95ee\u9898\u3001\u8d21\u732e\u793a\u4f8b\u7a0b\u5e8f\u7b49\uff0c\u5747\u4f1a\u88ab\u8bb0\u5f55\u5728\n\u81f4\u8c22\n\uff0c\u5341\u5206\u611f\u8c22\u60a8\u5bf9Keras\u4e2d\u6587\u6587\u6863\u7684\u8d21\u732e\uff01\n\n\n\u540c\u65f6\uff0c\u4e5f\u6b22\u8fce\u60a8\u64b0\u6587\u5411\u672c\u6587\u6863\u6295\u7a3f\uff0c\u60a8\u7684\u7a3f\u4ef6\u88ab\u5f55\u7528\u540e\u5c06\u4ee5\u5355\u72ec\u7684\u9875\u9762\u663e\u793a\u5728\u7f51\u7ad9\u4e2d\uff0c\u60a8\u6709\u6743\u5728\u60a8\u7684\u7f51\u9875\u4e0b\u8bbe\u7f6e\u8d5e\u52a9\u4e8c\u7ef4\u7801\uff0c\u4ee5\u83b7\u53d6\u6765\u81ea\u7f51\u53cb\u7684\u5c0f\u989d\u8d5e\u52a9\u3002\n\n\n\u5982\u679c\u4f60\u53d1\u73b0\u672c\u6587\u6863\u7f3a\u5931\u4e86\u5b98\u65b9\u6587\u6863\u7684\u90e8\u5206\u5185\u5bb9\uff0c\u8bf7\u79ef\u6781\u8054\u7cfb\u6211\u8865\u5145\u3002\n\n\n\u672c\u6587\u6863\u76f8\u5bf9\u4e8e\u539f\u6587\u6863\u6709\u66f4\u591a\u7684\u4f7f\u7528\u6307\u5bfc\u548c\u6982\u5ff5\u6f84\u6e05\uff0c\u8bf7\u5728\u4f7f\u7528\u65f6\u5173\u6ce8\u6587\u6863\u4e2d\u7684Tips\uff0c\u7279\u522b\u7684\uff0c\u672c\u6587\u6863\u7684\u989d\u5916\u6a21\u5757\u8fd8\u6709\uff1a\n\n\n\n\n\n\n\u4e00\u4e9b\u57fa\u672c\u6982\u5ff5\uff1a\u4f4d\u4e8e\u5feb\u901f\u5f00\u59cb\u6a21\u5757\u7684\n\u4e00\u4e9b\u57fa\u672c\u6982\u5ff5\n\u7b80\u5355\u4ecb\u7ecd\u4e86\u4f7f\u7528Keras\u524d\u9700\u8981\u77e5\u9053\u7684\u4e00\u4e9b\u5c0f\u77e5\u8bc6\uff0c\u65b0\u624b\u5728\u4f7f\u7528\u524d\u5e94\u8be5\u5148\u9605\u8bfb\u672c\u90e8\u5206\u7684\u6587\u6863\u3002\n\n\n\n\n\n\nKeras\u5b89\u88c5\u548c\u914d\u7f6e\u6307\u5357\uff0c\u63d0\u4f9b\u4e86\u8be6\u7ec6\u7684Linux\u548cWindows\u4e0bKeras\u7684\u5b89\u88c5\u548c\u914d\u7f6e\u6b65\u9aa4\u3002\n\n\n\n\n\n\n\u6df1\u5ea6\u5b66\u4e60\u4e0eKeras\uff1a\u4f4d\u4e8e\u5bfc\u822a\u680f\u6700\u4e0b\u65b9\u7684\u8be5\u6a21\u5757\u7ffb\u8bd1\u4e86\u6765\u81eaKeras\u4f5c\u8005\u535a\u5ba2\nkeras.io\n\u548c\u5176\u4ed6Keras\u76f8\u5173\u535a\u5ba2\u7684\u6587\u7ae0\uff0c\u8be5\u680f\u76ee\u7684\u6587\u7ae0\u63d0\u4f9b\u4e86\u5bf9\u6df1\u5ea6\u5b66\u4e60\u7684\u7406\u89e3\u548c\u5927\u91cf\u4f7f\u7528Keras\u7684\u4f8b\u5b50\uff0c\u60a8\u4e5f\u53ef\u4ee5\u5411\u8fd9\u4e2a\u680f\u76ee\u6295\u7a3f\u3002\n\u6240\u6709\u7684\u6587\u7ae0\u5747\u5728\u9192\u76ee\u4f4d\u7f6e\u6807\u5fd7\u6807\u660e\u6765\u6e90\u4e0e\u4f5c\u8005\uff0c\u672c\u6587\u6863\u5bf9\u8be5\u680f\u76ee\u6587\u7ae0\u7684\u539f\u6587\u4e0d\u5177\u6709\u4efb\u4f55\u5904\u7f6e\u6743\u3002\u5982\u60a8\u4ecd\u89c9\u4e0d\u59a5\uff0c\u8bf7\u8054\u7cfb\u672c\u4eba\uff08moyan_work@foxmail.com\uff09\u5220\u9664\u3002\n\n\n\n\n\n\n\n\n\u5f53\u524d\u7248\u672c\u4e0e\u66f4\u65b0\n\n\n\u5982\u679c\u4f60\u53d1\u73b0\u672c\u6587\u6863\u63d0\u4f9b\u7684\u4fe1\u606f\u6709\u8bef\uff0c\u6709\u4e24\u79cd\u53ef\u80fd\uff1a\n\n\n\n\n\n\n\u4f60\u7684Keras\u7248\u672c\u8fc7\u4f4e\uff1a\u8bb0\u4f4fKeras\u662f\u4e00\u4e2a\u53d1\u5c55\u8fc5\u901f\u7684\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u8bf7\u4fdd\u6301\u4f60\u7684Keras\u4e0e\u5b98\u65b9\u6700\u65b0\u7684release\u7248\u672c\u76f8\u7b26\n\n\n\n\n\n\n\u6211\u4eec\u7684\u4e2d\u6587\u6587\u6863\u6ca1\u6709\u53ca\u65f6\u66f4\u65b0\uff1a\u5982\u679c\u662f\u8fd9\u79cd\u60c5\u51b5\uff0c\u8bf7\u53d1\u90ae\u4ef6\u7ed9\u6211\uff0c\u6211\u4f1a\u5c3d\u5feb\u66f4\u65b0\n\n\n\n\n\n\n\u76ee\u524d\u6587\u6863\u7684\u7248\u672c\u53f7\u662f1.2.1\uff0c\u5bf9\u5e94\u4e8e\u5b98\u65b9\u76841.2.1 release \u7248\u672c, \u672c\u6b21\u66f4\u65b0\u7684\u4e3b\u8981\u5185\u5bb9\u662f\uff1a\n\n\n\n\n\u4e3aApplication\u4e2d\u7684\u56fe\u7247\u5206\u7c7b\u6a21\u578b\u589e\u52a0\u4e86\nclasses\n\u548c\ninput_shape\n\uff0c\u4f46\nclasses\n\u7684\u8bf4\u660e\u5728\u539f\u6587\u6863\u4e2d\u7f3a\u5931\n\n\n\u6682\u65f6\u79fb\u9664\u4e86SpatialDropout1D,SpatialDropout2D,SpatialDropout3D\u7684\u6587\u6863\uff0c\u4f46\u5b83\u4eec\u7684\u6e90\u4ee3\u7801\u4ecd\u7136\u4fdd\u7559\u5728\u4e2akeras\u4e2d\uff0c\u4f60\u4ecd\u7136\u53ef\u4ee5\u7528\u8fd9\u4e9blayer\n\n\n1.2.0\u548c\u5f53\u524d\u7248\u672c\u5747\u53ef\u4f7f\u7528ConvLSTM2D\u5c42\uff0c\u8fd9\u4e2a\u5c42\u5728\u4ee3\u7801\u4e2d\u6709\u8bf4\u660e\u4f46\u6ca1\u6709\u4f53\u73b0\u5728\u6587\u6863\u4e2d\uff0c\u6211\u4eec\u6682\u65f6\u4e5f\u4e0d\u63d0\u4f9b\u8fd9\u4e2a\u5c42\u7684\u8bf4\u660e\uff0c\u5982\u9700\u4f7f\u7528\u8bf7\u67e5\u770b\u6e90\u4ee3\u7801\u4e2d\u7684\u8bf4\u660e\n\n\n\u589e\u52a0\u4e86AC-GAN\u7684\u4f8b\u5b50\n\n\n\n\n\u6ce8\u610f\uff0ckeras\u5728github\u4e0a\u7684master\u5f80\u5f80\u8981\u9ad8\u4e8e\u5f53\u524d\u7684release\u7248\u672c\uff0c\u5982\u679c\u4f60\u4ece\u6e90\u7801\u7f16\u8bd1keras\uff0c\u53ef\u80fd\u67d0\u4e9b\u6a21\u5757\u4e0e\u6587\u6863\u8bf4\u660e\u4e0d\u76f8\u7b26\uff0c\u8bf7\u4ee5\u5b98\u65b9Github\u4ee3\u7801\u4e3a\u51c6\n\n\n\n\n\u5feb\u901f\u5f00\u59cb\uff1a30s\u4e0a\u624bKeras\n\n\nKeras\u7684\u6838\u5fc3\u6570\u636e\u7ed3\u6784\u662f\u201c\u6a21\u578b\u201d\uff0c\u6a21\u578b\u662f\u4e00\u79cd\u7ec4\u7ec7\u7f51\u7edc\u5c42\u7684\u65b9\u5f0f\u3002Keras\u4e2d\u4e3b\u8981\u7684\u6a21\u578b\u662fSequential\u6a21\u578b\uff0cSequential\u662f\u4e00\u7cfb\u5217\u7f51\u7edc\u5c42\u6309\u987a\u5e8f\u6784\u6210\u7684\u6808\u3002\u4f60\u4e5f\u53ef\u4ee5\u67e5\u770b\n\u6cdb\u578b\u6a21\u578b\n\u6765\u5b66\u4e60\u5efa\u7acb\u66f4\u590d\u6742\u7684\u6a21\u578b\n\n\nSequential\u6a21\u578b\u5982\u4e0b\n\n\nfrom keras.models import Sequential\n\nmodel = Sequential()\n\n\n\n\n\u5c06\u4e00\u4e9b\u7f51\u7edc\u5c42\u901a\u8fc7\n.add()\n\u5806\u53e0\u8d77\u6765\uff0c\u5c31\u6784\u6210\u4e86\u4e00\u4e2a\u6a21\u578b\uff1a\n\n\nfrom keras.layers import Dense, Activation\n\nmodel.add(Dense(output_dim=64, input_dim=100))\nmodel.add(Activation(\nrelu\n))\nmodel.add(Dense(output_dim=10))\nmodel.add(Activation(\nsoftmax\n))\n\n\n\n\n\u5b8c\u6210\u6a21\u578b\u7684\u642d\u5efa\u540e\uff0c\u6211\u4eec\u9700\u8981\u4f7f\u7528\n.compile()\n\u65b9\u6cd5\u6765\u7f16\u8bd1\u6a21\u578b\uff1a\n\n\nmodel.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n\n\n\n\n\u7f16\u8bd1\u6a21\u578b\u65f6\u5fc5\u987b\u6307\u660e\u635f\u5931\u51fd\u6570\u548c\u4f18\u5316\u5668\uff0c\u5982\u679c\u4f60\u9700\u8981\u7684\u8bdd\uff0c\u4e5f\u53ef\u4ee5\u81ea\u5df1\u5b9a\u5236\u635f\u5931\u51fd\u6570\u3002Keras\u7684\u4e00\u4e2a\u6838\u5fc3\u7406\u5ff5\u5c31\u662f\u7b80\u660e\u6613\u7528\u540c\u65f6\uff0c\u4fdd\u8bc1\u7528\u6237\u5bf9Keras\u7684\u7edd\u5bf9\u63a7\u5236\u529b\u5ea6\uff0c\u7528\u6237\u53ef\u4ee5\u6839\u636e\u81ea\u5df1\u7684\u9700\u8981\u5b9a\u5236\u81ea\u5df1\u7684\u6a21\u578b\u3001\u7f51\u7edc\u5c42\uff0c\u751a\u81f3\u4fee\u6539\u6e90\u4ee3\u7801\u3002\n\n\nfrom keras.optimizers import SGD\nmodel.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.01, momentum=0.9, nesterov=True))\n\n\n\n\n\u5b8c\u6210\u6a21\u578b\u7f16\u8bd1\u540e\uff0c\u6211\u4eec\u5728\u8bad\u7ec3\u6570\u636e\u4e0a\u6309batch\u8fdb\u884c\u4e00\u5b9a\u6b21\u6570\u7684\u8fed\u4ee3\u8bad\u7ec3\uff0c\u4ee5\u62df\u5408\u7f51\u7edc\uff0c\u5173\u4e8e\u4e3a\u4ec0\u4e48\u8981\u4f7f\u7528\u2018batch\u2019\uff0c\u8bf7\u53c2\u8003\n\u4e00\u4e9b\u57fa\u672c\u6982\u5ff5\n\n\nmodel.fit(X_train, Y_train, nb_epoch=5, batch_size=32)\n\n\n\n\n\u5f53\u7136\uff0c\u6211\u4eec\u4e5f\u53ef\u4ee5\u624b\u52a8\u5c06\u4e00\u4e2a\u4e2abatch\u7684\u6570\u636e\u9001\u5165\u7f51\u7edc\u4e2d\u8bad\u7ec3\uff0c\u8fd9\u65f6\u5019\u9700\u8981\u4f7f\u7528\uff1a\n\n\nmodel.train_on_batch(X_batch, Y_batch)\n\n\n\n\n\u968f\u540e\uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u4e00\u884c\u4ee3\u7801\u5bf9\u6211\u4eec\u7684\u6a21\u578b\u8fdb\u884c\u8bc4\u4f30\uff0c\u770b\u770b\u6a21\u578b\u7684\u6307\u6807\u662f\u5426\u6ee1\u8db3\u6211\u4eec\u7684\u8981\u6c42\uff1a\n\n\nloss_and_metrics = model.evaluate(X_test, Y_test, batch_size=32)\n\n\n\n\n\u6216\u8005\uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u6211\u4eec\u7684\u6a21\u578b\uff0c\u5bf9\u65b0\u7684\u6570\u636e\u8fdb\u884c\u9884\u6d4b\uff1a\n\n\nclasses = model.predict_classes(X_test, batch_size=32)\nproba = model.predict_proba(X_test, batch_size=32)\n\n\n\n\n\u642d\u5efa\u4e00\u4e2a\u95ee\u7b54\u7cfb\u7edf\u3001\u56fe\u50cf\u5206\u7c7b\u6a21\u578b\uff0c\u6216\u795e\u7ecf\u56fe\u7075\u673a\u3001word2vec\u8bcd\u5d4c\u5165\u5668\u5c31\u662f\u8fd9\u4e48\u5feb\u3002\u652f\u6491\u6df1\u5ea6\u5b66\u4e60\u7684\u57fa\u672c\u60f3\u6cd5\u672c\u5c31\u662f\u7b80\u5355\u7684\uff0c\u73b0\u5728\u8ba9\u6211\u4eec\u628a\u5b83\u7684\u5b9e\u73b0\u4e5f\u53d8\u7684\u7b80\u5355\u8d77\u6765\uff01\n\n\n\u4e3a\u4e86\u66f4\u6df1\u5165\u7684\u4e86\u89e3Keras\uff0c\u6211\u4eec\u5efa\u8bae\u4f60\u67e5\u770b\u4e00\u4e0b\u4e0b\u9762\u7684\u4e24\u4e2atutorial\n\n\n\n\n\u5feb\u901f\u5f00\u59cbSequntial\u6a21\u578b\n\n\n\u5feb\u901f\u5f00\u59cb\u6cdb\u578b\u6a21\u578b\n\n\n\n\n\u8fd8\u6709\u6211\u4eec\u5bf9\u4e00\u4e9b\u6982\u5ff5\u7684\u89e3\u91ca\n\n\n\n\n\u4e00\u4e9b\u57fa\u672c\u6982\u5ff5\n\n\n\n\n\u5728Keras\u4ee3\u7801\u5305\u7684examples\u6587\u4ef6\u5939\u91cc\uff0c\u6211\u4eec\u63d0\u4f9b\u4e86\u4e00\u4e9b\u66f4\u9ad8\u7ea7\u7684\u6a21\u578b\uff1a\u57fa\u4e8e\u8bb0\u5fc6\u7f51\u7edc\u7684\u95ee\u7b54\u7cfb\u7edf\u3001\u57fa\u4e8eLSTM\u7684\u6587\u672c\u7684\u6587\u672c\u751f\u6210\u7b49\u3002\n\n\n\n\n\u5b89\u88c5\n\n\nKeras\u4f7f\u7528\u4e86\u4e0b\u9762\u7684\u4f9d\u8d56\u5305\uff1a\n\n\n\n\n\n\nnumpy\uff0cscipy\n\n\n\n\n\n\npyyaml\n\n\n\n\n\n\nHDF5, h5py\uff08\u53ef\u9009\uff0c\u4ec5\u5728\u6a21\u578b\u7684save/load\u51fd\u6570\u4e2d\u4f7f\u7528\uff09\n\n\n\n\n\n\n\u5f53\u4f7f\u7528TensorFlow\u4e3a\u540e\u7aef\u65f6\uff1a\n\n\n\n\nTensorFlow\n\n\n\n\n\u5f53\u4f7f\u7528Theano\u4f5c\u4e3a\u540e\u7aef\u65f6\uff1a\n\n\n\n\nTheano\n\n\n\n\n\u3010Tips\u3011\u201c\u540e\u7aef\u201d\u7ffb\u8bd1\u81eabackend\uff0c\u6307\u7684\u662fKeras\u4f9d\u8d56\u4e8e\u5b8c\u6210\u5e95\u5c42\u7684\u5f20\u91cf\u8fd0\u7b97\u7684\u8f6f\u4ef6\u5305\u3002\u3010@Bigmoyan\u3011\n\n\n\u5b89\u88c5Keras\u65f6\uff0c\u8bf7\ncd\n\u5230Keras\u7684\u6587\u4ef6\u5939\u4e2d\uff0c\u5e76\u8fd0\u884c\u4e0b\u9762\u7684\u5b89\u88c5\u547d\u4ee4\uff1a\n\n\nsudo python setup.py install\n\n\n\n\n\u4f60\u4e5f\u53ef\u4ee5\u4f7f\u7528PyPI\u6765\u5b89\u88c5Keras\n\n\nsudo pip install keras\n\n\n\n\n\u8be6\u7ec6\u7684Windows\u548cLinux\u5b89\u88c5\u6559\u7a0b\u8bf7\u53c2\u8003\u201c\u5feb\u901f\u5f00\u59cb\u201d\u4e00\u8282\u4e2d\u7ed9\u51fa\u7684\u5b89\u88c5\u6559\u7a0b\uff0c\u7279\u522b\u9e23\u8c22SCP-173\u7f16\u5199\u4e86\u8fd9\u4e9b\u6559\u7a0b\n\n\n\n\n\u5728Theano\u548cTensorFlow\u95f4\u5207\u6362\n\n\nKeras\u9ed8\u8ba4\u4f7f\u7528TensorFlow\u4f5c\u4e3a\u540e\u7aef\u6765\u8fdb\u884c\u5f20\u91cf\u64cd\u4f5c\uff0c\u5982\u9700\u5207\u6362\u5230Theano\uff0c\u8bf7\u67e5\u770b\n\u8fd9\u91cc\n\n\n\n\n\u6280\u672f\u652f\u6301\n\n\n\u4f60\u53ef\u4ee5\u5728\u4e0b\u5217\u7f51\u5740\u63d0\u95ee\u6216\u52a0\u5165Keras\u5f00\u53d1\u8ba8\u8bba:\n\n\n\n\nKeras Google group\n\n\nKeras Slack channel\n,[\n\u70b9\u51fb\u8fd9\u91cc\n]\u83b7\u5f97\u9080\u8bf7.\n\n\n\n\n\u4f60\u4e5f\u53ef\u4ee5\u5728\nGithub issues\n\u91cc\u63d0\u95ee\u6216\u8bf7\u6c42\u65b0\u7279\u6027\u3002\u5728\u63d0\u95ee\u4e4b\u524d\u8bf7\u786e\u4fdd\u4f60\u9605\u8bfb\u8fc7\u6211\u4eec\u7684\n\u6307\u5bfc\n\n\n\u540c\u65f6\uff0c\u6211\u4eec\u4e5f\u6b22\u8fce\u540c\u5b66\u4eec\u52a0\u6211\u4eec\u7684QQ\u7fa4119427073\u8fdb\u884c\u8ba8\u8bba\uff08\u6f5c\u6c34\u548c\u704c\u6c34\u4f1a\u88abT\uff0c\u5165\u7fa4\u8bf4\u660e\u516c\u53f8/\u5b66\u6821-\u804c\u4f4d/\u5e74\u7ea7\uff09\n\n\n\n\n\u5c0f\u989d\u8d5e\u52a9\n\n\n\u5982\u679c\u4f60\u89c9\u5f97\u672c\u6587\u6863\u5bf9\u4f60\u7684\u7814\u7a76\u548c\u4f7f\u7528\u6709\u6240\u5e2e\u52a9\uff0c\u6b22\u8fce\u626b\u4e0b\u9762\u7684\u4e8c\u7ef4\u7801\u5bf9\u4f5c\u8005\u8fdb\u884c\u5c0f\u989d\u8d5e\u52a9\uff0c\u4ee5\u9f13\u52b1\u4f5c\u8005\u8fdb\u4e00\u6b65\u5b8c\u5584\u6587\u6863\u5185\u5bb9\uff0c\u63d0\u9ad8\u6587\u6863\u8d28\u91cf\u3002\u540c\u65f6\uff0c\u4e0d\u59a8\u4e3a\n\u672c\u6587\u6863\u7684github\n\u52a0\u9897\u661f\u54e6\n\n\n\n\n\u5982\u679c\u4f60\u89c9\u5f97\u6709\u7528\u9875\u9762\u4e0b\u6709\u5c0f\u989d\u8d5e\u52a9\u7684\u4e8c\u7ef4\u7801\u6216\u5fae\u4fe1/\u652f\u4ed8\u5b9d\u8d26\u53f7\uff0c\u8bf4\u660e\u8be5\u9875\u9762\u7531\u5176\u4ed6\u4f5c\u8005\u8d21\u732e\uff0c\u8981\u5bf9\u4ed6\u4eec\u8fdb\u884c\u5c0f\u989d\u8d5e\u52a9\u8bf7\u4f7f\u7528\u8be5\u9875\u9762\u4e0b\u7684\u4e8c\u7ef4\u7801\u6216\u8d26\u53f7", 
            "title": "\u4e3b\u9875"
        }, 
        {
            "location": "/#kerastheanotensorflow", 
            "text": "", 
            "title": "Keras:\u57fa\u4e8eTheano\u548cTensorFlow\u7684\u6df1\u5ea6\u5b66\u4e60\u5e93"
        }, 
        {
            "location": "/#keras", 
            "text": "Keras\u662f\u4e00\u4e2a\u9ad8\u5c42\u795e\u7ecf\u7f51\u7edc\u5e93\uff0cKeras\u7531\u7eafPython\u7f16\u5199\u800c\u6210\u5e76\u57faTensorflow\u6216Theano\u3002Keras\n\u4e3a\u652f\u6301\u5feb\u901f\u5b9e\u9a8c\u800c\u751f\uff0c\u80fd\u591f\u628a\u4f60\u7684idea\u8fc5\u901f\u8f6c\u6362\u4e3a\u7ed3\u679c\uff0c\u5982\u679c\u4f60\u6709\u5982\u4e0b\u9700\u6c42\uff0c\u8bf7\u9009\u62e9Keras\uff1a   \u7b80\u6613\u548c\u5feb\u901f\u7684\u539f\u578b\u8bbe\u8ba1\uff08keras\u5177\u6709\u9ad8\u5ea6\u6a21\u5757\u5316\uff0c\u6781\u7b80\uff0c\u548c\u53ef\u6269\u5145\u7279\u6027\uff09  \u652f\u6301CNN\u548cRNN\uff0c\u6216\u4e8c\u8005\u7684\u7ed3\u5408  \u652f\u6301\u4efb\u610f\u7684\u94fe\u63a5\u65b9\u6848\uff08\u5305\u62ec\u591a\u8f93\u5165\u548c\u591a\u8f93\u51fa\u8bad\u7ec3\uff09  \u65e0\u7f1dCPU\u548cGPU\u5207\u6362   Keras\u9002\u7528\u7684Python\u7248\u672c\u662f\uff1aPython 2.7-3.5  Keras\u7684\u8bbe\u8ba1\u539f\u5219\u662f    \u6a21\u5757\u6027\uff1a\u6a21\u578b\u53ef\u7406\u89e3\u4e3a\u4e00\u4e2a\u72ec\u7acb\u7684\u5e8f\u5217\u6216\u56fe\uff0c\u5b8c\u5168\u53ef\u914d\u7f6e\u7684\u6a21\u5757\u4ee5\u6700\u5c11\u7684\u4ee3\u4ef7\u81ea\u7531\u7ec4\u5408\u5728\u4e00\u8d77\u3002\u5177\u4f53\u800c\u8a00\uff0c\u7f51\u7edc\u5c42\u3001\u635f\u5931\u51fd\u6570\u3001\u4f18\u5316\u5668\u3001\u521d\u59cb\u5316\u7b56\u7565\u3001\u6fc0\u6d3b\u51fd\u6570\u3001\u6b63\u5219\u5316\u65b9\u6cd5\u90fd\u662f\u72ec\u7acb\u7684\u6a21\u5757\uff0c\u4f60\u53ef\u4ee5\u4f7f\u7528\u5b83\u4eec\u6765\u6784\u5efa\u81ea\u5df1\u7684\u6a21\u578b\u3002    \u6781\u7b80\u4e3b\u4e49\uff1a\u6bcf\u4e2a\u6a21\u5757\u90fd\u5e94\u8be5\u5c3d\u91cf\u7684\u7b80\u6d01\u3002\u6bcf\u4e00\u6bb5\u4ee3\u7801\u90fd\u5e94\u8be5\u5728\u521d\u6b21\u9605\u8bfb\u65f6\u90fd\u663e\u5f97\u76f4\u89c2\u6613\u61c2\u3002\u6ca1\u6709\u9ed1\u9b54\u6cd5\uff0c\u56e0\u4e3a\u5b83\u5c06\u7ed9\u8fed\u4ee3\u548c\u521b\u65b0\u5e26\u6765\u9ebb\u70e6\u3002    \u6613\u6269\u5c55\u6027\uff1a\u6dfb\u52a0\u65b0\u6a21\u5757\u8d85\u7ea7\u7b80\u5355\u7684\u5bb9\u6613\uff0c\u53ea\u9700\u8981\u4eff\u7167\u73b0\u6709\u7684\u6a21\u5757\u7f16\u5199\u65b0\u7684\u7c7b\u6216\u51fd\u6570\u5373\u53ef\u3002\u521b\u5efa\u65b0\u6a21\u5757\u7684\u4fbf\u5229\u6027\u4f7f\u5f97Keras\u66f4\u9002\u5408\u4e8e\u5148\u8fdb\u7684\u7814\u7a76\u5de5\u4f5c\u3002    \u4e0ePython\u534f\u4f5c\uff1aKeras\u6ca1\u6709\u5355\u72ec\u7684\u6a21\u578b\u914d\u7f6e\u6587\u4ef6\u7c7b\u578b\uff08\u4f5c\u4e3a\u5bf9\u6bd4\uff0ccaffe\u6709\uff09\uff0c\u6a21\u578b\u7531python\u4ee3\u7801\u63cf\u8ff0\uff0c\u4f7f\u5176\u66f4\u7d27\u51d1\u548c\u66f4\u6613debug\uff0c\u5e76\u63d0\u4f9b\u4e86\u6269\u5c55\u7684\u4fbf\u5229\u6027\u3002    Keras\u4ece2015\u5e743\u6708\u5f00\u59cb\u542f\u52a8\uff0c\u7ecf\u8fc7\u4e00\u5e74\u591a\u7684\u5f00\u53d1\uff0c\u76ee\u524dKeras\u8fdb\u5165\u4e861.0\u7684\u65f6\u4ee3\u3002Keras 1.0\u4f9d\u7136\u9075\u5faa\u76f8\u540c\u7684\u8bbe\u8ba1\u539f\u5219\uff0c\u4f46\u4e0e\u4e4b\u524d\u7684\u7248\u672c\u76f8\u6bd4\u6709\u5f88\u5927\u7684\u4e0d\u540c\u3002\u5982\u679c\u4f60\u66fe\u7ecf\u4f7f\u7528\u8fc7\u6b64\u524d\u7684\u5176\u4ed6\u7248\u672cKeras\u3002\u4f60\u6216\u8bb8\u4f1a\u5173\u5fc31.0\u7684\u65b0\u7279\u6027\u3002    \u6cdb\u578b\u6a21\u578b\uff1a\u7b80\u5355\u548c\u5f3a\u5927\u7684\u65b0\u6a21\u5757\uff0c\u7528\u4e8e\u652f\u6301\u590d\u6742\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7684\u642d\u5efa\u3002    \u66f4\u4f18\u79c0\u7684\u6027\u80fd\uff1a\u73b0\u5728\uff0cKeras\u6a21\u578b\u7684\u7f16\u8bd1\u65f6\u95f4\u5f97\u5230\u7f29\u77ed\u3002\u6240\u6709\u7684RNN\u73b0\u5728\u90fd\u53ef\u4ee5\u7528\u4e24\u79cd\u65b9\u5f0f\u5b9e\u73b0\uff0c\u4ee5\u4f9b\u7528\u6237\u5728\u4e0d\u540c\u914d\u7f6e\u4efb\u52a1\u548c\u914d\u7f6e\u73af\u5883\u4e0b\u53d6\u5f97\u6700\u5927\u6027\u80fd\u3002\u73b0\u5728\uff0c\u57fa\u4e8eTheano\u7684RNN\u4e5f\u53ef\u4ee5\u88ab\u5c55\u5f00\uff0c\u4ee5\u83b7\u5f97\u5927\u698225%\u7684\u52a0\u901f\u8ba1\u7b97\u3002    \u6d4b\u91cf\u6307\u6807\uff1a\u73b0\u5728\uff0c\u4f60\u53ef\u4ee5\u63d0\u4f9b\u4e00\u7cfb\u5217\u7684\u6d4b\u91cf\u6307\u6807\u6765\u5728Keras\u7684\u4efb\u4f55\u76d1\u6d4b\u70b9\u89c2\u5bdf\u6a21\u578b\u6027\u80fd\u3002    \u66f4\u4f18\u7684\u7528\u6237\u4f53\u9a8c\uff1a\u6211\u4eec\u9762\u5411\u4f7f\u7528\u8005\u91cd\u65b0\u7f16\u5199\u4e86\u4ee3\u7801\uff0c\u4f7f\u5f97\u51fd\u6570API\u66f4\u7b80\u5355\u6613\u8bb0\uff0c\u540c\u65f6\u63d0\u4f9b\u66f4\u6709\u6548\u7684\u51fa\u9519\u4fe1\u606f\u3002    \u65b0\u7248\u672c\u7684Keras\u63d0\u4f9b\u4e86Lambda\u5c42\uff0c\u4ee5\u5b9e\u73b0\u4e00\u4e9b\u7b80\u5355\u7684\u8ba1\u7b97\u4efb\u52a1\u3002    ...    \u5982\u679c\u4f60\u5df2\u7ecf\u57fa\u4e8eKeras0.3\u7f16\u5199\u4e86\u81ea\u5df1\u7684\u5c42\uff0c\u90a3\u4e48\u5728\u5347\u7ea7\u540e\uff0c\u4f60\u9700\u8981\u4e3a\u81ea\u5df1\u7684\u4ee3\u7801\u505a\u4ee5\u4e0b\u8c03\u6574\uff0c\u4ee5\u5728Keras1.0\u4e0a\u7ee7\u7eed\u8fd0\u884c\u3002\u8bf7\u53c2\u8003 \u7f16\u5199\u81ea\u5df1\u7684\u5c42", 
            "title": "\u8fd9\u5c31\u662fKeras"
        }, 
        {
            "location": "/#keras-cn", 
            "text": "\u672c\u6587\u6863\u662fKeras\u6587\u6863\u7684\u4e2d\u6587\u7248\uff0c\u5305\u62ec keras.io \u7684\u5168\u90e8\u5185\u5bb9\uff0c\u4ee5\u53ca\u66f4\u591a\u7684\u4f8b\u5b50\u3001\u89e3\u91ca\u548c\u5efa\u8bae  \u73b0\u5728\uff0ckeras-cn\u7684\u7248\u672c\u53f7\u5c06\u7b80\u5355\u7684\u8ddf\u968f\u6700\u65b0\u7684keras release\u7248\u672c  \u7531\u4e8e\u4f5c\u8005\u6c34\u5e73\u548c\u7814\u7a76\u65b9\u5411\u6240\u9650\uff0c\u65e0\u6cd5\u5bf9\u6240\u6709\u6a21\u5757\u90fd\u975e\u5e38\u7cbe\u901a\uff0c\u56e0\u6b64\u6587\u6863\u4e2d\u4e0d\u53ef\u907f\u514d\u7684\u4f1a\u51fa\u73b0\u5404\u79cd\u9519\u8bef\u3001\u758f\u6f0f\u548c\u4e0d\u8db3\u4e4b\u5904\u3002\u5982\u679c\u60a8\u5728\u4f7f\u7528\u8fc7\u7a0b\u4e2d\u6709\u4efb\u4f55\u610f\u89c1\u3001\u5efa\u8bae\u548c\u7591\u95ee\uff0c\u6b22\u8fce\u53d1\u9001\u90ae\u4ef6\u5230moyan_work@foxmail.com\u4e0e\u6211\u53d6\u5f97\u8054\u7cfb\u3002  \u60a8\u5bf9\u6587\u6863\u7684\u4efb\u4f55\u8d21\u732e\uff0c\u5305\u62ec\u6587\u6863\u7684\u7ffb\u8bd1\u3001\u67e5\u7f3a\u8865\u6f0f\u3001\u6982\u5ff5\u89e3\u91ca\u3001\u53d1\u73b0\u548c\u4fee\u6539\u95ee\u9898\u3001\u8d21\u732e\u793a\u4f8b\u7a0b\u5e8f\u7b49\uff0c\u5747\u4f1a\u88ab\u8bb0\u5f55\u5728 \u81f4\u8c22 \uff0c\u5341\u5206\u611f\u8c22\u60a8\u5bf9Keras\u4e2d\u6587\u6587\u6863\u7684\u8d21\u732e\uff01  \u540c\u65f6\uff0c\u4e5f\u6b22\u8fce\u60a8\u64b0\u6587\u5411\u672c\u6587\u6863\u6295\u7a3f\uff0c\u60a8\u7684\u7a3f\u4ef6\u88ab\u5f55\u7528\u540e\u5c06\u4ee5\u5355\u72ec\u7684\u9875\u9762\u663e\u793a\u5728\u7f51\u7ad9\u4e2d\uff0c\u60a8\u6709\u6743\u5728\u60a8\u7684\u7f51\u9875\u4e0b\u8bbe\u7f6e\u8d5e\u52a9\u4e8c\u7ef4\u7801\uff0c\u4ee5\u83b7\u53d6\u6765\u81ea\u7f51\u53cb\u7684\u5c0f\u989d\u8d5e\u52a9\u3002  \u5982\u679c\u4f60\u53d1\u73b0\u672c\u6587\u6863\u7f3a\u5931\u4e86\u5b98\u65b9\u6587\u6863\u7684\u90e8\u5206\u5185\u5bb9\uff0c\u8bf7\u79ef\u6781\u8054\u7cfb\u6211\u8865\u5145\u3002  \u672c\u6587\u6863\u76f8\u5bf9\u4e8e\u539f\u6587\u6863\u6709\u66f4\u591a\u7684\u4f7f\u7528\u6307\u5bfc\u548c\u6982\u5ff5\u6f84\u6e05\uff0c\u8bf7\u5728\u4f7f\u7528\u65f6\u5173\u6ce8\u6587\u6863\u4e2d\u7684Tips\uff0c\u7279\u522b\u7684\uff0c\u672c\u6587\u6863\u7684\u989d\u5916\u6a21\u5757\u8fd8\u6709\uff1a    \u4e00\u4e9b\u57fa\u672c\u6982\u5ff5\uff1a\u4f4d\u4e8e\u5feb\u901f\u5f00\u59cb\u6a21\u5757\u7684 \u4e00\u4e9b\u57fa\u672c\u6982\u5ff5 \u7b80\u5355\u4ecb\u7ecd\u4e86\u4f7f\u7528Keras\u524d\u9700\u8981\u77e5\u9053\u7684\u4e00\u4e9b\u5c0f\u77e5\u8bc6\uff0c\u65b0\u624b\u5728\u4f7f\u7528\u524d\u5e94\u8be5\u5148\u9605\u8bfb\u672c\u90e8\u5206\u7684\u6587\u6863\u3002    Keras\u5b89\u88c5\u548c\u914d\u7f6e\u6307\u5357\uff0c\u63d0\u4f9b\u4e86\u8be6\u7ec6\u7684Linux\u548cWindows\u4e0bKeras\u7684\u5b89\u88c5\u548c\u914d\u7f6e\u6b65\u9aa4\u3002    \u6df1\u5ea6\u5b66\u4e60\u4e0eKeras\uff1a\u4f4d\u4e8e\u5bfc\u822a\u680f\u6700\u4e0b\u65b9\u7684\u8be5\u6a21\u5757\u7ffb\u8bd1\u4e86\u6765\u81eaKeras\u4f5c\u8005\u535a\u5ba2 keras.io \u548c\u5176\u4ed6Keras\u76f8\u5173\u535a\u5ba2\u7684\u6587\u7ae0\uff0c\u8be5\u680f\u76ee\u7684\u6587\u7ae0\u63d0\u4f9b\u4e86\u5bf9\u6df1\u5ea6\u5b66\u4e60\u7684\u7406\u89e3\u548c\u5927\u91cf\u4f7f\u7528Keras\u7684\u4f8b\u5b50\uff0c\u60a8\u4e5f\u53ef\u4ee5\u5411\u8fd9\u4e2a\u680f\u76ee\u6295\u7a3f\u3002\n\u6240\u6709\u7684\u6587\u7ae0\u5747\u5728\u9192\u76ee\u4f4d\u7f6e\u6807\u5fd7\u6807\u660e\u6765\u6e90\u4e0e\u4f5c\u8005\uff0c\u672c\u6587\u6863\u5bf9\u8be5\u680f\u76ee\u6587\u7ae0\u7684\u539f\u6587\u4e0d\u5177\u6709\u4efb\u4f55\u5904\u7f6e\u6743\u3002\u5982\u60a8\u4ecd\u89c9\u4e0d\u59a5\uff0c\u8bf7\u8054\u7cfb\u672c\u4eba\uff08moyan_work@foxmail.com\uff09\u5220\u9664\u3002", 
            "title": "\u5173\u4e8eKeras-cn"
        }, 
        {
            "location": "/#_1", 
            "text": "\u5982\u679c\u4f60\u53d1\u73b0\u672c\u6587\u6863\u63d0\u4f9b\u7684\u4fe1\u606f\u6709\u8bef\uff0c\u6709\u4e24\u79cd\u53ef\u80fd\uff1a    \u4f60\u7684Keras\u7248\u672c\u8fc7\u4f4e\uff1a\u8bb0\u4f4fKeras\u662f\u4e00\u4e2a\u53d1\u5c55\u8fc5\u901f\u7684\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u8bf7\u4fdd\u6301\u4f60\u7684Keras\u4e0e\u5b98\u65b9\u6700\u65b0\u7684release\u7248\u672c\u76f8\u7b26    \u6211\u4eec\u7684\u4e2d\u6587\u6587\u6863\u6ca1\u6709\u53ca\u65f6\u66f4\u65b0\uff1a\u5982\u679c\u662f\u8fd9\u79cd\u60c5\u51b5\uff0c\u8bf7\u53d1\u90ae\u4ef6\u7ed9\u6211\uff0c\u6211\u4f1a\u5c3d\u5feb\u66f4\u65b0    \u76ee\u524d\u6587\u6863\u7684\u7248\u672c\u53f7\u662f1.2.1\uff0c\u5bf9\u5e94\u4e8e\u5b98\u65b9\u76841.2.1 release \u7248\u672c, \u672c\u6b21\u66f4\u65b0\u7684\u4e3b\u8981\u5185\u5bb9\u662f\uff1a   \u4e3aApplication\u4e2d\u7684\u56fe\u7247\u5206\u7c7b\u6a21\u578b\u589e\u52a0\u4e86 classes \u548c input_shape \uff0c\u4f46 classes \u7684\u8bf4\u660e\u5728\u539f\u6587\u6863\u4e2d\u7f3a\u5931  \u6682\u65f6\u79fb\u9664\u4e86SpatialDropout1D,SpatialDropout2D,SpatialDropout3D\u7684\u6587\u6863\uff0c\u4f46\u5b83\u4eec\u7684\u6e90\u4ee3\u7801\u4ecd\u7136\u4fdd\u7559\u5728\u4e2akeras\u4e2d\uff0c\u4f60\u4ecd\u7136\u53ef\u4ee5\u7528\u8fd9\u4e9blayer  1.2.0\u548c\u5f53\u524d\u7248\u672c\u5747\u53ef\u4f7f\u7528ConvLSTM2D\u5c42\uff0c\u8fd9\u4e2a\u5c42\u5728\u4ee3\u7801\u4e2d\u6709\u8bf4\u660e\u4f46\u6ca1\u6709\u4f53\u73b0\u5728\u6587\u6863\u4e2d\uff0c\u6211\u4eec\u6682\u65f6\u4e5f\u4e0d\u63d0\u4f9b\u8fd9\u4e2a\u5c42\u7684\u8bf4\u660e\uff0c\u5982\u9700\u4f7f\u7528\u8bf7\u67e5\u770b\u6e90\u4ee3\u7801\u4e2d\u7684\u8bf4\u660e  \u589e\u52a0\u4e86AC-GAN\u7684\u4f8b\u5b50   \u6ce8\u610f\uff0ckeras\u5728github\u4e0a\u7684master\u5f80\u5f80\u8981\u9ad8\u4e8e\u5f53\u524d\u7684release\u7248\u672c\uff0c\u5982\u679c\u4f60\u4ece\u6e90\u7801\u7f16\u8bd1keras\uff0c\u53ef\u80fd\u67d0\u4e9b\u6a21\u5757\u4e0e\u6587\u6863\u8bf4\u660e\u4e0d\u76f8\u7b26\uff0c\u8bf7\u4ee5\u5b98\u65b9Github\u4ee3\u7801\u4e3a\u51c6", 
            "title": "\u5f53\u524d\u7248\u672c\u4e0e\u66f4\u65b0"
        }, 
        {
            "location": "/#30skeras", 
            "text": "Keras\u7684\u6838\u5fc3\u6570\u636e\u7ed3\u6784\u662f\u201c\u6a21\u578b\u201d\uff0c\u6a21\u578b\u662f\u4e00\u79cd\u7ec4\u7ec7\u7f51\u7edc\u5c42\u7684\u65b9\u5f0f\u3002Keras\u4e2d\u4e3b\u8981\u7684\u6a21\u578b\u662fSequential\u6a21\u578b\uff0cSequential\u662f\u4e00\u7cfb\u5217\u7f51\u7edc\u5c42\u6309\u987a\u5e8f\u6784\u6210\u7684\u6808\u3002\u4f60\u4e5f\u53ef\u4ee5\u67e5\u770b \u6cdb\u578b\u6a21\u578b \u6765\u5b66\u4e60\u5efa\u7acb\u66f4\u590d\u6742\u7684\u6a21\u578b  Sequential\u6a21\u578b\u5982\u4e0b  from keras.models import Sequential\n\nmodel = Sequential()  \u5c06\u4e00\u4e9b\u7f51\u7edc\u5c42\u901a\u8fc7 .add() \u5806\u53e0\u8d77\u6765\uff0c\u5c31\u6784\u6210\u4e86\u4e00\u4e2a\u6a21\u578b\uff1a  from keras.layers import Dense, Activation\n\nmodel.add(Dense(output_dim=64, input_dim=100))\nmodel.add(Activation( relu ))\nmodel.add(Dense(output_dim=10))\nmodel.add(Activation( softmax ))  \u5b8c\u6210\u6a21\u578b\u7684\u642d\u5efa\u540e\uff0c\u6211\u4eec\u9700\u8981\u4f7f\u7528 .compile() \u65b9\u6cd5\u6765\u7f16\u8bd1\u6a21\u578b\uff1a  model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])  \u7f16\u8bd1\u6a21\u578b\u65f6\u5fc5\u987b\u6307\u660e\u635f\u5931\u51fd\u6570\u548c\u4f18\u5316\u5668\uff0c\u5982\u679c\u4f60\u9700\u8981\u7684\u8bdd\uff0c\u4e5f\u53ef\u4ee5\u81ea\u5df1\u5b9a\u5236\u635f\u5931\u51fd\u6570\u3002Keras\u7684\u4e00\u4e2a\u6838\u5fc3\u7406\u5ff5\u5c31\u662f\u7b80\u660e\u6613\u7528\u540c\u65f6\uff0c\u4fdd\u8bc1\u7528\u6237\u5bf9Keras\u7684\u7edd\u5bf9\u63a7\u5236\u529b\u5ea6\uff0c\u7528\u6237\u53ef\u4ee5\u6839\u636e\u81ea\u5df1\u7684\u9700\u8981\u5b9a\u5236\u81ea\u5df1\u7684\u6a21\u578b\u3001\u7f51\u7edc\u5c42\uff0c\u751a\u81f3\u4fee\u6539\u6e90\u4ee3\u7801\u3002  from keras.optimizers import SGD\nmodel.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.01, momentum=0.9, nesterov=True))  \u5b8c\u6210\u6a21\u578b\u7f16\u8bd1\u540e\uff0c\u6211\u4eec\u5728\u8bad\u7ec3\u6570\u636e\u4e0a\u6309batch\u8fdb\u884c\u4e00\u5b9a\u6b21\u6570\u7684\u8fed\u4ee3\u8bad\u7ec3\uff0c\u4ee5\u62df\u5408\u7f51\u7edc\uff0c\u5173\u4e8e\u4e3a\u4ec0\u4e48\u8981\u4f7f\u7528\u2018batch\u2019\uff0c\u8bf7\u53c2\u8003 \u4e00\u4e9b\u57fa\u672c\u6982\u5ff5  model.fit(X_train, Y_train, nb_epoch=5, batch_size=32)  \u5f53\u7136\uff0c\u6211\u4eec\u4e5f\u53ef\u4ee5\u624b\u52a8\u5c06\u4e00\u4e2a\u4e2abatch\u7684\u6570\u636e\u9001\u5165\u7f51\u7edc\u4e2d\u8bad\u7ec3\uff0c\u8fd9\u65f6\u5019\u9700\u8981\u4f7f\u7528\uff1a  model.train_on_batch(X_batch, Y_batch)  \u968f\u540e\uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u4e00\u884c\u4ee3\u7801\u5bf9\u6211\u4eec\u7684\u6a21\u578b\u8fdb\u884c\u8bc4\u4f30\uff0c\u770b\u770b\u6a21\u578b\u7684\u6307\u6807\u662f\u5426\u6ee1\u8db3\u6211\u4eec\u7684\u8981\u6c42\uff1a  loss_and_metrics = model.evaluate(X_test, Y_test, batch_size=32)  \u6216\u8005\uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u6211\u4eec\u7684\u6a21\u578b\uff0c\u5bf9\u65b0\u7684\u6570\u636e\u8fdb\u884c\u9884\u6d4b\uff1a  classes = model.predict_classes(X_test, batch_size=32)\nproba = model.predict_proba(X_test, batch_size=32)  \u642d\u5efa\u4e00\u4e2a\u95ee\u7b54\u7cfb\u7edf\u3001\u56fe\u50cf\u5206\u7c7b\u6a21\u578b\uff0c\u6216\u795e\u7ecf\u56fe\u7075\u673a\u3001word2vec\u8bcd\u5d4c\u5165\u5668\u5c31\u662f\u8fd9\u4e48\u5feb\u3002\u652f\u6491\u6df1\u5ea6\u5b66\u4e60\u7684\u57fa\u672c\u60f3\u6cd5\u672c\u5c31\u662f\u7b80\u5355\u7684\uff0c\u73b0\u5728\u8ba9\u6211\u4eec\u628a\u5b83\u7684\u5b9e\u73b0\u4e5f\u53d8\u7684\u7b80\u5355\u8d77\u6765\uff01  \u4e3a\u4e86\u66f4\u6df1\u5165\u7684\u4e86\u89e3Keras\uff0c\u6211\u4eec\u5efa\u8bae\u4f60\u67e5\u770b\u4e00\u4e0b\u4e0b\u9762\u7684\u4e24\u4e2atutorial   \u5feb\u901f\u5f00\u59cbSequntial\u6a21\u578b  \u5feb\u901f\u5f00\u59cb\u6cdb\u578b\u6a21\u578b   \u8fd8\u6709\u6211\u4eec\u5bf9\u4e00\u4e9b\u6982\u5ff5\u7684\u89e3\u91ca   \u4e00\u4e9b\u57fa\u672c\u6982\u5ff5   \u5728Keras\u4ee3\u7801\u5305\u7684examples\u6587\u4ef6\u5939\u91cc\uff0c\u6211\u4eec\u63d0\u4f9b\u4e86\u4e00\u4e9b\u66f4\u9ad8\u7ea7\u7684\u6a21\u578b\uff1a\u57fa\u4e8e\u8bb0\u5fc6\u7f51\u7edc\u7684\u95ee\u7b54\u7cfb\u7edf\u3001\u57fa\u4e8eLSTM\u7684\u6587\u672c\u7684\u6587\u672c\u751f\u6210\u7b49\u3002", 
            "title": "\u5feb\u901f\u5f00\u59cb\uff1a30s\u4e0a\u624bKeras"
        }, 
        {
            "location": "/#_2", 
            "text": "Keras\u4f7f\u7528\u4e86\u4e0b\u9762\u7684\u4f9d\u8d56\u5305\uff1a    numpy\uff0cscipy    pyyaml    HDF5, h5py\uff08\u53ef\u9009\uff0c\u4ec5\u5728\u6a21\u578b\u7684save/load\u51fd\u6570\u4e2d\u4f7f\u7528\uff09    \u5f53\u4f7f\u7528TensorFlow\u4e3a\u540e\u7aef\u65f6\uff1a   TensorFlow   \u5f53\u4f7f\u7528Theano\u4f5c\u4e3a\u540e\u7aef\u65f6\uff1a   Theano   \u3010Tips\u3011\u201c\u540e\u7aef\u201d\u7ffb\u8bd1\u81eabackend\uff0c\u6307\u7684\u662fKeras\u4f9d\u8d56\u4e8e\u5b8c\u6210\u5e95\u5c42\u7684\u5f20\u91cf\u8fd0\u7b97\u7684\u8f6f\u4ef6\u5305\u3002\u3010@Bigmoyan\u3011  \u5b89\u88c5Keras\u65f6\uff0c\u8bf7 cd \u5230Keras\u7684\u6587\u4ef6\u5939\u4e2d\uff0c\u5e76\u8fd0\u884c\u4e0b\u9762\u7684\u5b89\u88c5\u547d\u4ee4\uff1a  sudo python setup.py install  \u4f60\u4e5f\u53ef\u4ee5\u4f7f\u7528PyPI\u6765\u5b89\u88c5Keras  sudo pip install keras  \u8be6\u7ec6\u7684Windows\u548cLinux\u5b89\u88c5\u6559\u7a0b\u8bf7\u53c2\u8003\u201c\u5feb\u901f\u5f00\u59cb\u201d\u4e00\u8282\u4e2d\u7ed9\u51fa\u7684\u5b89\u88c5\u6559\u7a0b\uff0c\u7279\u522b\u9e23\u8c22SCP-173\u7f16\u5199\u4e86\u8fd9\u4e9b\u6559\u7a0b", 
            "title": "\u5b89\u88c5"
        }, 
        {
            "location": "/#theanotensorflow", 
            "text": "Keras\u9ed8\u8ba4\u4f7f\u7528TensorFlow\u4f5c\u4e3a\u540e\u7aef\u6765\u8fdb\u884c\u5f20\u91cf\u64cd\u4f5c\uff0c\u5982\u9700\u5207\u6362\u5230Theano\uff0c\u8bf7\u67e5\u770b \u8fd9\u91cc", 
            "title": "\u5728Theano\u548cTensorFlow\u95f4\u5207\u6362"
        }, 
        {
            "location": "/#_3", 
            "text": "\u4f60\u53ef\u4ee5\u5728\u4e0b\u5217\u7f51\u5740\u63d0\u95ee\u6216\u52a0\u5165Keras\u5f00\u53d1\u8ba8\u8bba:   Keras Google group  Keras Slack channel ,[ \u70b9\u51fb\u8fd9\u91cc ]\u83b7\u5f97\u9080\u8bf7.   \u4f60\u4e5f\u53ef\u4ee5\u5728 Github issues \u91cc\u63d0\u95ee\u6216\u8bf7\u6c42\u65b0\u7279\u6027\u3002\u5728\u63d0\u95ee\u4e4b\u524d\u8bf7\u786e\u4fdd\u4f60\u9605\u8bfb\u8fc7\u6211\u4eec\u7684 \u6307\u5bfc  \u540c\u65f6\uff0c\u6211\u4eec\u4e5f\u6b22\u8fce\u540c\u5b66\u4eec\u52a0\u6211\u4eec\u7684QQ\u7fa4119427073\u8fdb\u884c\u8ba8\u8bba\uff08\u6f5c\u6c34\u548c\u704c\u6c34\u4f1a\u88abT\uff0c\u5165\u7fa4\u8bf4\u660e\u516c\u53f8/\u5b66\u6821-\u804c\u4f4d/\u5e74\u7ea7\uff09", 
            "title": "\u6280\u672f\u652f\u6301"
        }, 
        {
            "location": "/#_4", 
            "text": "\u5982\u679c\u4f60\u89c9\u5f97\u672c\u6587\u6863\u5bf9\u4f60\u7684\u7814\u7a76\u548c\u4f7f\u7528\u6709\u6240\u5e2e\u52a9\uff0c\u6b22\u8fce\u626b\u4e0b\u9762\u7684\u4e8c\u7ef4\u7801\u5bf9\u4f5c\u8005\u8fdb\u884c\u5c0f\u989d\u8d5e\u52a9\uff0c\u4ee5\u9f13\u52b1\u4f5c\u8005\u8fdb\u4e00\u6b65\u5b8c\u5584\u6587\u6863\u5185\u5bb9\uff0c\u63d0\u9ad8\u6587\u6863\u8d28\u91cf\u3002\u540c\u65f6\uff0c\u4e0d\u59a8\u4e3a \u672c\u6587\u6863\u7684github \u52a0\u9897\u661f\u54e6   \u5982\u679c\u4f60\u89c9\u5f97\u6709\u7528\u9875\u9762\u4e0b\u6709\u5c0f\u989d\u8d5e\u52a9\u7684\u4e8c\u7ef4\u7801\u6216\u5fae\u4fe1/\u652f\u4ed8\u5b9d\u8d26\u53f7\uff0c\u8bf4\u660e\u8be5\u9875\u9762\u7531\u5176\u4ed6\u4f5c\u8005\u8d21\u732e\uff0c\u8981\u5bf9\u4ed6\u4eec\u8fdb\u884c\u5c0f\u989d\u8d5e\u52a9\u8bf7\u4f7f\u7528\u8be5\u9875\u9762\u4e0b\u7684\u4e8c\u7ef4\u7801\u6216\u8d26\u53f7", 
            "title": "\u5c0f\u989d\u8d5e\u52a9"
        }, 
        {
            "location": "/getting_started/concepts/", 
            "text": "\u4e00\u4e9b\u57fa\u672c\u6982\u5ff5\n\n\n\u5728\u5f00\u59cb\u5b66\u4e60Keras\u4e4b\u524d\uff0c\u6211\u4eec\u5e0c\u671b\u4f20\u9012\u4e00\u4e9b\u5173\u4e8eKeras\uff0c\u5173\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u57fa\u672c\u6982\u5ff5\u548c\u6280\u672f\uff0c\u6211\u4eec\u5efa\u8bae\u65b0\u624b\u5728\u4f7f\u7528Keras\u4e4b\u524d\u6d4f\u89c8\u4e00\u4e0b\u672c\u9875\u9762\u63d0\u5230\u7684\u5185\u5bb9\uff0c\u8fd9\u5c06\u51cf\u5c11\u4f60\u5b66\u4e60\u4e2d\u7684\u56f0\u60d1\n\n\n\u7b26\u53f7\u8ba1\u7b97\n\n\nKeras\u7684\u5e95\u5c42\u5e93\u4f7f\u7528Theano\u6216TensorFlow\uff0c\u8fd9\u4e24\u4e2a\u5e93\u4e5f\u79f0\u4e3aKeras\u7684\u540e\u7aef\u3002\u65e0\u8bba\u662fTheano\u8fd8\u662fTensorFlow\uff0c\u90fd\u662f\u4e00\u4e2a\u201c\u7b26\u53f7\u4e3b\u4e49\u201d\u7684\u5e93\u3002\n\n\n\u56e0\u6b64\uff0c\u8fd9\u4e5f\u4f7f\u5f97Keras\u7684\u7f16\u7a0b\u4e0e\u4f20\u7edf\u7684Python\u4ee3\u7801\u6709\u6240\u5dee\u522b\u3002\u7b3c\u7edf\u7684\u8bf4\uff0c\u7b26\u53f7\u4e3b\u4e49\u7684\u8ba1\u7b97\u9996\u5148\u5b9a\u4e49\u5404\u79cd\u53d8\u91cf\uff0c\u7136\u540e\u5efa\u7acb\u4e00\u4e2a\u201c\u8ba1\u7b97\u56fe\u201d\uff0c\u8ba1\u7b97\u56fe\u89c4\u5b9a\u4e86\u5404\u4e2a\u53d8\u91cf\u4e4b\u95f4\u7684\u8ba1\u7b97\u5173\u7cfb\u3002\u5efa\u7acb\u597d\u7684\u8ba1\u7b97\u56fe\u9700\u8981\u7f16\u8bd1\u5df2\u786e\u5b9a\u5176\u5185\u90e8\u7ec6\u8282\uff0c\u7136\u800c\uff0c\u6b64\u65f6\u7684\u8ba1\u7b97\u56fe\u8fd8\u662f\u4e00\u4e2a\u201c\u7a7a\u58f3\u5b50\u201d\uff0c\u91cc\u9762\u6ca1\u6709\u4efb\u4f55\u5b9e\u9645\u7684\u6570\u636e\uff0c\u53ea\u6709\u5f53\u4f60\u628a\u9700\u8981\u8fd0\u7b97\u7684\u8f93\u5165\u653e\u8fdb\u53bb\u540e\uff0c\u624d\u80fd\u5728\u6574\u4e2a\u6a21\u578b\u4e2d\u5f62\u6210\u6570\u636e\u6d41\uff0c\u4ece\u800c\u5f62\u6210\u8f93\u51fa\u503c\u3002\n\n\nKeras\u7684\u6a21\u578b\u642d\u5efa\u5f62\u5f0f\u5c31\u662f\u8fd9\u79cd\u65b9\u6cd5\uff0c\u5728\u4f60\u642d\u5efaKeras\u6a21\u578b\u5b8c\u6bd5\u540e\uff0c\u4f60\u7684\u6a21\u578b\u5c31\u662f\u4e00\u4e2a\u7a7a\u58f3\u5b50\uff0c\u53ea\u6709\u5b9e\u9645\u751f\u6210\u53ef\u8c03\u7528\u7684\u51fd\u6570\u540e\uff08K.function\uff09\uff0c\u8f93\u5165\u6570\u636e\uff0c\u624d\u4f1a\u5f62\u6210\u771f\u6b63\u7684\u6570\u636e\u6d41\u3002\n\n\n\u4f7f\u7528\u8ba1\u7b97\u56fe\u7684\u8bed\u8a00\uff0c\u5982Theano\uff0c\u4ee5\u96be\u4ee5\u8c03\u8bd5\u800c\u95fb\u540d\uff0c\u5f53Keras\u7684Debug\u8fdb\u5165Theano\u8fd9\u4e2a\u5c42\u6b21\u65f6\uff0c\u5f80\u5f80\u4e5f\u4ee4\u4eba\u5934\u75db\u3002\u6ca1\u6709\u7ecf\u9a8c\u7684\u5f00\u53d1\u8005\u5f88\u96be\u76f4\u89c2\u7684\u611f\u53d7\u5230\u8ba1\u7b97\u56fe\u5230\u5e95\u5728\u5e72\u4e9b\u4ec0\u4e48\u3002\u5c3d\u7ba1\u5f88\u8ba9\u4eba\u5934\u75db\uff0c\u4f46\u5927\u591a\u6570\u7684\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u4f7f\u7528\u7684\u90fd\u662f\u7b26\u53f7\u8ba1\u7b97\u8fd9\u4e00\u5957\u65b9\u6cd5\uff0c\u56e0\u4e3a\u7b26\u53f7\u8ba1\u7b97\u80fd\u591f\u63d0\u4f9b\u5173\u952e\u7684\u8ba1\u7b97\u4f18\u5316\u3001\u81ea\u52a8\u6c42\u5bfc\u7b49\u529f\u80fd\u3002\n\n\n\u6211\u4eec\u5efa\u8bae\u4f60\u5728\u4f7f\u7528\u524d\u7a0d\u5fae\u4e86\u89e3\u4e00\u4e0bTheano\u6216TensorFlow\uff0cBing/Google\u4e00\u4e0b\u5373\u53ef\uff0c\u5982\u679c\u6211\u4eec\u8981\u53cdbaidu\uff0c\u90a3\u5c31\u4ece\u62d2\u7edd\u4f7f\u7528baidu\u5f00\u59cb\uff0c\u5149\u6482\u5634\u70ae\u662f\u6ca1\u6709\u7528\u7684\u3002\n\n\n\u5f20\u91cf\n\n\n\u5f20\u91cf\uff0c\u6216tensor\uff0c\u662f\u672c\u6587\u6863\u4f1a\u7ecf\u5e38\u51fa\u73b0\u7684\u4e00\u4e2a\u8bcd\u6c47\uff0c\u5728\u6b64\u7a0d\u4f5c\u89e3\u91ca\u3002\n\n\n\u4f7f\u7528\u8fd9\u4e2a\u8bcd\u6c47\u7684\u76ee\u7684\u662f\u4e3a\u4e86\u8868\u8ff0\u7edf\u4e00\uff0c\u5f20\u91cf\u53ef\u4ee5\u770b\u4f5c\u662f\u5411\u91cf\u3001\u77e9\u9635\u7684\u81ea\u7136\u63a8\u5e7f\uff0c\u6211\u4eec\u7528\u5f20\u91cf\u6765\u8868\u793a\u5e7f\u6cdb\u7684\u6570\u636e\u7c7b\u578b\u3002\n\n\n\u89c4\u6a21\u6700\u5c0f\u7684\u5f20\u91cf\u662f0\u9636\u5f20\u91cf\uff0c\u5373\u6807\u91cf\uff0c\u4e5f\u5c31\u662f\u4e00\u4e2a\u6570\u3002\n\n\n\u5f53\u6211\u4eec\u628a\u4e00\u4e9b\u6570\u6709\u5e8f\u7684\u6392\u5217\u8d77\u6765\uff0c\u5c31\u5f62\u6210\u4e861\u9636\u5f20\u91cf\uff0c\u4e5f\u5c31\u662f\u4e00\u4e2a\u5411\u91cf\n\n\n\u5982\u679c\u6211\u4eec\u7ee7\u7eed\u628a\u4e00\u7ec4\u5411\u91cf\u6709\u5e8f\u7684\u6392\u5217\u8d77\u6765\uff0c\u5c31\u5f62\u6210\u4e862\u9636\u5f20\u91cf\uff0c\u4e5f\u5c31\u662f\u4e00\u4e2a\u77e9\u9635\n\n\n\u628a\u77e9\u9635\u645e\u8d77\u6765\uff0c\u5c31\u662f3\u9636\u5f20\u91cf\uff0c\u6211\u4eec\u53ef\u4ee5\u79f0\u4e3a\u4e00\u4e2a\u7acb\u65b9\u4f53\uff0c\u5177\u67093\u4e2a\u989c\u8272\u901a\u9053\u7684\u5f69\u8272\u56fe\u7247\u5c31\u662f\u4e00\u4e2a\u8fd9\u6837\u7684\u7acb\u65b9\u4f53\n\n\n\u628a\u77e9\u9635\u645e\u8d77\u6765\uff0c\u597d\u5427\u8fd9\u6b21\u6211\u4eec\u771f\u7684\u6ca1\u6709\u7ed9\u5b83\u8d77\u522b\u540d\u4e86\uff0c\u5c31\u53eb4\u9636\u5f20\u91cf\u4e86\uff0c\u4e0d\u8981\u53bb\u8bd5\u56fe\u60f3\u50cf4\u9636\u5f20\u91cf\u662f\u4ec0\u4e48\u6837\u5b50\uff0c\u5b83\u5c31\u662f\u4e2a\u6570\u5b66\u4e0a\u7684\u6982\u5ff5\u3002\n\n\n\u5f20\u91cf\u7684\u9636\u6570\u6709\u65f6\u5019\u4e5f\u79f0\u4e3a\u7ef4\u5ea6\uff0c\u6216\u8005\u8f74\uff0c\u8f74\u8fd9\u4e2a\u8bcd\u7ffb\u8bd1\u81ea\u82f1\u6587axis\u3002\u8b6c\u5982\u4e00\u4e2a\u77e9\u9635[[1,2],[3,4]]\uff0c\u662f\u4e00\u4e2a2\u9636\u5f20\u91cf\uff0c\u6709\u4e24\u4e2a\u7ef4\u5ea6\u6216\u8f74\uff0c\u6cbf\u7740\u7b2c0\u4e2a\u8f74\uff08\u4e3a\u4e86\u4e0epython\u7684\u8ba1\u6570\u65b9\u5f0f\u4e00\u81f4\uff0c\u672c\u6587\u6863\u7ef4\u5ea6\u548c\u8f74\u4ece0\u7b97\u8d77\uff09\u4f60\u770b\u5230\u7684\u662f[1,2]\uff0c[3,4]\u4e24\u4e2a\u5411\u91cf\uff0c\u6cbf\u7740\u7b2c1\u4e2a\u8f74\u4f60\u770b\u5230\u7684\u662f[1,3]\uff0c[2,4]\u4e24\u4e2a\u5411\u91cf\u3002\n\n\n\u8981\u7406\u89e3\u201c\u6cbf\u7740\u67d0\u4e2a\u8f74\u201d\u662f\u4ec0\u4e48\u610f\u601d\uff0c\u4e0d\u59a8\u8bd5\u7740\u8fd0\u884c\u4e00\u4e0b\u4e0b\u9762\u7684\u4ee3\u7801\uff1a\n\n\nimport numpy as np\n\na = np.array([[1,2],[3,4]])\nsum0 = np.sum(a, axis=0)\nsum1 = np.sum(a, axis=1)\n\nprint sum0\nprint sum1\n\n\n\n\n\u5173\u4e8e\u5f20\u91cf\uff0c\u76ee\u524d\u77e5\u9053\u8fd9\u4e48\u591a\u5c31\u8db3\u591f\u4e86\u3002\u4e8b\u5b9e\u4e0a\u6211\u4e5f\u5c31\u77e5\u9053\u8fd9\u4e48\u591a\n\n\n'th'\u4e0e'tf'\n\n\n\u8fd9\u662f\u4e00\u4e2a\u65e0\u53ef\u5948\u4f55\u7684\u95ee\u9898\uff0c\u5728\u5982\u4f55\u8868\u793a\u4e00\u7ec4\u5f69\u8272\u56fe\u7247\u7684\u95ee\u9898\u4e0a\uff0cTheano\u548cTensorFlow\u53d1\u751f\u4e86\u5206\u6b67\uff0c'th'\u6a21\u5f0f\uff0c\u4e5f\u5373Theano\u6a21\u5f0f\u4f1a\u628a100\u5f20RGB\u4e09\u901a\u9053\u768416\u00d732\uff08\u9ad8\u4e3a16\u5bbd\u4e3a32\uff09\u5f69\u8272\u56fe\u8868\u793a\u4e3a\u4e0b\u9762\u8fd9\u79cd\u5f62\u5f0f\uff08100,3,16,32\uff09\uff0cCaffe\u91c7\u53d6\u7684\u4e5f\u662f\u8fd9\u79cd\u65b9\u5f0f\u3002\u7b2c0\u4e2a\u7ef4\u5ea6\u662f\u6837\u672c\u7ef4\uff0c\u4ee3\u8868\u6837\u672c\u7684\u6570\u76ee\uff0c\u7b2c1\u4e2a\u7ef4\u5ea6\u662f\u901a\u9053\u7ef4\uff0c\u4ee3\u8868\u989c\u8272\u901a\u9053\u6570\u3002\u540e\u9762\u4e24\u4e2a\u5c31\u662f\u9ad8\u548c\u5bbd\u4e86\u3002\n\n\n\u800cTensorFlow\uff0c\u5373'tf'\u6a21\u5f0f\u7684\u8868\u8fbe\u5f62\u5f0f\u662f\uff08100,16,32,3\uff09\uff0c\u5373\u628a\u901a\u9053\u7ef4\u653e\u5728\u4e86\u6700\u540e\u3002\u8fd9\u4e24\u4e2a\u8868\u8fbe\u65b9\u6cd5\u672c\u8d28\u4e0a\u6ca1\u6709\u4ec0\u4e48\u533a\u522b\u3002\n\n\nKeras\u9ed8\u8ba4\u7684\u6570\u636e\u7ec4\u7ec7\u5f62\u5f0f\u5728~/.keras/keras.json\u4e2d\u89c4\u5b9a\uff0c\u53ef\u67e5\u770b\u8be5\u6587\u4ef6\u7684\nimage_dim_ordering\n\u4e00\u9879\u67e5\u770b\uff0c\u4e5f\u53ef\u5728\u4ee3\u7801\u4e2d\u901a\u8fc7K.image_dim_ordering()\u51fd\u6570\u8fd4\u56de\uff0c\u8bf7\u5728\u7f51\u7edc\u7684\u8bad\u7ec3\u548c\u6d4b\u8bd5\u4e2d\u4fdd\u6301\u7ef4\u5ea6\u987a\u5e8f\u4e00\u81f4\u3002\n\n\n\u5509\uff0c\u771f\u662f\u86cb\u75bc\uff0c\u4f60\u4eec\u5546\u91cf\u597d\u4e0d\u884c\u5417\uff1f\n\n\n\n\n\n\n\u6cdb\u578b\u6a21\u578b\n\n\n\n\n\n\n\u6cdb\u578b\u6a21\u578b\u7b97\u662f\u672c\u6587\u6863\u6bd4\u8f83\u539f\u521b\u7684\u8bcd\u6c47\u4e86\uff0c\u6240\u4ee5\u8fd9\u91cc\u8981\u8bf4\u4e00\u4e0b\n\n\n\u5728\u539f\u672c\u7684Keras\u7248\u672c\u4e2d\uff0c\u6a21\u578b\u5176\u5b9e\u6709\u4e24\u79cd\uff0c\u4e00\u79cd\u53ebSequential\uff0c\u79f0\u4e3a\u5e8f\u8d2f\u6a21\u578b\uff0c\u4e5f\u5c31\u662f\u5355\u8f93\u5165\u5355\u8f93\u51fa\uff0c\u4e00\u6761\u8def\u901a\u5230\u5e95\uff0c\u5c42\u4e0e\u5c42\u4e4b\u95f4\u53ea\u6709\u76f8\u90bb\u5173\u7cfb\uff0c\u8de8\u5c42\u8fde\u63a5\u7edf\u7edf\u6ca1\u6709\u3002\u8fd9\u79cd\u6a21\u578b\u7f16\u8bd1\u901f\u5ea6\u5feb\uff0c\u64cd\u4f5c\u4e0a\u4e5f\u6bd4\u8f83\u7b80\u5355\u3002\u7b2c\u4e8c\u79cd\u6a21\u578b\u79f0\u4e3aGraph\uff0c\u5373\u56fe\u6a21\u578b\uff0c\u8fd9\u4e2a\u6a21\u578b\u652f\u6301\u591a\u8f93\u5165\u591a\u8f93\u51fa\uff0c\u5c42\u4e0e\u5c42\u4e4b\u95f4\u60f3\u600e\u4e48\u8fde\u600e\u4e48\u8fde\uff0c\u4f46\u662f\u7f16\u8bd1\u901f\u5ea6\u6162\u3002\u53ef\u4ee5\u770b\u5230\uff0cSequential\u5176\u5b9e\u662fGraph\u7684\u4e00\u4e2a\u7279\u6b8a\u60c5\u51b5\u3002\n\n\n\u5728\u73b0\u5728\u8fd9\u7248Keras\u4e2d\uff0c\u56fe\u6a21\u578b\u88ab\u79fb\u9664\uff0c\u800c\u589e\u52a0\u4e86\u4e86\u201cfunctional model API\u201d\uff0c\u8fd9\u4e2a\u4e1c\u897f\uff0c\u66f4\u52a0\u5f3a\u8c03\u4e86Sequential\u662f\u7279\u6b8a\u60c5\u51b5\u8fd9\u4e00\u70b9\u3002\u4e00\u822c\u7684\u6a21\u578b\u5c31\u79f0\u4e3aModel\uff0c\u7136\u540e\u5982\u679c\u4f60\u8981\u7528\u7b80\u5355\u7684Sequential\uff0cOK\uff0c\u90a3\u8fd8\u6709\u4e00\u4e2a\u5feb\u6377\u65b9\u5f0fSequential\u3002\n\n\n\u7531\u4e8efunctional model API\u8868\u8fbe\u7684\u662f\u201c\u4e00\u822c\u7684\u6a21\u578b\u201d\u8fd9\u4e2a\u6982\u5ff5\uff0c\u6211\u4eec\u8fd9\u91cc\u5c06\u5176\u8bd1\u4e3a\u6cdb\u578b\u6a21\u578b\uff0c\u5373\u53ea\u8981\u8fd9\u4e2a\u4e1c\u897f\u63a5\u6536\u4e00\u4e2a\u6216\u4e00\u4e9b\u5f20\u91cf\u4f5c\u4e3a\u8f93\u5165\uff0c\u7136\u540e\u8f93\u51fa\u7684\u4e5f\u662f\u4e00\u4e2a\u6216\u4e00\u4e9b\u5f20\u91cf\uff0c\u90a3\u4e0d\u7ba1\u5b83\u662f\u4ec0\u4e48\u9b3c\uff0c\u7edf\u7edf\u90fd\u79f0\u4f5c\u201c\u6a21\u578b\u201d\u3002\u5982\u679c\u4f60\u6709\u66f4\u8d34\u5207\u7684\u8bd1\u6cd5\uff0c\u4e5f\u6b22\u8fce\u8054\u7cfb\u6211\u4fee\u6539\u3002\n\n\n\n\n\n\nbatch\n\n\n\n\n\u8fd9\u4e2a\u6982\u5ff5\u4e0eKeras\u65e0\u5173\uff0c\u8001\u5b9e\u8bb2\u4e0d\u5e94\u8be5\u51fa\u73b0\u5728\u8fd9\u91cc\u7684\uff0c\u4f46\u662f\u56e0\u4e3a\u5b83\u9891\u7e41\u51fa\u73b0\uff0c\u800c\u4e14\u4e0d\u4e86\u89e3\u8fd9\u4e2a\u6280\u672f\u7684\u8bdd\u770b\u51fd\u6570\u8bf4\u660e\u4f1a\u5f88\u5934\u75db\uff0c\u8fd9\u91cc\u8fd8\u662f\u7b80\u5355\u8bf4\u4e00\u4e0b\u3002\n\n\n\u6df1\u5ea6\u5b66\u4e60\u7684\u4f18\u5316\u7b97\u6cd5\uff0c\u8bf4\u767d\u4e86\u5c31\u662f\u68af\u5ea6\u4e0b\u964d\u3002\u6bcf\u6b21\u7684\u53c2\u6570\u66f4\u65b0\u6709\u4e24\u79cd\u65b9\u5f0f\u3002\n\n\n\u7b2c\u4e00\u79cd\uff0c\u904d\u5386\u5168\u90e8\u6570\u636e\u96c6\u7b97\u4e00\u6b21\u635f\u5931\u51fd\u6570\uff0c\u7136\u540e\u7b97\u51fd\u6570\u5bf9\u5404\u4e2a\u53c2\u6570\u7684\u68af\u5ea6\uff0c\u66f4\u65b0\u68af\u5ea6\u3002\u8fd9\u79cd\u65b9\u6cd5\u6bcf\u66f4\u65b0\u4e00\u6b21\u53c2\u6570\u90fd\u8981\u628a\u6570\u636e\u96c6\u91cc\u7684\u6240\u6709\u6837\u672c\u90fd\u770b\u4e00\u904d\uff0c\u8ba1\u7b97\u91cf\u5f00\u9500\u5927\uff0c\u8ba1\u7b97\u901f\u5ea6\u6162\uff0c\u4e0d\u652f\u6301\u5728\u7ebf\u5b66\u4e60\uff0c\u8fd9\u79f0\u4e3aBatch gradient descent\uff0c\u6279\u68af\u5ea6\u4e0b\u964d\u3002\n\n\n\u53e6\u4e00\u79cd\uff0c\u6bcf\u770b\u4e00\u4e2a\u6570\u636e\u5c31\u7b97\u4e00\u4e0b\u635f\u5931\u51fd\u6570\uff0c\u7136\u540e\u6c42\u68af\u5ea6\u66f4\u65b0\u53c2\u6570\uff0c\u8fd9\u4e2a\u79f0\u4e3a\u968f\u673a\u68af\u5ea6\u4e0b\u964d\uff0cstochastic gradient descent\u3002\u8fd9\u4e2a\u65b9\u6cd5\u901f\u5ea6\u6bd4\u8f83\u5feb\uff0c\u4f46\u662f\u6536\u655b\u6027\u80fd\u4e0d\u592a\u597d\uff0c\u53ef\u80fd\u5728\u6700\u4f18\u70b9\u9644\u8fd1\u6643\u6765\u6643\u53bb\uff0chit\u4e0d\u5230\u6700\u4f18\u70b9\u3002\u4e24\u6b21\u53c2\u6570\u7684\u66f4\u65b0\u4e5f\u6709\u53ef\u80fd\u4e92\u76f8\u62b5\u6d88\u6389\uff0c\u9020\u6210\u76ee\u6807\u51fd\u6570\u9707\u8361\u7684\u6bd4\u8f83\u5267\u70c8\u3002\n\n\n\u4e3a\u4e86\u514b\u670d\u4e24\u79cd\u65b9\u6cd5\u7684\u7f3a\u70b9\uff0c\u73b0\u5728\u4e00\u822c\u91c7\u7528\u7684\u662f\u4e00\u79cd\u6298\u4e2d\u624b\u6bb5\uff0cmini-batch gradient decent\uff0c\u5c0f\u6279\u7684\u68af\u5ea6\u4e0b\u964d\uff0c\u8fd9\u79cd\u65b9\u6cd5\u628a\u6570\u636e\u5206\u4e3a\u82e5\u5e72\u4e2a\u6279\uff0c\u6309\u6279\u6765\u66f4\u65b0\u53c2\u6570\uff0c\u8fd9\u6837\uff0c\u4e00\u4e2a\u6279\u4e2d\u7684\u4e00\u7ec4\u6570\u636e\u5171\u540c\u51b3\u5b9a\u4e86\u672c\u6b21\u68af\u5ea6\u7684\u65b9\u5411\uff0c\u4e0b\u964d\u8d77\u6765\u5c31\u4e0d\u5bb9\u6613\u8dd1\u504f\uff0c\u51cf\u5c11\u4e86\u968f\u673a\u6027\u3002\u53e6\u4e00\u65b9\u9762\u56e0\u4e3a\u6279\u7684\u6837\u672c\u6570\u4e0e\u6574\u4e2a\u6570\u636e\u96c6\u76f8\u6bd4\u5c0f\u4e86\u5f88\u591a\uff0c\u8ba1\u7b97\u91cf\u4e5f\u4e0d\u662f\u5f88\u5927\u3002\n\n\n\u57fa\u672c\u4e0a\u73b0\u5728\u7684\u68af\u5ea6\u4e0b\u964d\u90fd\u662f\u57fa\u4e8emini-batch\u7684\uff0c\u6240\u4ee5Keras\u7684\u6a21\u5757\u4e2d\u7ecf\u5e38\u4f1a\u51fa\u73b0batch_size\uff0c\u5c31\u662f\u6307\u8fd9\u4e2a\u3002\n\n\n\u987a\u4fbf\u8bf4\u4e00\u53e5\uff0cKeras\u4e2d\u7528\u7684\u4f18\u5316\u5668SGD\u662fstochastic gradient descent\u7684\u7f29\u5199\uff0c\u4f46\u4e0d\u4ee3\u8868\u662f\u4e00\u4e2a\u6837\u672c\u5c31\u66f4\u65b0\u4e00\u56de\uff0c\u8fd8\u662f\u57fa\u4e8emini-batch\u7684\u3002\n\n\n\u5bf9\u65b0\u624b\u53cb\u597d\u7684\u5c0f\u8bf4\u660e\n\n\n\u867d\u7136\u8fd9\u4e0d\u662f\u6211\u4eec\u5e94\u8be5\u505a\u7684\u5de5\u4f5c\uff0c\u4f46\u4e3a\u4e86\u4f53\u73b0\u672c\u6559\u7a0b\u5bf9\u65b0\u624b\u7684\u53cb\u597d\uff0c\u6211\u4eec\u5728\u8fd9\u91cc\u7b80\u5355\u5217\u4e00\u4e0b\u4f7f\u7528keras\u9700\u8981\u7684\u5148\u884c\u77e5\u8bc6\u3002\u7a0d\u6709\u7ecf\u9a8c\u7684\u7814\u7a76\u8005\u6216\u5f00\u53d1\u8005\u8bf7\u5ffd\u7565\u672c\u8282\uff0c\u5bf9\u4e8e\u65b0\u624b\uff0c\u6211\u4eec\u5efa\u8bae\u5728\u5f00\u59cb\u4e4b\u524d\uff0c\u786e\u4fdd\u4f60\u4e86\u89e3\u4e0b\u9762\u63d0\u5230\u7684\u672f\u8bed\u7684\u57fa\u672c\u6982\u5ff5\u3002\u5982\u679c\u4f60\u786e\u5b9e\u5bf9\u67d0\u9879\u5185\u5bb9\u4e0d\u4e86\u89e3\uff0c\u8bf7\u9996\u5148\u67e5\u9605\u76f8\u5173\u8d44\u6599\uff0c\u4ee5\u514d\u5728\u672a\u6765\u4f7f\u7528\u4e2d\u5e26\u6765\u56f0\u60d1\u3002\n\n\n\u5173\u4e8ePython\n\n\n\n\n\n\n\u663e\u7136\u4f60\u5e94\u5bf9Python\u6709\u4e00\u5b9a\u7684\u719f\u6089\uff0c\u5305\u62ec\u5176\u57fa\u672c\u8bed\u6cd5\uff0c\u6570\u636e\u7c7b\u578b\uff0c\u8bed\u8a00\u7279\u70b9\u7b49\uff0c\u5982\u679c\u4f60\u8fd8\u4e0d\u80fd\u4f7f\u7528Python\u8fdb\u884c\u7a0b\u5e8f\u8bbe\u8ba1\uff0c\u6216\u4e0d\u80fd\u907f\u514dPython\u4e2d\u5e38\u89c1\u7684\u4e00\u4e9b\u5c0f\u9677\u9631\uff0c\u6216\u8bb8\u4f60\u5e94\u8be5\u5148\u53bb\u627e\u4e2a\u6559\u7a0b\u8865\u5145\u4e00\u4e0b\u3002\u8fd9\u91cc\u63a8\u4e00\u4e2a\u5feb\u901f\u5b66\u4e60Python\u7684\u6559\u7a0b\n\u5ed6\u96ea\u5cf0\u7684Python\u6559\u7a0b\n\n\n\n\n\n\n\u4f60\u5e94\u8be5\u6709\u9762\u5411\u5bf9\u8c61\u7684\u6982\u5ff5\uff0c\u77e5\u9053\u7c7b\u3001\u5bf9\u8c61\u3001\u5c01\u88c5\u3001\u591a\u6001\u3001\u7ee7\u627f\u3001\u4f5c\u7528\u57df\u7b49\u672f\u8bed\u7684\u542b\u4e49\u3002\n\n\n\n\n\n\n\u4f60\u5e94\u8be5\u5bf9Python\u7684\u79d1\u5b66\u8ba1\u7b97\u5305\u548c\u6df1\u5ea6\u5b66\u4e60\u5305\u6709\u4e00\u5b9a\u4e86\u89e3\uff0c\u8fd9\u4e9b\u5305\u5305\u542b\u4f46\u4e0d\u9650\u4e8enumpy, scipy, scikit-learn, pandas...\n\n\n\n\n\n\n\u7279\u522b\u5730\uff0c\u4f60\u9700\u8981\u4e86\u89e3\u4ec0\u4e48\u662f\u751f\u6210\u5668\u51fd\u6570\uff08generator\uff09\uff0c\u4ee5\u53ca\u5982\u4f55\u7f16\u5199\u751f\u6210\u5668\u51fd\u6570\u3002\u4ec0\u4e48\u662f\u533f\u540d\u51fd\u6570\uff08lambda\uff09\n\n\n\n\n\n\n\u5173\u4e8e\u6df1\u5ea6\u5b66\u4e60\n\n\n\u7531\u4e8eKeras\u662f\u4e3a\u6df1\u5ea6\u5b66\u4e60\u8bbe\u8ba1\u7684\u5de5\u5177\uff0c\u6211\u4eec\u8fd9\u91cc\u53ea\u5217\u4e3e\u6df1\u5ea6\u5b66\u4e60\u4e2d\u7684\u4e00\u4e9b\u57fa\u672c\u6982\u5ff5\u3002\u8bf7\u786e\u4fdd\u4f60\u5bf9\u4e0b\u9762\u7684\u6982\u5ff5\u6709\u4e00\u5b9a\u7406\u89e3\u3002\n\n\n\n\n\n\n\u6709\u76d1\u7763\u5b66\u4e60\uff0c\u65e0\u76d1\u7763\u5b66\u4e60\uff0c\u5206\u7c7b\uff0c\u805a\u7c7b\uff0c\u56de\u5f52\n\n\n\n\n\n\n\u795e\u7ecf\u5143\u6a21\u578b\uff0c\u591a\u5c42\u611f\u77e5\u5668\uff0cBP\u7b97\u6cd5\n\n\n\n\n\n\n\u76ee\u6807\u51fd\u6570\uff08\u635f\u5931\u51fd\u6570\uff09\uff0c\u6fc0\u6d3b\u51fd\u6570\uff0c\u68af\u5ea6\u4e0b\u964d\u6cd5\n\n\n\n\n\n\n\u5168\u8fde\u63a5\u7f51\u7edc\u3001\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u3001\u9012\u5f52\u795e\u7ecf\u7f51\u7edc\n\n\n\n\n\n\n\u8bad\u7ec3\u96c6\uff0c\u6d4b\u8bd5\u96c6\uff0c\u4ea4\u53c9\u9a8c\u8bc1\uff0c\u6b20\u62df\u5408\uff0c\u8fc7\u62df\u5408\n\n\n\n\n\n\n\u6570\u636e\u89c4\u8303\u5316\n\n\n\n\n\n\n\u5176\u4ed6\u6211\u8fd8\u6ca1\u60f3\u5230\u7684\u4e1c\u897f\u2026\u2026\u60f3\u5230\u518d\u8865\u5145\n\n\n\n\n\n\n\u5176\u4ed6\n\n\n\u5176\u4ed6\u9700\u8981\u6ce8\u610f\u7684\u6982\u5ff5\uff0c\u6211\u4eec\u5c06\u4f7f\u7528[Tips]\u6807\u6ce8\u51fa\u6765\uff0c\u5982\u679c\u8be5\u6982\u5ff5\u53cd\u590d\u51fa\u73b0\u53c8\u6bd4\u8f83\u91cd\u8981\uff0c\u6211\u4eec\u4f1a\u5199\u5230\u8fd9\u91cc\u3002\u5c31\u9171\uff0c\u73a9\u7684\u6109\u5feb\u54df\u3002", 
            "title": "\u4e00\u4e9b\u57fa\u672c\u6982\u5ff5"
        }, 
        {
            "location": "/getting_started/concepts/#_1", 
            "text": "\u5728\u5f00\u59cb\u5b66\u4e60Keras\u4e4b\u524d\uff0c\u6211\u4eec\u5e0c\u671b\u4f20\u9012\u4e00\u4e9b\u5173\u4e8eKeras\uff0c\u5173\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u57fa\u672c\u6982\u5ff5\u548c\u6280\u672f\uff0c\u6211\u4eec\u5efa\u8bae\u65b0\u624b\u5728\u4f7f\u7528Keras\u4e4b\u524d\u6d4f\u89c8\u4e00\u4e0b\u672c\u9875\u9762\u63d0\u5230\u7684\u5185\u5bb9\uff0c\u8fd9\u5c06\u51cf\u5c11\u4f60\u5b66\u4e60\u4e2d\u7684\u56f0\u60d1", 
            "title": "\u4e00\u4e9b\u57fa\u672c\u6982\u5ff5"
        }, 
        {
            "location": "/getting_started/concepts/#_2", 
            "text": "Keras\u7684\u5e95\u5c42\u5e93\u4f7f\u7528Theano\u6216TensorFlow\uff0c\u8fd9\u4e24\u4e2a\u5e93\u4e5f\u79f0\u4e3aKeras\u7684\u540e\u7aef\u3002\u65e0\u8bba\u662fTheano\u8fd8\u662fTensorFlow\uff0c\u90fd\u662f\u4e00\u4e2a\u201c\u7b26\u53f7\u4e3b\u4e49\u201d\u7684\u5e93\u3002  \u56e0\u6b64\uff0c\u8fd9\u4e5f\u4f7f\u5f97Keras\u7684\u7f16\u7a0b\u4e0e\u4f20\u7edf\u7684Python\u4ee3\u7801\u6709\u6240\u5dee\u522b\u3002\u7b3c\u7edf\u7684\u8bf4\uff0c\u7b26\u53f7\u4e3b\u4e49\u7684\u8ba1\u7b97\u9996\u5148\u5b9a\u4e49\u5404\u79cd\u53d8\u91cf\uff0c\u7136\u540e\u5efa\u7acb\u4e00\u4e2a\u201c\u8ba1\u7b97\u56fe\u201d\uff0c\u8ba1\u7b97\u56fe\u89c4\u5b9a\u4e86\u5404\u4e2a\u53d8\u91cf\u4e4b\u95f4\u7684\u8ba1\u7b97\u5173\u7cfb\u3002\u5efa\u7acb\u597d\u7684\u8ba1\u7b97\u56fe\u9700\u8981\u7f16\u8bd1\u5df2\u786e\u5b9a\u5176\u5185\u90e8\u7ec6\u8282\uff0c\u7136\u800c\uff0c\u6b64\u65f6\u7684\u8ba1\u7b97\u56fe\u8fd8\u662f\u4e00\u4e2a\u201c\u7a7a\u58f3\u5b50\u201d\uff0c\u91cc\u9762\u6ca1\u6709\u4efb\u4f55\u5b9e\u9645\u7684\u6570\u636e\uff0c\u53ea\u6709\u5f53\u4f60\u628a\u9700\u8981\u8fd0\u7b97\u7684\u8f93\u5165\u653e\u8fdb\u53bb\u540e\uff0c\u624d\u80fd\u5728\u6574\u4e2a\u6a21\u578b\u4e2d\u5f62\u6210\u6570\u636e\u6d41\uff0c\u4ece\u800c\u5f62\u6210\u8f93\u51fa\u503c\u3002  Keras\u7684\u6a21\u578b\u642d\u5efa\u5f62\u5f0f\u5c31\u662f\u8fd9\u79cd\u65b9\u6cd5\uff0c\u5728\u4f60\u642d\u5efaKeras\u6a21\u578b\u5b8c\u6bd5\u540e\uff0c\u4f60\u7684\u6a21\u578b\u5c31\u662f\u4e00\u4e2a\u7a7a\u58f3\u5b50\uff0c\u53ea\u6709\u5b9e\u9645\u751f\u6210\u53ef\u8c03\u7528\u7684\u51fd\u6570\u540e\uff08K.function\uff09\uff0c\u8f93\u5165\u6570\u636e\uff0c\u624d\u4f1a\u5f62\u6210\u771f\u6b63\u7684\u6570\u636e\u6d41\u3002  \u4f7f\u7528\u8ba1\u7b97\u56fe\u7684\u8bed\u8a00\uff0c\u5982Theano\uff0c\u4ee5\u96be\u4ee5\u8c03\u8bd5\u800c\u95fb\u540d\uff0c\u5f53Keras\u7684Debug\u8fdb\u5165Theano\u8fd9\u4e2a\u5c42\u6b21\u65f6\uff0c\u5f80\u5f80\u4e5f\u4ee4\u4eba\u5934\u75db\u3002\u6ca1\u6709\u7ecf\u9a8c\u7684\u5f00\u53d1\u8005\u5f88\u96be\u76f4\u89c2\u7684\u611f\u53d7\u5230\u8ba1\u7b97\u56fe\u5230\u5e95\u5728\u5e72\u4e9b\u4ec0\u4e48\u3002\u5c3d\u7ba1\u5f88\u8ba9\u4eba\u5934\u75db\uff0c\u4f46\u5927\u591a\u6570\u7684\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u4f7f\u7528\u7684\u90fd\u662f\u7b26\u53f7\u8ba1\u7b97\u8fd9\u4e00\u5957\u65b9\u6cd5\uff0c\u56e0\u4e3a\u7b26\u53f7\u8ba1\u7b97\u80fd\u591f\u63d0\u4f9b\u5173\u952e\u7684\u8ba1\u7b97\u4f18\u5316\u3001\u81ea\u52a8\u6c42\u5bfc\u7b49\u529f\u80fd\u3002  \u6211\u4eec\u5efa\u8bae\u4f60\u5728\u4f7f\u7528\u524d\u7a0d\u5fae\u4e86\u89e3\u4e00\u4e0bTheano\u6216TensorFlow\uff0cBing/Google\u4e00\u4e0b\u5373\u53ef\uff0c\u5982\u679c\u6211\u4eec\u8981\u53cdbaidu\uff0c\u90a3\u5c31\u4ece\u62d2\u7edd\u4f7f\u7528baidu\u5f00\u59cb\uff0c\u5149\u6482\u5634\u70ae\u662f\u6ca1\u6709\u7528\u7684\u3002", 
            "title": "\u7b26\u53f7\u8ba1\u7b97"
        }, 
        {
            "location": "/getting_started/concepts/#_3", 
            "text": "\u5f20\u91cf\uff0c\u6216tensor\uff0c\u662f\u672c\u6587\u6863\u4f1a\u7ecf\u5e38\u51fa\u73b0\u7684\u4e00\u4e2a\u8bcd\u6c47\uff0c\u5728\u6b64\u7a0d\u4f5c\u89e3\u91ca\u3002  \u4f7f\u7528\u8fd9\u4e2a\u8bcd\u6c47\u7684\u76ee\u7684\u662f\u4e3a\u4e86\u8868\u8ff0\u7edf\u4e00\uff0c\u5f20\u91cf\u53ef\u4ee5\u770b\u4f5c\u662f\u5411\u91cf\u3001\u77e9\u9635\u7684\u81ea\u7136\u63a8\u5e7f\uff0c\u6211\u4eec\u7528\u5f20\u91cf\u6765\u8868\u793a\u5e7f\u6cdb\u7684\u6570\u636e\u7c7b\u578b\u3002  \u89c4\u6a21\u6700\u5c0f\u7684\u5f20\u91cf\u662f0\u9636\u5f20\u91cf\uff0c\u5373\u6807\u91cf\uff0c\u4e5f\u5c31\u662f\u4e00\u4e2a\u6570\u3002  \u5f53\u6211\u4eec\u628a\u4e00\u4e9b\u6570\u6709\u5e8f\u7684\u6392\u5217\u8d77\u6765\uff0c\u5c31\u5f62\u6210\u4e861\u9636\u5f20\u91cf\uff0c\u4e5f\u5c31\u662f\u4e00\u4e2a\u5411\u91cf  \u5982\u679c\u6211\u4eec\u7ee7\u7eed\u628a\u4e00\u7ec4\u5411\u91cf\u6709\u5e8f\u7684\u6392\u5217\u8d77\u6765\uff0c\u5c31\u5f62\u6210\u4e862\u9636\u5f20\u91cf\uff0c\u4e5f\u5c31\u662f\u4e00\u4e2a\u77e9\u9635  \u628a\u77e9\u9635\u645e\u8d77\u6765\uff0c\u5c31\u662f3\u9636\u5f20\u91cf\uff0c\u6211\u4eec\u53ef\u4ee5\u79f0\u4e3a\u4e00\u4e2a\u7acb\u65b9\u4f53\uff0c\u5177\u67093\u4e2a\u989c\u8272\u901a\u9053\u7684\u5f69\u8272\u56fe\u7247\u5c31\u662f\u4e00\u4e2a\u8fd9\u6837\u7684\u7acb\u65b9\u4f53  \u628a\u77e9\u9635\u645e\u8d77\u6765\uff0c\u597d\u5427\u8fd9\u6b21\u6211\u4eec\u771f\u7684\u6ca1\u6709\u7ed9\u5b83\u8d77\u522b\u540d\u4e86\uff0c\u5c31\u53eb4\u9636\u5f20\u91cf\u4e86\uff0c\u4e0d\u8981\u53bb\u8bd5\u56fe\u60f3\u50cf4\u9636\u5f20\u91cf\u662f\u4ec0\u4e48\u6837\u5b50\uff0c\u5b83\u5c31\u662f\u4e2a\u6570\u5b66\u4e0a\u7684\u6982\u5ff5\u3002  \u5f20\u91cf\u7684\u9636\u6570\u6709\u65f6\u5019\u4e5f\u79f0\u4e3a\u7ef4\u5ea6\uff0c\u6216\u8005\u8f74\uff0c\u8f74\u8fd9\u4e2a\u8bcd\u7ffb\u8bd1\u81ea\u82f1\u6587axis\u3002\u8b6c\u5982\u4e00\u4e2a\u77e9\u9635[[1,2],[3,4]]\uff0c\u662f\u4e00\u4e2a2\u9636\u5f20\u91cf\uff0c\u6709\u4e24\u4e2a\u7ef4\u5ea6\u6216\u8f74\uff0c\u6cbf\u7740\u7b2c0\u4e2a\u8f74\uff08\u4e3a\u4e86\u4e0epython\u7684\u8ba1\u6570\u65b9\u5f0f\u4e00\u81f4\uff0c\u672c\u6587\u6863\u7ef4\u5ea6\u548c\u8f74\u4ece0\u7b97\u8d77\uff09\u4f60\u770b\u5230\u7684\u662f[1,2]\uff0c[3,4]\u4e24\u4e2a\u5411\u91cf\uff0c\u6cbf\u7740\u7b2c1\u4e2a\u8f74\u4f60\u770b\u5230\u7684\u662f[1,3]\uff0c[2,4]\u4e24\u4e2a\u5411\u91cf\u3002  \u8981\u7406\u89e3\u201c\u6cbf\u7740\u67d0\u4e2a\u8f74\u201d\u662f\u4ec0\u4e48\u610f\u601d\uff0c\u4e0d\u59a8\u8bd5\u7740\u8fd0\u884c\u4e00\u4e0b\u4e0b\u9762\u7684\u4ee3\u7801\uff1a  import numpy as np\n\na = np.array([[1,2],[3,4]])\nsum0 = np.sum(a, axis=0)\nsum1 = np.sum(a, axis=1)\n\nprint sum0\nprint sum1  \u5173\u4e8e\u5f20\u91cf\uff0c\u76ee\u524d\u77e5\u9053\u8fd9\u4e48\u591a\u5c31\u8db3\u591f\u4e86\u3002\u4e8b\u5b9e\u4e0a\u6211\u4e5f\u5c31\u77e5\u9053\u8fd9\u4e48\u591a", 
            "title": "\u5f20\u91cf"
        }, 
        {
            "location": "/getting_started/concepts/#thtf", 
            "text": "\u8fd9\u662f\u4e00\u4e2a\u65e0\u53ef\u5948\u4f55\u7684\u95ee\u9898\uff0c\u5728\u5982\u4f55\u8868\u793a\u4e00\u7ec4\u5f69\u8272\u56fe\u7247\u7684\u95ee\u9898\u4e0a\uff0cTheano\u548cTensorFlow\u53d1\u751f\u4e86\u5206\u6b67\uff0c'th'\u6a21\u5f0f\uff0c\u4e5f\u5373Theano\u6a21\u5f0f\u4f1a\u628a100\u5f20RGB\u4e09\u901a\u9053\u768416\u00d732\uff08\u9ad8\u4e3a16\u5bbd\u4e3a32\uff09\u5f69\u8272\u56fe\u8868\u793a\u4e3a\u4e0b\u9762\u8fd9\u79cd\u5f62\u5f0f\uff08100,3,16,32\uff09\uff0cCaffe\u91c7\u53d6\u7684\u4e5f\u662f\u8fd9\u79cd\u65b9\u5f0f\u3002\u7b2c0\u4e2a\u7ef4\u5ea6\u662f\u6837\u672c\u7ef4\uff0c\u4ee3\u8868\u6837\u672c\u7684\u6570\u76ee\uff0c\u7b2c1\u4e2a\u7ef4\u5ea6\u662f\u901a\u9053\u7ef4\uff0c\u4ee3\u8868\u989c\u8272\u901a\u9053\u6570\u3002\u540e\u9762\u4e24\u4e2a\u5c31\u662f\u9ad8\u548c\u5bbd\u4e86\u3002  \u800cTensorFlow\uff0c\u5373'tf'\u6a21\u5f0f\u7684\u8868\u8fbe\u5f62\u5f0f\u662f\uff08100,16,32,3\uff09\uff0c\u5373\u628a\u901a\u9053\u7ef4\u653e\u5728\u4e86\u6700\u540e\u3002\u8fd9\u4e24\u4e2a\u8868\u8fbe\u65b9\u6cd5\u672c\u8d28\u4e0a\u6ca1\u6709\u4ec0\u4e48\u533a\u522b\u3002  Keras\u9ed8\u8ba4\u7684\u6570\u636e\u7ec4\u7ec7\u5f62\u5f0f\u5728~/.keras/keras.json\u4e2d\u89c4\u5b9a\uff0c\u53ef\u67e5\u770b\u8be5\u6587\u4ef6\u7684 image_dim_ordering \u4e00\u9879\u67e5\u770b\uff0c\u4e5f\u53ef\u5728\u4ee3\u7801\u4e2d\u901a\u8fc7K.image_dim_ordering()\u51fd\u6570\u8fd4\u56de\uff0c\u8bf7\u5728\u7f51\u7edc\u7684\u8bad\u7ec3\u548c\u6d4b\u8bd5\u4e2d\u4fdd\u6301\u7ef4\u5ea6\u987a\u5e8f\u4e00\u81f4\u3002  \u5509\uff0c\u771f\u662f\u86cb\u75bc\uff0c\u4f60\u4eec\u5546\u91cf\u597d\u4e0d\u884c\u5417\uff1f", 
            "title": "'th'\u4e0e'tf'"
        }, 
        {
            "location": "/getting_started/concepts/#_4", 
            "text": "\u6cdb\u578b\u6a21\u578b\u7b97\u662f\u672c\u6587\u6863\u6bd4\u8f83\u539f\u521b\u7684\u8bcd\u6c47\u4e86\uff0c\u6240\u4ee5\u8fd9\u91cc\u8981\u8bf4\u4e00\u4e0b  \u5728\u539f\u672c\u7684Keras\u7248\u672c\u4e2d\uff0c\u6a21\u578b\u5176\u5b9e\u6709\u4e24\u79cd\uff0c\u4e00\u79cd\u53ebSequential\uff0c\u79f0\u4e3a\u5e8f\u8d2f\u6a21\u578b\uff0c\u4e5f\u5c31\u662f\u5355\u8f93\u5165\u5355\u8f93\u51fa\uff0c\u4e00\u6761\u8def\u901a\u5230\u5e95\uff0c\u5c42\u4e0e\u5c42\u4e4b\u95f4\u53ea\u6709\u76f8\u90bb\u5173\u7cfb\uff0c\u8de8\u5c42\u8fde\u63a5\u7edf\u7edf\u6ca1\u6709\u3002\u8fd9\u79cd\u6a21\u578b\u7f16\u8bd1\u901f\u5ea6\u5feb\uff0c\u64cd\u4f5c\u4e0a\u4e5f\u6bd4\u8f83\u7b80\u5355\u3002\u7b2c\u4e8c\u79cd\u6a21\u578b\u79f0\u4e3aGraph\uff0c\u5373\u56fe\u6a21\u578b\uff0c\u8fd9\u4e2a\u6a21\u578b\u652f\u6301\u591a\u8f93\u5165\u591a\u8f93\u51fa\uff0c\u5c42\u4e0e\u5c42\u4e4b\u95f4\u60f3\u600e\u4e48\u8fde\u600e\u4e48\u8fde\uff0c\u4f46\u662f\u7f16\u8bd1\u901f\u5ea6\u6162\u3002\u53ef\u4ee5\u770b\u5230\uff0cSequential\u5176\u5b9e\u662fGraph\u7684\u4e00\u4e2a\u7279\u6b8a\u60c5\u51b5\u3002  \u5728\u73b0\u5728\u8fd9\u7248Keras\u4e2d\uff0c\u56fe\u6a21\u578b\u88ab\u79fb\u9664\uff0c\u800c\u589e\u52a0\u4e86\u4e86\u201cfunctional model API\u201d\uff0c\u8fd9\u4e2a\u4e1c\u897f\uff0c\u66f4\u52a0\u5f3a\u8c03\u4e86Sequential\u662f\u7279\u6b8a\u60c5\u51b5\u8fd9\u4e00\u70b9\u3002\u4e00\u822c\u7684\u6a21\u578b\u5c31\u79f0\u4e3aModel\uff0c\u7136\u540e\u5982\u679c\u4f60\u8981\u7528\u7b80\u5355\u7684Sequential\uff0cOK\uff0c\u90a3\u8fd8\u6709\u4e00\u4e2a\u5feb\u6377\u65b9\u5f0fSequential\u3002  \u7531\u4e8efunctional model API\u8868\u8fbe\u7684\u662f\u201c\u4e00\u822c\u7684\u6a21\u578b\u201d\u8fd9\u4e2a\u6982\u5ff5\uff0c\u6211\u4eec\u8fd9\u91cc\u5c06\u5176\u8bd1\u4e3a\u6cdb\u578b\u6a21\u578b\uff0c\u5373\u53ea\u8981\u8fd9\u4e2a\u4e1c\u897f\u63a5\u6536\u4e00\u4e2a\u6216\u4e00\u4e9b\u5f20\u91cf\u4f5c\u4e3a\u8f93\u5165\uff0c\u7136\u540e\u8f93\u51fa\u7684\u4e5f\u662f\u4e00\u4e2a\u6216\u4e00\u4e9b\u5f20\u91cf\uff0c\u90a3\u4e0d\u7ba1\u5b83\u662f\u4ec0\u4e48\u9b3c\uff0c\u7edf\u7edf\u90fd\u79f0\u4f5c\u201c\u6a21\u578b\u201d\u3002\u5982\u679c\u4f60\u6709\u66f4\u8d34\u5207\u7684\u8bd1\u6cd5\uff0c\u4e5f\u6b22\u8fce\u8054\u7cfb\u6211\u4fee\u6539\u3002", 
            "title": "\u6cdb\u578b\u6a21\u578b"
        }, 
        {
            "location": "/getting_started/concepts/#batch", 
            "text": "\u8fd9\u4e2a\u6982\u5ff5\u4e0eKeras\u65e0\u5173\uff0c\u8001\u5b9e\u8bb2\u4e0d\u5e94\u8be5\u51fa\u73b0\u5728\u8fd9\u91cc\u7684\uff0c\u4f46\u662f\u56e0\u4e3a\u5b83\u9891\u7e41\u51fa\u73b0\uff0c\u800c\u4e14\u4e0d\u4e86\u89e3\u8fd9\u4e2a\u6280\u672f\u7684\u8bdd\u770b\u51fd\u6570\u8bf4\u660e\u4f1a\u5f88\u5934\u75db\uff0c\u8fd9\u91cc\u8fd8\u662f\u7b80\u5355\u8bf4\u4e00\u4e0b\u3002  \u6df1\u5ea6\u5b66\u4e60\u7684\u4f18\u5316\u7b97\u6cd5\uff0c\u8bf4\u767d\u4e86\u5c31\u662f\u68af\u5ea6\u4e0b\u964d\u3002\u6bcf\u6b21\u7684\u53c2\u6570\u66f4\u65b0\u6709\u4e24\u79cd\u65b9\u5f0f\u3002  \u7b2c\u4e00\u79cd\uff0c\u904d\u5386\u5168\u90e8\u6570\u636e\u96c6\u7b97\u4e00\u6b21\u635f\u5931\u51fd\u6570\uff0c\u7136\u540e\u7b97\u51fd\u6570\u5bf9\u5404\u4e2a\u53c2\u6570\u7684\u68af\u5ea6\uff0c\u66f4\u65b0\u68af\u5ea6\u3002\u8fd9\u79cd\u65b9\u6cd5\u6bcf\u66f4\u65b0\u4e00\u6b21\u53c2\u6570\u90fd\u8981\u628a\u6570\u636e\u96c6\u91cc\u7684\u6240\u6709\u6837\u672c\u90fd\u770b\u4e00\u904d\uff0c\u8ba1\u7b97\u91cf\u5f00\u9500\u5927\uff0c\u8ba1\u7b97\u901f\u5ea6\u6162\uff0c\u4e0d\u652f\u6301\u5728\u7ebf\u5b66\u4e60\uff0c\u8fd9\u79f0\u4e3aBatch gradient descent\uff0c\u6279\u68af\u5ea6\u4e0b\u964d\u3002  \u53e6\u4e00\u79cd\uff0c\u6bcf\u770b\u4e00\u4e2a\u6570\u636e\u5c31\u7b97\u4e00\u4e0b\u635f\u5931\u51fd\u6570\uff0c\u7136\u540e\u6c42\u68af\u5ea6\u66f4\u65b0\u53c2\u6570\uff0c\u8fd9\u4e2a\u79f0\u4e3a\u968f\u673a\u68af\u5ea6\u4e0b\u964d\uff0cstochastic gradient descent\u3002\u8fd9\u4e2a\u65b9\u6cd5\u901f\u5ea6\u6bd4\u8f83\u5feb\uff0c\u4f46\u662f\u6536\u655b\u6027\u80fd\u4e0d\u592a\u597d\uff0c\u53ef\u80fd\u5728\u6700\u4f18\u70b9\u9644\u8fd1\u6643\u6765\u6643\u53bb\uff0chit\u4e0d\u5230\u6700\u4f18\u70b9\u3002\u4e24\u6b21\u53c2\u6570\u7684\u66f4\u65b0\u4e5f\u6709\u53ef\u80fd\u4e92\u76f8\u62b5\u6d88\u6389\uff0c\u9020\u6210\u76ee\u6807\u51fd\u6570\u9707\u8361\u7684\u6bd4\u8f83\u5267\u70c8\u3002  \u4e3a\u4e86\u514b\u670d\u4e24\u79cd\u65b9\u6cd5\u7684\u7f3a\u70b9\uff0c\u73b0\u5728\u4e00\u822c\u91c7\u7528\u7684\u662f\u4e00\u79cd\u6298\u4e2d\u624b\u6bb5\uff0cmini-batch gradient decent\uff0c\u5c0f\u6279\u7684\u68af\u5ea6\u4e0b\u964d\uff0c\u8fd9\u79cd\u65b9\u6cd5\u628a\u6570\u636e\u5206\u4e3a\u82e5\u5e72\u4e2a\u6279\uff0c\u6309\u6279\u6765\u66f4\u65b0\u53c2\u6570\uff0c\u8fd9\u6837\uff0c\u4e00\u4e2a\u6279\u4e2d\u7684\u4e00\u7ec4\u6570\u636e\u5171\u540c\u51b3\u5b9a\u4e86\u672c\u6b21\u68af\u5ea6\u7684\u65b9\u5411\uff0c\u4e0b\u964d\u8d77\u6765\u5c31\u4e0d\u5bb9\u6613\u8dd1\u504f\uff0c\u51cf\u5c11\u4e86\u968f\u673a\u6027\u3002\u53e6\u4e00\u65b9\u9762\u56e0\u4e3a\u6279\u7684\u6837\u672c\u6570\u4e0e\u6574\u4e2a\u6570\u636e\u96c6\u76f8\u6bd4\u5c0f\u4e86\u5f88\u591a\uff0c\u8ba1\u7b97\u91cf\u4e5f\u4e0d\u662f\u5f88\u5927\u3002  \u57fa\u672c\u4e0a\u73b0\u5728\u7684\u68af\u5ea6\u4e0b\u964d\u90fd\u662f\u57fa\u4e8emini-batch\u7684\uff0c\u6240\u4ee5Keras\u7684\u6a21\u5757\u4e2d\u7ecf\u5e38\u4f1a\u51fa\u73b0batch_size\uff0c\u5c31\u662f\u6307\u8fd9\u4e2a\u3002  \u987a\u4fbf\u8bf4\u4e00\u53e5\uff0cKeras\u4e2d\u7528\u7684\u4f18\u5316\u5668SGD\u662fstochastic gradient descent\u7684\u7f29\u5199\uff0c\u4f46\u4e0d\u4ee3\u8868\u662f\u4e00\u4e2a\u6837\u672c\u5c31\u66f4\u65b0\u4e00\u56de\uff0c\u8fd8\u662f\u57fa\u4e8emini-batch\u7684\u3002", 
            "title": "batch"
        }, 
        {
            "location": "/getting_started/concepts/#_5", 
            "text": "\u867d\u7136\u8fd9\u4e0d\u662f\u6211\u4eec\u5e94\u8be5\u505a\u7684\u5de5\u4f5c\uff0c\u4f46\u4e3a\u4e86\u4f53\u73b0\u672c\u6559\u7a0b\u5bf9\u65b0\u624b\u7684\u53cb\u597d\uff0c\u6211\u4eec\u5728\u8fd9\u91cc\u7b80\u5355\u5217\u4e00\u4e0b\u4f7f\u7528keras\u9700\u8981\u7684\u5148\u884c\u77e5\u8bc6\u3002\u7a0d\u6709\u7ecf\u9a8c\u7684\u7814\u7a76\u8005\u6216\u5f00\u53d1\u8005\u8bf7\u5ffd\u7565\u672c\u8282\uff0c\u5bf9\u4e8e\u65b0\u624b\uff0c\u6211\u4eec\u5efa\u8bae\u5728\u5f00\u59cb\u4e4b\u524d\uff0c\u786e\u4fdd\u4f60\u4e86\u89e3\u4e0b\u9762\u63d0\u5230\u7684\u672f\u8bed\u7684\u57fa\u672c\u6982\u5ff5\u3002\u5982\u679c\u4f60\u786e\u5b9e\u5bf9\u67d0\u9879\u5185\u5bb9\u4e0d\u4e86\u89e3\uff0c\u8bf7\u9996\u5148\u67e5\u9605\u76f8\u5173\u8d44\u6599\uff0c\u4ee5\u514d\u5728\u672a\u6765\u4f7f\u7528\u4e2d\u5e26\u6765\u56f0\u60d1\u3002", 
            "title": "\u5bf9\u65b0\u624b\u53cb\u597d\u7684\u5c0f\u8bf4\u660e"
        }, 
        {
            "location": "/getting_started/concepts/#python", 
            "text": "\u663e\u7136\u4f60\u5e94\u5bf9Python\u6709\u4e00\u5b9a\u7684\u719f\u6089\uff0c\u5305\u62ec\u5176\u57fa\u672c\u8bed\u6cd5\uff0c\u6570\u636e\u7c7b\u578b\uff0c\u8bed\u8a00\u7279\u70b9\u7b49\uff0c\u5982\u679c\u4f60\u8fd8\u4e0d\u80fd\u4f7f\u7528Python\u8fdb\u884c\u7a0b\u5e8f\u8bbe\u8ba1\uff0c\u6216\u4e0d\u80fd\u907f\u514dPython\u4e2d\u5e38\u89c1\u7684\u4e00\u4e9b\u5c0f\u9677\u9631\uff0c\u6216\u8bb8\u4f60\u5e94\u8be5\u5148\u53bb\u627e\u4e2a\u6559\u7a0b\u8865\u5145\u4e00\u4e0b\u3002\u8fd9\u91cc\u63a8\u4e00\u4e2a\u5feb\u901f\u5b66\u4e60Python\u7684\u6559\u7a0b \u5ed6\u96ea\u5cf0\u7684Python\u6559\u7a0b    \u4f60\u5e94\u8be5\u6709\u9762\u5411\u5bf9\u8c61\u7684\u6982\u5ff5\uff0c\u77e5\u9053\u7c7b\u3001\u5bf9\u8c61\u3001\u5c01\u88c5\u3001\u591a\u6001\u3001\u7ee7\u627f\u3001\u4f5c\u7528\u57df\u7b49\u672f\u8bed\u7684\u542b\u4e49\u3002    \u4f60\u5e94\u8be5\u5bf9Python\u7684\u79d1\u5b66\u8ba1\u7b97\u5305\u548c\u6df1\u5ea6\u5b66\u4e60\u5305\u6709\u4e00\u5b9a\u4e86\u89e3\uff0c\u8fd9\u4e9b\u5305\u5305\u542b\u4f46\u4e0d\u9650\u4e8enumpy, scipy, scikit-learn, pandas...    \u7279\u522b\u5730\uff0c\u4f60\u9700\u8981\u4e86\u89e3\u4ec0\u4e48\u662f\u751f\u6210\u5668\u51fd\u6570\uff08generator\uff09\uff0c\u4ee5\u53ca\u5982\u4f55\u7f16\u5199\u751f\u6210\u5668\u51fd\u6570\u3002\u4ec0\u4e48\u662f\u533f\u540d\u51fd\u6570\uff08lambda\uff09", 
            "title": "\u5173\u4e8ePython"
        }, 
        {
            "location": "/getting_started/concepts/#_6", 
            "text": "\u7531\u4e8eKeras\u662f\u4e3a\u6df1\u5ea6\u5b66\u4e60\u8bbe\u8ba1\u7684\u5de5\u5177\uff0c\u6211\u4eec\u8fd9\u91cc\u53ea\u5217\u4e3e\u6df1\u5ea6\u5b66\u4e60\u4e2d\u7684\u4e00\u4e9b\u57fa\u672c\u6982\u5ff5\u3002\u8bf7\u786e\u4fdd\u4f60\u5bf9\u4e0b\u9762\u7684\u6982\u5ff5\u6709\u4e00\u5b9a\u7406\u89e3\u3002    \u6709\u76d1\u7763\u5b66\u4e60\uff0c\u65e0\u76d1\u7763\u5b66\u4e60\uff0c\u5206\u7c7b\uff0c\u805a\u7c7b\uff0c\u56de\u5f52    \u795e\u7ecf\u5143\u6a21\u578b\uff0c\u591a\u5c42\u611f\u77e5\u5668\uff0cBP\u7b97\u6cd5    \u76ee\u6807\u51fd\u6570\uff08\u635f\u5931\u51fd\u6570\uff09\uff0c\u6fc0\u6d3b\u51fd\u6570\uff0c\u68af\u5ea6\u4e0b\u964d\u6cd5    \u5168\u8fde\u63a5\u7f51\u7edc\u3001\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u3001\u9012\u5f52\u795e\u7ecf\u7f51\u7edc    \u8bad\u7ec3\u96c6\uff0c\u6d4b\u8bd5\u96c6\uff0c\u4ea4\u53c9\u9a8c\u8bc1\uff0c\u6b20\u62df\u5408\uff0c\u8fc7\u62df\u5408    \u6570\u636e\u89c4\u8303\u5316    \u5176\u4ed6\u6211\u8fd8\u6ca1\u60f3\u5230\u7684\u4e1c\u897f\u2026\u2026\u60f3\u5230\u518d\u8865\u5145", 
            "title": "\u5173\u4e8e\u6df1\u5ea6\u5b66\u4e60"
        }, 
        {
            "location": "/getting_started/concepts/#_7", 
            "text": "\u5176\u4ed6\u9700\u8981\u6ce8\u610f\u7684\u6982\u5ff5\uff0c\u6211\u4eec\u5c06\u4f7f\u7528[Tips]\u6807\u6ce8\u51fa\u6765\uff0c\u5982\u679c\u8be5\u6982\u5ff5\u53cd\u590d\u51fa\u73b0\u53c8\u6bd4\u8f83\u91cd\u8981\uff0c\u6211\u4eec\u4f1a\u5199\u5230\u8fd9\u91cc\u3002\u5c31\u9171\uff0c\u73a9\u7684\u6109\u5feb\u54df\u3002", 
            "title": "\u5176\u4ed6"
        }, 
        {
            "location": "/getting_started/keras_linux/", 
            "text": "\u58f0\u660e\n\n\n\u672c\u6559\u7a0b\u4e0d\u5f97\u7528\u4e8e\u4efb\u4f55\u5f62\u5f0f\u7684\u5546\u4e1a\u7528\u9014\uff0c\u5982\u679c\u9700\u8981\u8f6c\u8f7d\u8bf7\u4e0e\u4f5c\u8005SCP-173\u8054\u7cfb\uff0c\u5982\u679c\u53d1\u73b0\u672a\u7ecf\u5141\u8bb8\u590d\u5236\u8f6c\u8f7d\uff0c\u5c06\u4fdd\u7559\u8ffd\u6c42\u5176\u6cd5\u5f8b\u8d23\u4efb\u7684\u6743\u5229\u3002\n\n\n\n\n\u5173\u4e8e\u8ba1\u7b97\u673a\u7684\u786c\u4ef6\u914d\u7f6e\u8bf4\u660e\n\n\n\u63a8\u8350\u914d\u7f6e\n\n\n\u5982\u679c\u60a8\u662f\u9ad8\u6821\u5b66\u751f\u6216\u8005\u9ad8\u7ea7\u7814\u7a76\u4eba\u5458\uff0c\u5e76\u4e14\u5b9e\u9a8c\u5ba4\u6216\u8005\u4e2a\u4eba\u8d44\u91d1\u5145\u6c9b\uff0c\u5efa\u8bae\u60a8\u91c7\u7528\u5982\u4e0b\u914d\u7f6e\uff1a\n\n\n\n\n\u4e3b\u677f\uff1aX99\u578b\u53f7\u6216Z170\u578b\u53f7\n\n\nCPU\uff1ai7-5830K\u6216i7-6700K \u53ca\u5176\u4ee5\u4e0a\u9ad8\u7ea7\u578b\u53f7\n\n\n\u5185\u5b58\uff1a\u54c1\u724c\u5185\u5b58\uff0c\u603b\u5bb9\u91cf32G\u4ee5\u4e0a\uff0c\u6839\u636e\u4e3b\u677f\u7ec4\u62104\u901a\u9053\u62168\u901a\u9053\n\n\nSSD\uff1a\u54c1\u724c\u56fa\u6001\u786c\u76d8\uff0c\u5bb9\u91cf256G\u4ee5\u4e0a\n\n\n\u663e\u5361\uff1a\nNVIDIA GTX 1080 Ti\u3001NVIDIA GTX 1080\u3001NVIDIA GTX 1070\u3001NVIDIA GTX 1060 (\u987a\u5e8f\u4e3a\u4f18\u5148\u5efa\u8bae\uff0c\u5e76\u4e14\u5efa\u8bae\u540c\u4e00\u663e\u5361\uff0c\u53ef\u4ee5\u6839\u636e\u4e3b\u677f\u63d2\u69fd\u6570\u91cf\u8d2d\u4e70\u591a\u5757\uff0c\u4f8b\u5982X99\u578b\u53f7\u4e3b\u677f\u6700\u591a\u53ef\u4ee5\u91c7\u7528\u00d74\u7684\u663e\u5361)\n\n\n\u7535\u6e90\uff1a\u7531\u4e3b\u673a\u673a\u5bb9\u91cf\u7684\u786e\u5b9a\uff0c\u4e00\u822c\u6709\u663e\u5361\u603b\u5bb9\u91cf\u540e\u518d\u52a0200W\u5373\u53ef\n\n\n\n\n\u6700\u4f4e\u914d\u7f6e\n\n\n\u5982\u679c\u60a8\u662f\u4ec5\u4ec5\u7528\u4e8e\u81ea\u5b66\u6216\u4ee3\u7801\u8c03\u8bd5\uff0c\u4ea6\u6216\u662f\u6761\u4ef6\u6240\u9650\u4ec5\u91c7\u7528\u81ea\u5df1\u73b0\u6709\u7684\u8bbe\u5907\u8fdb\u884c\u5f00\u53d1\uff0c\u90a3\u4e48\u60a8\u7684\u7535\u8111\u81f3\u5c11\u6ee1\u8db3\u4ee5\u4e0b\u51e0\u70b9\uff1a\n\n\n\n\nCPU\uff1aIntel\u7b2c\u4e09\u4ee3i5\u548ci7\u4ee5\u4e0a\u7cfb\u5217\u4ea7\u54c1\u6216\u540c\u6027\u80fdAMD\u516c\u53f8\u4ea7\u54c1\n\n\n\u5185\u5b58\uff1a\u603b\u5bb9\u91cf4G\u4ee5\u4e0a\n\n\n\n\nCPU\u8bf4\u660e\n\n\n\n\n\u5927\u591a\u6570CPU\u76ee\u524d\u652f\u6301\u591a\u6838\u591a\u7ebf\u7a0b\uff0c\u90a3\u4e48\u5982\u679c\u60a8\u91c7\u7528CPU\u52a0\u901f\uff0c\u5c31\u53ef\u4ee5\u4f7f\u7528\u591a\u7ebf\u7a0b\u8fd0\u7b97\u3002\u8fd9\u65b9\u9762\u7684\u4f18\u52bf\u5bf9\u4e8e\u670d\u52a1\u5668CPU\u96c6\u7fa4\u548c\u591a\u6838\u5e76\u884cCPU\u5c24\u4e3a\u5173\u952e\n\n\n\n\n\u663e\u5361\u8bf4\u660e\n\n\n\n\n\u5982\u679c\u60a8\u7684\u663e\u5361\u662f\u975eNVIDIA\u516c\u53f8\u7684\u4ea7\u54c1\u6216\u662fNVIDIA GTX\u7cfb\u5217\u4e2d\u578b\u53f7\u7684\u7b2c\u4e00\u4e2a\u6570\u5b57\u4f4e\u4e8e4\u6216NVIDIA\u7684GT\u7cfb\u5217\uff0c\u90fd\u4e0d\u5efa\u8bae\u60a8\u91c7\u7528\u6b64\u7c7b\u663e\u5361\u8fdb\u884c\u52a0\u901f\u8ba1\u7b97\uff0c\u4f8b\u5982\nNVIDIA GT 910\n\u3001\nNVIDIA GTX 450\n \u7b49\u7b49\u3002\n\n\n\u5982\u679c\u60a8\u7684\u663e\u5361\u4e3a\u7b14\u8bb0\u672c\u4e0a\u7684GTX\u79fb\u52a8\u663e\u5361\uff08\u578b\u53f7\u540e\u9762\u5e26\u6709\u6807\u8bc6M\uff09\uff0c\u90a3\u4e48\u8bf7\u60a8\u614e\u91cd\u4f7f\u7528\u663e\u5361\u52a0\u901f\uff0c\u56e0\u4e3a\u79fb\u52a8\u7248GPU\u5f88\u5bb9\u6613\u53d1\u751f\u8fc7\u70ed\u70e7\u6bc1\u73b0\u8c61\u3002\n\n\n\u5982\u679c\u60a8\u7684\u663e\u5361\uff0c\u663e\u793a\u7684\u662f\u8bf8\u5982 \nHD5000\n,\nATI 5650\n \u7b49\u7c7b\u578b\u7684\u663e\u5361\uff0c\u90a3\u4e48\u60a8\u53ea\u80fd\u4f7f\u7528CPU\u52a0\u901f\n\n\n\u5982\u679c\u60a8\u7684\u663e\u5361\u4e3aPascal\u67b6\u6784\u7684\u663e\u5361\uff08\nNVIDIA GTX 1080\n,\nNVIDIA GTX 1070\n\u7b49\uff09\uff0c\u60a8\u53ea\u80fd\u5728\u4e4b\u540e\u7684\u914d\u7f6e\u4e2d\u9009\u62e9\nCUDA 8.0\n\n\n\n\n\n\n\u57fa\u672c\u5f00\u53d1\u73af\u5883\u642d\u5efa\n\n\n1. Linux \u53d1\u884c\u7248\n\n\nlinux\u6709\u5f88\u591a\u53d1\u884c\u7248\uff0c\u672c\u6587\u5f3a\u70c8\u5efa\u8bae\u8bfb\u8005\u91c7\u7528\u65b0\u7248\u7684\nUbuntu 16.04 LTS\n\n\u4e00\u65b9\u9762\uff0c\u5bf9\u4e8e\u5927\u591a\u6570\u65b0\u624b\u6765\u8bf4Ubuntu\u5177\u6709\u5f88\u597d\u7684\u56fe\u5f62\u754c\u9762\uff0c\u4e0e\u4e50\u89c2\u7684\u5f00\u6e90\u793e\u533a\uff1b\u53e6\u4e00\u65b9\u9762\uff0cUbuntu\u662fNvidia\u5b98\u65b9\u4ee5\u53ca\u7edd\u5927\u591a\u6570\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u9ed8\u8ba4\u5f00\u53d1\u73af\u5883\u3002\n\u4e2a\u4eba\u4e0d\u5efa\u8bae\u4f7f\u7528Ubuntu Kylin\uff0c\u4e4b\u524d\u63d0\u51fa\u6709\u90e8\u5206\u4fe1\u606f\u8868\u793a\uff0c\u4e2d\u56fd\u5b98\u65b9\u5f00\u53d1\u7684\u8fd9\u4e2a\u7248\u672c\u6709\u90e8\u5206\u529f\u80fd\u88ab\u201c\u9609\u5272\u201d\uff0c\u4f60\u61c2\u5f97\u3002\nUbuntu 16.04 LTS\u4e0b\u8f7d\u5730\u5740\uff1a\n\n\nhttp://www.ubuntu.org.cn/download/desktop\n\n\n\n\n\u901a\u8fc7U\u76d8\u5b89\u88c5\u597d\u540e\uff0c\u8fdb\u884c\u521d\u59cb\u5316\u73af\u5883\u8bbe\u7f6e\u3002\n\n\n2. Ubuntu\u521d\u59cb\u73af\u5883\u8bbe\u7f6e\n\n\n\n\n\u5b89\u88c5\u5f00\u53d1\u5305\n\u6253\u5f00\n\u7ec8\u7aef\n\u8f93\u5165\uff1a\n\n\n\n\n# \u7cfb\u7edf\u5347\u7ea7\n\n sudo apt update\n\n sudo apt upgrade\n# \u5b89\u88c5python\u57fa\u7840\u5f00\u53d1\u5305\n\n sudo apt install -y python-dev python-pip python-nose gcc g++ git gfortran vim\n\n\n\n\n\n\n\u5b89\u88c5\u8fd0\u7b97\u52a0\u901f\u5e93\n\u6253\u5f00\n\u7ec8\u7aef\n\u8f93\u5165\uff1a\n\n\n\n\n sudo apt install -y libopenblas-dev liblapack-dev libatlas-base-dev\n\n\n\n\n3. CUDA\u5f00\u53d1\u73af\u5883\u7684\u642d\u5efa(CPU\u52a0\u901f\u8df3\u8fc7)\n\n\n\u5982\u679c\u60a8\u7684\u4ec5\u4ec5\u91c7\u7528cpu\u52a0\u901f\uff0c\u53ef\u8df3\u8fc7\u6b64\u6b65\u9aa4\n\n- \u4e0b\u8f7dCUDA8.0\n\n\n\u4e0b\u8f7d\u5730\u5740\uff1a\n\n\nhttps://developer.nvidia.com/cuda-downloads\n\n\n\n\n\u4e4b\u540e\u6253\u5f00\n\u7ec8\u7aef\n\u8f93\u5165\uff1a\n\n\n sudo dpkg -i cuda-repo-ubuntu1604-8-0-local_8.0.44-1_amd64.deb\n\n sudo apt update\n\n sudo apt install cuda\n\n\n\n\n\u81ea\u52a8\u914d\u7f6e\u6210\u529f\u5c31\u597d\u3002\n\n\n\n\n\u5c06CUDA\u8def\u5f84\u6dfb\u52a0\u81f3\u73af\u5883\u53d8\u91cf\n\u5728\n\u7ec8\u7aef\n\u8f93\u5165\uff1a\n\n\n\n\n sudo gedit /etc/bash.bashrc\n\n\n\n\n\u5728\nbash.bashrc\n\u6587\u4ef6\u4e2d\u6dfb\u52a0\uff1a\n\n\nexport CUDA_HOME=/usr/local/cuda-8.0\nexport PATH=/usr/local/cuda-8.0/bin${PATH:+:${PATH}}\nexport LD_LIBRARY_PATH=/usr/local/cuda-8.0/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}\n\n\n\n\n\u4e4b\u540e\nsource gedit /etc/.bashrc\n\u5373\u53ef\n\u540c\u6837\uff0c\u5728\n\u7ec8\u7aef\n\u8f93\u5165\uff1a\n\n\n sudo gedit ~/.bashrc\n\n\n\n\n\u5728\n.bashrc\n\u4e2d\u6dfb\u52a0\u5982\u4e0a\u76f8\u540c\u5185\u5bb9\n\uff08\u5982\u679c\u60a8\u4f7f\u7528\u7684\u662f\nzsh\n\uff0c\u5728\n~/.zshrc\n\u6dfb\u52a0\u5373\u53ef\uff09\n\n\n\n\n\u6d4b\u8bd5\n\u5728\n\u7ec8\u7aef\n\u8f93\u5165\uff1a\n\n\n\n\n nvcc -V \n\n\n\n\n\u4f1a\u5f97\u5230\u76f8\u5e94\u7684nvcc\u7f16\u8bd1\u5668\u76f8\u5e94\u7684\u4fe1\u606f\uff0c\u90a3\u4e48CUDA\u914d\u7f6e\u6210\u529f\u4e86\u3002\n\u8bb0\u5f97\u91cd\u542f\u7cfb\u7edf\n\n\n4. \u52a0\u901f\u5e93cuDNN\uff08\u53ef\u9009\uff09\n\n\n\u4ece\u5b98\u7f51\u4e0b\u8f7d\u9700\u8981\u6ce8\u518c\u8d26\u53f7\u7533\u8bf7\uff0c\u4e24\u4e09\u5929\u6279\u51c6\u3002\u7f51\u76d8\u641c\u7d22\u4e00\u822c\u4e5f\u80fd\u627e\u5230\u6700\u65b0\u7248\u3002 \nLinux\u76ee\u524d\u5c31\u662fcudnn-8.0-win-x64-v5.1-prod.zip\u3002 \n\u4e0b\u8f7d\u89e3\u538b\u51fa\u6765\u662f\u540d\u4e3acuda\u7684\u6587\u4ef6\u5939\uff0c\u91cc\u9762\u6709bin\u3001include\u3001lib\uff0c\u5c06\u4e09\u4e2a\u6587\u4ef6\u5939\u590d\u5236\u5230\u5b89\u88c5CUDA\u7684\u5730\u65b9\u8986\u76d6\u5bf9\u5e94\u6587\u4ef6\u5939\uff0c\u5728\u7ec8\u7aef\u4e2d\u8f93\u5165\uff1a\n\n\n sudo cp include/cudnn.h /usr/local/cuda-8.0/include/\n\n sudo cp lib64/* /usr/local/cuda-8.0/lib64/\n\n\n\n\nKeras\u6846\u67b6\u642d\u5efa\n\n\n\u76f8\u5173\u5f00\u53d1\u5305\u5b89\u88c5\n\n\n\u5728\n\u7ec8\u7aef\n\u4e2d\u8f93\u5165:\n\n\n sudo pip install -U --pre pip setuptools wheel\n\n sudo pip install -U --pre numpy scipy matplotlib scikit-learn scikit-image\n\n sudo pip install -U --pre theano\n\n sudo pip install -U --pre keras\n\n\n\n\n\u5b89\u88c5\u5b8c\u6bd5\u540e\uff0c\u8f93\u5165\npython\n\uff0c\u7136\u540e\u8f93\u5165\uff1a\n\n\n import theano\n\n import keras\n\n\n\n\n\u5982\u679c\u6ca1\u6709\u4efb\u4f55\u63d0\u793a\uff0c\u5219\u8868\u660e\u5b89\u88c5\u5df2\u7ecf\u6210\u529f\n\n\nKeras\u73af\u5883\u8bbe\u7f6e\n\n\n\n\n\u4fee\u6539\u9ed8\u8ba4keras\u540e\u7aef\n\u5728\n\u7ec8\u7aef\n\u4e2d\u8f93\u5165:\n\n\n\n\n gedit ~/.keras/keras.json\n\n\n\n\n\n\n\u914d\u7f6etheano\u6587\u4ef6\n\u5728\n\u7ec8\u7aef\n\u4e2d\u8f93\u5165:\n\n\n\n\n gedit ~/.theanorc\n\n\n\n\n\u5e76\u5199\u5165\u4ee5\u4e0b\uff1a\n\n\n[global]\nopenmp=False \ndevice = gpu   \nfloatX = float32  \nallow_input_downcast=True  \n[lib]\ncnmem = 0.8 \n[blas]\nldflags= -lopenblas\n[nvcc]\nfastmath = True  \n\n\n\n\n\u5982\u679c\u60a8\u7684\u6240\u5b89\u88c5\u7684\u662fCPU\u52a0\u901f\u7248\u672c\uff0c\u90a3\u4e48\n.theanorc\n\u6587\u4ef6\u914d\u7f6e\u5982\u4e0b\uff1a\n\n\n[global]\nopenmp=True \ndevice = cpu \nfloatX = float32  \nallow_input_downcast=True  \n[blas]\nldflags= -lopenblas \n\n\n\n\n\u4e4b\u540e\u53ef\u4ee5\u9a8c\u8bc1keras\u662f\u5426\u5b89\u88c5\u6210\u529f,\u5728\u547d\u4ee4\u884c\u4e2d\u8f93\u5165Python\u547d\u4ee4\u8fdb\u5165Python\u53d8\u6210\u547d\u4ee4\u884c\u73af\u5883\uff1a\n\n\nimport keras\n\n\n\n\n\u6ca1\u6709\u62a5\u9519\uff0c\u5e76\u4e14\u4f1a\u6253\u5370\u51fa\u5173\u4e8e\u663e\u5361\u4fe1\u606f\u4ee5\u53ca\ncnmem\n\u7b49\u4fe1\u606f\uff08CPU\u7248\u672c\u6ca1\u6709\uff09\u90a3\u4e48Keras\u5c31\u5df2\u7ecf\n\u6210\u529f\u5b89\u88c5\n\u4e86\u3002\n\n\n\u52a0\u901f\u6d4b\u8bd5\n\n\n\u901f\u5ea6\u6d4b\u8bd5\n\n\n\u65b0\u5efa\u4e00\u4e2a\u6587\u4ef6\ntest.py\n\uff0c\u5185\u5bb9\u4e3a\uff1a\n\n\nfrom theano import function, config, shared, sandbox\nimport theano.tensor as T\nimport numpy\nimport time\n\nvlen = 10 * 30 * 768  # 10 x #cores x # threads per core  \niters = 1000\n\nrng = numpy.random.RandomState(22)\nx = shared(numpy.asarray(rng.rand(vlen), config.floatX))\nf = function([], T.exp(x))\nprint(f.maker.fgraph.toposort())\nt0 = time.time()\nfor i in range(iters):\n    r = f()\nt1 = time.time()\nprint(\nLooping %d times took %f seconds\n % (iters, t1 - t0))\nprint(\nResult is %s\n % (r,))\nif numpy.any([isinstance(x.op, T.Elemwise) for x in f.maker.fgraph.toposort()]):\n    print('Used the cpu')\nelse:\n    print('Used the gpu')\n\n\n\n\n\u5728GTX 970\u663e\u5361\u4e0b\uff0c\u8f93\u51fa\u7ed3\u679c\u5927\u6982\u662f0.21\u79d2\uff0c\u5728\u4e00\u767e\u500d\u8fd0\u7b97\u91cf\u4e0b19\u79d2\uff0c\u53ef\u4ee5\u8fdb\u884c\u5bf9\u6bd4\u3002\n\u7406\u8bba\u4e0a\uff0c\u76f8\u6bd4\u8f83\u4e3b\u9891\u4e3a3.3GHz\u7684CPU\uff0c\u52a0\u901f\u6bd4\u5e94\u8be5\u662f75\u500d\uff0c\u4f46\u4e0d\u540c\u7684ssd\u548c\u5185\u5b58\u9650\u5236\u4e86IO\u63a5\u53e3\u4f20\u8f93\u901f\u5ea6\u3002\n\n\nKeras\u4e2dmnist\u6570\u636e\u96c6\u6d4b\u8bd5\n\n\n\u4e0b\u8f7dKeras\u5f00\u53d1\u5305\n\n\ngit clone https://github.com/fchollet/keras.git\ncd keras/examples/\npython mnist_mlp.py\n\n\n\n\n\u7a0b\u5e8f\u65e0\u9519\u8fdb\u884c\uff0c\u81f3\u6b64\uff0ckeras\u5b89\u88c5\u5b8c\u6210\u3002\n\n\n\u58f0\u660e\u4e0e\u8054\u7cfb\u65b9\u5f0f\n\n\n\u7531\u4e8e\u4f5c\u8005\u6c34\u5e73\u548c\u7814\u7a76\u65b9\u5411\u6240\u9650\uff0c\u65e0\u6cd5\u5bf9\u6240\u6709\u6a21\u5757\u90fd\u975e\u5e38\u7cbe\u901a\uff0c\u56e0\u6b64\u6587\u6863\u4e2d\u4e0d\u53ef\u907f\u514d\u7684\u4f1a\u51fa\u73b0\u5404\u79cd\u9519\u8bef\u3001\u758f\u6f0f\u548c\u4e0d\u8db3\u4e4b\u5904\u3002\u5982\u679c\u60a8\u5728\u4f7f\u7528\u8fc7\u7a0b\u4e2d\u6709\u4efb\u4f55\u610f\u89c1\u3001\u5efa\u8bae\u548c\u7591\u95ee\uff0c\u6b22\u8fce\u53d1\u9001\u90ae\u4ef6\u5230scp173.cool@gmail.com\u4e0e\u4f5c\u8005\u53d6\u5f97\u8054\u7cfb.\n\n\n\u672c\u6559\u7a0b\u4e0d\u5f97\u7528\u4e8e\u4efb\u4f55\u5f62\u5f0f\u7684\u5546\u4e1a\u7528\u9014\uff0c\u5982\u679c\u9700\u8981\u8f6c\u8f7d\u8bf7\u4e0e\u4f5c\u8005\u6216\u4e2d\u6587\u6587\u6863\u4f5c\u8005\u8054\u7cfb\uff0c\u5982\u679c\u53d1\u73b0\u672a\u7ecf\u5141\u8bb8\u590d\u5236\u8f6c\u8f7d\uff0c\u5c06\u4fdd\u7559\u8ffd\u6c42\u5176\u6cd5\u5f8b\u8d23\u4efb\u7684\u6743\u5229\u3002\n\n\n\u4f5c\u8005\uff1a\nSCP-173\n\nE-mail \uff1ascp173.cool@gmail.com\n\n\u5982\u679c\u60a8\u9700\u8981\u53ca\u65f6\u5f97\u5230\u6307\u5bfc\u5e2e\u52a9\uff0c\u53ef\u4ee5\u52a0\u5fae\u4fe1\uff1aSCP173-cool\uff0c\u914c\u60c5\u6253\u8d4f\u5373\u53ef", 
            "title": "Keras\u5b89\u88c5\u548c\u914d\u7f6e\u6307\u5357(Linux)"
        }, 
        {
            "location": "/getting_started/keras_linux/#_1", 
            "text": "\u672c\u6559\u7a0b\u4e0d\u5f97\u7528\u4e8e\u4efb\u4f55\u5f62\u5f0f\u7684\u5546\u4e1a\u7528\u9014\uff0c\u5982\u679c\u9700\u8981\u8f6c\u8f7d\u8bf7\u4e0e\u4f5c\u8005SCP-173\u8054\u7cfb\uff0c\u5982\u679c\u53d1\u73b0\u672a\u7ecf\u5141\u8bb8\u590d\u5236\u8f6c\u8f7d\uff0c\u5c06\u4fdd\u7559\u8ffd\u6c42\u5176\u6cd5\u5f8b\u8d23\u4efb\u7684\u6743\u5229\u3002", 
            "title": "\u58f0\u660e"
        }, 
        {
            "location": "/getting_started/keras_linux/#_2", 
            "text": "", 
            "title": "\u5173\u4e8e\u8ba1\u7b97\u673a\u7684\u786c\u4ef6\u914d\u7f6e\u8bf4\u660e"
        }, 
        {
            "location": "/getting_started/keras_linux/#_3", 
            "text": "\u5982\u679c\u60a8\u662f\u9ad8\u6821\u5b66\u751f\u6216\u8005\u9ad8\u7ea7\u7814\u7a76\u4eba\u5458\uff0c\u5e76\u4e14\u5b9e\u9a8c\u5ba4\u6216\u8005\u4e2a\u4eba\u8d44\u91d1\u5145\u6c9b\uff0c\u5efa\u8bae\u60a8\u91c7\u7528\u5982\u4e0b\u914d\u7f6e\uff1a   \u4e3b\u677f\uff1aX99\u578b\u53f7\u6216Z170\u578b\u53f7  CPU\uff1ai7-5830K\u6216i7-6700K \u53ca\u5176\u4ee5\u4e0a\u9ad8\u7ea7\u578b\u53f7  \u5185\u5b58\uff1a\u54c1\u724c\u5185\u5b58\uff0c\u603b\u5bb9\u91cf32G\u4ee5\u4e0a\uff0c\u6839\u636e\u4e3b\u677f\u7ec4\u62104\u901a\u9053\u62168\u901a\u9053  SSD\uff1a\u54c1\u724c\u56fa\u6001\u786c\u76d8\uff0c\u5bb9\u91cf256G\u4ee5\u4e0a  \u663e\u5361\uff1a NVIDIA GTX 1080 Ti\u3001NVIDIA GTX 1080\u3001NVIDIA GTX 1070\u3001NVIDIA GTX 1060 (\u987a\u5e8f\u4e3a\u4f18\u5148\u5efa\u8bae\uff0c\u5e76\u4e14\u5efa\u8bae\u540c\u4e00\u663e\u5361\uff0c\u53ef\u4ee5\u6839\u636e\u4e3b\u677f\u63d2\u69fd\u6570\u91cf\u8d2d\u4e70\u591a\u5757\uff0c\u4f8b\u5982X99\u578b\u53f7\u4e3b\u677f\u6700\u591a\u53ef\u4ee5\u91c7\u7528\u00d74\u7684\u663e\u5361)  \u7535\u6e90\uff1a\u7531\u4e3b\u673a\u673a\u5bb9\u91cf\u7684\u786e\u5b9a\uff0c\u4e00\u822c\u6709\u663e\u5361\u603b\u5bb9\u91cf\u540e\u518d\u52a0200W\u5373\u53ef", 
            "title": "\u63a8\u8350\u914d\u7f6e"
        }, 
        {
            "location": "/getting_started/keras_linux/#_4", 
            "text": "\u5982\u679c\u60a8\u662f\u4ec5\u4ec5\u7528\u4e8e\u81ea\u5b66\u6216\u4ee3\u7801\u8c03\u8bd5\uff0c\u4ea6\u6216\u662f\u6761\u4ef6\u6240\u9650\u4ec5\u91c7\u7528\u81ea\u5df1\u73b0\u6709\u7684\u8bbe\u5907\u8fdb\u884c\u5f00\u53d1\uff0c\u90a3\u4e48\u60a8\u7684\u7535\u8111\u81f3\u5c11\u6ee1\u8db3\u4ee5\u4e0b\u51e0\u70b9\uff1a   CPU\uff1aIntel\u7b2c\u4e09\u4ee3i5\u548ci7\u4ee5\u4e0a\u7cfb\u5217\u4ea7\u54c1\u6216\u540c\u6027\u80fdAMD\u516c\u53f8\u4ea7\u54c1  \u5185\u5b58\uff1a\u603b\u5bb9\u91cf4G\u4ee5\u4e0a", 
            "title": "\u6700\u4f4e\u914d\u7f6e"
        }, 
        {
            "location": "/getting_started/keras_linux/#cpu", 
            "text": "\u5927\u591a\u6570CPU\u76ee\u524d\u652f\u6301\u591a\u6838\u591a\u7ebf\u7a0b\uff0c\u90a3\u4e48\u5982\u679c\u60a8\u91c7\u7528CPU\u52a0\u901f\uff0c\u5c31\u53ef\u4ee5\u4f7f\u7528\u591a\u7ebf\u7a0b\u8fd0\u7b97\u3002\u8fd9\u65b9\u9762\u7684\u4f18\u52bf\u5bf9\u4e8e\u670d\u52a1\u5668CPU\u96c6\u7fa4\u548c\u591a\u6838\u5e76\u884cCPU\u5c24\u4e3a\u5173\u952e", 
            "title": "CPU\u8bf4\u660e"
        }, 
        {
            "location": "/getting_started/keras_linux/#_5", 
            "text": "\u5982\u679c\u60a8\u7684\u663e\u5361\u662f\u975eNVIDIA\u516c\u53f8\u7684\u4ea7\u54c1\u6216\u662fNVIDIA GTX\u7cfb\u5217\u4e2d\u578b\u53f7\u7684\u7b2c\u4e00\u4e2a\u6570\u5b57\u4f4e\u4e8e4\u6216NVIDIA\u7684GT\u7cfb\u5217\uff0c\u90fd\u4e0d\u5efa\u8bae\u60a8\u91c7\u7528\u6b64\u7c7b\u663e\u5361\u8fdb\u884c\u52a0\u901f\u8ba1\u7b97\uff0c\u4f8b\u5982 NVIDIA GT 910 \u3001 NVIDIA GTX 450  \u7b49\u7b49\u3002  \u5982\u679c\u60a8\u7684\u663e\u5361\u4e3a\u7b14\u8bb0\u672c\u4e0a\u7684GTX\u79fb\u52a8\u663e\u5361\uff08\u578b\u53f7\u540e\u9762\u5e26\u6709\u6807\u8bc6M\uff09\uff0c\u90a3\u4e48\u8bf7\u60a8\u614e\u91cd\u4f7f\u7528\u663e\u5361\u52a0\u901f\uff0c\u56e0\u4e3a\u79fb\u52a8\u7248GPU\u5f88\u5bb9\u6613\u53d1\u751f\u8fc7\u70ed\u70e7\u6bc1\u73b0\u8c61\u3002  \u5982\u679c\u60a8\u7684\u663e\u5361\uff0c\u663e\u793a\u7684\u662f\u8bf8\u5982  HD5000 , ATI 5650  \u7b49\u7c7b\u578b\u7684\u663e\u5361\uff0c\u90a3\u4e48\u60a8\u53ea\u80fd\u4f7f\u7528CPU\u52a0\u901f  \u5982\u679c\u60a8\u7684\u663e\u5361\u4e3aPascal\u67b6\u6784\u7684\u663e\u5361\uff08 NVIDIA GTX 1080 , NVIDIA GTX 1070 \u7b49\uff09\uff0c\u60a8\u53ea\u80fd\u5728\u4e4b\u540e\u7684\u914d\u7f6e\u4e2d\u9009\u62e9 CUDA 8.0", 
            "title": "\u663e\u5361\u8bf4\u660e"
        }, 
        {
            "location": "/getting_started/keras_linux/#_6", 
            "text": "", 
            "title": "\u57fa\u672c\u5f00\u53d1\u73af\u5883\u642d\u5efa"
        }, 
        {
            "location": "/getting_started/keras_linux/#1-linux", 
            "text": "linux\u6709\u5f88\u591a\u53d1\u884c\u7248\uff0c\u672c\u6587\u5f3a\u70c8\u5efa\u8bae\u8bfb\u8005\u91c7\u7528\u65b0\u7248\u7684 Ubuntu 16.04 LTS \n\u4e00\u65b9\u9762\uff0c\u5bf9\u4e8e\u5927\u591a\u6570\u65b0\u624b\u6765\u8bf4Ubuntu\u5177\u6709\u5f88\u597d\u7684\u56fe\u5f62\u754c\u9762\uff0c\u4e0e\u4e50\u89c2\u7684\u5f00\u6e90\u793e\u533a\uff1b\u53e6\u4e00\u65b9\u9762\uff0cUbuntu\u662fNvidia\u5b98\u65b9\u4ee5\u53ca\u7edd\u5927\u591a\u6570\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u9ed8\u8ba4\u5f00\u53d1\u73af\u5883\u3002\n\u4e2a\u4eba\u4e0d\u5efa\u8bae\u4f7f\u7528Ubuntu Kylin\uff0c\u4e4b\u524d\u63d0\u51fa\u6709\u90e8\u5206\u4fe1\u606f\u8868\u793a\uff0c\u4e2d\u56fd\u5b98\u65b9\u5f00\u53d1\u7684\u8fd9\u4e2a\u7248\u672c\u6709\u90e8\u5206\u529f\u80fd\u88ab\u201c\u9609\u5272\u201d\uff0c\u4f60\u61c2\u5f97\u3002\nUbuntu 16.04 LTS\u4e0b\u8f7d\u5730\u5740\uff1a  http://www.ubuntu.org.cn/download/desktop   \u901a\u8fc7U\u76d8\u5b89\u88c5\u597d\u540e\uff0c\u8fdb\u884c\u521d\u59cb\u5316\u73af\u5883\u8bbe\u7f6e\u3002", 
            "title": "1. Linux \u53d1\u884c\u7248"
        }, 
        {
            "location": "/getting_started/keras_linux/#2-ubuntu", 
            "text": "\u5b89\u88c5\u5f00\u53d1\u5305\n\u6253\u5f00 \u7ec8\u7aef \u8f93\u5165\uff1a   # \u7cfb\u7edf\u5347\u7ea7  sudo apt update  sudo apt upgrade\n# \u5b89\u88c5python\u57fa\u7840\u5f00\u53d1\u5305  sudo apt install -y python-dev python-pip python-nose gcc g++ git gfortran vim   \u5b89\u88c5\u8fd0\u7b97\u52a0\u901f\u5e93\n\u6253\u5f00 \u7ec8\u7aef \u8f93\u5165\uff1a    sudo apt install -y libopenblas-dev liblapack-dev libatlas-base-dev", 
            "title": "2. Ubuntu\u521d\u59cb\u73af\u5883\u8bbe\u7f6e"
        }, 
        {
            "location": "/getting_started/keras_linux/#3-cudacpu", 
            "text": "\u5982\u679c\u60a8\u7684\u4ec5\u4ec5\u91c7\u7528cpu\u52a0\u901f\uff0c\u53ef\u8df3\u8fc7\u6b64\u6b65\u9aa4 \n- \u4e0b\u8f7dCUDA8.0  \u4e0b\u8f7d\u5730\u5740\uff1a  https://developer.nvidia.com/cuda-downloads   \u4e4b\u540e\u6253\u5f00 \u7ec8\u7aef \u8f93\u5165\uff1a   sudo dpkg -i cuda-repo-ubuntu1604-8-0-local_8.0.44-1_amd64.deb  sudo apt update  sudo apt install cuda  \u81ea\u52a8\u914d\u7f6e\u6210\u529f\u5c31\u597d\u3002   \u5c06CUDA\u8def\u5f84\u6dfb\u52a0\u81f3\u73af\u5883\u53d8\u91cf\n\u5728 \u7ec8\u7aef \u8f93\u5165\uff1a    sudo gedit /etc/bash.bashrc  \u5728 bash.bashrc \u6587\u4ef6\u4e2d\u6dfb\u52a0\uff1a  export CUDA_HOME=/usr/local/cuda-8.0\nexport PATH=/usr/local/cuda-8.0/bin${PATH:+:${PATH}}\nexport LD_LIBRARY_PATH=/usr/local/cuda-8.0/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}  \u4e4b\u540e source gedit /etc/.bashrc \u5373\u53ef\n\u540c\u6837\uff0c\u5728 \u7ec8\u7aef \u8f93\u5165\uff1a   sudo gedit ~/.bashrc  \u5728 .bashrc \u4e2d\u6dfb\u52a0\u5982\u4e0a\u76f8\u540c\u5185\u5bb9\n\uff08\u5982\u679c\u60a8\u4f7f\u7528\u7684\u662f zsh \uff0c\u5728 ~/.zshrc \u6dfb\u52a0\u5373\u53ef\uff09   \u6d4b\u8bd5\n\u5728 \u7ec8\u7aef \u8f93\u5165\uff1a    nvcc -V   \u4f1a\u5f97\u5230\u76f8\u5e94\u7684nvcc\u7f16\u8bd1\u5668\u76f8\u5e94\u7684\u4fe1\u606f\uff0c\u90a3\u4e48CUDA\u914d\u7f6e\u6210\u529f\u4e86\u3002\n\u8bb0\u5f97\u91cd\u542f\u7cfb\u7edf", 
            "title": "3. CUDA\u5f00\u53d1\u73af\u5883\u7684\u642d\u5efa(CPU\u52a0\u901f\u8df3\u8fc7)"
        }, 
        {
            "location": "/getting_started/keras_linux/#4-cudnn", 
            "text": "\u4ece\u5b98\u7f51\u4e0b\u8f7d\u9700\u8981\u6ce8\u518c\u8d26\u53f7\u7533\u8bf7\uff0c\u4e24\u4e09\u5929\u6279\u51c6\u3002\u7f51\u76d8\u641c\u7d22\u4e00\u822c\u4e5f\u80fd\u627e\u5230\u6700\u65b0\u7248\u3002 \nLinux\u76ee\u524d\u5c31\u662fcudnn-8.0-win-x64-v5.1-prod.zip\u3002 \n\u4e0b\u8f7d\u89e3\u538b\u51fa\u6765\u662f\u540d\u4e3acuda\u7684\u6587\u4ef6\u5939\uff0c\u91cc\u9762\u6709bin\u3001include\u3001lib\uff0c\u5c06\u4e09\u4e2a\u6587\u4ef6\u5939\u590d\u5236\u5230\u5b89\u88c5CUDA\u7684\u5730\u65b9\u8986\u76d6\u5bf9\u5e94\u6587\u4ef6\u5939\uff0c\u5728\u7ec8\u7aef\u4e2d\u8f93\u5165\uff1a   sudo cp include/cudnn.h /usr/local/cuda-8.0/include/  sudo cp lib64/* /usr/local/cuda-8.0/lib64/", 
            "title": "4. \u52a0\u901f\u5e93cuDNN\uff08\u53ef\u9009\uff09"
        }, 
        {
            "location": "/getting_started/keras_linux/#keras", 
            "text": "", 
            "title": "Keras\u6846\u67b6\u642d\u5efa"
        }, 
        {
            "location": "/getting_started/keras_linux/#_7", 
            "text": "\u5728 \u7ec8\u7aef \u4e2d\u8f93\u5165:   sudo pip install -U --pre pip setuptools wheel  sudo pip install -U --pre numpy scipy matplotlib scikit-learn scikit-image  sudo pip install -U --pre theano  sudo pip install -U --pre keras  \u5b89\u88c5\u5b8c\u6bd5\u540e\uff0c\u8f93\u5165 python \uff0c\u7136\u540e\u8f93\u5165\uff1a   import theano  import keras  \u5982\u679c\u6ca1\u6709\u4efb\u4f55\u63d0\u793a\uff0c\u5219\u8868\u660e\u5b89\u88c5\u5df2\u7ecf\u6210\u529f", 
            "title": "\u76f8\u5173\u5f00\u53d1\u5305\u5b89\u88c5"
        }, 
        {
            "location": "/getting_started/keras_linux/#keras_1", 
            "text": "\u4fee\u6539\u9ed8\u8ba4keras\u540e\u7aef\n\u5728 \u7ec8\u7aef \u4e2d\u8f93\u5165:    gedit ~/.keras/keras.json   \u914d\u7f6etheano\u6587\u4ef6\n\u5728 \u7ec8\u7aef \u4e2d\u8f93\u5165:    gedit ~/.theanorc  \u5e76\u5199\u5165\u4ee5\u4e0b\uff1a  [global]\nopenmp=False \ndevice = gpu   \nfloatX = float32  \nallow_input_downcast=True  \n[lib]\ncnmem = 0.8 \n[blas]\nldflags= -lopenblas\n[nvcc]\nfastmath = True    \u5982\u679c\u60a8\u7684\u6240\u5b89\u88c5\u7684\u662fCPU\u52a0\u901f\u7248\u672c\uff0c\u90a3\u4e48 .theanorc \u6587\u4ef6\u914d\u7f6e\u5982\u4e0b\uff1a  [global]\nopenmp=True \ndevice = cpu \nfloatX = float32  \nallow_input_downcast=True  \n[blas]\nldflags= -lopenblas   \u4e4b\u540e\u53ef\u4ee5\u9a8c\u8bc1keras\u662f\u5426\u5b89\u88c5\u6210\u529f,\u5728\u547d\u4ee4\u884c\u4e2d\u8f93\u5165Python\u547d\u4ee4\u8fdb\u5165Python\u53d8\u6210\u547d\u4ee4\u884c\u73af\u5883\uff1a  import keras  \u6ca1\u6709\u62a5\u9519\uff0c\u5e76\u4e14\u4f1a\u6253\u5370\u51fa\u5173\u4e8e\u663e\u5361\u4fe1\u606f\u4ee5\u53ca cnmem \u7b49\u4fe1\u606f\uff08CPU\u7248\u672c\u6ca1\u6709\uff09\u90a3\u4e48Keras\u5c31\u5df2\u7ecf \u6210\u529f\u5b89\u88c5 \u4e86\u3002", 
            "title": "Keras\u73af\u5883\u8bbe\u7f6e"
        }, 
        {
            "location": "/getting_started/keras_linux/#_8", 
            "text": "", 
            "title": "\u52a0\u901f\u6d4b\u8bd5"
        }, 
        {
            "location": "/getting_started/keras_linux/#_9", 
            "text": "\u65b0\u5efa\u4e00\u4e2a\u6587\u4ef6 test.py \uff0c\u5185\u5bb9\u4e3a\uff1a  from theano import function, config, shared, sandbox\nimport theano.tensor as T\nimport numpy\nimport time\n\nvlen = 10 * 30 * 768  # 10 x #cores x # threads per core  \niters = 1000\n\nrng = numpy.random.RandomState(22)\nx = shared(numpy.asarray(rng.rand(vlen), config.floatX))\nf = function([], T.exp(x))\nprint(f.maker.fgraph.toposort())\nt0 = time.time()\nfor i in range(iters):\n    r = f()\nt1 = time.time()\nprint( Looping %d times took %f seconds  % (iters, t1 - t0))\nprint( Result is %s  % (r,))\nif numpy.any([isinstance(x.op, T.Elemwise) for x in f.maker.fgraph.toposort()]):\n    print('Used the cpu')\nelse:\n    print('Used the gpu')  \u5728GTX 970\u663e\u5361\u4e0b\uff0c\u8f93\u51fa\u7ed3\u679c\u5927\u6982\u662f0.21\u79d2\uff0c\u5728\u4e00\u767e\u500d\u8fd0\u7b97\u91cf\u4e0b19\u79d2\uff0c\u53ef\u4ee5\u8fdb\u884c\u5bf9\u6bd4\u3002\n\u7406\u8bba\u4e0a\uff0c\u76f8\u6bd4\u8f83\u4e3b\u9891\u4e3a3.3GHz\u7684CPU\uff0c\u52a0\u901f\u6bd4\u5e94\u8be5\u662f75\u500d\uff0c\u4f46\u4e0d\u540c\u7684ssd\u548c\u5185\u5b58\u9650\u5236\u4e86IO\u63a5\u53e3\u4f20\u8f93\u901f\u5ea6\u3002", 
            "title": "\u901f\u5ea6\u6d4b\u8bd5"
        }, 
        {
            "location": "/getting_started/keras_linux/#kerasmnist", 
            "text": "\u4e0b\u8f7dKeras\u5f00\u53d1\u5305  git clone https://github.com/fchollet/keras.git\ncd keras/examples/\npython mnist_mlp.py  \u7a0b\u5e8f\u65e0\u9519\u8fdb\u884c\uff0c\u81f3\u6b64\uff0ckeras\u5b89\u88c5\u5b8c\u6210\u3002", 
            "title": "Keras\u4e2dmnist\u6570\u636e\u96c6\u6d4b\u8bd5"
        }, 
        {
            "location": "/getting_started/keras_linux/#_10", 
            "text": "\u7531\u4e8e\u4f5c\u8005\u6c34\u5e73\u548c\u7814\u7a76\u65b9\u5411\u6240\u9650\uff0c\u65e0\u6cd5\u5bf9\u6240\u6709\u6a21\u5757\u90fd\u975e\u5e38\u7cbe\u901a\uff0c\u56e0\u6b64\u6587\u6863\u4e2d\u4e0d\u53ef\u907f\u514d\u7684\u4f1a\u51fa\u73b0\u5404\u79cd\u9519\u8bef\u3001\u758f\u6f0f\u548c\u4e0d\u8db3\u4e4b\u5904\u3002\u5982\u679c\u60a8\u5728\u4f7f\u7528\u8fc7\u7a0b\u4e2d\u6709\u4efb\u4f55\u610f\u89c1\u3001\u5efa\u8bae\u548c\u7591\u95ee\uff0c\u6b22\u8fce\u53d1\u9001\u90ae\u4ef6\u5230scp173.cool@gmail.com\u4e0e\u4f5c\u8005\u53d6\u5f97\u8054\u7cfb.  \u672c\u6559\u7a0b\u4e0d\u5f97\u7528\u4e8e\u4efb\u4f55\u5f62\u5f0f\u7684\u5546\u4e1a\u7528\u9014\uff0c\u5982\u679c\u9700\u8981\u8f6c\u8f7d\u8bf7\u4e0e\u4f5c\u8005\u6216\u4e2d\u6587\u6587\u6863\u4f5c\u8005\u8054\u7cfb\uff0c\u5982\u679c\u53d1\u73b0\u672a\u7ecf\u5141\u8bb8\u590d\u5236\u8f6c\u8f7d\uff0c\u5c06\u4fdd\u7559\u8ffd\u6c42\u5176\u6cd5\u5f8b\u8d23\u4efb\u7684\u6743\u5229\u3002  \u4f5c\u8005\uff1a SCP-173 \nE-mail \uff1ascp173.cool@gmail.com \u5982\u679c\u60a8\u9700\u8981\u53ca\u65f6\u5f97\u5230\u6307\u5bfc\u5e2e\u52a9\uff0c\u53ef\u4ee5\u52a0\u5fae\u4fe1\uff1aSCP173-cool\uff0c\u914c\u60c5\u6253\u8d4f\u5373\u53ef", 
            "title": "\u58f0\u660e\u4e0e\u8054\u7cfb\u65b9\u5f0f"
        }, 
        {
            "location": "/getting_started/keras_windows/", 
            "text": "\u58f0\u660e\n\n\n\u672c\u6559\u7a0b\u4e0d\u5f97\u7528\u4e8e\u4efb\u4f55\u5f62\u5f0f\u7684\u5546\u4e1a\u7528\u9014\uff0c\u5982\u679c\u9700\u8981\u8f6c\u8f7d\u8bf7\u4e0e\u4f5c\u8005SCP-173\u8054\u7cfb\uff0c\u5982\u679c\u53d1\u73b0\u672a\u7ecf\u5141\u8bb8\u590d\u5236\u8f6c\u8f7d\uff0c\u5c06\u4fdd\u7559\u8ffd\u6c42\u5176\u6cd5\u5f8b\u8d23\u4efb\u7684\u6743\u5229\u3002\n\n\n\n\n\u8fd9\u91cc\u9700\u8981\u8bf4\u660e\u4e00\u4e0b\uff0c\u7b14\u8005\n\u4e0d\u5efa\u8bae\u5728Windows\u73af\u5883\u4e0b\u8fdb\u884c\u6df1\u5ea6\u5b66\u4e60\u7684\u7814\u7a76\n\uff0c\u4e00\u65b9\u9762\u662f\u56e0\u4e3aWindows\u6240\u5bf9\u5e94\u7684\u6846\u67b6\u642d\u5efa\u7684\u4f9d\u8d56\u8fc7\u591a\uff0c\u793e\u533a\u8bbe\u5b9a\u4e0d\u5b8c\u5168\uff1b\u53e6\u4e00\u65b9\u9762\uff0cLinux\u7cfb\u7edf\u4e0b\u5bf9\u663e\u5361\u652f\u6301\u3001\u5185\u5b58\u91ca\u653e\u4ee5\u53ca\u5b58\u50a8\u7a7a\u95f4\u8c03\u6574\u7b49\u786c\u4ef6\u529f\u80fd\u652f\u6301\u8f83\u597d\u3002\u5982\u679c\u60a8\u5bf9Linux\u73af\u5883\u611f\u5230\u964c\u751f\uff0c\u5e76\u4e14\u5927\u591a\u6570\u5f00\u53d1\u73af\u5883\u5728Windows\u4e0b\u66f4\u65b9\u4fbf\u64cd\u4f5c\u7684\u8bdd\uff0c\u5e0c\u671b\u8fd9\u7bc7\u6587\u7ae0\u5bf9\u60a8\u4f1a\u6709\u5e2e\u52a9\u3002\n\n\n\n\n\u5173\u4e8e\u8ba1\u7b97\u673a\u7684\u786c\u4ef6\u914d\u7f6e\u8bf4\u660e\n\n\n\u63a8\u8350\u914d\u7f6e\n\n\n\u5982\u679c\u60a8\u662f\u9ad8\u6821\u5b66\u751f\u6216\u8005\u9ad8\u7ea7\u7814\u7a76\u4eba\u5458\uff0c\u5e76\u4e14\u5b9e\u9a8c\u5ba4\u6216\u8005\u4e2a\u4eba\u8d44\u91d1\u5145\u6c9b\uff0c\u5efa\u8bae\u60a8\u91c7\u7528\u5982\u4e0b\u914d\u7f6e\uff1a\n\n\n\n\n\u4e3b\u677f\uff1aX99\u578b\u53f7\u6216Z170\u578b\u53f7\n\n\nCPU\uff1ai7-5830K\u6216i7-6700K \u53ca\u5176\u4ee5\u4e0a\u9ad8\u7ea7\u578b\u53f7\n\n\n\u5185\u5b58\uff1a\u54c1\u724c\u5185\u5b58\uff0c\u603b\u5bb9\u91cf32G\u4ee5\u4e0a\uff0c\u6839\u636e\u4e3b\u677f\u7ec4\u62104\u901a\u9053\u62168\u901a\u9053\n\n\nSSD\uff1a\u54c1\u724c\u56fa\u6001\u786c\u76d8\uff0c\u5bb9\u91cf256G\u4ee5\u4e0a\n\n\n\u663e\u5361\uff1aNVIDIA GTX 1080 Ti\u3001NVIDIA GTX 1080\u3001NVIDIA GTX 1070\u3001NVIDIA GTX 1060 (\u987a\u5e8f\u4e3a\u4f18\u5148\u5efa\u8bae\uff0c\u5e76\u4e14\u5efa\u8bae\u540c\u4e00\u663e\u5361\uff0c\u53ef\u4ee5\u6839\u636e\u4e3b\u677f\u63d2\u69fd\u6570\u91cf\u8d2d\u4e70\u591a\u5757\uff0c\u4f8b\u5982X99\u578b\u53f7\u4e3b\u677f\u6700\u591a\u53ef\u4ee5\u91c7\u7528\u00d74\u7684\u663e\u5361)\n\n\n\u7535\u6e90\uff1a\u7531\u4e3b\u673a\u673a\u5bb9\u91cf\u7684\u786e\u5b9a\uff0c\u4e00\u822c\u6709\u663e\u5361\u603b\u5bb9\u91cf\u540e\u518d\u52a0200W\u5373\u53ef\n\n\n\n\n\u6700\u4f4e\u914d\u7f6e\n\n\n\u5982\u679c\u60a8\u662f\u4ec5\u4ec5\u7528\u4e8e\u81ea\u5b66\u6216\u4ee3\u7801\u8c03\u8bd5\uff0c\u4ea6\u6216\u662f\u6761\u4ef6\u6240\u9650\u4ec5\u91c7\u7528\u81ea\u5df1\u73b0\u6709\u7684\u8bbe\u5907\u8fdb\u884c\u5f00\u53d1\uff0c\u90a3\u4e48\u60a8\u7684\u7535\u8111\u81f3\u5c11\u6ee1\u8db3\u4ee5\u4e0b\u51e0\u70b9\uff1a\n\n\n\n\nCPU\uff1aIntel\u7b2c\u4e09\u4ee3i5\u548ci7\u4ee5\u4e0a\u7cfb\u5217\u4ea7\u54c1\u6216\u540c\u6027\u80fdAMD\u516c\u53f8\u4ea7\u54c1\n\n\n\u5185\u5b58\uff1a\u603b\u5bb9\u91cf4G\u4ee5\u4e0a\n\n\n\n\nCPU\u8bf4\u660e\n\n\n\n\n\u5927\u591a\u6570CPU\u76ee\u524d\u652f\u6301\u591a\u6838\u591a\u7ebf\u7a0b\uff0c\u90a3\u4e48\u5982\u679c\u60a8\u91c7\u7528CPU\u52a0\u901f\uff0c\u5c31\u53ef\u4ee5\u4f7f\u7528\u591a\u7ebf\u7a0b\u8fd0\u7b97\u3002\u8fd9\u65b9\u9762\u7684\u4f18\u52bf\u5bf9\u4e8e\u670d\u52a1\u5668CPU\u96c6\u7fa4\u548c\u591a\u6838\u5e76\u884cCPU\u5c24\u4e3a\u5173\u952e\n\n\n\n\n\u663e\u5361\u8bf4\u660e\n\n\n\n\n\u5982\u679c\u60a8\u7684\u663e\u5361\u662f\u975eNVIDIA\u516c\u53f8\u7684\u4ea7\u54c1\u6216\u662fNVIDIA GTX\u7cfb\u5217\u4e2d\u578b\u53f7\u7684\u7b2c\u4e00\u4e2a\u6570\u5b57\u4f4e\u4e8e4\u6216NVIDIA\u7684GT\u7cfb\u5217\uff0c\u90fd\u4e0d\u5efa\u8bae\u60a8\u91c7\u7528\u6b64\u7c7b\u663e\u5361\u8fdb\u884c\u52a0\u901f\u8ba1\u7b97\uff0c\u4f8b\u5982\nNVIDIA GT 910\n\u3001\nNVIDIA GTX 450\n \u7b49\u7b49\u3002\n\n\n\u5982\u679c\u60a8\u7684\u663e\u5361\u4e3a\u7b14\u8bb0\u672c\u4e0a\u7684GTX\u79fb\u52a8\u663e\u5361\uff08\u578b\u53f7\u540e\u9762\u5e26\u6709\u6807\u8bc6M\uff09\uff0c\u90a3\u4e48\u8bf7\u60a8\u614e\u91cd\u4f7f\u7528\u663e\u5361\u52a0\u901f\uff0c\u56e0\u4e3a\u79fb\u52a8\u7248GPU\u5f88\u5bb9\u6613\u53d1\u751f\u8fc7\u70ed\u70e7\u6bc1\u73b0\u8c61\u3002\n\n\n\u5982\u679c\u60a8\u7684\u663e\u5361\uff0c\u663e\u793a\u7684\u662f\u8bf8\u5982 \nHD5000\n,\nATI 5650\n \u7b49\u7c7b\u578b\u7684\u663e\u5361\uff0c\u90a3\u4e48\u60a8\u53ea\u80fd\u4f7f\u7528CPU\u52a0\u901f\n\n\n\u5982\u679c\u60a8\u7684\u663e\u5361\u4e3aPascal\u67b6\u6784\u7684\u663e\u5361\uff08\nNVIDIA GTX 1080\n,\nNVIDIA GTX 1070\n\u7b49\uff09\uff0c\u60a8\u53ea\u80fd\u5728\u4e4b\u540e\u7684\u914d\u7f6e\u4e2d\u9009\u62e9\nVisual Studio 2015\n\u548c\nCUDA 8.0\n\n\n\n\n\u57fa\u672c\u5f00\u53d1\u73af\u5883\u642d\u5efa\n\n\n1. Microsoft Windows \u7248\u672c\n\n\n\u5173\u4e8eWindows\u7684\u7248\u672c\u9009\u62e9\uff0c\u672c\u4eba\u5f3a\u70c8\u5efa\u8bae\u5bf9\u4e8e\u90e8\u5206\u9ad8\u6027\u80fd\u7684\u65b0\u673a\u5668\u91c7\u7528\nWindows 10\n\u4f5c\u4e3a\u57fa\u7840\u73af\u5883\uff0c\u90e8\u5206\u8001\u65e7\u7b14\u8bb0\u672c\u6216\u4f4e\u6027\u80fd\u673a\u5668\u91c7\u7528\nWindows 7\n\u5373\u53ef\uff0c\u672c\u6587\u73af\u5883\u5c06\u4ee5\nWindows 10\n\u4f5c\u4e3a\u5f00\u53d1\u73af\u5883\u8fdb\u884c\u63cf\u8ff0\u3002\u5bf9\u4e8eWindows 10\u7684\u53d1\u884c\u7248\u672c\u9009\u62e9\uff0c\u7b14\u8005\u5efa\u8bae\u91c7\u7528\nWindows_10_enterprise_2016_ltsb_x64\n\u4f5c\u4e3a\u57fa\u7840\u73af\u5883\u3002\n\n\n\u8fd9\u91cc\u63a8\u8350\u5230\nMSDN\u6211\u544a\u8bc9\u4f60\n\u4e0b\u8f7d\uff0c\u4e5f\u611f\u8c22\u4f5c\u8005\u56fd\u5185\u4f18\u79c0\u4f5c\u8005\n\u96ea\u9f99\u72fc\u524d\u8f88\n\u6240\u505a\u51fa\u7684\u8d21\u732e\u3002\n\n\n\n\n\u76f4\u63a5\u8d34\u51fa\u70ed\u94fe\uff0c\u590d\u5236\u7c98\u8d34\u8fc5\u96f7\u4e0b\u8f7d\uff1a\n\n\ned2k://|file|cn_windows_10_enterprise_2016_ltsb_x64_dvd_9060409.iso|3821895680|FF17FF2D5919E3A560151BBC11C399D1|/\n\n\n\n\n2. \u7f16\u8bd1\u73af\u5883Microsoft Visual Studio 2010 - 2015\n\n\n(\u5b89\u88c5CPU\u7248\u672c\u975e\u5fc5\u987b\u5b89\u88c5)\n\n\nCUDA\u7f16\u8bd1\u5668\u4e3aMicrosoft Visual Studio\uff0c\u7248\u672c\u4ece2010-2015\uff0c\u5176\u4e2d\ncuda7.5\n\u4ec5\u652f\u63012010\u30012012\u30012013\uff0c\ncuda8.0\n\u4ec5\u652f\u63012015\u7248\u672c\uff0c\u672c\u6587\u91c7\u7528\nVisual Studio 2015 Update 3\n\u3002\n\u540c\u6837\u76f4\u63a5\u8d34\u51fa\u8fc5\u96f7\u70ed\u94fe\uff1a\n\n\ned2k://|file|cn_visual_studio_professional_2015_with_update_3_x86_x64_dvd_8923256.iso|7745202176|DD35D3D169D553224BE5FB44E074ED5E|/\n\n\n\n\n\n\n3. Python\u73af\u5883\n\n\npython\u73af\u5883\u5efa\u8bbe\u63a8\u8350\u4f7f\u7528\u79d1\u5b66\u8ba1\u7b97\u96c6\u6210python\u53d1\u884c\u7248\nAnaconda\n\uff0cAnaconda\u662fPython\u4f17\u591a\u53d1\u884c\u7248\u4e2d\u975e\u5e38\u9002\u7528\u4e8e\u79d1\u5b66\u8ba1\u7b97\u7684\u7248\u672c\uff0c\u91cc\u9762\u5df2\u7ecf\u96c6\u6210\u4e86\u5f88\u591a\u4f18\u79c0\u7684\u79d1\u5b66\u8ba1\u7b97Python\u5e93\u3002\n\u5bf9\u4e8e\u641e\u79d1\u5b66\u8ba1\u7b97\u4e0e\u6df1\u5ea6\u5b66\u4e60\u7684\u670b\u53cb\u4eec\uff0c\u5efa\u8bae\u5b89\u88c5\nAnconda2.7\n\u7248\u672c\uff0c\u5982\u679c\u60a8\u559c\u6b22\u4f7f\u7528\nAnaconda3.5\n\u7248\u672c\u4e5f\u6ca1\u6709\u592a\u5927\u95ee\u9898\uff0c\u5173\u4e8e\u5f88\u591a\u65e9\u671f\u7684python3.5\u4e0d\u517c\u5bb9\u95ee\u9898\u73b0\u5728\u5df2\u7ecf\u5168\u90e8\u89e3\u51b3\uff0c\u672c\u6587\u9ed8\u8ba4\u4f7f\u7528\nAnaconda2.7\n\n\n\u4e0b\u8f7d\u5730\u5740\uff1a \nAnaconda\n\n\n4. GCC\u7f16\u8bd1\u73af\u5883\n\n\ngcc/g++\u662fWindows\u73af\u5883\u4e0eLinux\u73af\u5883\u975e\u5e38\u5927\u7684\u4e00\u4e2a\u5dee\u522b\u70b9\u3002\u4e0d\u7ba1\u662fcpu\u7248\u672c\u8fd8\u662fgpu\u7248\u672c\u90fd\u9700\u8981\u5b89\u88c5GCC\u7f16\u8bd1\u73af\u5883\u3002\n\u672c\u6587\u63d0\u4f9b\u4e24\u79cd\u89e3\u51b3\u65b9\u6848\uff1a\n\n\n\n\nMinGW\n    Minimalist GNU for Windows\uff0c\u5b89\u88c5\u597dAnaconda\u4e4b\u540e\u5728CMD\u6216\u8005Powershell\u4e2d\u8f93\u5165\uff1a\n\n\n\n\nconda install mingw libpython\n\n\n\n\n\n\nMSYS2\n    \u4e00\u90e8\u5206\u8bfb\u8005\u81ea\u5df1\u672c\u8eab\u5df2\u7ecf\u5177\u6709\u4e86Python\u73af\u5883\uff0c\u518d\u5b89\u88c5Anaconda\u4f1a\u9020\u6210\u5f88\u5927\u7684\u4e0d\u4fbf\uff0c\u90a3\u4e48\u672c\u6587\u63a8\u8350\u5b89\u88c5MSYS2\uff0c\u7f51\u7ad9\u4e0a\u6709\u8be6\u7ec6\u7684\u5982\u4f55\u5b89\u88c5\u7684\u8bf4\u660e\uff0c\u672c\u6587\u4e0d\u518d\u8d58\u8ff0\u3002 \n\n\n\n\n5. CUDA\n\n\n(\u4ec5\u4f7f\u7528CPU\u7248\u672c\u4e0d\u5fc5\u5b89\u88c5)\n\nCUDA Toolkit\u662fNVIDIA\u516c\u53f8\u9762\u5411GPU\u7f16\u7a0b\u63d0\u4f9b\u7684\u57fa\u7840\u5de5\u5177\u5305\uff0c\u4e5f\u662f\u9a71\u52a8\u663e\u5361\u8ba1\u7b97\u7684\u6838\u5fc3\u6280\u672f\u5de5\u5177\u3002\n\u76f4\u63a5\u5b89\u88c5CUDA8.0\u5373\u53ef\n\u4e0b\u8f7d\u5730\u5740\uff1a\nhttps://developer.nvidia.com/cuda-downloads\n\n\n\u5728\u4e0b\u8f7d\u4e4b\u540e\uff0c\u6309\u7167\u6b65\u9aa4\u5b89\u88c5\uff0c\n\u4e0d\u5efa\u8bae\u65b0\u624b\u4fee\u6539\u5b89\u88c5\u76ee\u5f55\n\uff0c\u540c\u4e0a\uff0c\u73af\u5883\u4e0d\u9700\u8981\u914d\u7f6e\uff0c\u5b89\u88c5\u7a0b\u5e8f\u4f1a\u81ea\u52a8\u914d\u7f6e\u597d\u3002\n\n\n6. \uff08\u53ef\u9009\uff09\u52a0\u901f\u5e93CuDNN\n\n\n\u4ece\u5b98\u7f51\u4e0b\u8f7d\u9700\u8981\u6ce8\u518c\u8d26\u53f7\u7533\u8bf7\uff0c\u4e24\u4e09\u5929\u6279\u51c6\u3002\u7f51\u76d8\u641c\u7d22\u4e00\u822c\u4e5f\u80fd\u627e\u5230\u6700\u65b0\u7248\u3002 \nWindows\u76ee\u524d\u5c31\u662fcudnn-7.0-win-x64-v5.0-prod.zip\u3002 \n\u4e0b\u8f7d\u89e3\u538b\u51fa\u6765\u662f\u540d\u4e3acuda\u7684\u6587\u4ef6\u5939\uff0c\u91cc\u9762\u6709bin\u3001include\u3001lib\uff0c\u5c06\u4e09\u4e2a\u6587\u4ef6\u5939\u590d\u5236\u5230\u5b89\u88c5CUDA\u7684\u5730\u65b9\u8986\u76d6\u5bf9\u5e94\u6587\u4ef6\u5939\uff0c\u9ed8\u8ba4\u6587\u4ef6\u5939\u5728\uff1a\nC:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\n\n\n\n\nKeras \u6846\u67b6\u642d\u5efa\n\n\n\u5b89\u88c5\n\n\nKeras\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u662f\u57fa\u4e8eTheano\u6216Tensorflow\u6846\u67b6\u5b89\u88c5\u7684\uff0c\u6240\u4ee5\u9996\u5148\u8981\u51c6\u5907\u5e95\u5c42\u6846\u67b6\u7684\u642d\u5efa\uff0c\u7136\u800c\u76ee\u524dTensorflow\u4e0d\u652f\u6301Windows\u7248\u672c\uff0c\u6240\u4ee5\u672c\u6587\u9009\u7528Theano\u5b89\u88c5\u5373\u53ef\n\n\u5728CMD\u547d\u4ee4\u884c\u6216\u8005Powershell\u4e2d\u8f93\u5165\uff1a\n\n\npip install theano -U --pre\npip install keras -U --pre\n\n\n\n\n\u6216\u8005\u60f3\u8981\u52a0\u901f\u5f00\u53d1\u7248\u672c\uff0c\u7528\uff08\u524d\u63d0\u662f\u5df2\u7ecfgit, conda install git\uff09\n\n\npip install --upgrade --no-deps git+git://github.com/Theano/Theano.git\n\n\n\n\n\u73af\u5883\u914d\u7f6e\n\n\n\u5728\u6211\u7684\u7535\u8111\u4e0a\u53f3\u952e-\n\u5c5e\u6027-\n\u9ad8\u7ea7-\n\u73af\u5883\u53d8\u91cf-\n\u7cfb\u7edf\u53d8\u91cf\u4e2d\u7684path\uff0c\u6dfb\u52a0\n\n\nC:\\Anaconda2;C:\\Anaconda2\\Scripts;C:\\Anaconda2\\MinGW\n\\bin;C:\\Anaconda2\\MinGW\\x86_64-w64-mingw32\\lib;\n\n\n\n\n\u6ce8\u610f\n\uff0c\u672c\u6587\u5c06Anaconda\u5b89\u88c5\u81f3C\u76d8\u6839\u76ee\u5f55\uff0c\u6839\u636e\u81ea\u5df1\u7684\u60c5\u51b5\u8fdb\u884c\u4fee\u6539\uff1b\u53e6\u5916\u5728\u4e4b\u524d\u5b89\u88c5gcc/g++\u65f6\u91c7\u7528MSYS2\u65b9\u5f0f\u5b89\u88c5\u7684\uff0c\u4fee\u6539\u5e76\u91cd\u65b0\u5b9a\u4f4dMinGW\u6587\u4ef6\u5939\uff0c\u5e76\u505a\u76f8\u5e94\u4fee\u6539\u3002\n\n\n\u4e4b\u540e\u5e76\u65b0\u5efa\u53d8\u91cfPYTHONPATH\uff0c\u5e76\u6dfb\u52a0\n\n\nC:\\Anaconda2\\Lib\\site-packages\\theano;\n\n\n\n\n\n\n\n\u4fee\u6539\u9ed8\u8ba4\u540e\u7aef\n\n\n\n\n\u6253\u5f00\nC:\\Users\\\u5f53\u524d\u7528\u6237\u540d\\.keras\n,\u4fee\u6539\u6587\u4ef6\u5939\u5185\u7684\nkeras.json\n\u6587\u4ef6\u5982\u4e0b\uff1a\n\n\n{\n\nimage_dim_ordering\n:\nth\n,\n\nepsilon\n:1e-07,\n\nfloatx\n:\nfloat32\n,\n\nbackend\n:\ntheano\n\n}\n\n\n\n\n\n\n\nTheano\u52a0\u901f\u914d\u7f6e\n\u5728\u7528\u6237\u76ee\u5f55\uff0c\u4e5f\u5c31\u662f\nC:\\Users\\\u5f53\u524d\u7528\u6237\u540d\\\n\uff0c\u65b0\u5efa\n.theanorc.txt\n\u3002 \u8fd9\u4e2a\u8def\u5f84\u53ef\u4ee5\u901a\u8fc7\u4fee\u6539Theano\u7684configparser.py\u6765\u6539\u53d8\u3002Theano\u88c5\u5728Anaconda\\Lib\\site-packages\u91cc .theanorc.txt\u7684\u5185\u5bb9\uff1a\n\n\n\n\n[global]\nopenmp=False \ndevice = gpu   \noptimizer_including=cudnn #\u4e0d\u7528cudnn\u7684\u8bdd\u5c31\u4e0d\u8981\u8fd9\u53e5\uff0c\u5b9e\u9645\u4e0a\u4e0d\u7528\u52a0\uff0c\u53ea\u8981\u521a\u521a\u914d\u7f6e\u5230\u4f4d\u5c31\u884c  \nfloatX = float32  \nallow_input_downcast=True  \n[lib]\ncnmem = 0.8  #theano\u9ed1\u79d1\u6280\uff0c\u521d\u59cb\u5316\u663e\u5b58\u6bd4\u4f8b\n[blas]\nldflags=   #\u52a0\u901f\u5e93\n[gcc]\ncxxflags=-IC:\\Anaconda2\\MinGW  \n[nvcc]\nfastmath = True  \n--flags=-LC:\\Anaconda2\\libs #\u6539\u6210\u81ea\u5df1\u88c5\u7684\u76ee\u5f55\n--compiler_bindir=D:\\Microsoft Visual Studio 12.0\\VC\\bin #\u6539\u6210\u81ea\u5df1\u88c5\u7684\u76ee\u5f55\n#\u6700\u540e\u8bb0\u5f97\u628a\u6c49\u5b57\u5168\u5220\u4e86\n\n\n\n\n\u5982\u679c\u60a8\u7684\u6240\u5b89\u88c5\u7684\u662fCPU\u52a0\u901f\u7248\u672c\uff0c\u90a3\u4e48\n.theanorc.txt\n\u6587\u4ef6\u914d\u7f6e\u5982\u4e0b\uff1a\n\n\n[global]\nopenmp=True \ndevice = cpu \nfloatX = float32  \nallow_input_downcast=True  \n[gcc]\ncxxflags=-IC:\\Anaconda2\\MinGW \n\n\n\n\n\u4e4b\u540e\u53ef\u4ee5\u9a8c\u8bc1keras\u662f\u5426\u5b89\u88c5\u6210\u529f,\u5728\u547d\u4ee4\u884c\u4e2d\u8f93\u5165Python\u547d\u4ee4\u8fdb\u5165Python\u53d8\u6210\u547d\u4ee4\u884c\u73af\u5883\uff1a\n\n\nimport keras\nUsing Theano(Tensorflow) backend.\n\n\n\n\n\n\n\u6ca1\u6709\u62a5\u9519\uff0c\u90a3\u4e48Keras\u5c31\u5df2\u7ecf\n\u6210\u529f\u5b89\u88c5\n\u4e86\n\n\n\u52a0\u901f\u6d4b\u8bd5\n\n\n\u73af\u5883\u6d4b\u8bd5\n\n\n\u5728\u547d\u4ee4\u884c\u4e2d\u8fdb\u5165Python\u73af\u5883\uff0c\u8f93\u5165\uff1a\n\n\nimport theano\n\n\n\n\n\u4f1a\u51fa\u73b0\u4e00\u7cfb\u5217\u4fe1\u606f\uff0c\u5305\u62ec\u663e\u5361\u578b\u53f7\u3001\u6d6e\u70b9\u6570\u7c7b\u578b\u3001\u662f\u5426\u91c7\u7528CNmem\u548ccuDNN\uff08\u5982\u679c\u4f7f\u7528\u4e86\u7684\u8bdd\uff09\u7b49\u7b49\uff0c\u90a3\u4e48\u606d\u559c\u4f60\uff0c\u73af\u5883\u5f7b\u5e95\u914d\u7f6e\u6210\u529f\u3002\n\u5982\u679c\u4f7f\u7528\u4e86Windows\u7cfb\u7edf\u7684\u8bfb\u8005\uff0c\u7535\u8111\u4e0a\u53ef\u80fd\u4f1a\u51fa\u73b0\uff0cdebug\u7684\u5b57\u6837\uff0c\u8fd9\u662f\u7b2c\u4e00\u6b21\u4f7f\u7528\uff0c\u5728\u7f16\u8bd1\u751f\u6210\u8fd0\u884c\u5e93\uff0c\u5c5e\u4e8e\u6b63\u5e38\u73b0\u8c61\u3002\n\n\n\u52a0\u901f\u5e93\u6d4b\u8bd5\n\n\nPython\u73af\u5883\u4e0b\u8f93\u5165\uff1a\n\n\nimport numpy \nid(numpy.dot) == id(numpy.core.multiarray.dot) \n\n\n\n\n\u5982\u679c\u5f97\u5230\u7684\u7ed3\u679c\u4e3a\nFalse\n\uff0c\u8bf4\u660e\u4f60\u7684\u9664\u4e86gpu\u52a0\u901f\u8fd8\u5f97\u5230\u4e86\u6570\u5b66\u5e93blas\u52a0\u901f\uff0c\u6309\u7167\u6559\u7a0b\u987a\u5e8f\u914d\u7f6e\u7684Linux\u7528\u6237\u662f\u4e00\u5b9a\u53ef\u4ee5\u5f97\u5230False\u7ed3\u679c\u7684\uff1bWindows\u7528\u6237\u5f97\u5230\nTrue\n\u4e5f\u6ca1\u6709\u5173\u7cfb\uff0c\u56e0\u4e3aAnaconda\u4e2d\u5df2\u7ecf\u5185\u7f6e\u4e86MKL\u52a0\u901f\u5e93\uff0c\u5982\u679c\u60f3\u4f7f\u7528Openblas\u53ef\u4ee5\u6309\u7167\u6587\u672b\u7684\u8054\u7cfb\u65b9\u5f0f\u8054\u7cfb\u6211\u3002\n\n\n\u901f\u5ea6\u6d4b\u8bd5\n\n\n\u65b0\u5efa\u4e00\u4e2a\u6587\u4ef6\ntest.py\n\uff0c\u5185\u5bb9\u4e3a\uff1a\n\n\nfrom theano import function, config, shared, sandbox\nimport theano.tensor as T\nimport numpy\nimport time\n\nvlen = 10 * 30 * 768  # 10 x #cores x # threads per core #\u8fd9\u91cc\u53ef\u4ee5\u52a0\u4e00\u4e24\u4e2a0\uff0c\u591a\u6d4b\u8bd5\u4e00\u4e0b\uff0c\u8bb0\u5f97\u53bb\u6389\u6c49\u5b57 \niters = 1000\n\nrng = numpy.random.RandomState(22)\nx = shared(numpy.asarray(rng.rand(vlen), config.floatX))\nf = function([], T.exp(x))\nprint(f.maker.fgraph.toposort())\nt0 = time.time()\nfor i in xrange(iters):\n    r = f()\nt1 = time.time()\nprint(\nLooping %d times took %f seconds\n % (iters, t1 - t0))\nprint(\nResult is %s\n % (r,))\nif numpy.any([isinstance(x.op, T.Elemwise) for x in f.maker.fgraph.toposort()]):\n    print('Used the cpu')\nelse:\n    print('Used the gpu')\n\n\n\n\n\u5728GTX 970\u663e\u5361\u4e0b\uff0c\u8f93\u51fa\u7ed3\u679c\u5927\u6982\u662f0.21\u79d2\uff0c\u5728\u4e00\u767e\u500d\u8fd0\u7b97\u91cf\u4e0b19\u79d2\uff0c\u53ef\u4ee5\u8fdb\u884c\u5bf9\u6bd4\u3002\n\u7406\u8bba\u4e0a\uff0c\u76f8\u6bd4\u8f83\u4e3b\u9891\u4e3a3.3GHz\u7684CPU\uff0c\u52a0\u901f\u6bd4\u5e94\u8be5\u662f75\u500d\uff0c\u4f46\u4e0d\u540c\u7684ssd\u548c\u5185\u5b58\u9650\u5236\u4e86IO\u63a5\u53e3\u4f20\u8f93\u901f\u5ea6\u3002\n\n\nKeras\u4e2dmnist\u6570\u636e\u96c6\u6d4b\u8bd5\n\n\n\u4e0b\u8f7dKeras\u5f00\u53d1\u5305\n\n\ngit clone https://github.com/fchollet/keras.git\ncd keras/examples/\npython mnist_mlp.py\n\n\n\n\n\u7a0b\u5e8f\u65e0\u9519\u8fdb\u884c\uff0c\u81f3\u6b64\uff0ckeras\u5b89\u88c5\u5b8c\u6210\u3002\n\n\n\u4e00\u4e2aAnaconda3\u4e2d\u914d\u7f6e\u9047\u5230\u7684\u5f02\u5e38\u89e3\u51b3\u65b9\u5f0f\n\n\n\u76ee\u524d\u53d1\u73b0\u4f7f\u7528Anaconda3\u5b89\u88c5theano\u65f6\u53ef\u80fd\u4f1a\u6709\u4e00\u4e2a\u51b2\u7a81\uff1a\n\n\nAttributeError\uff1amodule \u2018configparser\u2019 has no attribute \u2018SafeConfigParser\u2019\n\n\n\n\n\u6682\u65f6\u53ea\u6709\u7528\u4ee5\u4e0b\u65b9\u6cd5\u5904\u7406\uff1a\n\n\n\u5bf9Anaconda3\\Lib\\site-packages\\theano\\configparser.py\u66f4\u6539\u6587\u4ef6\u540d\uff0c\u6bd4\u5982\u6539\u4e3aconfig_parser.py\uff0c\u5728pycharm\u6216\u5176\u4ed6IDE\u4e2d\u968f\u610f\u8fd0\u884c\u4e00\u4e2acnn\u811a\u672c\uff0c\u5bf9\u9047\u5230\u7684\u6bcf\u4e00\u4e2a\u63d0\u793a\u9519\u8bef\u624b\u52a8\u66f4\u6539\u5f15\u7528\u5230\u7684\u6587\u4ef6\u540d\u4e3atheano.config_parser\uff0c\u5728\u5c06\u6240\u6709\u5f15\u7528\u5230\u8fd9\u4e2a\u6587\u4ef6\u7684\u4f4d\u7f6e\u90fd\u6539\u6b63\u540e\uff0c\u5e94\u8be5\u5c31\u6ca1\u6709\u95ee\u9898\u4e86\u3002\n\n\n\u58f0\u660e\u4e0e\u8054\u7cfb\u65b9\u5f0f\n\n\n\u7531\u4e8e\u4f5c\u8005\u6c34\u5e73\u548c\u7814\u7a76\u65b9\u5411\u6240\u9650\uff0c\u65e0\u6cd5\u5bf9\u6240\u6709\u6a21\u5757\u90fd\u975e\u5e38\u7cbe\u901a\uff0c\u56e0\u6b64\u6587\u6863\u4e2d\u4e0d\u53ef\u907f\u514d\u7684\u4f1a\u51fa\u73b0\u5404\u79cd\u9519\u8bef\u3001\u758f\u6f0f\u548c\u4e0d\u8db3\u4e4b\u5904\u3002\u5982\u679c\u60a8\u5728\u4f7f\u7528\u8fc7\u7a0b\u4e2d\u6709\u4efb\u4f55\u610f\u89c1\u3001\u5efa\u8bae\u548c\u7591\u95ee\uff0c\u6b22\u8fce\u53d1\u9001\u90ae\u4ef6\u5230scp173.cool@gmail.com\u4e0e\u4e2d\u6587\u6587\u6863\u4f5c\u8005\u53d6\u5f97\u8054\u7cfb.\n\n\n\u672c\u6559\u7a0b\u4e0d\u5f97\u7528\u4e8e\u4efb\u4f55\u5f62\u5f0f\u7684\u5546\u4e1a\u7528\u9014\uff0c\u5982\u679c\u9700\u8981\u8f6c\u8f7d\u8bf7\u4e0e\u4f5c\u8005\u6216\u4e2d\u6587\u6587\u6863\u4f5c\u8005\u8054\u7cfb\uff0c\u5982\u679c\u53d1\u73b0\u672a\u7ecf\u5141\u8bb8\u590d\u5236\u8f6c\u8f7d\uff0c\u5c06\u4fdd\u7559\u8ffd\u6c42\u5176\u6cd5\u5f8b\u8d23\u4efb\u7684\u6743\u5229\u3002\n\n\n\u4f5c\u8005\uff1a\nSCP-173\n\nE-mail \uff1ascp173.cool@gmail.com\n\n\u5982\u679c\u60a8\u9700\u8981\u53ca\u65f6\u5f97\u5230\u6307\u5bfc\u5e2e\u52a9\uff0c\u53ef\u4ee5\u52a0\u5fae\u4fe1\uff1aSCP173-cool\uff0c\u914c\u60c5\u6253\u8d4f\u5373\u53ef", 
            "title": "Keras\u5b89\u88c5\u548c\u914d\u7f6e\u6307\u5357(Windows)"
        }, 
        {
            "location": "/getting_started/keras_windows/#_1", 
            "text": "\u672c\u6559\u7a0b\u4e0d\u5f97\u7528\u4e8e\u4efb\u4f55\u5f62\u5f0f\u7684\u5546\u4e1a\u7528\u9014\uff0c\u5982\u679c\u9700\u8981\u8f6c\u8f7d\u8bf7\u4e0e\u4f5c\u8005SCP-173\u8054\u7cfb\uff0c\u5982\u679c\u53d1\u73b0\u672a\u7ecf\u5141\u8bb8\u590d\u5236\u8f6c\u8f7d\uff0c\u5c06\u4fdd\u7559\u8ffd\u6c42\u5176\u6cd5\u5f8b\u8d23\u4efb\u7684\u6743\u5229\u3002   \u8fd9\u91cc\u9700\u8981\u8bf4\u660e\u4e00\u4e0b\uff0c\u7b14\u8005 \u4e0d\u5efa\u8bae\u5728Windows\u73af\u5883\u4e0b\u8fdb\u884c\u6df1\u5ea6\u5b66\u4e60\u7684\u7814\u7a76 \uff0c\u4e00\u65b9\u9762\u662f\u56e0\u4e3aWindows\u6240\u5bf9\u5e94\u7684\u6846\u67b6\u642d\u5efa\u7684\u4f9d\u8d56\u8fc7\u591a\uff0c\u793e\u533a\u8bbe\u5b9a\u4e0d\u5b8c\u5168\uff1b\u53e6\u4e00\u65b9\u9762\uff0cLinux\u7cfb\u7edf\u4e0b\u5bf9\u663e\u5361\u652f\u6301\u3001\u5185\u5b58\u91ca\u653e\u4ee5\u53ca\u5b58\u50a8\u7a7a\u95f4\u8c03\u6574\u7b49\u786c\u4ef6\u529f\u80fd\u652f\u6301\u8f83\u597d\u3002\u5982\u679c\u60a8\u5bf9Linux\u73af\u5883\u611f\u5230\u964c\u751f\uff0c\u5e76\u4e14\u5927\u591a\u6570\u5f00\u53d1\u73af\u5883\u5728Windows\u4e0b\u66f4\u65b9\u4fbf\u64cd\u4f5c\u7684\u8bdd\uff0c\u5e0c\u671b\u8fd9\u7bc7\u6587\u7ae0\u5bf9\u60a8\u4f1a\u6709\u5e2e\u52a9\u3002", 
            "title": "\u58f0\u660e"
        }, 
        {
            "location": "/getting_started/keras_windows/#_2", 
            "text": "", 
            "title": "\u5173\u4e8e\u8ba1\u7b97\u673a\u7684\u786c\u4ef6\u914d\u7f6e\u8bf4\u660e"
        }, 
        {
            "location": "/getting_started/keras_windows/#_3", 
            "text": "\u5982\u679c\u60a8\u662f\u9ad8\u6821\u5b66\u751f\u6216\u8005\u9ad8\u7ea7\u7814\u7a76\u4eba\u5458\uff0c\u5e76\u4e14\u5b9e\u9a8c\u5ba4\u6216\u8005\u4e2a\u4eba\u8d44\u91d1\u5145\u6c9b\uff0c\u5efa\u8bae\u60a8\u91c7\u7528\u5982\u4e0b\u914d\u7f6e\uff1a   \u4e3b\u677f\uff1aX99\u578b\u53f7\u6216Z170\u578b\u53f7  CPU\uff1ai7-5830K\u6216i7-6700K \u53ca\u5176\u4ee5\u4e0a\u9ad8\u7ea7\u578b\u53f7  \u5185\u5b58\uff1a\u54c1\u724c\u5185\u5b58\uff0c\u603b\u5bb9\u91cf32G\u4ee5\u4e0a\uff0c\u6839\u636e\u4e3b\u677f\u7ec4\u62104\u901a\u9053\u62168\u901a\u9053  SSD\uff1a\u54c1\u724c\u56fa\u6001\u786c\u76d8\uff0c\u5bb9\u91cf256G\u4ee5\u4e0a  \u663e\u5361\uff1aNVIDIA GTX 1080 Ti\u3001NVIDIA GTX 1080\u3001NVIDIA GTX 1070\u3001NVIDIA GTX 1060 (\u987a\u5e8f\u4e3a\u4f18\u5148\u5efa\u8bae\uff0c\u5e76\u4e14\u5efa\u8bae\u540c\u4e00\u663e\u5361\uff0c\u53ef\u4ee5\u6839\u636e\u4e3b\u677f\u63d2\u69fd\u6570\u91cf\u8d2d\u4e70\u591a\u5757\uff0c\u4f8b\u5982X99\u578b\u53f7\u4e3b\u677f\u6700\u591a\u53ef\u4ee5\u91c7\u7528\u00d74\u7684\u663e\u5361)  \u7535\u6e90\uff1a\u7531\u4e3b\u673a\u673a\u5bb9\u91cf\u7684\u786e\u5b9a\uff0c\u4e00\u822c\u6709\u663e\u5361\u603b\u5bb9\u91cf\u540e\u518d\u52a0200W\u5373\u53ef", 
            "title": "\u63a8\u8350\u914d\u7f6e"
        }, 
        {
            "location": "/getting_started/keras_windows/#_4", 
            "text": "\u5982\u679c\u60a8\u662f\u4ec5\u4ec5\u7528\u4e8e\u81ea\u5b66\u6216\u4ee3\u7801\u8c03\u8bd5\uff0c\u4ea6\u6216\u662f\u6761\u4ef6\u6240\u9650\u4ec5\u91c7\u7528\u81ea\u5df1\u73b0\u6709\u7684\u8bbe\u5907\u8fdb\u884c\u5f00\u53d1\uff0c\u90a3\u4e48\u60a8\u7684\u7535\u8111\u81f3\u5c11\u6ee1\u8db3\u4ee5\u4e0b\u51e0\u70b9\uff1a   CPU\uff1aIntel\u7b2c\u4e09\u4ee3i5\u548ci7\u4ee5\u4e0a\u7cfb\u5217\u4ea7\u54c1\u6216\u540c\u6027\u80fdAMD\u516c\u53f8\u4ea7\u54c1  \u5185\u5b58\uff1a\u603b\u5bb9\u91cf4G\u4ee5\u4e0a", 
            "title": "\u6700\u4f4e\u914d\u7f6e"
        }, 
        {
            "location": "/getting_started/keras_windows/#cpu", 
            "text": "\u5927\u591a\u6570CPU\u76ee\u524d\u652f\u6301\u591a\u6838\u591a\u7ebf\u7a0b\uff0c\u90a3\u4e48\u5982\u679c\u60a8\u91c7\u7528CPU\u52a0\u901f\uff0c\u5c31\u53ef\u4ee5\u4f7f\u7528\u591a\u7ebf\u7a0b\u8fd0\u7b97\u3002\u8fd9\u65b9\u9762\u7684\u4f18\u52bf\u5bf9\u4e8e\u670d\u52a1\u5668CPU\u96c6\u7fa4\u548c\u591a\u6838\u5e76\u884cCPU\u5c24\u4e3a\u5173\u952e", 
            "title": "CPU\u8bf4\u660e"
        }, 
        {
            "location": "/getting_started/keras_windows/#_5", 
            "text": "\u5982\u679c\u60a8\u7684\u663e\u5361\u662f\u975eNVIDIA\u516c\u53f8\u7684\u4ea7\u54c1\u6216\u662fNVIDIA GTX\u7cfb\u5217\u4e2d\u578b\u53f7\u7684\u7b2c\u4e00\u4e2a\u6570\u5b57\u4f4e\u4e8e4\u6216NVIDIA\u7684GT\u7cfb\u5217\uff0c\u90fd\u4e0d\u5efa\u8bae\u60a8\u91c7\u7528\u6b64\u7c7b\u663e\u5361\u8fdb\u884c\u52a0\u901f\u8ba1\u7b97\uff0c\u4f8b\u5982 NVIDIA GT 910 \u3001 NVIDIA GTX 450  \u7b49\u7b49\u3002  \u5982\u679c\u60a8\u7684\u663e\u5361\u4e3a\u7b14\u8bb0\u672c\u4e0a\u7684GTX\u79fb\u52a8\u663e\u5361\uff08\u578b\u53f7\u540e\u9762\u5e26\u6709\u6807\u8bc6M\uff09\uff0c\u90a3\u4e48\u8bf7\u60a8\u614e\u91cd\u4f7f\u7528\u663e\u5361\u52a0\u901f\uff0c\u56e0\u4e3a\u79fb\u52a8\u7248GPU\u5f88\u5bb9\u6613\u53d1\u751f\u8fc7\u70ed\u70e7\u6bc1\u73b0\u8c61\u3002  \u5982\u679c\u60a8\u7684\u663e\u5361\uff0c\u663e\u793a\u7684\u662f\u8bf8\u5982  HD5000 , ATI 5650  \u7b49\u7c7b\u578b\u7684\u663e\u5361\uff0c\u90a3\u4e48\u60a8\u53ea\u80fd\u4f7f\u7528CPU\u52a0\u901f  \u5982\u679c\u60a8\u7684\u663e\u5361\u4e3aPascal\u67b6\u6784\u7684\u663e\u5361\uff08 NVIDIA GTX 1080 , NVIDIA GTX 1070 \u7b49\uff09\uff0c\u60a8\u53ea\u80fd\u5728\u4e4b\u540e\u7684\u914d\u7f6e\u4e2d\u9009\u62e9 Visual Studio 2015 \u548c CUDA 8.0", 
            "title": "\u663e\u5361\u8bf4\u660e"
        }, 
        {
            "location": "/getting_started/keras_windows/#_6", 
            "text": "", 
            "title": "\u57fa\u672c\u5f00\u53d1\u73af\u5883\u642d\u5efa"
        }, 
        {
            "location": "/getting_started/keras_windows/#1-microsoft-windows", 
            "text": "\u5173\u4e8eWindows\u7684\u7248\u672c\u9009\u62e9\uff0c\u672c\u4eba\u5f3a\u70c8\u5efa\u8bae\u5bf9\u4e8e\u90e8\u5206\u9ad8\u6027\u80fd\u7684\u65b0\u673a\u5668\u91c7\u7528 Windows 10 \u4f5c\u4e3a\u57fa\u7840\u73af\u5883\uff0c\u90e8\u5206\u8001\u65e7\u7b14\u8bb0\u672c\u6216\u4f4e\u6027\u80fd\u673a\u5668\u91c7\u7528 Windows 7 \u5373\u53ef\uff0c\u672c\u6587\u73af\u5883\u5c06\u4ee5 Windows 10 \u4f5c\u4e3a\u5f00\u53d1\u73af\u5883\u8fdb\u884c\u63cf\u8ff0\u3002\u5bf9\u4e8eWindows 10\u7684\u53d1\u884c\u7248\u672c\u9009\u62e9\uff0c\u7b14\u8005\u5efa\u8bae\u91c7\u7528 Windows_10_enterprise_2016_ltsb_x64 \u4f5c\u4e3a\u57fa\u7840\u73af\u5883\u3002  \u8fd9\u91cc\u63a8\u8350\u5230 MSDN\u6211\u544a\u8bc9\u4f60 \u4e0b\u8f7d\uff0c\u4e5f\u611f\u8c22\u4f5c\u8005\u56fd\u5185\u4f18\u79c0\u4f5c\u8005 \u96ea\u9f99\u72fc\u524d\u8f88 \u6240\u505a\u51fa\u7684\u8d21\u732e\u3002   \u76f4\u63a5\u8d34\u51fa\u70ed\u94fe\uff0c\u590d\u5236\u7c98\u8d34\u8fc5\u96f7\u4e0b\u8f7d\uff1a  ed2k://|file|cn_windows_10_enterprise_2016_ltsb_x64_dvd_9060409.iso|3821895680|FF17FF2D5919E3A560151BBC11C399D1|/", 
            "title": "1. Microsoft Windows \u7248\u672c"
        }, 
        {
            "location": "/getting_started/keras_windows/#2-microsoft-visual-studio-2010-2015", 
            "text": "(\u5b89\u88c5CPU\u7248\u672c\u975e\u5fc5\u987b\u5b89\u88c5)  CUDA\u7f16\u8bd1\u5668\u4e3aMicrosoft Visual Studio\uff0c\u7248\u672c\u4ece2010-2015\uff0c\u5176\u4e2d cuda7.5 \u4ec5\u652f\u63012010\u30012012\u30012013\uff0c cuda8.0 \u4ec5\u652f\u63012015\u7248\u672c\uff0c\u672c\u6587\u91c7\u7528 Visual Studio 2015 Update 3 \u3002\n\u540c\u6837\u76f4\u63a5\u8d34\u51fa\u8fc5\u96f7\u70ed\u94fe\uff1a  ed2k://|file|cn_visual_studio_professional_2015_with_update_3_x86_x64_dvd_8923256.iso|7745202176|DD35D3D169D553224BE5FB44E074ED5E|/", 
            "title": "2. \u7f16\u8bd1\u73af\u5883Microsoft Visual Studio 2010 - 2015"
        }, 
        {
            "location": "/getting_started/keras_windows/#3-python", 
            "text": "python\u73af\u5883\u5efa\u8bbe\u63a8\u8350\u4f7f\u7528\u79d1\u5b66\u8ba1\u7b97\u96c6\u6210python\u53d1\u884c\u7248 Anaconda \uff0cAnaconda\u662fPython\u4f17\u591a\u53d1\u884c\u7248\u4e2d\u975e\u5e38\u9002\u7528\u4e8e\u79d1\u5b66\u8ba1\u7b97\u7684\u7248\u672c\uff0c\u91cc\u9762\u5df2\u7ecf\u96c6\u6210\u4e86\u5f88\u591a\u4f18\u79c0\u7684\u79d1\u5b66\u8ba1\u7b97Python\u5e93\u3002\n\u5bf9\u4e8e\u641e\u79d1\u5b66\u8ba1\u7b97\u4e0e\u6df1\u5ea6\u5b66\u4e60\u7684\u670b\u53cb\u4eec\uff0c\u5efa\u8bae\u5b89\u88c5 Anconda2.7 \u7248\u672c\uff0c\u5982\u679c\u60a8\u559c\u6b22\u4f7f\u7528 Anaconda3.5 \u7248\u672c\u4e5f\u6ca1\u6709\u592a\u5927\u95ee\u9898\uff0c\u5173\u4e8e\u5f88\u591a\u65e9\u671f\u7684python3.5\u4e0d\u517c\u5bb9\u95ee\u9898\u73b0\u5728\u5df2\u7ecf\u5168\u90e8\u89e3\u51b3\uff0c\u672c\u6587\u9ed8\u8ba4\u4f7f\u7528 Anaconda2.7  \u4e0b\u8f7d\u5730\u5740\uff1a  Anaconda", 
            "title": "3. Python\u73af\u5883"
        }, 
        {
            "location": "/getting_started/keras_windows/#4-gcc", 
            "text": "gcc/g++\u662fWindows\u73af\u5883\u4e0eLinux\u73af\u5883\u975e\u5e38\u5927\u7684\u4e00\u4e2a\u5dee\u522b\u70b9\u3002\u4e0d\u7ba1\u662fcpu\u7248\u672c\u8fd8\u662fgpu\u7248\u672c\u90fd\u9700\u8981\u5b89\u88c5GCC\u7f16\u8bd1\u73af\u5883\u3002\n\u672c\u6587\u63d0\u4f9b\u4e24\u79cd\u89e3\u51b3\u65b9\u6848\uff1a   MinGW\n    Minimalist GNU for Windows\uff0c\u5b89\u88c5\u597dAnaconda\u4e4b\u540e\u5728CMD\u6216\u8005Powershell\u4e2d\u8f93\u5165\uff1a   conda install mingw libpython   MSYS2\n    \u4e00\u90e8\u5206\u8bfb\u8005\u81ea\u5df1\u672c\u8eab\u5df2\u7ecf\u5177\u6709\u4e86Python\u73af\u5883\uff0c\u518d\u5b89\u88c5Anaconda\u4f1a\u9020\u6210\u5f88\u5927\u7684\u4e0d\u4fbf\uff0c\u90a3\u4e48\u672c\u6587\u63a8\u8350\u5b89\u88c5MSYS2\uff0c\u7f51\u7ad9\u4e0a\u6709\u8be6\u7ec6\u7684\u5982\u4f55\u5b89\u88c5\u7684\u8bf4\u660e\uff0c\u672c\u6587\u4e0d\u518d\u8d58\u8ff0\u3002", 
            "title": "4. GCC\u7f16\u8bd1\u73af\u5883"
        }, 
        {
            "location": "/getting_started/keras_windows/#5-cuda", 
            "text": "(\u4ec5\u4f7f\u7528CPU\u7248\u672c\u4e0d\u5fc5\u5b89\u88c5) \nCUDA Toolkit\u662fNVIDIA\u516c\u53f8\u9762\u5411GPU\u7f16\u7a0b\u63d0\u4f9b\u7684\u57fa\u7840\u5de5\u5177\u5305\uff0c\u4e5f\u662f\u9a71\u52a8\u663e\u5361\u8ba1\u7b97\u7684\u6838\u5fc3\u6280\u672f\u5de5\u5177\u3002\n\u76f4\u63a5\u5b89\u88c5CUDA8.0\u5373\u53ef\n\u4e0b\u8f7d\u5730\u5740\uff1a https://developer.nvidia.com/cuda-downloads  \u5728\u4e0b\u8f7d\u4e4b\u540e\uff0c\u6309\u7167\u6b65\u9aa4\u5b89\u88c5\uff0c \u4e0d\u5efa\u8bae\u65b0\u624b\u4fee\u6539\u5b89\u88c5\u76ee\u5f55 \uff0c\u540c\u4e0a\uff0c\u73af\u5883\u4e0d\u9700\u8981\u914d\u7f6e\uff0c\u5b89\u88c5\u7a0b\u5e8f\u4f1a\u81ea\u52a8\u914d\u7f6e\u597d\u3002", 
            "title": "5. CUDA"
        }, 
        {
            "location": "/getting_started/keras_windows/#6-cudnn", 
            "text": "\u4ece\u5b98\u7f51\u4e0b\u8f7d\u9700\u8981\u6ce8\u518c\u8d26\u53f7\u7533\u8bf7\uff0c\u4e24\u4e09\u5929\u6279\u51c6\u3002\u7f51\u76d8\u641c\u7d22\u4e00\u822c\u4e5f\u80fd\u627e\u5230\u6700\u65b0\u7248\u3002 \nWindows\u76ee\u524d\u5c31\u662fcudnn-7.0-win-x64-v5.0-prod.zip\u3002 \n\u4e0b\u8f7d\u89e3\u538b\u51fa\u6765\u662f\u540d\u4e3acuda\u7684\u6587\u4ef6\u5939\uff0c\u91cc\u9762\u6709bin\u3001include\u3001lib\uff0c\u5c06\u4e09\u4e2a\u6587\u4ef6\u5939\u590d\u5236\u5230\u5b89\u88c5CUDA\u7684\u5730\u65b9\u8986\u76d6\u5bf9\u5e94\u6587\u4ef6\u5939\uff0c\u9ed8\u8ba4\u6587\u4ef6\u5939\u5728\uff1a C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA", 
            "title": "6. \uff08\u53ef\u9009\uff09\u52a0\u901f\u5e93CuDNN"
        }, 
        {
            "location": "/getting_started/keras_windows/#keras", 
            "text": "", 
            "title": "Keras \u6846\u67b6\u642d\u5efa"
        }, 
        {
            "location": "/getting_started/keras_windows/#_7", 
            "text": "Keras\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u662f\u57fa\u4e8eTheano\u6216Tensorflow\u6846\u67b6\u5b89\u88c5\u7684\uff0c\u6240\u4ee5\u9996\u5148\u8981\u51c6\u5907\u5e95\u5c42\u6846\u67b6\u7684\u642d\u5efa\uff0c\u7136\u800c\u76ee\u524dTensorflow\u4e0d\u652f\u6301Windows\u7248\u672c\uff0c\u6240\u4ee5\u672c\u6587\u9009\u7528Theano\u5b89\u88c5\u5373\u53ef \n\u5728CMD\u547d\u4ee4\u884c\u6216\u8005Powershell\u4e2d\u8f93\u5165\uff1a  pip install theano -U --pre\npip install keras -U --pre  \u6216\u8005\u60f3\u8981\u52a0\u901f\u5f00\u53d1\u7248\u672c\uff0c\u7528\uff08\u524d\u63d0\u662f\u5df2\u7ecfgit, conda install git\uff09  pip install --upgrade --no-deps git+git://github.com/Theano/Theano.git", 
            "title": "\u5b89\u88c5"
        }, 
        {
            "location": "/getting_started/keras_windows/#_8", 
            "text": "\u5728\u6211\u7684\u7535\u8111\u4e0a\u53f3\u952e- \u5c5e\u6027- \u9ad8\u7ea7- \u73af\u5883\u53d8\u91cf- \u7cfb\u7edf\u53d8\u91cf\u4e2d\u7684path\uff0c\u6dfb\u52a0  C:\\Anaconda2;C:\\Anaconda2\\Scripts;C:\\Anaconda2\\MinGW\n\\bin;C:\\Anaconda2\\MinGW\\x86_64-w64-mingw32\\lib;  \u6ce8\u610f \uff0c\u672c\u6587\u5c06Anaconda\u5b89\u88c5\u81f3C\u76d8\u6839\u76ee\u5f55\uff0c\u6839\u636e\u81ea\u5df1\u7684\u60c5\u51b5\u8fdb\u884c\u4fee\u6539\uff1b\u53e6\u5916\u5728\u4e4b\u524d\u5b89\u88c5gcc/g++\u65f6\u91c7\u7528MSYS2\u65b9\u5f0f\u5b89\u88c5\u7684\uff0c\u4fee\u6539\u5e76\u91cd\u65b0\u5b9a\u4f4dMinGW\u6587\u4ef6\u5939\uff0c\u5e76\u505a\u76f8\u5e94\u4fee\u6539\u3002  \u4e4b\u540e\u5e76\u65b0\u5efa\u53d8\u91cfPYTHONPATH\uff0c\u5e76\u6dfb\u52a0  C:\\Anaconda2\\Lib\\site-packages\\theano;   \u4fee\u6539\u9ed8\u8ba4\u540e\u7aef   \u6253\u5f00 C:\\Users\\\u5f53\u524d\u7528\u6237\u540d\\.keras ,\u4fee\u6539\u6587\u4ef6\u5939\u5185\u7684 keras.json \u6587\u4ef6\u5982\u4e0b\uff1a  { image_dim_ordering : th , epsilon :1e-07, floatx : float32 , backend : theano \n}   Theano\u52a0\u901f\u914d\u7f6e\n\u5728\u7528\u6237\u76ee\u5f55\uff0c\u4e5f\u5c31\u662f C:\\Users\\\u5f53\u524d\u7528\u6237\u540d\\ \uff0c\u65b0\u5efa .theanorc.txt \u3002 \u8fd9\u4e2a\u8def\u5f84\u53ef\u4ee5\u901a\u8fc7\u4fee\u6539Theano\u7684configparser.py\u6765\u6539\u53d8\u3002Theano\u88c5\u5728Anaconda\\Lib\\site-packages\u91cc .theanorc.txt\u7684\u5185\u5bb9\uff1a   [global]\nopenmp=False \ndevice = gpu   \noptimizer_including=cudnn #\u4e0d\u7528cudnn\u7684\u8bdd\u5c31\u4e0d\u8981\u8fd9\u53e5\uff0c\u5b9e\u9645\u4e0a\u4e0d\u7528\u52a0\uff0c\u53ea\u8981\u521a\u521a\u914d\u7f6e\u5230\u4f4d\u5c31\u884c  \nfloatX = float32  \nallow_input_downcast=True  \n[lib]\ncnmem = 0.8  #theano\u9ed1\u79d1\u6280\uff0c\u521d\u59cb\u5316\u663e\u5b58\u6bd4\u4f8b\n[blas]\nldflags=   #\u52a0\u901f\u5e93\n[gcc]\ncxxflags=-IC:\\Anaconda2\\MinGW  \n[nvcc]\nfastmath = True  \n--flags=-LC:\\Anaconda2\\libs #\u6539\u6210\u81ea\u5df1\u88c5\u7684\u76ee\u5f55\n--compiler_bindir=D:\\Microsoft Visual Studio 12.0\\VC\\bin #\u6539\u6210\u81ea\u5df1\u88c5\u7684\u76ee\u5f55\n#\u6700\u540e\u8bb0\u5f97\u628a\u6c49\u5b57\u5168\u5220\u4e86  \u5982\u679c\u60a8\u7684\u6240\u5b89\u88c5\u7684\u662fCPU\u52a0\u901f\u7248\u672c\uff0c\u90a3\u4e48 .theanorc.txt \u6587\u4ef6\u914d\u7f6e\u5982\u4e0b\uff1a  [global]\nopenmp=True \ndevice = cpu \nfloatX = float32  \nallow_input_downcast=True  \n[gcc]\ncxxflags=-IC:\\Anaconda2\\MinGW   \u4e4b\u540e\u53ef\u4ee5\u9a8c\u8bc1keras\u662f\u5426\u5b89\u88c5\u6210\u529f,\u5728\u547d\u4ee4\u884c\u4e2d\u8f93\u5165Python\u547d\u4ee4\u8fdb\u5165Python\u53d8\u6210\u547d\u4ee4\u884c\u73af\u5883\uff1a  import keras\nUsing Theano(Tensorflow) backend.   \u6ca1\u6709\u62a5\u9519\uff0c\u90a3\u4e48Keras\u5c31\u5df2\u7ecf \u6210\u529f\u5b89\u88c5 \u4e86", 
            "title": "\u73af\u5883\u914d\u7f6e"
        }, 
        {
            "location": "/getting_started/keras_windows/#_9", 
            "text": "", 
            "title": "\u52a0\u901f\u6d4b\u8bd5"
        }, 
        {
            "location": "/getting_started/keras_windows/#_10", 
            "text": "\u5728\u547d\u4ee4\u884c\u4e2d\u8fdb\u5165Python\u73af\u5883\uff0c\u8f93\u5165\uff1a  import theano  \u4f1a\u51fa\u73b0\u4e00\u7cfb\u5217\u4fe1\u606f\uff0c\u5305\u62ec\u663e\u5361\u578b\u53f7\u3001\u6d6e\u70b9\u6570\u7c7b\u578b\u3001\u662f\u5426\u91c7\u7528CNmem\u548ccuDNN\uff08\u5982\u679c\u4f7f\u7528\u4e86\u7684\u8bdd\uff09\u7b49\u7b49\uff0c\u90a3\u4e48\u606d\u559c\u4f60\uff0c\u73af\u5883\u5f7b\u5e95\u914d\u7f6e\u6210\u529f\u3002\n\u5982\u679c\u4f7f\u7528\u4e86Windows\u7cfb\u7edf\u7684\u8bfb\u8005\uff0c\u7535\u8111\u4e0a\u53ef\u80fd\u4f1a\u51fa\u73b0\uff0cdebug\u7684\u5b57\u6837\uff0c\u8fd9\u662f\u7b2c\u4e00\u6b21\u4f7f\u7528\uff0c\u5728\u7f16\u8bd1\u751f\u6210\u8fd0\u884c\u5e93\uff0c\u5c5e\u4e8e\u6b63\u5e38\u73b0\u8c61\u3002", 
            "title": "\u73af\u5883\u6d4b\u8bd5"
        }, 
        {
            "location": "/getting_started/keras_windows/#_11", 
            "text": "Python\u73af\u5883\u4e0b\u8f93\u5165\uff1a  import numpy \nid(numpy.dot) == id(numpy.core.multiarray.dot)   \u5982\u679c\u5f97\u5230\u7684\u7ed3\u679c\u4e3a False \uff0c\u8bf4\u660e\u4f60\u7684\u9664\u4e86gpu\u52a0\u901f\u8fd8\u5f97\u5230\u4e86\u6570\u5b66\u5e93blas\u52a0\u901f\uff0c\u6309\u7167\u6559\u7a0b\u987a\u5e8f\u914d\u7f6e\u7684Linux\u7528\u6237\u662f\u4e00\u5b9a\u53ef\u4ee5\u5f97\u5230False\u7ed3\u679c\u7684\uff1bWindows\u7528\u6237\u5f97\u5230 True \u4e5f\u6ca1\u6709\u5173\u7cfb\uff0c\u56e0\u4e3aAnaconda\u4e2d\u5df2\u7ecf\u5185\u7f6e\u4e86MKL\u52a0\u901f\u5e93\uff0c\u5982\u679c\u60f3\u4f7f\u7528Openblas\u53ef\u4ee5\u6309\u7167\u6587\u672b\u7684\u8054\u7cfb\u65b9\u5f0f\u8054\u7cfb\u6211\u3002", 
            "title": "\u52a0\u901f\u5e93\u6d4b\u8bd5"
        }, 
        {
            "location": "/getting_started/keras_windows/#_12", 
            "text": "\u65b0\u5efa\u4e00\u4e2a\u6587\u4ef6 test.py \uff0c\u5185\u5bb9\u4e3a\uff1a  from theano import function, config, shared, sandbox\nimport theano.tensor as T\nimport numpy\nimport time\n\nvlen = 10 * 30 * 768  # 10 x #cores x # threads per core #\u8fd9\u91cc\u53ef\u4ee5\u52a0\u4e00\u4e24\u4e2a0\uff0c\u591a\u6d4b\u8bd5\u4e00\u4e0b\uff0c\u8bb0\u5f97\u53bb\u6389\u6c49\u5b57 \niters = 1000\n\nrng = numpy.random.RandomState(22)\nx = shared(numpy.asarray(rng.rand(vlen), config.floatX))\nf = function([], T.exp(x))\nprint(f.maker.fgraph.toposort())\nt0 = time.time()\nfor i in xrange(iters):\n    r = f()\nt1 = time.time()\nprint( Looping %d times took %f seconds  % (iters, t1 - t0))\nprint( Result is %s  % (r,))\nif numpy.any([isinstance(x.op, T.Elemwise) for x in f.maker.fgraph.toposort()]):\n    print('Used the cpu')\nelse:\n    print('Used the gpu')  \u5728GTX 970\u663e\u5361\u4e0b\uff0c\u8f93\u51fa\u7ed3\u679c\u5927\u6982\u662f0.21\u79d2\uff0c\u5728\u4e00\u767e\u500d\u8fd0\u7b97\u91cf\u4e0b19\u79d2\uff0c\u53ef\u4ee5\u8fdb\u884c\u5bf9\u6bd4\u3002\n\u7406\u8bba\u4e0a\uff0c\u76f8\u6bd4\u8f83\u4e3b\u9891\u4e3a3.3GHz\u7684CPU\uff0c\u52a0\u901f\u6bd4\u5e94\u8be5\u662f75\u500d\uff0c\u4f46\u4e0d\u540c\u7684ssd\u548c\u5185\u5b58\u9650\u5236\u4e86IO\u63a5\u53e3\u4f20\u8f93\u901f\u5ea6\u3002", 
            "title": "\u901f\u5ea6\u6d4b\u8bd5"
        }, 
        {
            "location": "/getting_started/keras_windows/#kerasmnist", 
            "text": "\u4e0b\u8f7dKeras\u5f00\u53d1\u5305  git clone https://github.com/fchollet/keras.git\ncd keras/examples/\npython mnist_mlp.py  \u7a0b\u5e8f\u65e0\u9519\u8fdb\u884c\uff0c\u81f3\u6b64\uff0ckeras\u5b89\u88c5\u5b8c\u6210\u3002", 
            "title": "Keras\u4e2dmnist\u6570\u636e\u96c6\u6d4b\u8bd5"
        }, 
        {
            "location": "/getting_started/keras_windows/#anaconda3", 
            "text": "\u76ee\u524d\u53d1\u73b0\u4f7f\u7528Anaconda3\u5b89\u88c5theano\u65f6\u53ef\u80fd\u4f1a\u6709\u4e00\u4e2a\u51b2\u7a81\uff1a  AttributeError\uff1amodule \u2018configparser\u2019 has no attribute \u2018SafeConfigParser\u2019  \u6682\u65f6\u53ea\u6709\u7528\u4ee5\u4e0b\u65b9\u6cd5\u5904\u7406\uff1a  \u5bf9Anaconda3\\Lib\\site-packages\\theano\\configparser.py\u66f4\u6539\u6587\u4ef6\u540d\uff0c\u6bd4\u5982\u6539\u4e3aconfig_parser.py\uff0c\u5728pycharm\u6216\u5176\u4ed6IDE\u4e2d\u968f\u610f\u8fd0\u884c\u4e00\u4e2acnn\u811a\u672c\uff0c\u5bf9\u9047\u5230\u7684\u6bcf\u4e00\u4e2a\u63d0\u793a\u9519\u8bef\u624b\u52a8\u66f4\u6539\u5f15\u7528\u5230\u7684\u6587\u4ef6\u540d\u4e3atheano.config_parser\uff0c\u5728\u5c06\u6240\u6709\u5f15\u7528\u5230\u8fd9\u4e2a\u6587\u4ef6\u7684\u4f4d\u7f6e\u90fd\u6539\u6b63\u540e\uff0c\u5e94\u8be5\u5c31\u6ca1\u6709\u95ee\u9898\u4e86\u3002", 
            "title": "\u4e00\u4e2aAnaconda3\u4e2d\u914d\u7f6e\u9047\u5230\u7684\u5f02\u5e38\u89e3\u51b3\u65b9\u5f0f"
        }, 
        {
            "location": "/getting_started/keras_windows/#_13", 
            "text": "\u7531\u4e8e\u4f5c\u8005\u6c34\u5e73\u548c\u7814\u7a76\u65b9\u5411\u6240\u9650\uff0c\u65e0\u6cd5\u5bf9\u6240\u6709\u6a21\u5757\u90fd\u975e\u5e38\u7cbe\u901a\uff0c\u56e0\u6b64\u6587\u6863\u4e2d\u4e0d\u53ef\u907f\u514d\u7684\u4f1a\u51fa\u73b0\u5404\u79cd\u9519\u8bef\u3001\u758f\u6f0f\u548c\u4e0d\u8db3\u4e4b\u5904\u3002\u5982\u679c\u60a8\u5728\u4f7f\u7528\u8fc7\u7a0b\u4e2d\u6709\u4efb\u4f55\u610f\u89c1\u3001\u5efa\u8bae\u548c\u7591\u95ee\uff0c\u6b22\u8fce\u53d1\u9001\u90ae\u4ef6\u5230scp173.cool@gmail.com\u4e0e\u4e2d\u6587\u6587\u6863\u4f5c\u8005\u53d6\u5f97\u8054\u7cfb.  \u672c\u6559\u7a0b\u4e0d\u5f97\u7528\u4e8e\u4efb\u4f55\u5f62\u5f0f\u7684\u5546\u4e1a\u7528\u9014\uff0c\u5982\u679c\u9700\u8981\u8f6c\u8f7d\u8bf7\u4e0e\u4f5c\u8005\u6216\u4e2d\u6587\u6587\u6863\u4f5c\u8005\u8054\u7cfb\uff0c\u5982\u679c\u53d1\u73b0\u672a\u7ecf\u5141\u8bb8\u590d\u5236\u8f6c\u8f7d\uff0c\u5c06\u4fdd\u7559\u8ffd\u6c42\u5176\u6cd5\u5f8b\u8d23\u4efb\u7684\u6743\u5229\u3002  \u4f5c\u8005\uff1a SCP-173 \nE-mail \uff1ascp173.cool@gmail.com \u5982\u679c\u60a8\u9700\u8981\u53ca\u65f6\u5f97\u5230\u6307\u5bfc\u5e2e\u52a9\uff0c\u53ef\u4ee5\u52a0\u5fae\u4fe1\uff1aSCP173-cool\uff0c\u914c\u60c5\u6253\u8d4f\u5373\u53ef", 
            "title": "\u58f0\u660e\u4e0e\u8054\u7cfb\u65b9\u5f0f"
        }, 
        {
            "location": "/getting_started/sequential_model/", 
            "text": "\u5feb\u901f\u5f00\u59cbSequential\u6a21\u578b\n\n\nSequential\n\u662f\u591a\u4e2a\u7f51\u7edc\u5c42\u7684\u7ebf\u6027\u5806\u53e0\n\n\n\u53ef\u4ee5\u901a\u8fc7\u5411\nSequential\n\u6a21\u578b\u4f20\u9012\u4e00\u4e2alayer\u7684list\u6765\u6784\u9020\u8be5\u6a21\u578b\uff1a\n\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation\n\nmodel = Sequential([\nDense(32, input_dim=784),\nActivation('relu'),\nDense(10),\nActivation('softmax'),\n])\n\n\n\n\n\u4e5f\u53ef\u4ee5\u901a\u8fc7\n.add()\n\u65b9\u6cd5\u4e00\u4e2a\u4e2a\u7684\u5c06layer\u52a0\u5165\u6a21\u578b\u4e2d\uff1a\n\n\nmodel = Sequential()\nmodel.add(Dense(32, input_dim=784))\nmodel.add(Activation('relu'))\n\n\n\n\n\n\n\u6307\u5b9a\u8f93\u5165\u6570\u636e\u7684shape\n\n\n\u6a21\u578b\u9700\u8981\u77e5\u9053\u8f93\u5165\u6570\u636e\u7684shape\uff0c\u56e0\u6b64\uff0c\nSequential\n\u7684\u7b2c\u4e00\u5c42\u9700\u8981\u63a5\u53d7\u4e00\u4e2a\u5173\u4e8e\u8f93\u5165\u6570\u636eshape\u7684\u53c2\u6570\uff0c\u540e\u9762\u7684\u5404\u4e2a\u5c42\u5219\u53ef\u4ee5\u81ea\u52a8\u7684\u63a8\u5bfc\u51fa\u4e2d\u95f4\u6570\u636e\u7684shape\uff0c\u56e0\u6b64\u4e0d\u9700\u8981\u4e3a\u6bcf\u4e2a\u5c42\u90fd\u6307\u5b9a\u8fd9\u4e2a\u53c2\u6570\u3002\u6709\u51e0\u79cd\u65b9\u6cd5\u6765\u4e3a\u7b2c\u4e00\u5c42\u6307\u5b9a\u8f93\u5165\u6570\u636e\u7684shape\n\n\n\n\n\n\n\u4f20\u9012\u4e00\u4e2a\ninput_shape\n\u7684\u5173\u952e\u5b57\u53c2\u6570\u7ed9\u7b2c\u4e00\u5c42\uff0c\ninput_shape\n\u662f\u4e00\u4e2atuple\u7c7b\u578b\u7684\u6570\u636e\uff0c\u5176\u4e2d\u4e5f\u53ef\u4ee5\u586b\u5165\nNone\n\uff0c\u5982\u679c\u586b\u5165\nNone\n\u5219\u8868\u793a\u6b64\u4f4d\u7f6e\u53ef\u80fd\u662f\u4efb\u4f55\u6b63\u6574\u6570\u3002\u6570\u636e\u7684batch\u5927\u5c0f\u4e0d\u5e94\u5305\u542b\u5728\u5176\u4e2d\u3002\n\n\n\n\n\n\n\u4f20\u9012\u4e00\u4e2a\nbatch_input_shape\n\u7684\u5173\u952e\u5b57\u53c2\u6570\u7ed9\u7b2c\u4e00\u5c42\uff0c\u8be5\u53c2\u6570\u5305\u542b\u6570\u636e\u7684batch\u5927\u5c0f\u3002\u8be5\u53c2\u6570\u5728\u6307\u5b9a\u56fa\u5b9a\u5927\u5c0fbatch\u65f6\u6bd4\u8f83\u6709\u7528\uff0c\u4f8b\u5982\u5728stateful RNNs\u4e2d\u3002\u4e8b\u5b9e\u4e0a\uff0cKeras\u5728\u5185\u90e8\u4f1a\u901a\u8fc7\u6dfb\u52a0\u4e00\u4e2aNone\u5c06input_shape\u8f6c\u5316\u4e3abatch_input_shape\n\n\n\n\n\n\n\u6709\u4e9b2D\u5c42\uff0c\u5982\nDense\n\uff0c\u652f\u6301\u901a\u8fc7\u6307\u5b9a\u5176\u8f93\u5165\u7ef4\u5ea6\ninput_dim\n\u6765\u9690\u542b\u7684\u6307\u5b9a\u8f93\u5165\u6570\u636eshape\u3002\u4e00\u4e9b3D\u7684\u65f6\u57df\u5c42\u652f\u6301\u901a\u8fc7\u53c2\u6570\ninput_dim\n\u548c\ninput_length\n\u6765\u6307\u5b9a\u8f93\u5165shape\u3002\n\n\n\n\n\n\n\u4e0b\u9762\u7684\u4e09\u4e2a\u6307\u5b9a\u8f93\u5165\u6570\u636eshape\u7684\u65b9\u6cd5\u662f\u4e25\u683c\u7b49\u4ef7\u7684\uff1a\n\n\nmodel = Sequential()\nmodel.add(Dense(32, input_shape=(784,)))\n\n\n\n\nmodel = Sequential()\nmodel.add(Dense(32, batch_input_shape=(None, 784)))\n# note that batch dimension is \nNone\n here,\n# so the model will be able to process batches of any size.\n/pre\n\n\n\n\n\nmodel = Sequential()\nmodel.add(Dense(32, input_dim=784))\n\n\n\n\n\u4e0b\u9762\u4e09\u79cd\u65b9\u6cd5\u4e5f\u662f\u4e25\u683c\u7b49\u4ef7\u7684\uff1a\n\n\nmodel = Sequential()\nmodel.add(LSTM(32, input_shape=(10, 64)))\n\n\n\n\nmodel = Sequential()\nmodel.add(LSTM(32, batch_input_shape=(None, 10, 64)))\n\n\n\n\nmodel = Sequential()\nmodel.add(LSTM(32, input_length=10, input_dim=64))\n\n\n\n\n\n\nMerge\u5c42\n\n\n\u591a\u4e2a\nSequential\n\u53ef\u7ecf\u7531\u4e00\u4e2aMerge\u5c42\u5408\u5e76\u5230\u4e00\u4e2a\u8f93\u51fa\u3002Merge\u5c42\u7684\u8f93\u51fa\u662f\u4e00\u4e2a\u53ef\u4ee5\u88ab\u6dfb\u52a0\u5230\u65b0 \nSequential\n\u7684\u5c42\u5bf9\u8c61\u3002\u4e0b\u9762\u8fd9\u4e2a\u4f8b\u5b50\u5c06\u4e24\u4e2aSequential\u5408\u5e76\u5230\u4e00\u8d77\uff1a\n\n\nfrom keras.layers import Merge\n\nleft_branch = Sequential()\nleft_branch.add(Dense(32, input_dim=784))\n\nright_branch = Sequential()\nright_branch.add(Dense(32, input_dim=784))\n\nmerged = Merge([left_branch, right_branch], mode='concat')\n\nfinal_model = Sequential()\nfinal_model.add(merged)\nfinal_model.add(Dense(10, activation='softmax'))\n\n\n\n\n\n\nMerge\u5c42\u652f\u6301\u4e00\u4e9b\u9884\u5b9a\u4e49\u7684\u5408\u5e76\u6a21\u5f0f\uff0c\u5305\u62ec\uff1a\n\n\n\n\nsum\n(defualt):\u9010\u5143\u7d20\u76f8\u52a0\n\n\nconcat\n:\u5f20\u91cf\u4e32\u8054\uff0c\u53ef\u4ee5\u901a\u8fc7\u63d0\u4f9b\nconcat_axis\n\u7684\u5173\u952e\u5b57\u53c2\u6570\u6307\u5b9a\u6309\u7167\u54ea\u4e2a\u8f74\u8fdb\u884c\u4e32\u8054\n\n\nmul\n\uff1a\u9010\u5143\u7d20\u76f8\u4e58\n\n\nave\n\uff1a\u5f20\u91cf\u5e73\u5747\n\n\ndot\n\uff1a\u5f20\u91cf\u76f8\u4e58\uff0c\u53ef\u4ee5\u901a\u8fc7\ndot_axis\n\u5173\u952e\u5b57\u53c2\u6570\u6765\u6307\u5b9a\u8981\u6d88\u53bb\u7684\u8f74\n\n\ncos\n\uff1a\u8ba1\u7b972D\u5f20\u91cf\uff08\u5373\u77e9\u9635\uff09\u4e2d\u5404\u4e2a\u5411\u91cf\u7684\u4f59\u5f26\u8ddd\u79bb\n\n\n\n\n\u8fd9\u4e2a\u4e24\u4e2a\u5206\u652f\u7684\u6a21\u578b\u53ef\u4ee5\u901a\u8fc7\u4e0b\u9762\u7684\u4ee3\u7801\u8bad\u7ec3:\n\n\nfinal_model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\nfinal_model.fit([input_data_1, input_data_2], targets)  # we pass one data array per model input\n\n\n\n\n\u4e5f\u53ef\u4ee5\u4e3aMerge\u5c42\u63d0\u4f9b\u5173\u952e\u5b57\u53c2\u6570\nmode\n\uff0c\u4ee5\u5b9e\u73b0\u4efb\u610f\u7684\u53d8\u6362\uff0c\u4f8b\u5982\uff1a\n\n\nmerged = Merge([left_branch, right_branch], mode=lambda x: x[0] - x[1])\n\n\n\n\n\u73b0\u5728\u4f60\u5df2\u7ecf\u5b66\u4f1a\u5b9a\u4e49\u51e0\u4e4e\u4efb\u4f55Keras\u7684\u6a21\u578b\u4e86\uff0c\u5bf9\u4e8e\u4e0d\u80fd\u901a\u8fc7Sequential\u548cMerge\u7ec4\u5408\u751f\u6210\u7684\u590d\u6742\u6a21\u578b\uff0c\u53ef\u4ee5\u53c2\u8003\n\u6cdb\u578b\u6a21\u578bAPI\n\n\n\n\n\u7f16\u8bd1\n\n\n\u5728\u8bad\u7ec3\u6a21\u578b\u4e4b\u524d\uff0c\u6211\u4eec\u9700\u8981\u901a\u8fc7\ncompile\n\u6765\u5bf9\u5b66\u4e60\u8fc7\u7a0b\u8fdb\u884c\u914d\u7f6e\u3002\ncompile\n\u63a5\u6536\u4e09\u4e2a\u53c2\u6570\uff1a\n\n\n\n\n\n\n\u4f18\u5316\u5668optimizer\uff1a\u8be5\u53c2\u6570\u53ef\u6307\u5b9a\u4e3a\u5df2\u9884\u5b9a\u4e49\u7684\u4f18\u5316\u5668\u540d\uff0c\u5982\nrmsprop\n\u3001\nadagrad\n\uff0c\u6216\u4e00\u4e2a\nOptimizer\n\u7c7b\u7684\u5bf9\u8c61\uff0c\u8be6\u60c5\u89c1\noptimizers\n\n\n\n\n\n\n\u635f\u5931\u51fd\u6570loss\uff1a\u8be5\u53c2\u6570\u4e3a\u6a21\u578b\u8bd5\u56fe\u6700\u5c0f\u5316\u7684\u76ee\u6807\u51fd\u6570\uff0c\u5b83\u53ef\u4e3a\u9884\u5b9a\u4e49\u7684\u635f\u5931\u51fd\u6570\u540d\uff0c\u5982\ncategorical_crossentropy\n\u3001\nmse\n\uff0c\u4e5f\u53ef\u4ee5\u4e3a\u4e00\u4e2a\u635f\u5931\u51fd\u6570\u3002\u8be6\u60c5\u89c1\nobjectives\n\n\n\n\n\n\n\u6307\u6807\u5217\u8868metrics\uff1a\u5bf9\u5206\u7c7b\u95ee\u9898\uff0c\u6211\u4eec\u4e00\u822c\u5c06\u8be5\u5217\u8868\u8bbe\u7f6e\u4e3a\nmetrics=['accuracy']\n\u3002\u6307\u6807\u53ef\u4ee5\u662f\u4e00\u4e2a\u9884\u5b9a\u4e49\u6307\u6807\u7684\u540d\u5b57,\u4e5f\u53ef\u4ee5\u662f\u4e00\u4e2a\u7528\u6237\u5b9a\u5236\u7684\u51fd\u6570.\u6307\u6807\u51fd\u6570\u5e94\u8be5\u8fd4\u56de\u5355\u4e2a\u5f20\u91cf,\u6216\u4e00\u4e2a\u5b8c\u6210\nmetric_name - \n metric_value\n\u6620\u5c04\u7684\u5b57\u5178.\u8bf7\u53c2\u8003\n\u6027\u80fd\u8bc4\u4f30\n\n\n\n\n\n\n# for a multi-class classification problem\nmodel.compile(optimizer='rmsprop',\nloss='categorical_crossentropy',\nmetrics=['accuracy'])\n\n# for a binary classification problem\nmodel.compile(optimizer='rmsprop',\nloss='binary_crossentropy',\nmetrics=['accuracy'])\n\n# for a mean squared error regression problem\nmodel.compile(optimizer='rmsprop',\nloss='mse')\n\n# for custom metrices\n\n\n# for custom metrics\nimport keras.backend as K\n\ndef mean_pred(y_true, y_pred):\n    return K.mean(y_pred)\n\ndef false_rates(y_true, y_pred):\n    false_neg = ...\n    false_pos = ...\n    return {\n        'false_neg': false_neg,\n        'false_pos': false_pos,\n    }\n\nmodel.compile(optimizer='rmsprop',\n              loss='binary_crossentropy',\n              metrics=['accuracy', mean_pred, false_rates])\n\n\n\n\n\n\n\u8bad\u7ec3\n\n\nKeras\u4ee5Numpy\u6570\u7ec4\u4f5c\u4e3a\u8f93\u5165\u6570\u636e\u548c\u6807\u7b7e\u7684\u6570\u636e\u7c7b\u578b\u3002\u8bad\u7ec3\u6a21\u578b\u4e00\u822c\u4f7f\u7528\nfit\n\u51fd\u6570\uff0c\u8be5\u51fd\u6570\u7684\u8be6\u60c5\u89c1\n\u8fd9\u91cc\n\u3002\u4e0b\u9762\u662f\u4e00\u4e9b\u4f8b\u5b50\u3002\n\n\n# for a single-input model with 2 classes (binary):\nmodel = Sequential()\nmodel.add(Dense(1, input_dim=784, activation='sigmoid'))\nmodel.compile(optimizer='rmsprop',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\n# generate dummy data\nimport numpy as np\ndata = np.random.random((1000, 784))\nlabels = np.random.randint(2, size=(1000, 1))\n\n# train the model, iterating on the data in batches\n# of 32 samples\nmodel.fit(data, labels, nb_epoch=10, batch_size=32)\n\n\n\n\n# for a multi-input model with 10 classes:\n\nleft_branch = Sequential()\nleft_branch.add(Dense(32, input_dim=784))\n\nright_branch = Sequential()\nright_branch.add(Dense(32, input_dim=784))\n\nmerged = Merge([left_branch, right_branch], mode='concat')\n\nmodel = Sequential()\nmodel.add(merged)\nmodel.add(Dense(10, activation='softmax'))\n\nmodel.compile(optimizer='rmsprop',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\n# generate dummy data\nimport numpy as np\nfrom keras.utils.np_utils import to_categorical\ndata_1 = np.random.random((1000, 784))\ndata_2 = np.random.random((1000, 784))\n\n# these are integers between 0 and 9\nlabels = np.random.randint(10, size=(1000, 1))\n# we convert the labels to a binary matrix of size (1000, 10)\n# for use with categorical_crossentropy\nlabels = to_categorical(labels, 10)\n\n# train the model\n# note that we are passing a list of Numpy arrays as training data\n# since the model has 2 inputs\nmodel.fit([data_1, data_2], labels, nb_epoch=10, batch_size=32)\n\n\n\n\n\n\n\u4f8b\u5b50\n\n\n\u8fd9\u91cc\u662f\u4e00\u4e9b\u5e2e\u52a9\u4f60\u5f00\u59cb\u7684\u4f8b\u5b50\n\n\n\u5728Keras\u4ee3\u7801\u5305\u7684examples\u6587\u4ef6\u5939\u4e2d\uff0c\u4f60\u5c06\u627e\u5230\u4f7f\u7528\u771f\u5b9e\u6570\u636e\u7684\u793a\u4f8b\u6a21\u578b\uff1a\n\n\n\n\nCIFAR10 \u5c0f\u56fe\u7247\u5206\u7c7b\uff1a\u4f7f\u7528CNN\u548c\u5b9e\u65f6\u6570\u636e\u63d0\u5347\n\n\nIMDB \u7535\u5f71\u8bc4\u8bba\u89c2\u70b9\u5206\u7c7b\uff1a\u4f7f\u7528LSTM\u5904\u7406\u6210\u5e8f\u5217\u7684\u8bcd\u8bed\n\n\nReuters\uff08\u8def\u900f\u793e\uff09\u65b0\u95fb\u4e3b\u9898\u5206\u7c7b\uff1a\u4f7f\u7528\u591a\u5c42\u611f\u77e5\u5668\uff08MLP\uff09\n\n\nMNIST\u624b\u5199\u6570\u5b57\u8bc6\u522b\uff1a\u4f7f\u7528\u591a\u5c42\u611f\u77e5\u5668\u548cCNN\n\n\n\u5b57\u7b26\u7ea7\u6587\u672c\u751f\u6210\uff1a\u4f7f\u7528LSTM\n...\n\n\n\n\n\u57fa\u4e8e\u591a\u5c42\u611f\u77e5\u5668\u7684softmax\u591a\u5206\u7c7b\uff1a\n\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation\nfrom keras.optimizers import SGD\n\nmodel = Sequential()\n# Dense(64) is a fully-connected layer with 64 hidden units.\n# in the first layer, you must specify the expected input data shape:\n# here, 20-dimensional vectors.\nmodel.add(Dense(64, input_dim=20, init='uniform'))\nmodel.add(Activation('tanh'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(64, init='uniform'))\nmodel.add(Activation('tanh'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, init='uniform'))\nmodel.add(Activation('softmax'))\n\nsgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=sgd,\n              metrics=['accuracy'])\n\nmodel.fit(X_train, y_train,\n          nb_epoch=20,\n          batch_size=16)\nscore = model.evaluate(X_test, y_test, batch_size=16)   \n\n\n\n\n\u76f8\u4f3cMLP\u7684\u53e6\u4e00\u79cd\u5b9e\u73b0\uff1a\n\n\nmodel = Sequential()\nmodel.add(Dense(64, input_dim=20, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='adadelta',\n              metrics=['accuracy'])\n\n\n\n\n\u7528\u4e8e\u4e8c\u5206\u7c7b\u7684\u591a\u5c42\u611f\u77e5\u5668\uff1a\n\n\nmodel = Sequential()\nmodel.add(Dense(64, input_dim=20, init='uniform', activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer='rmsprop',\n              metrics=['accuracy'])\n\n\n\n\n\u7c7b\u4f3cVGG\u7684\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff1a\n\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Convolution2D, MaxPooling2D\nfrom keras.optimizers import SGD\n\nmodel = Sequential()\n# input: 100x100 images with 3 channels -\n (3, 100, 100) tensors.\n# this applies 32 convolution filters of size 3x3 each.\nmodel.add(Convolution2D(32, 3, 3, border_mode='valid', input_shape=(3, 100, 100)))\nmodel.add(Activation('relu'))\nmodel.add(Convolution2D(32, 3, 3))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Convolution2D(64, 3, 3, border_mode='valid'))\nmodel.add(Activation('relu'))\nmodel.add(Convolution2D(64, 3, 3))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\n# Note: Keras does automatic shape inference.\nmodel.add(Dense(256))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(10))\nmodel.add(Activation('softmax'))\n\nsgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\nmodel.compile(loss='categorical_crossentropy', optimizer=sgd)\n\nmodel.fit(X_train, Y_train, batch_size=32, nb_epoch=1)\n\n\n\n\n\u4f7f\u7528LSTM\u7684\u5e8f\u5217\u5206\u7c7b\n\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation\nfrom keras.layers import Embedding\nfrom keras.layers import LSTM\n\nmodel = Sequential()\nmodel.add(Embedding(max_features, 256, input_length=maxlen))\nmodel.add(LSTM(output_dim=128, activation='sigmoid', inner_activation='hard_sigmoid'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1))\nmodel.add(Activation('sigmoid'))\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer='rmsprop',\n              metrics=['accuracy'])\n\nmodel.fit(X_train, Y_train, batch_size=16, nb_epoch=10)\nscore = model.evaluate(X_test, Y_test, batch_size=16)\n\n\n\n\n\u4f7f\u7528\u5e26\u6709\u95e8\u9650\u7684\u9012\u5f52\u5355\u5143\u8fdb\u884c\u56fe\u50cf\u63cf\u8ff0\uff1a\n\n\n\uff08\u5355\u8bcd\u7ea7\u522b\u5d4c\u5165\uff0c\u63cf\u8ff0\u8bed\u53e5\u6700\u591a16\u4e2a\u5355\u8bcd\uff09\n\n\n\u6ce8\u610f\uff0c\u8981\u4f7f\u8be5\u7f51\u7edc\u826f\u597d\u5de5\u4f5c\u9700\u8981\u66f4\u5927\u89c4\u6a21\u7684\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u5e76\u4ee5\u9884\u8bad\u7ec3\u6743\u91cd\u521d\u59cb\u5316\uff0c\u6b64\u5904\u4ec5\u4e3a\u7ed3\u6784\u793a\u4f8b\u3002\n\n\nmax_caption_len = 16\nvocab_size = 10000\n\n# first, let's define an image model that\n# will encode pictures into 128-dimensional vectors.\n# it should be initialized with pre-trained weights.\nimage_model = Sequential()\nimage_model.add(Convolution2D(32, 3, 3, border_mode='valid', input_shape=(3, 100, 100)))\nimage_model.add(Activation('relu'))\nimage_model.add(Convolution2D(32, 3, 3))\nimage_model.add(Activation('relu'))\nimage_model.add(MaxPooling2D(pool_size=(2, 2)))\n\nimage_model.add(Convolution2D(64, 3, 3, border_mode='valid'))\nimage_model.add(Activation('relu'))\nimage_model.add(Convolution2D(64, 3, 3))\nimage_model.add(Activation('relu'))\nimage_model.add(MaxPooling2D(pool_size=(2, 2)))\n\nimage_model.add(Flatten())\nimage_model.add(Dense(128))\n\n# let's load the weights from a save file.\nimage_model.load_weights('weight_file.h5')\n\n# next, let's define a RNN model that encodes sequences of words\n# into sequences of 128-dimensional word vectors.\nlanguage_model = Sequential()\nlanguage_model.add(Embedding(vocab_size, 256, input_length=max_caption_len))\nlanguage_model.add(GRU(output_dim=128, return_sequences=True))\nlanguage_model.add(TimeDistributed(Dense(128))\n\n# let's repeat the image vector to turn it into a sequence.\nimage_model.add(RepeatVector(max_caption_len))\n\n# the output of both models will be tensors of shape (samples, max_caption_len, 128).\n# let's concatenate these 2 vector sequences.\nmodel = Sequential()\nmodel.add(Merge([image_model, language_model], mode='concat', concat_axis=-1))\n# let's encode this vector sequence into a single vector\nmodel.add(GRU(256, return_sequences=False))\n# which will be used to compute a probability\n# distribution over what the next word in the caption should be!\nmodel.add(Dense(vocab_size))\nmodel.add(Activation('softmax'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n\n# \nimages\n is a numpy float array of shape (nb_samples, nb_channels=3, width, height).\n# \ncaptions\n is a numpy integer array of shape (nb_samples, max_caption_len)\n# containing word index sequences representing partial captions.\n# \nnext_words\n is a numpy float array of shape (nb_samples, vocab_size)\n# containing a categorical encoding (0s and 1s) of the next word in the corresponding\n# partial caption.\nmodel.fit([images, partial_captions], next_words, batch_size=16, nb_epoch=100)\n\n\n\n\n\u7528\u4e8e\u5e8f\u5217\u5206\u7c7b\u7684\u6808\u5f0fLSTM\n\n\n\u5728\u8be5\u6a21\u578b\u4e2d\uff0c\u6211\u4eec\u5c06\u4e09\u4e2aLSTM\u5806\u53e0\u5728\u4e00\u8d77\uff0c\u662f\u8be5\u6a21\u578b\u80fd\u591f\u5b66\u4e60\u66f4\u9ad8\u5c42\u6b21\u7684\u65f6\u57df\u7279\u5f81\u8868\u793a\u3002\n\n\n\u5f00\u59cb\u7684\u4e24\u5c42LSTM\u8fd4\u56de\u5176\u5168\u90e8\u8f93\u51fa\u5e8f\u5217\uff0c\u800c\u7b2c\u4e09\u5c42LSTM\u53ea\u8fd4\u56de\u5176\u8f93\u51fa\u5e8f\u5217\u7684\u6700\u540e\u4e00\u6b65\u7ed3\u679c\uff0c\u4ece\u800c\u5176\u65f6\u57df\u7ef4\u5ea6\u964d\u4f4e\uff08\u5373\u5c06\u8f93\u5165\u5e8f\u5217\u8f6c\u6362\u4e3a\u5355\u4e2a\u5411\u91cf\uff09\n\n\n\n\nfrom keras.models import Sequential\nfrom keras.layers import LSTM, Dense\nimport numpy as np\n\ndata_dim = 16\ntimesteps = 8\nnb_classes = 10\n\n# expected input data shape: (batch_size, timesteps, data_dim)\nmodel = Sequential()\nmodel.add(LSTM(32, return_sequences=True,\n               input_shape=(timesteps, data_dim)))  # returns a sequence of vectors of dimension 32\nmodel.add(LSTM(32, return_sequences=True))  # returns a sequence of vectors of dimension 32\nmodel.add(LSTM(32))  # return a single vector of dimension 32\nmodel.add(Dense(10, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='rmsprop',\n              metrics=['accuracy'])\n\n# generate dummy training data\nx_train = np.random.random((1000, timesteps, data_dim))\ny_train = np.random.random((1000, nb_classes))\n\n# generate dummy validation data\nx_val = np.random.random((100, timesteps, data_dim))\ny_val = np.random.random((100, nb_classes))\n\nmodel.fit(x_train, y_train,\n          batch_size=64, nb_epoch=5,\n          validation_data=(x_val, y_val))\n\n\n\n\n\u91c7\u7528\u72b6\u6001LSTM\u7684\u76f8\u540c\u6a21\u578b\n\n\n\u72b6\u6001\uff08stateful\uff09LSTM\u7684\u7279\u70b9\u662f\uff0c\u5728\u5904\u7406\u8fc7\u4e00\u4e2abatch\u7684\u8bad\u7ec3\u6570\u636e\u540e\uff0c\u5176\u5185\u90e8\u72b6\u6001\uff08\u8bb0\u5fc6\uff09\u4f1a\u88ab\u4f5c\u4e3a\u4e0b\u4e00\u4e2abatch\u7684\u8bad\u7ec3\u6570\u636e\u7684\u521d\u59cb\u72b6\u6001\u3002\u72b6\u6001LSTM\u4f7f\u5f97\u6211\u4eec\u53ef\u4ee5\u5728\u5408\u7406\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\u5185\u5904\u7406\u8f83\u957f\u5e8f\u5217\n\n\n\u8bf7FAQ\u4e2d\u5173\u4e8e\n\u72b6\u6001LSTM\n\u7684\u90e8\u5206\u83b7\u53d6\u66f4\u591a\u4fe1\u606f\n\n\nfrom keras.models import Sequential\nfrom keras.layers import LSTM, Dense\nimport numpy as np\n\ndata_dim = 16\ntimesteps = 8\nnb_classes = 10\nbatch_size = 32\n\n# expected input batch shape: (batch_size, timesteps, data_dim)\n# note that we have to provide the full batch_input_shape since the network is stateful.\n# the sample of index i in batch k is the follow-up for the sample i in batch k-1.\nmodel = Sequential()\nmodel.add(LSTM(32, return_sequences=True, stateful=True,\n               batch_input_shape=(batch_size, timesteps, data_dim)))\nmodel.add(LSTM(32, return_sequences=True, stateful=True))\nmodel.add(LSTM(32, stateful=True))\nmodel.add(Dense(10, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='rmsprop',\n              metrics=['accuracy'])\n\n# generate dummy training data\nx_train = np.random.random((batch_size * 10, timesteps, data_dim))\ny_train = np.random.random((batch_size * 10, nb_classes))\n\n# generate dummy validation data\nx_val = np.random.random((batch_size * 3, timesteps, data_dim))\ny_val = np.random.random((batch_size * 3, nb_classes))\n\nmodel.fit(x_train, y_train,\n          batch_size=batch_size, nb_epoch=5,\n          validation_data=(x_val, y_val))\n\n\n\n\n\u5c06\u4e24\u4e2aLSTM\u5408\u5e76\u4f5c\u4e3a\u7f16\u7801\u7aef\u6765\u5904\u7406\u4e24\u8def\u5e8f\u5217\u7684\u5206\u7c7b\n\n\n\u5728\u672c\u6a21\u578b\u4e2d\uff0c\u4e24\u8def\u8f93\u5165\u5e8f\u5217\u901a\u8fc7\u4e24\u4e2aLSTM\u88ab\u7f16\u7801\u4e3a\u7279\u5f81\u5411\u91cf\n\n\n\u4e24\u8def\u7279\u5f81\u5411\u91cf\u88ab\u4e32\u8fde\u5728\u4e00\u8d77\uff0c\u7136\u540e\u901a\u8fc7\u4e00\u4e2a\u5168\u8fde\u63a5\u7f51\u7edc\u5f97\u5230\u7ed3\u679c\uff0c\u793a\u610f\u56fe\u5982\u4e0b\uff1a\n\n\n\n\nfrom keras.models import Sequential\nfrom keras.layers import Merge, LSTM, Dense\nimport numpy as np\n\ndata_dim = 16\ntimesteps = 8\nnb_classes = 10\n\nencoder_a = Sequential()\nencoder_a.add(LSTM(32, input_shape=(timesteps, data_dim)))\n\nencoder_b = Sequential()\nencoder_b.add(LSTM(32, input_shape=(timesteps, data_dim)))\n\ndecoder = Sequential()\ndecoder.add(Merge([encoder_a, encoder_b], mode='concat'))\ndecoder.add(Dense(32, activation='relu'))\ndecoder.add(Dense(nb_classes, activation='softmax'))\n\ndecoder.compile(loss='categorical_crossentropy',\n                optimizer='rmsprop',\n                metrics=['accuracy'])\n\n# generate dummy training data\nx_train_a = np.random.random((1000, timesteps, data_dim))\nx_train_b = np.random.random((1000, timesteps, data_dim))\ny_train = np.random.random((1000, nb_classes))\n\n# generate dummy validation data\nx_val_a = np.random.random((100, timesteps, data_dim))\nx_val_b = np.random.random((100, timesteps, data_dim))\ny_val = np.random.random((100, nb_classes))\n\ndecoder.fit([x_train_a, x_train_b], y_train,\n            batch_size=64, nb_epoch=5,\n            validation_data=([x_val_a, x_val_b], y_val))", 
            "title": "\u5feb\u901f\u5f00\u59cbSequential\u6a21\u578b"
        }, 
        {
            "location": "/getting_started/sequential_model/#sequential", 
            "text": "Sequential \u662f\u591a\u4e2a\u7f51\u7edc\u5c42\u7684\u7ebf\u6027\u5806\u53e0  \u53ef\u4ee5\u901a\u8fc7\u5411 Sequential \u6a21\u578b\u4f20\u9012\u4e00\u4e2alayer\u7684list\u6765\u6784\u9020\u8be5\u6a21\u578b\uff1a  from keras.models import Sequential\nfrom keras.layers import Dense, Activation\n\nmodel = Sequential([\nDense(32, input_dim=784),\nActivation('relu'),\nDense(10),\nActivation('softmax'),\n])  \u4e5f\u53ef\u4ee5\u901a\u8fc7 .add() \u65b9\u6cd5\u4e00\u4e2a\u4e2a\u7684\u5c06layer\u52a0\u5165\u6a21\u578b\u4e2d\uff1a  model = Sequential()\nmodel.add(Dense(32, input_dim=784))\nmodel.add(Activation('relu'))", 
            "title": "\u5feb\u901f\u5f00\u59cbSequential\u6a21\u578b"
        }, 
        {
            "location": "/getting_started/sequential_model/#shape", 
            "text": "\u6a21\u578b\u9700\u8981\u77e5\u9053\u8f93\u5165\u6570\u636e\u7684shape\uff0c\u56e0\u6b64\uff0c Sequential \u7684\u7b2c\u4e00\u5c42\u9700\u8981\u63a5\u53d7\u4e00\u4e2a\u5173\u4e8e\u8f93\u5165\u6570\u636eshape\u7684\u53c2\u6570\uff0c\u540e\u9762\u7684\u5404\u4e2a\u5c42\u5219\u53ef\u4ee5\u81ea\u52a8\u7684\u63a8\u5bfc\u51fa\u4e2d\u95f4\u6570\u636e\u7684shape\uff0c\u56e0\u6b64\u4e0d\u9700\u8981\u4e3a\u6bcf\u4e2a\u5c42\u90fd\u6307\u5b9a\u8fd9\u4e2a\u53c2\u6570\u3002\u6709\u51e0\u79cd\u65b9\u6cd5\u6765\u4e3a\u7b2c\u4e00\u5c42\u6307\u5b9a\u8f93\u5165\u6570\u636e\u7684shape    \u4f20\u9012\u4e00\u4e2a input_shape \u7684\u5173\u952e\u5b57\u53c2\u6570\u7ed9\u7b2c\u4e00\u5c42\uff0c input_shape \u662f\u4e00\u4e2atuple\u7c7b\u578b\u7684\u6570\u636e\uff0c\u5176\u4e2d\u4e5f\u53ef\u4ee5\u586b\u5165 None \uff0c\u5982\u679c\u586b\u5165 None \u5219\u8868\u793a\u6b64\u4f4d\u7f6e\u53ef\u80fd\u662f\u4efb\u4f55\u6b63\u6574\u6570\u3002\u6570\u636e\u7684batch\u5927\u5c0f\u4e0d\u5e94\u5305\u542b\u5728\u5176\u4e2d\u3002    \u4f20\u9012\u4e00\u4e2a batch_input_shape \u7684\u5173\u952e\u5b57\u53c2\u6570\u7ed9\u7b2c\u4e00\u5c42\uff0c\u8be5\u53c2\u6570\u5305\u542b\u6570\u636e\u7684batch\u5927\u5c0f\u3002\u8be5\u53c2\u6570\u5728\u6307\u5b9a\u56fa\u5b9a\u5927\u5c0fbatch\u65f6\u6bd4\u8f83\u6709\u7528\uff0c\u4f8b\u5982\u5728stateful RNNs\u4e2d\u3002\u4e8b\u5b9e\u4e0a\uff0cKeras\u5728\u5185\u90e8\u4f1a\u901a\u8fc7\u6dfb\u52a0\u4e00\u4e2aNone\u5c06input_shape\u8f6c\u5316\u4e3abatch_input_shape    \u6709\u4e9b2D\u5c42\uff0c\u5982 Dense \uff0c\u652f\u6301\u901a\u8fc7\u6307\u5b9a\u5176\u8f93\u5165\u7ef4\u5ea6 input_dim \u6765\u9690\u542b\u7684\u6307\u5b9a\u8f93\u5165\u6570\u636eshape\u3002\u4e00\u4e9b3D\u7684\u65f6\u57df\u5c42\u652f\u6301\u901a\u8fc7\u53c2\u6570 input_dim \u548c input_length \u6765\u6307\u5b9a\u8f93\u5165shape\u3002    \u4e0b\u9762\u7684\u4e09\u4e2a\u6307\u5b9a\u8f93\u5165\u6570\u636eshape\u7684\u65b9\u6cd5\u662f\u4e25\u683c\u7b49\u4ef7\u7684\uff1a  model = Sequential()\nmodel.add(Dense(32, input_shape=(784,)))  model = Sequential()\nmodel.add(Dense(32, batch_input_shape=(None, 784)))\n# note that batch dimension is  None  here,\n# so the model will be able to process batches of any size. /pre   model = Sequential()\nmodel.add(Dense(32, input_dim=784))  \u4e0b\u9762\u4e09\u79cd\u65b9\u6cd5\u4e5f\u662f\u4e25\u683c\u7b49\u4ef7\u7684\uff1a  model = Sequential()\nmodel.add(LSTM(32, input_shape=(10, 64)))  model = Sequential()\nmodel.add(LSTM(32, batch_input_shape=(None, 10, 64)))  model = Sequential()\nmodel.add(LSTM(32, input_length=10, input_dim=64))", 
            "title": "\u6307\u5b9a\u8f93\u5165\u6570\u636e\u7684shape"
        }, 
        {
            "location": "/getting_started/sequential_model/#merge", 
            "text": "\u591a\u4e2a Sequential \u53ef\u7ecf\u7531\u4e00\u4e2aMerge\u5c42\u5408\u5e76\u5230\u4e00\u4e2a\u8f93\u51fa\u3002Merge\u5c42\u7684\u8f93\u51fa\u662f\u4e00\u4e2a\u53ef\u4ee5\u88ab\u6dfb\u52a0\u5230\u65b0  Sequential \u7684\u5c42\u5bf9\u8c61\u3002\u4e0b\u9762\u8fd9\u4e2a\u4f8b\u5b50\u5c06\u4e24\u4e2aSequential\u5408\u5e76\u5230\u4e00\u8d77\uff1a  from keras.layers import Merge\n\nleft_branch = Sequential()\nleft_branch.add(Dense(32, input_dim=784))\n\nright_branch = Sequential()\nright_branch.add(Dense(32, input_dim=784))\n\nmerged = Merge([left_branch, right_branch], mode='concat')\n\nfinal_model = Sequential()\nfinal_model.add(merged)\nfinal_model.add(Dense(10, activation='softmax'))   Merge\u5c42\u652f\u6301\u4e00\u4e9b\u9884\u5b9a\u4e49\u7684\u5408\u5e76\u6a21\u5f0f\uff0c\u5305\u62ec\uff1a   sum (defualt):\u9010\u5143\u7d20\u76f8\u52a0  concat :\u5f20\u91cf\u4e32\u8054\uff0c\u53ef\u4ee5\u901a\u8fc7\u63d0\u4f9b concat_axis \u7684\u5173\u952e\u5b57\u53c2\u6570\u6307\u5b9a\u6309\u7167\u54ea\u4e2a\u8f74\u8fdb\u884c\u4e32\u8054  mul \uff1a\u9010\u5143\u7d20\u76f8\u4e58  ave \uff1a\u5f20\u91cf\u5e73\u5747  dot \uff1a\u5f20\u91cf\u76f8\u4e58\uff0c\u53ef\u4ee5\u901a\u8fc7 dot_axis \u5173\u952e\u5b57\u53c2\u6570\u6765\u6307\u5b9a\u8981\u6d88\u53bb\u7684\u8f74  cos \uff1a\u8ba1\u7b972D\u5f20\u91cf\uff08\u5373\u77e9\u9635\uff09\u4e2d\u5404\u4e2a\u5411\u91cf\u7684\u4f59\u5f26\u8ddd\u79bb   \u8fd9\u4e2a\u4e24\u4e2a\u5206\u652f\u7684\u6a21\u578b\u53ef\u4ee5\u901a\u8fc7\u4e0b\u9762\u7684\u4ee3\u7801\u8bad\u7ec3:  final_model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\nfinal_model.fit([input_data_1, input_data_2], targets)  # we pass one data array per model input  \u4e5f\u53ef\u4ee5\u4e3aMerge\u5c42\u63d0\u4f9b\u5173\u952e\u5b57\u53c2\u6570 mode \uff0c\u4ee5\u5b9e\u73b0\u4efb\u610f\u7684\u53d8\u6362\uff0c\u4f8b\u5982\uff1a  merged = Merge([left_branch, right_branch], mode=lambda x: x[0] - x[1])  \u73b0\u5728\u4f60\u5df2\u7ecf\u5b66\u4f1a\u5b9a\u4e49\u51e0\u4e4e\u4efb\u4f55Keras\u7684\u6a21\u578b\u4e86\uff0c\u5bf9\u4e8e\u4e0d\u80fd\u901a\u8fc7Sequential\u548cMerge\u7ec4\u5408\u751f\u6210\u7684\u590d\u6742\u6a21\u578b\uff0c\u53ef\u4ee5\u53c2\u8003 \u6cdb\u578b\u6a21\u578bAPI", 
            "title": "Merge\u5c42"
        }, 
        {
            "location": "/getting_started/sequential_model/#_1", 
            "text": "\u5728\u8bad\u7ec3\u6a21\u578b\u4e4b\u524d\uff0c\u6211\u4eec\u9700\u8981\u901a\u8fc7 compile \u6765\u5bf9\u5b66\u4e60\u8fc7\u7a0b\u8fdb\u884c\u914d\u7f6e\u3002 compile \u63a5\u6536\u4e09\u4e2a\u53c2\u6570\uff1a    \u4f18\u5316\u5668optimizer\uff1a\u8be5\u53c2\u6570\u53ef\u6307\u5b9a\u4e3a\u5df2\u9884\u5b9a\u4e49\u7684\u4f18\u5316\u5668\u540d\uff0c\u5982 rmsprop \u3001 adagrad \uff0c\u6216\u4e00\u4e2a Optimizer \u7c7b\u7684\u5bf9\u8c61\uff0c\u8be6\u60c5\u89c1 optimizers    \u635f\u5931\u51fd\u6570loss\uff1a\u8be5\u53c2\u6570\u4e3a\u6a21\u578b\u8bd5\u56fe\u6700\u5c0f\u5316\u7684\u76ee\u6807\u51fd\u6570\uff0c\u5b83\u53ef\u4e3a\u9884\u5b9a\u4e49\u7684\u635f\u5931\u51fd\u6570\u540d\uff0c\u5982 categorical_crossentropy \u3001 mse \uff0c\u4e5f\u53ef\u4ee5\u4e3a\u4e00\u4e2a\u635f\u5931\u51fd\u6570\u3002\u8be6\u60c5\u89c1 objectives    \u6307\u6807\u5217\u8868metrics\uff1a\u5bf9\u5206\u7c7b\u95ee\u9898\uff0c\u6211\u4eec\u4e00\u822c\u5c06\u8be5\u5217\u8868\u8bbe\u7f6e\u4e3a metrics=['accuracy'] \u3002\u6307\u6807\u53ef\u4ee5\u662f\u4e00\u4e2a\u9884\u5b9a\u4e49\u6307\u6807\u7684\u540d\u5b57,\u4e5f\u53ef\u4ee5\u662f\u4e00\u4e2a\u7528\u6237\u5b9a\u5236\u7684\u51fd\u6570.\u6307\u6807\u51fd\u6570\u5e94\u8be5\u8fd4\u56de\u5355\u4e2a\u5f20\u91cf,\u6216\u4e00\u4e2a\u5b8c\u6210 metric_name -   metric_value \u6620\u5c04\u7684\u5b57\u5178.\u8bf7\u53c2\u8003 \u6027\u80fd\u8bc4\u4f30    # for a multi-class classification problem\nmodel.compile(optimizer='rmsprop',\nloss='categorical_crossentropy',\nmetrics=['accuracy'])\n\n# for a binary classification problem\nmodel.compile(optimizer='rmsprop',\nloss='binary_crossentropy',\nmetrics=['accuracy'])\n\n# for a mean squared error regression problem\nmodel.compile(optimizer='rmsprop',\nloss='mse')\n\n# for custom metrices\n\n\n# for custom metrics\nimport keras.backend as K\n\ndef mean_pred(y_true, y_pred):\n    return K.mean(y_pred)\n\ndef false_rates(y_true, y_pred):\n    false_neg = ...\n    false_pos = ...\n    return {\n        'false_neg': false_neg,\n        'false_pos': false_pos,\n    }\n\nmodel.compile(optimizer='rmsprop',\n              loss='binary_crossentropy',\n              metrics=['accuracy', mean_pred, false_rates])", 
            "title": "\u7f16\u8bd1"
        }, 
        {
            "location": "/getting_started/sequential_model/#_2", 
            "text": "Keras\u4ee5Numpy\u6570\u7ec4\u4f5c\u4e3a\u8f93\u5165\u6570\u636e\u548c\u6807\u7b7e\u7684\u6570\u636e\u7c7b\u578b\u3002\u8bad\u7ec3\u6a21\u578b\u4e00\u822c\u4f7f\u7528 fit \u51fd\u6570\uff0c\u8be5\u51fd\u6570\u7684\u8be6\u60c5\u89c1 \u8fd9\u91cc \u3002\u4e0b\u9762\u662f\u4e00\u4e9b\u4f8b\u5b50\u3002  # for a single-input model with 2 classes (binary):\nmodel = Sequential()\nmodel.add(Dense(1, input_dim=784, activation='sigmoid'))\nmodel.compile(optimizer='rmsprop',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\n# generate dummy data\nimport numpy as np\ndata = np.random.random((1000, 784))\nlabels = np.random.randint(2, size=(1000, 1))\n\n# train the model, iterating on the data in batches\n# of 32 samples\nmodel.fit(data, labels, nb_epoch=10, batch_size=32)  # for a multi-input model with 10 classes:\n\nleft_branch = Sequential()\nleft_branch.add(Dense(32, input_dim=784))\n\nright_branch = Sequential()\nright_branch.add(Dense(32, input_dim=784))\n\nmerged = Merge([left_branch, right_branch], mode='concat')\n\nmodel = Sequential()\nmodel.add(merged)\nmodel.add(Dense(10, activation='softmax'))\n\nmodel.compile(optimizer='rmsprop',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\n# generate dummy data\nimport numpy as np\nfrom keras.utils.np_utils import to_categorical\ndata_1 = np.random.random((1000, 784))\ndata_2 = np.random.random((1000, 784))\n\n# these are integers between 0 and 9\nlabels = np.random.randint(10, size=(1000, 1))\n# we convert the labels to a binary matrix of size (1000, 10)\n# for use with categorical_crossentropy\nlabels = to_categorical(labels, 10)\n\n# train the model\n# note that we are passing a list of Numpy arrays as training data\n# since the model has 2 inputs\nmodel.fit([data_1, data_2], labels, nb_epoch=10, batch_size=32)", 
            "title": "\u8bad\u7ec3"
        }, 
        {
            "location": "/getting_started/sequential_model/#_3", 
            "text": "\u8fd9\u91cc\u662f\u4e00\u4e9b\u5e2e\u52a9\u4f60\u5f00\u59cb\u7684\u4f8b\u5b50  \u5728Keras\u4ee3\u7801\u5305\u7684examples\u6587\u4ef6\u5939\u4e2d\uff0c\u4f60\u5c06\u627e\u5230\u4f7f\u7528\u771f\u5b9e\u6570\u636e\u7684\u793a\u4f8b\u6a21\u578b\uff1a   CIFAR10 \u5c0f\u56fe\u7247\u5206\u7c7b\uff1a\u4f7f\u7528CNN\u548c\u5b9e\u65f6\u6570\u636e\u63d0\u5347  IMDB \u7535\u5f71\u8bc4\u8bba\u89c2\u70b9\u5206\u7c7b\uff1a\u4f7f\u7528LSTM\u5904\u7406\u6210\u5e8f\u5217\u7684\u8bcd\u8bed  Reuters\uff08\u8def\u900f\u793e\uff09\u65b0\u95fb\u4e3b\u9898\u5206\u7c7b\uff1a\u4f7f\u7528\u591a\u5c42\u611f\u77e5\u5668\uff08MLP\uff09  MNIST\u624b\u5199\u6570\u5b57\u8bc6\u522b\uff1a\u4f7f\u7528\u591a\u5c42\u611f\u77e5\u5668\u548cCNN  \u5b57\u7b26\u7ea7\u6587\u672c\u751f\u6210\uff1a\u4f7f\u7528LSTM\n...", 
            "title": "\u4f8b\u5b50"
        }, 
        {
            "location": "/getting_started/sequential_model/#softmax", 
            "text": "from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation\nfrom keras.optimizers import SGD\n\nmodel = Sequential()\n# Dense(64) is a fully-connected layer with 64 hidden units.\n# in the first layer, you must specify the expected input data shape:\n# here, 20-dimensional vectors.\nmodel.add(Dense(64, input_dim=20, init='uniform'))\nmodel.add(Activation('tanh'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(64, init='uniform'))\nmodel.add(Activation('tanh'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, init='uniform'))\nmodel.add(Activation('softmax'))\n\nsgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=sgd,\n              metrics=['accuracy'])\n\nmodel.fit(X_train, y_train,\n          nb_epoch=20,\n          batch_size=16)\nscore = model.evaluate(X_test, y_test, batch_size=16)", 
            "title": "\u57fa\u4e8e\u591a\u5c42\u611f\u77e5\u5668\u7684softmax\u591a\u5206\u7c7b\uff1a"
        }, 
        {
            "location": "/getting_started/sequential_model/#mlp", 
            "text": "model = Sequential()\nmodel.add(Dense(64, input_dim=20, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='adadelta',\n              metrics=['accuracy'])", 
            "title": "\u76f8\u4f3cMLP\u7684\u53e6\u4e00\u79cd\u5b9e\u73b0\uff1a"
        }, 
        {
            "location": "/getting_started/sequential_model/#_4", 
            "text": "model = Sequential()\nmodel.add(Dense(64, input_dim=20, init='uniform', activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer='rmsprop',\n              metrics=['accuracy'])", 
            "title": "\u7528\u4e8e\u4e8c\u5206\u7c7b\u7684\u591a\u5c42\u611f\u77e5\u5668\uff1a"
        }, 
        {
            "location": "/getting_started/sequential_model/#vgg", 
            "text": "from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Convolution2D, MaxPooling2D\nfrom keras.optimizers import SGD\n\nmodel = Sequential()\n# input: 100x100 images with 3 channels -  (3, 100, 100) tensors.\n# this applies 32 convolution filters of size 3x3 each.\nmodel.add(Convolution2D(32, 3, 3, border_mode='valid', input_shape=(3, 100, 100)))\nmodel.add(Activation('relu'))\nmodel.add(Convolution2D(32, 3, 3))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Convolution2D(64, 3, 3, border_mode='valid'))\nmodel.add(Activation('relu'))\nmodel.add(Convolution2D(64, 3, 3))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\n# Note: Keras does automatic shape inference.\nmodel.add(Dense(256))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(10))\nmodel.add(Activation('softmax'))\n\nsgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\nmodel.compile(loss='categorical_crossentropy', optimizer=sgd)\n\nmodel.fit(X_train, Y_train, batch_size=32, nb_epoch=1)", 
            "title": "\u7c7b\u4f3cVGG\u7684\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff1a"
        }, 
        {
            "location": "/getting_started/sequential_model/#lstm", 
            "text": "from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation\nfrom keras.layers import Embedding\nfrom keras.layers import LSTM\n\nmodel = Sequential()\nmodel.add(Embedding(max_features, 256, input_length=maxlen))\nmodel.add(LSTM(output_dim=128, activation='sigmoid', inner_activation='hard_sigmoid'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1))\nmodel.add(Activation('sigmoid'))\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer='rmsprop',\n              metrics=['accuracy'])\n\nmodel.fit(X_train, Y_train, batch_size=16, nb_epoch=10)\nscore = model.evaluate(X_test, Y_test, batch_size=16)", 
            "title": "\u4f7f\u7528LSTM\u7684\u5e8f\u5217\u5206\u7c7b"
        }, 
        {
            "location": "/getting_started/sequential_model/#_5", 
            "text": "\uff08\u5355\u8bcd\u7ea7\u522b\u5d4c\u5165\uff0c\u63cf\u8ff0\u8bed\u53e5\u6700\u591a16\u4e2a\u5355\u8bcd\uff09  \u6ce8\u610f\uff0c\u8981\u4f7f\u8be5\u7f51\u7edc\u826f\u597d\u5de5\u4f5c\u9700\u8981\u66f4\u5927\u89c4\u6a21\u7684\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u5e76\u4ee5\u9884\u8bad\u7ec3\u6743\u91cd\u521d\u59cb\u5316\uff0c\u6b64\u5904\u4ec5\u4e3a\u7ed3\u6784\u793a\u4f8b\u3002  max_caption_len = 16\nvocab_size = 10000\n\n# first, let's define an image model that\n# will encode pictures into 128-dimensional vectors.\n# it should be initialized with pre-trained weights.\nimage_model = Sequential()\nimage_model.add(Convolution2D(32, 3, 3, border_mode='valid', input_shape=(3, 100, 100)))\nimage_model.add(Activation('relu'))\nimage_model.add(Convolution2D(32, 3, 3))\nimage_model.add(Activation('relu'))\nimage_model.add(MaxPooling2D(pool_size=(2, 2)))\n\nimage_model.add(Convolution2D(64, 3, 3, border_mode='valid'))\nimage_model.add(Activation('relu'))\nimage_model.add(Convolution2D(64, 3, 3))\nimage_model.add(Activation('relu'))\nimage_model.add(MaxPooling2D(pool_size=(2, 2)))\n\nimage_model.add(Flatten())\nimage_model.add(Dense(128))\n\n# let's load the weights from a save file.\nimage_model.load_weights('weight_file.h5')\n\n# next, let's define a RNN model that encodes sequences of words\n# into sequences of 128-dimensional word vectors.\nlanguage_model = Sequential()\nlanguage_model.add(Embedding(vocab_size, 256, input_length=max_caption_len))\nlanguage_model.add(GRU(output_dim=128, return_sequences=True))\nlanguage_model.add(TimeDistributed(Dense(128))\n\n# let's repeat the image vector to turn it into a sequence.\nimage_model.add(RepeatVector(max_caption_len))\n\n# the output of both models will be tensors of shape (samples, max_caption_len, 128).\n# let's concatenate these 2 vector sequences.\nmodel = Sequential()\nmodel.add(Merge([image_model, language_model], mode='concat', concat_axis=-1))\n# let's encode this vector sequence into a single vector\nmodel.add(GRU(256, return_sequences=False))\n# which will be used to compute a probability\n# distribution over what the next word in the caption should be!\nmodel.add(Dense(vocab_size))\nmodel.add(Activation('softmax'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n\n#  images  is a numpy float array of shape (nb_samples, nb_channels=3, width, height).\n#  captions  is a numpy integer array of shape (nb_samples, max_caption_len)\n# containing word index sequences representing partial captions.\n#  next_words  is a numpy float array of shape (nb_samples, vocab_size)\n# containing a categorical encoding (0s and 1s) of the next word in the corresponding\n# partial caption.\nmodel.fit([images, partial_captions], next_words, batch_size=16, nb_epoch=100)", 
            "title": "\u4f7f\u7528\u5e26\u6709\u95e8\u9650\u7684\u9012\u5f52\u5355\u5143\u8fdb\u884c\u56fe\u50cf\u63cf\u8ff0\uff1a"
        }, 
        {
            "location": "/getting_started/sequential_model/#lstm_1", 
            "text": "\u5728\u8be5\u6a21\u578b\u4e2d\uff0c\u6211\u4eec\u5c06\u4e09\u4e2aLSTM\u5806\u53e0\u5728\u4e00\u8d77\uff0c\u662f\u8be5\u6a21\u578b\u80fd\u591f\u5b66\u4e60\u66f4\u9ad8\u5c42\u6b21\u7684\u65f6\u57df\u7279\u5f81\u8868\u793a\u3002  \u5f00\u59cb\u7684\u4e24\u5c42LSTM\u8fd4\u56de\u5176\u5168\u90e8\u8f93\u51fa\u5e8f\u5217\uff0c\u800c\u7b2c\u4e09\u5c42LSTM\u53ea\u8fd4\u56de\u5176\u8f93\u51fa\u5e8f\u5217\u7684\u6700\u540e\u4e00\u6b65\u7ed3\u679c\uff0c\u4ece\u800c\u5176\u65f6\u57df\u7ef4\u5ea6\u964d\u4f4e\uff08\u5373\u5c06\u8f93\u5165\u5e8f\u5217\u8f6c\u6362\u4e3a\u5355\u4e2a\u5411\u91cf\uff09   from keras.models import Sequential\nfrom keras.layers import LSTM, Dense\nimport numpy as np\n\ndata_dim = 16\ntimesteps = 8\nnb_classes = 10\n\n# expected input data shape: (batch_size, timesteps, data_dim)\nmodel = Sequential()\nmodel.add(LSTM(32, return_sequences=True,\n               input_shape=(timesteps, data_dim)))  # returns a sequence of vectors of dimension 32\nmodel.add(LSTM(32, return_sequences=True))  # returns a sequence of vectors of dimension 32\nmodel.add(LSTM(32))  # return a single vector of dimension 32\nmodel.add(Dense(10, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='rmsprop',\n              metrics=['accuracy'])\n\n# generate dummy training data\nx_train = np.random.random((1000, timesteps, data_dim))\ny_train = np.random.random((1000, nb_classes))\n\n# generate dummy validation data\nx_val = np.random.random((100, timesteps, data_dim))\ny_val = np.random.random((100, nb_classes))\n\nmodel.fit(x_train, y_train,\n          batch_size=64, nb_epoch=5,\n          validation_data=(x_val, y_val))", 
            "title": "\u7528\u4e8e\u5e8f\u5217\u5206\u7c7b\u7684\u6808\u5f0fLSTM"
        }, 
        {
            "location": "/getting_started/sequential_model/#lstm_2", 
            "text": "\u72b6\u6001\uff08stateful\uff09LSTM\u7684\u7279\u70b9\u662f\uff0c\u5728\u5904\u7406\u8fc7\u4e00\u4e2abatch\u7684\u8bad\u7ec3\u6570\u636e\u540e\uff0c\u5176\u5185\u90e8\u72b6\u6001\uff08\u8bb0\u5fc6\uff09\u4f1a\u88ab\u4f5c\u4e3a\u4e0b\u4e00\u4e2abatch\u7684\u8bad\u7ec3\u6570\u636e\u7684\u521d\u59cb\u72b6\u6001\u3002\u72b6\u6001LSTM\u4f7f\u5f97\u6211\u4eec\u53ef\u4ee5\u5728\u5408\u7406\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\u5185\u5904\u7406\u8f83\u957f\u5e8f\u5217  \u8bf7FAQ\u4e2d\u5173\u4e8e \u72b6\u6001LSTM \u7684\u90e8\u5206\u83b7\u53d6\u66f4\u591a\u4fe1\u606f  from keras.models import Sequential\nfrom keras.layers import LSTM, Dense\nimport numpy as np\n\ndata_dim = 16\ntimesteps = 8\nnb_classes = 10\nbatch_size = 32\n\n# expected input batch shape: (batch_size, timesteps, data_dim)\n# note that we have to provide the full batch_input_shape since the network is stateful.\n# the sample of index i in batch k is the follow-up for the sample i in batch k-1.\nmodel = Sequential()\nmodel.add(LSTM(32, return_sequences=True, stateful=True,\n               batch_input_shape=(batch_size, timesteps, data_dim)))\nmodel.add(LSTM(32, return_sequences=True, stateful=True))\nmodel.add(LSTM(32, stateful=True))\nmodel.add(Dense(10, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='rmsprop',\n              metrics=['accuracy'])\n\n# generate dummy training data\nx_train = np.random.random((batch_size * 10, timesteps, data_dim))\ny_train = np.random.random((batch_size * 10, nb_classes))\n\n# generate dummy validation data\nx_val = np.random.random((batch_size * 3, timesteps, data_dim))\ny_val = np.random.random((batch_size * 3, nb_classes))\n\nmodel.fit(x_train, y_train,\n          batch_size=batch_size, nb_epoch=5,\n          validation_data=(x_val, y_val))", 
            "title": "\u91c7\u7528\u72b6\u6001LSTM\u7684\u76f8\u540c\u6a21\u578b"
        }, 
        {
            "location": "/getting_started/sequential_model/#lstm_3", 
            "text": "\u5728\u672c\u6a21\u578b\u4e2d\uff0c\u4e24\u8def\u8f93\u5165\u5e8f\u5217\u901a\u8fc7\u4e24\u4e2aLSTM\u88ab\u7f16\u7801\u4e3a\u7279\u5f81\u5411\u91cf  \u4e24\u8def\u7279\u5f81\u5411\u91cf\u88ab\u4e32\u8fde\u5728\u4e00\u8d77\uff0c\u7136\u540e\u901a\u8fc7\u4e00\u4e2a\u5168\u8fde\u63a5\u7f51\u7edc\u5f97\u5230\u7ed3\u679c\uff0c\u793a\u610f\u56fe\u5982\u4e0b\uff1a   from keras.models import Sequential\nfrom keras.layers import Merge, LSTM, Dense\nimport numpy as np\n\ndata_dim = 16\ntimesteps = 8\nnb_classes = 10\n\nencoder_a = Sequential()\nencoder_a.add(LSTM(32, input_shape=(timesteps, data_dim)))\n\nencoder_b = Sequential()\nencoder_b.add(LSTM(32, input_shape=(timesteps, data_dim)))\n\ndecoder = Sequential()\ndecoder.add(Merge([encoder_a, encoder_b], mode='concat'))\ndecoder.add(Dense(32, activation='relu'))\ndecoder.add(Dense(nb_classes, activation='softmax'))\n\ndecoder.compile(loss='categorical_crossentropy',\n                optimizer='rmsprop',\n                metrics=['accuracy'])\n\n# generate dummy training data\nx_train_a = np.random.random((1000, timesteps, data_dim))\nx_train_b = np.random.random((1000, timesteps, data_dim))\ny_train = np.random.random((1000, nb_classes))\n\n# generate dummy validation data\nx_val_a = np.random.random((100, timesteps, data_dim))\nx_val_b = np.random.random((100, timesteps, data_dim))\ny_val = np.random.random((100, nb_classes))\n\ndecoder.fit([x_train_a, x_train_b], y_train,\n            batch_size=64, nb_epoch=5,\n            validation_data=([x_val_a, x_val_b], y_val))", 
            "title": "\u5c06\u4e24\u4e2aLSTM\u5408\u5e76\u4f5c\u4e3a\u7f16\u7801\u7aef\u6765\u5904\u7406\u4e24\u8def\u5e8f\u5217\u7684\u5206\u7c7b"
        }, 
        {
            "location": "/getting_started/functional_API/", 
            "text": "\u5feb\u901f\u5f00\u59cb\u6cdb\u578b\u6a21\u578b\n\n\nKeras\u6cdb\u578b\u6a21\u578b\u63a5\u53e3\u662f\u7528\u6237\u5b9a\u4e49\u591a\u8f93\u51fa\u6a21\u578b\u3001\u975e\u5faa\u73af\u6709\u5411\u6a21\u578b\u6216\u5177\u6709\u5171\u4eab\u5c42\u7684\u6a21\u578b\u7b49\u590d\u6742\u6a21\u578b\u7684\u9014\u5f84\n\n\n\u8fd9\u90e8\u5206\u7684\u6587\u6863\u5047\u8bbe\u4f60\u5df2\u7ecf\u5bf9\nSequential\n\u6a21\u578b\u5df2\u7ecf\u6bd4\u8f83\u719f\u6089\n\n\n\u8ba9\u6211\u4eec\u4ece\u7b80\u5355\u4e00\u70b9\u7684\u6a21\u578b\u5f00\u59cb\n\n\n\u7b2c\u4e00\u4e2a\u6a21\u578b\uff1a\u5168\u8fde\u63a5\u7f51\u7edc\n\n\nSequential\n\u5f53\u7136\u662f\u5b9e\u73b0\u5168\u8fde\u63a5\u7f51\u7edc\u7684\u6700\u597d\u65b9\u5f0f\uff0c\u4f46\u6211\u4eec\u4ece\u7b80\u5355\u7684\u5168\u8fde\u63a5\u7f51\u7edc\u5f00\u59cb\uff0c\u6709\u52a9\u4e8e\u6211\u4eec\u5b66\u4e60\u8fd9\u90e8\u5206\u7684\u5185\u5bb9\u3002\u5728\u5f00\u59cb\u524d\uff0c\u6709\u51e0\u4e2a\u6982\u5ff5\u9700\u8981\u6f84\u6e05\uff1a\n\n\n\n\n\n\n\u5c42\u5bf9\u8c61\u63a5\u53d7\u5f20\u91cf\u4e3a\u53c2\u6570\uff0c\u8fd4\u56de\u4e00\u4e2a\u5f20\u91cf\u3002\u5f20\u91cf\u5728\u6570\u5b66\u4e0a\u53ea\u662f\u6570\u636e\u7ed3\u6784\u7684\u6269\u5145\uff0c\u4e00\u9636\u5f20\u91cf\u5c31\u662f\u5411\u91cf\uff0c\u4e8c\u9636\u5f20\u91cf\u5c31\u662f\u77e9\u9635\uff0c\u4e09\u9636\u5f20\u91cf\u5c31\u662f\u7acb\u65b9\u4f53\u3002\u5728\u8fd9\u91cc\u5f20\u91cf\u53ea\u662f\u5e7f\u4e49\u7684\u8868\u8fbe\u4e00\u79cd\u6570\u636e\u7ed3\u6784\uff0c\u4f8b\u5982\u4e00\u5f20\u5f69\u8272\u56fe\u50cf\u5176\u5b9e\u5c31\u662f\u4e00\u4e2a\u4e09\u9636\u5f20\u91cf\uff0c\u5b83\u7531\u4e09\u4e2a\u901a\u9053\u7684\u50cf\u7d20\u503c\u5806\u53e0\u800c\u6210\u3002\u800c10000\u5f20\u5f69\u8272\u56fe\u6784\u6210\u7684\u4e00\u4e2a\u6570\u636e\u96c6\u5408\u5219\u662f\u56db\u9636\u5f20\u91cf\u3002\n\n\n\n\n\n\n\u8f93\u5165\u662f\u5f20\u91cf\uff0c\u8f93\u51fa\u4e5f\u662f\u5f20\u91cf\u7684\u4e00\u4e2a\u6846\u67b6\u5c31\u662f\u4e00\u4e2a\u6a21\u578b\n\n\n\n\n\n\n\u8fd9\u6837\u7684\u6a21\u578b\u53ef\u4ee5\u88ab\u50cfKeras\u7684\nSequential\n\u4e00\u6837\u88ab\u8bad\u7ec3\n\n\n\n\n\n\nfrom keras.layers import Input, Dense\nfrom keras.models import Model\n\n# this returns a tensor\ninputs = Input(shape=(784,))\n\n# a layer instance is callable on a tensor, and returns a tensor\nx = Dense(64, activation='relu')(inputs)\nx = Dense(64, activation='relu')(x)\npredictions = Dense(10, activation='softmax')(x)\n\n# this creates a model that includes\n# the Input layer and three Dense layers\nmodel = Model(input=inputs, output=predictions)\nmodel.compile(optimizer='rmsprop',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\nmodel.fit(data, labels)  # starts training\n\n\n\n\n\n\n\u6240\u6709\u7684\u6a21\u578b\u90fd\u662f\u53ef\u8c03\u7528\u7684\uff0c\u5c31\u50cf\u5c42\u4e00\u6837\n\n\n\u5229\u7528\u6cdb\u578b\u6a21\u578b\u7684\u63a5\u53e3\uff0c\u6211\u4eec\u53ef\u4ee5\u5f88\u5bb9\u6613\u7684\u91cd\u7528\u5df2\u7ecf\u8bad\u7ec3\u597d\u7684\u6a21\u578b\uff1a\u4f60\u53ef\u4ee5\u628a\u6a21\u578b\u5f53\u4f5c\u4e00\u4e2a\u5c42\u4e00\u6837\uff0c\u901a\u8fc7\u63d0\u4f9b\u4e00\u4e2atensor\u6765\u8c03\u7528\u5b83\u3002\u6ce8\u610f\u5f53\u4f60\u8c03\u7528\u4e00\u4e2a\u6a21\u578b\u65f6\uff0c\u4f60\u4e0d\u4ec5\u4ec5\u91cd\u7528\u4e86\u5b83\u7684\u7ed3\u6784\uff0c\u4e5f\u91cd\u7528\u4e86\u5b83\u7684\u6743\u91cd\u3002\n\n\nx = Input(shape=(784,))\n# this works, and returns the 10-way softmax we defined above.\ny = model(x)\n\n\n\n\n\u8fd9\u79cd\u65b9\u5f0f\u53ef\u4ee5\u5141\u8bb8\u4f60\u5feb\u901f\u7684\u521b\u5efa\u80fd\u5904\u7406\u5e8f\u5217\u4fe1\u53f7\u7684\u6a21\u578b\uff0c\u4f60\u53ef\u4ee5\u5f88\u5feb\u5c06\u4e00\u4e2a\u56fe\u50cf\u5206\u7c7b\u7684\u6a21\u578b\u53d8\u4e3a\u4e00\u4e2a\u5bf9\u89c6\u9891\u5206\u7c7b\u7684\u6a21\u578b\uff0c\u53ea\u9700\u8981\u4e00\u884c\u4ee3\u7801\uff1a\n\n\nfrom keras.layers import TimeDistributed\n\n# input tensor for sequences of 20 timesteps,\n# each containing a 784-dimensional vector\ninput_sequences = Input(shape=(20, 784))\n\n# this applies our previous model to every timestep in the input sequences.\n# the output of the previous model was a 10-way softmax,\n# so the output of the layer below will be a sequence of 20 vectors of size 10.\nprocessed_sequences = TimeDistributed(model)(input_sequences)\n\n\n\n\n\n\n\u591a\u8f93\u5165\u548c\u591a\u8f93\u51fa\u6a21\u578b\n\n\n\u4f7f\u7528\u6cdb\u578b\u6a21\u578b\u7684\u4e00\u4e2a\u5178\u578b\u573a\u666f\u662f\u642d\u5efa\u591a\u8f93\u5165\u3001\u591a\u8f93\u51fa\u7684\u6a21\u578b\u3002\n\n\n\u8003\u8651\u8fd9\u6837\u4e00\u4e2a\u6a21\u578b\u3002\u6211\u4eec\u5e0c\u671b\u9884\u6d4bTwitter\u4e0a\u4e00\u6761\u65b0\u95fb\u4f1a\u88ab\u8f6c\u53d1\u548c\u70b9\u8d5e\u591a\u5c11\u6b21\u3002\u6a21\u578b\u7684\u4e3b\u8981\u8f93\u5165\u662f\u65b0\u95fb\u672c\u8eab\uff0c\u4e5f\u5c31\u662f\u4e00\u4e2a\u8bcd\u8bed\u7684\u5e8f\u5217\u3002\u4f46\u6211\u4eec\u8fd8\u53ef\u4ee5\u62e5\u6709\u989d\u5916\u7684\u8f93\u5165\uff0c\u5982\u65b0\u95fb\u53d1\u5e03\u7684\u65e5\u671f\u7b49\u3002\u8fd9\u4e2a\u6a21\u578b\u7684\u635f\u5931\u51fd\u6570\u5c06\u7531\u4e24\u90e8\u5206\u7ec4\u6210\uff0c\u8f85\u52a9\u7684\u635f\u5931\u51fd\u6570\u8bc4\u4f30\u4ec5\u4ec5\u57fa\u4e8e\u65b0\u95fb\u672c\u8eab\u505a\u51fa\u9884\u6d4b\u7684\u60c5\u51b5\uff0c\u4e3b\u635f\u5931\u51fd\u6570\u8bc4\u4f30\u57fa\u4e8e\u65b0\u95fb\u548c\u989d\u5916\u4fe1\u606f\u7684\u9884\u6d4b\u7684\u60c5\u51b5\uff0c\u5373\u4f7f\u6765\u81ea\u4e3b\u635f\u5931\u51fd\u6570\u7684\u68af\u5ea6\u53d1\u751f\u5f25\u6563\uff0c\u6765\u81ea\u8f85\u52a9\u635f\u5931\u51fd\u6570\u7684\u4fe1\u606f\u4e5f\u80fd\u591f\u8bad\u7ec3Embeddding\u548cLSTM\u5c42\u3002\u5728\u6a21\u578b\u4e2d\u65e9\u70b9\u4f7f\u7528\u4e3b\u8981\u7684\u635f\u5931\u51fd\u6570\u662f\u5bf9\u4e8e\u6df1\u5ea6\u7f51\u7edc\u7684\u4e00\u4e2a\u826f\u597d\u7684\u6b63\u5219\u65b9\u6cd5\u3002\u603b\u800c\u8a00\u4e4b\uff0c\u8be5\u6a21\u578b\u6846\u56fe\u5982\u4e0b\uff1a\n\n\n\n\n\u8ba9\u6211\u4eec\u7528\u6cdb\u578b\u6a21\u578b\u6765\u5b9e\u73b0\u8fd9\u4e2a\u6846\u56fe\n\n\n\u4e3b\u8981\u7684\u8f93\u5165\u63a5\u6536\u65b0\u95fb\u672c\u8eab\uff0c\u5373\u4e00\u4e2a\u6574\u6570\u7684\u5e8f\u5217\uff08\u6bcf\u4e2a\u6574\u6570\u7f16\u7801\u4e86\u4e00\u4e2a\u8bcd\uff09\u3002\u8fd9\u4e9b\u6574\u6570\u4f4d\u4e8e1\u523010\uff0c000\u4e4b\u95f4\uff08\u5373\u6211\u4eec\u7684\u5b57\u5178\u670910\uff0c000\u4e2a\u8bcd\uff09\u3002\u8fd9\u4e2a\u5e8f\u5217\u6709100\u4e2a\u5355\u8bcd\u3002\n\n\nfrom keras.layers import Input, Embedding, LSTM, Dense, merge\nfrom keras.models import Model\n\n# headline input: meant to receive sequences of 100 integers, between 1 and 10000.\n# note that we can name any layer by passing it a \nname\n argument.\nmain_input = Input(shape=(100,), dtype='int32', name='main_input')\n\n# this embedding layer will encode the input sequence\n# into a sequence of dense 512-dimensional vectors.\nx = Embedding(output_dim=512, input_dim=10000, input_length=100)(main_input)\n\n# a LSTM will transform the vector sequence into a single vector,\n# containing information about the entire sequence\nlstm_out = LSTM(32)(x)\n\n\n\n\n\u7136\u540e\uff0c\u6211\u4eec\u63d2\u5165\u4e00\u4e2a\u989d\u5916\u7684\u635f\u5931\uff0c\u4f7f\u5f97\u5373\u4f7f\u5728\u4e3b\u635f\u5931\u5f88\u9ad8\u7684\u60c5\u51b5\u4e0b\uff0cLSTM\u548cEmbedding\u5c42\u4e5f\u53ef\u4ee5\u5e73\u6ed1\u7684\u8bad\u7ec3\u3002\n\n\nauxiliary_output = Dense(1, activation='sigmoid', name='aux_output')(lstm_out)\n\n\n\n\n\u518d\u7136\u540e\uff0c\u6211\u4eec\u5c06LSTM\u4e0e\u989d\u5916\u7684\u8f93\u5165\u6570\u636e\u4e32\u8054\u8d77\u6765\u7ec4\u6210\u8f93\u5165\uff0c\u9001\u5165\u6a21\u578b\u4e2d\uff1a\n\n\nauxiliary_input = Input(shape=(5,), name='aux_input')\nx = merge([lstm_out, auxiliary_input], mode='concat')\n\n# we stack a deep fully-connected network on top\nx = Dense(64, activation='relu')(x)\nx = Dense(64, activation='relu')(x)\nx = Dense(64, activation='relu')(x)\n\n# and finally we add the main logistic regression layer\nmain_output = Dense(1, activation='sigmoid', name='main_output')(x)\n\n\n\n\n\u6700\u540e\uff0c\u6211\u4eec\u5b9a\u4e49\u6574\u4e2a2\u8f93\u5165\uff0c2\u8f93\u51fa\u7684\u6a21\u578b\uff1a\n\n\nmodel = Model(input=[main_input, auxiliary_input], output=[main_output, auxiliary_output])\n\n\n\n\n\u6a21\u578b\u5b9a\u4e49\u5b8c\u6bd5\uff0c\u4e0b\u4e00\u6b65\u7f16\u8bd1\u6a21\u578b\u3002\u6211\u4eec\u7ed9\u989d\u5916\u7684\u635f\u5931\u8d4b0.2\u7684\u6743\u91cd\u3002\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u5173\u952e\u5b57\u53c2\u6570\nloss_weights\n\u6216\nloss\n\u6765\u4e3a\u4e0d\u540c\u7684\u8f93\u51fa\u8bbe\u7f6e\u4e0d\u540c\u7684\u635f\u5931\u51fd\u6570\u6216\u6743\u503c\u3002\u8fd9\u4e24\u4e2a\u53c2\u6570\u5747\u53ef\u4e3aPython\u7684\u5217\u8868\u6216\u5b57\u5178\u3002\u8fd9\u91cc\u6211\u4eec\u7ed9\nloss\n\u4f20\u9012\u5355\u4e2a\u635f\u5931\u51fd\u6570\uff0c\u8fd9\u4e2a\u635f\u5931\u51fd\u6570\u4f1a\u88ab\u5e94\u7528\u4e8e\u6240\u6709\u8f93\u51fa\u4e0a\u3002\n\n\nmodel.compile(optimizer='rmsprop', loss='binary_crossentropy',\n              loss_weights=[1., 0.2])\n\n\n\n\n\u7f16\u8bd1\u5b8c\u6210\u540e\uff0c\u6211\u4eec\u901a\u8fc7\u4f20\u9012\u8bad\u7ec3\u6570\u636e\u548c\u76ee\u6807\u503c\u8bad\u7ec3\u8be5\u6a21\u578b\uff1a\n\n\nmodel.fit([headline_data, additional_data], [labels, labels],\n          nb_epoch=50, batch_size=32)\n\n\n\n\n\n\u56e0\u4e3a\u6211\u4eec\u8f93\u5165\u548c\u8f93\u51fa\u662f\u88ab\u547d\u540d\u8fc7\u7684\uff08\u5728\u5b9a\u4e49\u65f6\u4f20\u9012\u4e86\u201cname\u201d\u53c2\u6570\uff09\uff0c\u6211\u4eec\u4e5f\u53ef\u4ee5\u7528\u4e0b\u9762\u7684\u65b9\u5f0f\u7f16\u8bd1\u548c\u8bad\u7ec3\u6a21\u578b\uff1a\n\n\nmodel.compile(optimizer='rmsprop',\n              loss={'main_output': 'binary_crossentropy', 'aux_output': 'binary_crossentropy'},\n              loss_weights={'main_output': 1., 'aux_output': 0.2})\n\n# and trained it via:\nmodel.fit({'main_input': headline_data, 'aux_input': additional_data},\n          {'main_output': labels, 'aux_output': labels},\n          nb_epoch=50, batch_size=32)\n\n\n\n\n\n\n\n\n        \n\n\n\u5171\u4eab\u5c42\n\n\n\u53e6\u4e00\u4e2a\u4f7f\u7528\u6cdb\u578b\u6a21\u578b\u7684\u573a\u5408\u662f\u4f7f\u7528\u5171\u4eab\u5c42\u7684\u65f6\u5019\u3002\n\n\n\u8003\u8651\u5fae\u535a\u6570\u636e\uff0c\u6211\u4eec\u5e0c\u671b\u5efa\u7acb\u6a21\u578b\u6765\u5224\u522b\u4e24\u6761\u5fae\u535a\u662f\u5426\u662f\u6765\u81ea\u540c\u4e00\u4e2a\u7528\u6237\uff0c\u8fd9\u4e2a\u9700\u6c42\u540c\u6837\u53ef\u4ee5\u7528\u6765\u5224\u65ad\u4e00\u4e2a\u7528\u6237\u7684\u4e24\u6761\u5fae\u535a\u7684\u76f8\u4f3c\u6027\u3002\n\n\n\u4e00\u79cd\u5b9e\u73b0\u65b9\u5f0f\u662f\uff0c\u6211\u4eec\u5efa\u7acb\u4e00\u4e2a\u6a21\u578b\uff0c\u5b83\u5206\u522b\u5c06\u4e24\u6761\u5fae\u535a\u7684\u6570\u636e\u6620\u5c04\u5230\u4e24\u4e2a\u7279\u5f81\u5411\u91cf\u4e0a\uff0c\u7136\u540e\u5c06\u7279\u5f81\u5411\u91cf\u4e32\u8054\u5e76\u52a0\u4e00\u4e2alogistic\u56de\u5f52\u5c42\uff0c\u8f93\u51fa\u5b83\u4eec\u6765\u81ea\u540c\u4e00\u4e2a\u7528\u6237\u7684\u6982\u7387\u3002\u8fd9\u79cd\u6a21\u578b\u7684\u8bad\u7ec3\u6570\u636e\u662f\u4e00\u5bf9\u5bf9\u7684\u5fae\u535a\u3002\n\n\n\u56e0\u4e3a\u8fd9\u4e2a\u95ee\u9898\u662f\u5bf9\u79f0\u7684\uff0c\u6240\u4ee5\u5904\u7406\u7b2c\u4e00\u6761\u5fae\u535a\u7684\u6a21\u578b\u5f53\u7136\u4e5f\u80fd\u91cd\u7528\u4e8e\u5904\u7406\u7b2c\u4e8c\u6761\u5fae\u535a\u3002\u6240\u4ee5\u8fd9\u91cc\u6211\u4eec\u4f7f\u7528\u4e00\u4e2a\u5171\u4eab\u7684LSTM\u5c42\u6765\u8fdb\u884c\u6620\u5c04\u3002\n\n\n\u9996\u5148\uff0c\u6211\u4eec\u5c06\u5fae\u535a\u7684\u6570\u636e\u8f6c\u4e3a\uff08140\uff0c256\uff09\u7684\u77e9\u9635\uff0c\u5373\u6bcf\u6761\u5fae\u535a\u6709140\u4e2a\u5b57\u7b26\uff0c\u6bcf\u4e2a\u5355\u8bcd\u7684\u7279\u5f81\u7531\u4e00\u4e2a256\u7ef4\u7684\u8bcd\u5411\u91cf\u8868\u793a\uff0c\u5411\u91cf\u7684\u6bcf\u4e2a\u5143\u7d20\u4e3a1\u8868\u793a\u67d0\u4e2a\u5b57\u7b26\u51fa\u73b0\uff0c\u4e3a0\u8868\u793a\u4e0d\u51fa\u73b0\uff0c\u8fd9\u662f\u4e00\u4e2aone-hot\u7f16\u7801\u3002\n\n\n\u3010Tips\u3011\u4e4b\u6240\u4ee5\u662f\uff08140\uff0c256\uff09\u662f\u56e0\u4e3a\u4e00\u6761\u5fae\u535a\u6700\u591a\u6709140\u4e2a\u5b57\u7b26\uff08\u636e\u8bf4\u73b0\u5728\u8981\u53d6\u6d88\u8fd9\u4e2a\u9650\u5236\u4e86\uff09\uff0c\u800c\u6269\u5c55\u7684ASCII\u7801\u8868\u7f16\u7801\u4e86\u5e38\u89c1\u7684256\u4e2a\u5b57\u7b26\u3002\u539f\u6587\u4e2d\u6b64\u5904\u4e3aTweet\uff0c\u6240\u4ee5\u5bf9\u5916\u56fd\u4eba\u800c\u8a00\u8fd9\u662f\u5408\u7406\u7684\u3002\u5982\u679c\u8003\u8651\u4e2d\u6587\u5b57\u7b26\uff0c\u90a3\u4e00\u4e2a\u5355\u8bcd\u7684\u8bcd\u5411\u91cf\u5c31\u4e0d\u6b62256\u4e86\u3002\u3010@Bigmoyan\u3011\n\n\nfrom keras.layers import Input, LSTM, Dense, merge\nfrom keras.models import Model\n\ntweet_a = Input(shape=(140, 256))\ntweet_b = Input(shape=(140, 256))   \n\n\n\n\n\u82e5\u8981\u5bf9\u4e0d\u540c\u7684\u8f93\u5165\u5171\u4eab\u540c\u4e00\u5c42\uff0c\u5c31\u521d\u59cb\u5316\u8be5\u5c42\u4e00\u6b21\uff0c\u7136\u540e\u591a\u6b21\u8c03\u7528\u5b83\n\n\n# this layer can take as input a matrix\n# and will return a vector of size 64\nshared_lstm = LSTM(64)\n\n# when we reuse the same layer instance\n# multiple times, the weights of the layer\n# are also being reused\n# (it is effectively *the same* layer)\nencoded_a = shared_lstm(tweet_a)\nencoded_b = shared_lstm(tweet_b)\n\n# we can then concatenate the two vectors:\nmerged_vector = merge([encoded_a, encoded_b], mode='concat', concat_axis=-1)\n\n# and add a logistic regression on top\npredictions = Dense(1, activation='sigmoid')(merged_vector)\n\n# we define a trainable model linking the\n# tweet inputs to the predictions\nmodel = Model(input=[tweet_a, tweet_b], output=predictions)\n\nmodel.compile(optimizer='rmsprop',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\nmodel.fit([data_a, data_b], labels, nb_epoch=10)\n\n\n\n\n\u5148\u6682\u505c\u4e00\u4e0b\uff0c\u770b\u770b\u5171\u4eab\u5c42\u5230\u5e95\u8f93\u51fa\u4e86\u4ec0\u4e48\uff0c\u5b83\u7684\u8f93\u51fa\u6570\u636eshape\u53c8\u662f\u4ec0\u4e48\n\n\n\n\n\u5c42\u201c\u8282\u70b9\u201d\u7684\u6982\u5ff5\n\n\n\u65e0\u8bba\u4f55\u65f6\uff0c\u5f53\u4f60\u5728\u67d0\u4e2a\u8f93\u5165\u4e0a\u8c03\u7528\u5c42\u65f6\uff0c\u4f60\u5c31\u521b\u5efa\u4e86\u4e00\u4e2a\u65b0\u7684\u5f20\u91cf\uff08\u5373\u8be5\u5c42\u7684\u8f93\u51fa\uff09\uff0c\u540c\u65f6\u4f60\u4e5f\u5728\u4e3a\u8fd9\u4e2a\u5c42\u589e\u52a0\u4e00\u4e2a\u201c\uff08\u8ba1\u7b97\uff09\u8282\u70b9\u201d\u3002\u8fd9\u4e2a\u8282\u70b9\u5c06\u8f93\u5165\u5f20\u91cf\u6620\u5c04\u4e3a\u8f93\u51fa\u5f20\u91cf\u3002\u5f53\u4f60\u591a\u6b21\u8c03\u7528\u8be5\u5c42\u65f6\uff0c\u8fd9\u4e2a\u5c42\u5c31\u6709\u4e86\u591a\u4e2a\u8282\u70b9\uff0c\u5176\u4e0b\u6807\u5206\u522b\u4e3a0\uff0c1\uff0c2...\n\n\n\u5728\u4e0a\u4e00\u7248\u672c\u7684Keras\u4e2d\uff0c\u4f60\u53ef\u4ee5\u901a\u8fc7\nlayer.get_output()\n\u65b9\u6cd5\u6765\u83b7\u5f97\u5c42\u7684\u8f93\u51fa\u5f20\u91cf\uff0c\u6216\u8005\u901a\u8fc7\nlayer.output_shape\n\u83b7\u5f97\u5176\u8f93\u51fa\u5f20\u91cf\u7684shape\u3002\u8fd9\u4e2a\u7248\u672c\u7684Keras\u4f60\u4ecd\u7136\u53ef\u4ee5\u8fd9\u4e48\u505a\uff08\u9664\u4e86\nlayer.get_output()\n\u88ab\noutput()\n\u66ff\u6362\uff09\u3002\u4f46\u5982\u679c\u4e00\u4e2a\u5c42\u4e0e\u591a\u4e2a\u8f93\u5165\u76f8\u8fde\uff0c\u4f1a\u51fa\u73b0\u4ec0\u4e48\u60c5\u51b5\u5462\uff1f\n\n\n\u5982\u679c\u5c42\u53ea\u4e0e\u4e00\u4e2a\u8f93\u5165\u76f8\u8fde\uff0c\u90a3\u6ca1\u6709\u4efb\u4f55\u56f0\u60d1\u7684\u5730\u65b9\u3002\n.output()\n\u5c06\u4f1a\u8fd4\u56de\u8be5\u5c42\u552f\u4e00\u7684\u8f93\u51fa\n\n\na = Input(shape=(140, 256))\n\nlstm = LSTM(32)\nencoded_a = lstm(a)\n\nassert lstm.output == encoded_a\n\n\n\n\n\u4f46\u5f53\u5c42\u4e0e\u591a\u4e2a\u8f93\u5165\u76f8\u8fde\u65f6\uff0c\u4f1a\u51fa\u73b0\u95ee\u9898\n\n\na = Input(shape=(140, 256))\nb = Input(shape=(140, 256))\n\nlstm = LSTM(32)\nencoded_a = lstm(a)\nencoded_b = lstm(b)\n\nlstm.output\n\n\n\n\n\u4e0a\u9762\u8fd9\u6bb5\u4ee3\u7801\u4f1a\u62a5\u9519\n\n\n AssertionError: Layer lstm_1 has multiple inbound nodes,\nhence the notion of \nlayer output\n is ill-defined.\nUse `get_output_at(node_index)` instead.\n\n\n\n\n\u901a\u8fc7\u4e0b\u9762\u8fd9\u79cd\u8c03\u7528\u65b9\u5f0f\u5373\u53ef\u89e3\u51b3\n\n\nassert lstm.get_output_at(0) == encoded_a\nassert lstm.get_output_at(1) == encoded_b\n\n\n\n\n\n\n\n\n\u591f\u7b80\u5355\u5427\uff1f\n\n\n\u5bf9\u4e8e\ninput_shape\n\u548c\noutput_shape\n\u4e5f\u662f\u4e00\u6837\uff0c\u5982\u679c\u4e00\u4e2a\u5c42\u53ea\u6709\u4e00\u4e2a\u8282\u70b9\uff0c\u6216\u6240\u6709\u7684\u8282\u70b9\u90fd\u6709\u76f8\u540c\u7684\u8f93\u5165\u6216\u8f93\u51fashape\uff0c\u90a3\u4e48\ninput_shape\n\u548c\noutput_shape\n\u90fd\u662f\u6ca1\u6709\u6b67\u4e49\u7684\uff0c\u5e76\u4e5f\u53ea\u8fd4\u56de\u4e00\u4e2a\u503c\u3002\u4f46\u662f\uff0c\u4f8b\u5982\u4f60\u628a\u4e00\u4e2a\u76f8\u540c\u7684\nConvolution2D\n\u5e94\u7528\u4e8e\u4e00\u4e2a\u5927\u5c0f\u4e3a(3,32,32)\u7684\u6570\u636e\uff0c\u7136\u540e\u53c8\u5c06\u5176\u5e94\u7528\u4e8e\u4e00\u4e2a(3,64,64)\u7684\u6570\u636e\uff0c\u90a3\u4e48\u6b64\u65f6\u8be5\u5c42\u5c31\u5177\u6709\u4e86\u591a\u4e2a\u8f93\u5165\u548c\u8f93\u51fa\u7684shape\uff0c\u4f60\u5c31\u9700\u8981\u663e\u5f0f\u7684\u6307\u5b9a\u8282\u70b9\u7684\u4e0b\u6807\uff0c\u6765\u8868\u660e\u4f60\u60f3\u53d6\u7684\u662f\u54ea\u4e2a\u4e86\n\n\na = Input(shape=(3, 32, 32))\nb = Input(shape=(3, 64, 64))\n\nconv = Convolution2D(16, 3, 3, border_mode='same')\nconved_a = conv(a)\n\n# only one input so far, the following will work:\nassert conv.input_shape == (None, 3, 32, 32)\n\nconved_b = conv(b)\n# now the `.input_shape` property wouldn't work, but this does:\nassert conv.get_input_shape_at(0) == (None, 3, 32, 32)\nassert conv.get_input_shape_at(1) == (None, 3, 64, 64)\n\n\n\n\n\n\n\u66f4\u591a\u7684\u4f8b\u5b50\n\n\n\u4ee3\u7801\u793a\u4f8b\u4f9d\u7136\u662f\u5b66\u4e60\u7684\u6700\u4f73\u65b9\u5f0f\uff0c\u8fd9\u91cc\u662f\u66f4\u591a\u7684\u4f8b\u5b50\n\n\ninception\u6a21\u578b\n\n\ninception\u7684\u8be6\u7ec6\u7ed3\u6784\u53c2\u89c1Google\u7684\u8fd9\u7bc7\u8bba\u6587\uff1a\nGoing Deeper with Convolutions\n\n\nfrom keras.layers import merge, Convolution2D, MaxPooling2D, Input\n\ninput_img = Input(shape=(3, 256, 256))\n\ntower_1 = Convolution2D(64, 1, 1, border_mode='same', activation='relu')(input_img)\ntower_1 = Convolution2D(64, 3, 3, border_mode='same', activation='relu')(tower_1)\n\ntower_2 = Convolution2D(64, 1, 1, border_mode='same', activation='relu')(input_img)\ntower_2 = Convolution2D(64, 5, 5, border_mode='same', activation='relu')(tower_2)\n\ntower_3 = MaxPooling2D((3, 3), strides=(1, 1), border_mode='same')(input_img)\ntower_3 = Convolution2D(64, 1, 1, border_mode='same', activation='relu')(tower_3)\n\noutput = merge([tower_1, tower_2, tower_3], mode='concat', concat_axis=1)\n\n\n\n\n\u5377\u79ef\u5c42\u7684\u6b8b\u5dee\u8fde\u63a5\n\n\n\u6b8b\u5dee\u7f51\u7edc\uff08Residual Network\uff09\u7684\u8be6\u7ec6\u4fe1\u606f\u8bf7\u53c2\u8003\u8fd9\u7bc7\u6587\u7ae0\uff1a\nDeep Residual Learning for Image Recognition\n\n\nfrom keras.layers import merge, Convolution2D, Input\n\n# input tensor for a 3-channel 256x256 image\nx = Input(shape=(3, 256, 256))\n# 3x3 conv with 3 output channels(same as input channels)\ny = Convolution2D(3, 3, 3, border_mode='same')(x)\n# this returns x + y.\nz = merge([x, y], mode='sum')\n\n\n\n\n\u5171\u4eab\u89c6\u89c9\u6a21\u578b\n\n\n\u8be5\u6a21\u578b\u5728\u4e24\u4e2a\u8f93\u5165\u4e0a\u91cd\u7528\u4e86\u56fe\u50cf\u5904\u7406\u7684\u6a21\u578b\uff0c\u7528\u6765\u5224\u522b\u4e24\u4e2aMNIST\u6570\u5b57\u662f\u5426\u662f\u76f8\u540c\u7684\u6570\u5b57\n\n\nfrom keras.layers import merge, Convolution2D, MaxPooling2D, Input, Dense, Flatten\nfrom keras.models import Model\n\n# first, define the vision modules\ndigit_input = Input(shape=(1, 27, 27))\nx = Convolution2D(64, 3, 3)(digit_input)\nx = Convolution2D(64, 3, 3)(x)\nx = MaxPooling2D((2, 2))(x)\nout = Flatten()(x)\n\nvision_model = Model(digit_input, out)\n\n# then define the tell-digits-apart model\ndigit_a = Input(shape=(1, 27, 27))\ndigit_b = Input(shape=(1, 27, 27))\n\n# the vision model will be shared, weights and all\nout_a = vision_model(digit_a)\nout_b = vision_model(digit_b)\n\nconcatenated = merge([out_a, out_b], mode='concat')\nout = Dense(1, activation='sigmoid')(concatenated)\n\nclassification_model = Model([digit_a, digit_b], out)\n\n\n\n\n\u89c6\u89c9\u95ee\u7b54\u6a21\u578b\n\n\n\u5728\u9488\u5bf9\u4e00\u5e45\u56fe\u7247\u4f7f\u7528\u81ea\u7136\u8bed\u8a00\u8fdb\u884c\u63d0\u95ee\u65f6\uff0c\u8be5\u6a21\u578b\u80fd\u591f\u63d0\u4f9b\u5173\u4e8e\u8be5\u56fe\u7247\u7684\u4e00\u4e2a\u5355\u8bcd\u7684\u7b54\u6848\n\n\n\u8fd9\u4e2a\u6a21\u578b\u5c06\u81ea\u7136\u8bed\u8a00\u7684\u95ee\u9898\u548c\u56fe\u7247\u5206\u522b\u6620\u5c04\u4e3a\u7279\u5f81\u5411\u91cf\uff0c\u5c06\u4e8c\u8005\u5408\u5e76\u540e\u8bad\u7ec3\u4e00\u4e2alogistic\u56de\u5f52\u5c42\uff0c\u4ece\u4e00\u7cfb\u5217\u53ef\u80fd\u7684\u56de\u7b54\u4e2d\u6311\u9009\u4e00\u4e2a\u3002\n\n\nfrom keras.layers import Convolution2D, MaxPooling2D, Flatten\nfrom keras.layers import Input, LSTM, Embedding, Dense, merge\nfrom keras.models import Model, Sequential\n\n# first, let's define a vision model using a Sequential model.\n# this model will encode an image into a vector.\nvision_model = Sequential()\nvision_model.add(Convolution2D(64, 3, 3, activation='relu', border_mode='same', input_shape=(3, 224, 224)))\nvision_model.add(Convolution2D(64, 3, 3, activation='relu'))\nvision_model.add(MaxPooling2D((2, 2)))\nvision_model.add(Convolution2D(128, 3, 3, activation='relu', border_mode='same'))\nvision_model.add(Convolution2D(128, 3, 3, activation='relu'))\nvision_model.add(MaxPooling2D((2, 2)))\nvision_model.add(Convolution2D(256, 3, 3, activation='relu', border_mode='same'))\nvision_model.add(Convolution2D(256, 3, 3, activation='relu'))\nvision_model.add(Convolution2D(256, 3, 3, activation='relu'))\nvision_model.add(MaxPooling2D((2, 2)))\nvision_model.add(Flatten())\n\n# now let's get a tensor with the output of our vision model:\nimage_input = Input(shape=(3, 224, 224))\nencoded_image = vision_model(image_input)\n\n# next, let's define a language model to encode the question into a vector.\n# each question will be at most 100 word long,\n# and we will index words as integers from 1 to 9999.\nquestion_input = Input(shape=(100,), dtype='int32')\nembedded_question = Embedding(input_dim=10000, output_dim=256, input_length=100)(question_input)\nencoded_question = LSTM(256)(embedded_question)\n\n# let's concatenate the question vector and the image vector:\nmerged = merge([encoded_question, encoded_image], mode='concat')\n\n# and let's train a logistic regression over 1000 words on top:\noutput = Dense(1000, activation='softmax')(merged)\n\n# this is our final model:\nvqa_model = Model(input=[image_input, question_input], output=output)\n\n# the next stage would be training this model on actual data.\n\n\n\n\n\u89c6\u9891\u95ee\u7b54\u6a21\u578b\n\n\n\u5728\u505a\u5b8c\u56fe\u7247\u95ee\u7b54\u6a21\u578b\u540e\uff0c\u6211\u4eec\u53ef\u4ee5\u5feb\u901f\u5c06\u5176\u8f6c\u4e3a\u89c6\u9891\u95ee\u7b54\u7684\u6a21\u578b\u3002\u5728\u9002\u5f53\u7684\u8bad\u7ec3\u4e0b\uff0c\u4f60\u53ef\u4ee5\u4e3a\u6a21\u578b\u63d0\u4f9b\u4e00\u4e2a\u77ed\u89c6\u9891\uff08\u5982100\u5e27\uff09\u7136\u540e\u5411\u6a21\u578b\u63d0\u95ee\u4e00\u4e2a\u5173\u4e8e\u8be5\u89c6\u9891\u7684\u95ee\u9898\uff0c\u5982\u201cwhat sport is the boy playing\uff1f\u201d-\n\u201cfootball\u201d\n\n\nfrom keras.layers import TimeDistributed\n\nvideo_input = Input(shape=(100, 3, 224, 224))\n# this is our video encoded via the previously trained vision_model (weights are reused)\nencoded_frame_sequence = TimeDistributed(vision_model)(video_input)  # the output will be a sequence of vectors\nencoded_video = LSTM(256)(encoded_frame_sequence)  # the output will be a vector\n\n# this is a model-level representation of the question encoder, reusing the same weights as before:\nquestion_encoder = Model(input=question_input, output=encoded_question)\n\n# let's use it to encode the question:\nvideo_question_input = Input(shape=(100,), dtype='int32')\nencoded_video_question = question_encoder(video_question_input)\n\n# and this is our video question answering model:\nmerged = merge([encoded_video, encoded_video_question], mode='concat')\noutput = Dense(1000, activation='softmax')(merged)\nvideo_qa_model = Model(input=[video_input, video_question_input], output=output)", 
            "title": "\u5feb\u901f\u5f00\u59cb\u6cdb\u578b\u6a21\u578b"
        }, 
        {
            "location": "/getting_started/functional_API/#_1", 
            "text": "Keras\u6cdb\u578b\u6a21\u578b\u63a5\u53e3\u662f\u7528\u6237\u5b9a\u4e49\u591a\u8f93\u51fa\u6a21\u578b\u3001\u975e\u5faa\u73af\u6709\u5411\u6a21\u578b\u6216\u5177\u6709\u5171\u4eab\u5c42\u7684\u6a21\u578b\u7b49\u590d\u6742\u6a21\u578b\u7684\u9014\u5f84  \u8fd9\u90e8\u5206\u7684\u6587\u6863\u5047\u8bbe\u4f60\u5df2\u7ecf\u5bf9 Sequential \u6a21\u578b\u5df2\u7ecf\u6bd4\u8f83\u719f\u6089  \u8ba9\u6211\u4eec\u4ece\u7b80\u5355\u4e00\u70b9\u7684\u6a21\u578b\u5f00\u59cb", 
            "title": "\u5feb\u901f\u5f00\u59cb\u6cdb\u578b\u6a21\u578b"
        }, 
        {
            "location": "/getting_started/functional_API/#_2", 
            "text": "Sequential \u5f53\u7136\u662f\u5b9e\u73b0\u5168\u8fde\u63a5\u7f51\u7edc\u7684\u6700\u597d\u65b9\u5f0f\uff0c\u4f46\u6211\u4eec\u4ece\u7b80\u5355\u7684\u5168\u8fde\u63a5\u7f51\u7edc\u5f00\u59cb\uff0c\u6709\u52a9\u4e8e\u6211\u4eec\u5b66\u4e60\u8fd9\u90e8\u5206\u7684\u5185\u5bb9\u3002\u5728\u5f00\u59cb\u524d\uff0c\u6709\u51e0\u4e2a\u6982\u5ff5\u9700\u8981\u6f84\u6e05\uff1a    \u5c42\u5bf9\u8c61\u63a5\u53d7\u5f20\u91cf\u4e3a\u53c2\u6570\uff0c\u8fd4\u56de\u4e00\u4e2a\u5f20\u91cf\u3002\u5f20\u91cf\u5728\u6570\u5b66\u4e0a\u53ea\u662f\u6570\u636e\u7ed3\u6784\u7684\u6269\u5145\uff0c\u4e00\u9636\u5f20\u91cf\u5c31\u662f\u5411\u91cf\uff0c\u4e8c\u9636\u5f20\u91cf\u5c31\u662f\u77e9\u9635\uff0c\u4e09\u9636\u5f20\u91cf\u5c31\u662f\u7acb\u65b9\u4f53\u3002\u5728\u8fd9\u91cc\u5f20\u91cf\u53ea\u662f\u5e7f\u4e49\u7684\u8868\u8fbe\u4e00\u79cd\u6570\u636e\u7ed3\u6784\uff0c\u4f8b\u5982\u4e00\u5f20\u5f69\u8272\u56fe\u50cf\u5176\u5b9e\u5c31\u662f\u4e00\u4e2a\u4e09\u9636\u5f20\u91cf\uff0c\u5b83\u7531\u4e09\u4e2a\u901a\u9053\u7684\u50cf\u7d20\u503c\u5806\u53e0\u800c\u6210\u3002\u800c10000\u5f20\u5f69\u8272\u56fe\u6784\u6210\u7684\u4e00\u4e2a\u6570\u636e\u96c6\u5408\u5219\u662f\u56db\u9636\u5f20\u91cf\u3002    \u8f93\u5165\u662f\u5f20\u91cf\uff0c\u8f93\u51fa\u4e5f\u662f\u5f20\u91cf\u7684\u4e00\u4e2a\u6846\u67b6\u5c31\u662f\u4e00\u4e2a\u6a21\u578b    \u8fd9\u6837\u7684\u6a21\u578b\u53ef\u4ee5\u88ab\u50cfKeras\u7684 Sequential \u4e00\u6837\u88ab\u8bad\u7ec3    from keras.layers import Input, Dense\nfrom keras.models import Model\n\n# this returns a tensor\ninputs = Input(shape=(784,))\n\n# a layer instance is callable on a tensor, and returns a tensor\nx = Dense(64, activation='relu')(inputs)\nx = Dense(64, activation='relu')(x)\npredictions = Dense(10, activation='softmax')(x)\n\n# this creates a model that includes\n# the Input layer and three Dense layers\nmodel = Model(input=inputs, output=predictions)\nmodel.compile(optimizer='rmsprop',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\nmodel.fit(data, labels)  # starts training", 
            "title": "\u7b2c\u4e00\u4e2a\u6a21\u578b\uff1a\u5168\u8fde\u63a5\u7f51\u7edc"
        }, 
        {
            "location": "/getting_started/functional_API/#_3", 
            "text": "\u5229\u7528\u6cdb\u578b\u6a21\u578b\u7684\u63a5\u53e3\uff0c\u6211\u4eec\u53ef\u4ee5\u5f88\u5bb9\u6613\u7684\u91cd\u7528\u5df2\u7ecf\u8bad\u7ec3\u597d\u7684\u6a21\u578b\uff1a\u4f60\u53ef\u4ee5\u628a\u6a21\u578b\u5f53\u4f5c\u4e00\u4e2a\u5c42\u4e00\u6837\uff0c\u901a\u8fc7\u63d0\u4f9b\u4e00\u4e2atensor\u6765\u8c03\u7528\u5b83\u3002\u6ce8\u610f\u5f53\u4f60\u8c03\u7528\u4e00\u4e2a\u6a21\u578b\u65f6\uff0c\u4f60\u4e0d\u4ec5\u4ec5\u91cd\u7528\u4e86\u5b83\u7684\u7ed3\u6784\uff0c\u4e5f\u91cd\u7528\u4e86\u5b83\u7684\u6743\u91cd\u3002  x = Input(shape=(784,))\n# this works, and returns the 10-way softmax we defined above.\ny = model(x)  \u8fd9\u79cd\u65b9\u5f0f\u53ef\u4ee5\u5141\u8bb8\u4f60\u5feb\u901f\u7684\u521b\u5efa\u80fd\u5904\u7406\u5e8f\u5217\u4fe1\u53f7\u7684\u6a21\u578b\uff0c\u4f60\u53ef\u4ee5\u5f88\u5feb\u5c06\u4e00\u4e2a\u56fe\u50cf\u5206\u7c7b\u7684\u6a21\u578b\u53d8\u4e3a\u4e00\u4e2a\u5bf9\u89c6\u9891\u5206\u7c7b\u7684\u6a21\u578b\uff0c\u53ea\u9700\u8981\u4e00\u884c\u4ee3\u7801\uff1a  from keras.layers import TimeDistributed\n\n# input tensor for sequences of 20 timesteps,\n# each containing a 784-dimensional vector\ninput_sequences = Input(shape=(20, 784))\n\n# this applies our previous model to every timestep in the input sequences.\n# the output of the previous model was a 10-way softmax,\n# so the output of the layer below will be a sequence of 20 vectors of size 10.\nprocessed_sequences = TimeDistributed(model)(input_sequences)", 
            "title": "\u6240\u6709\u7684\u6a21\u578b\u90fd\u662f\u53ef\u8c03\u7528\u7684\uff0c\u5c31\u50cf\u5c42\u4e00\u6837"
        }, 
        {
            "location": "/getting_started/functional_API/#_4", 
            "text": "\u4f7f\u7528\u6cdb\u578b\u6a21\u578b\u7684\u4e00\u4e2a\u5178\u578b\u573a\u666f\u662f\u642d\u5efa\u591a\u8f93\u5165\u3001\u591a\u8f93\u51fa\u7684\u6a21\u578b\u3002  \u8003\u8651\u8fd9\u6837\u4e00\u4e2a\u6a21\u578b\u3002\u6211\u4eec\u5e0c\u671b\u9884\u6d4bTwitter\u4e0a\u4e00\u6761\u65b0\u95fb\u4f1a\u88ab\u8f6c\u53d1\u548c\u70b9\u8d5e\u591a\u5c11\u6b21\u3002\u6a21\u578b\u7684\u4e3b\u8981\u8f93\u5165\u662f\u65b0\u95fb\u672c\u8eab\uff0c\u4e5f\u5c31\u662f\u4e00\u4e2a\u8bcd\u8bed\u7684\u5e8f\u5217\u3002\u4f46\u6211\u4eec\u8fd8\u53ef\u4ee5\u62e5\u6709\u989d\u5916\u7684\u8f93\u5165\uff0c\u5982\u65b0\u95fb\u53d1\u5e03\u7684\u65e5\u671f\u7b49\u3002\u8fd9\u4e2a\u6a21\u578b\u7684\u635f\u5931\u51fd\u6570\u5c06\u7531\u4e24\u90e8\u5206\u7ec4\u6210\uff0c\u8f85\u52a9\u7684\u635f\u5931\u51fd\u6570\u8bc4\u4f30\u4ec5\u4ec5\u57fa\u4e8e\u65b0\u95fb\u672c\u8eab\u505a\u51fa\u9884\u6d4b\u7684\u60c5\u51b5\uff0c\u4e3b\u635f\u5931\u51fd\u6570\u8bc4\u4f30\u57fa\u4e8e\u65b0\u95fb\u548c\u989d\u5916\u4fe1\u606f\u7684\u9884\u6d4b\u7684\u60c5\u51b5\uff0c\u5373\u4f7f\u6765\u81ea\u4e3b\u635f\u5931\u51fd\u6570\u7684\u68af\u5ea6\u53d1\u751f\u5f25\u6563\uff0c\u6765\u81ea\u8f85\u52a9\u635f\u5931\u51fd\u6570\u7684\u4fe1\u606f\u4e5f\u80fd\u591f\u8bad\u7ec3Embeddding\u548cLSTM\u5c42\u3002\u5728\u6a21\u578b\u4e2d\u65e9\u70b9\u4f7f\u7528\u4e3b\u8981\u7684\u635f\u5931\u51fd\u6570\u662f\u5bf9\u4e8e\u6df1\u5ea6\u7f51\u7edc\u7684\u4e00\u4e2a\u826f\u597d\u7684\u6b63\u5219\u65b9\u6cd5\u3002\u603b\u800c\u8a00\u4e4b\uff0c\u8be5\u6a21\u578b\u6846\u56fe\u5982\u4e0b\uff1a   \u8ba9\u6211\u4eec\u7528\u6cdb\u578b\u6a21\u578b\u6765\u5b9e\u73b0\u8fd9\u4e2a\u6846\u56fe  \u4e3b\u8981\u7684\u8f93\u5165\u63a5\u6536\u65b0\u95fb\u672c\u8eab\uff0c\u5373\u4e00\u4e2a\u6574\u6570\u7684\u5e8f\u5217\uff08\u6bcf\u4e2a\u6574\u6570\u7f16\u7801\u4e86\u4e00\u4e2a\u8bcd\uff09\u3002\u8fd9\u4e9b\u6574\u6570\u4f4d\u4e8e1\u523010\uff0c000\u4e4b\u95f4\uff08\u5373\u6211\u4eec\u7684\u5b57\u5178\u670910\uff0c000\u4e2a\u8bcd\uff09\u3002\u8fd9\u4e2a\u5e8f\u5217\u6709100\u4e2a\u5355\u8bcd\u3002  from keras.layers import Input, Embedding, LSTM, Dense, merge\nfrom keras.models import Model\n\n# headline input: meant to receive sequences of 100 integers, between 1 and 10000.\n# note that we can name any layer by passing it a  name  argument.\nmain_input = Input(shape=(100,), dtype='int32', name='main_input')\n\n# this embedding layer will encode the input sequence\n# into a sequence of dense 512-dimensional vectors.\nx = Embedding(output_dim=512, input_dim=10000, input_length=100)(main_input)\n\n# a LSTM will transform the vector sequence into a single vector,\n# containing information about the entire sequence\nlstm_out = LSTM(32)(x)  \u7136\u540e\uff0c\u6211\u4eec\u63d2\u5165\u4e00\u4e2a\u989d\u5916\u7684\u635f\u5931\uff0c\u4f7f\u5f97\u5373\u4f7f\u5728\u4e3b\u635f\u5931\u5f88\u9ad8\u7684\u60c5\u51b5\u4e0b\uff0cLSTM\u548cEmbedding\u5c42\u4e5f\u53ef\u4ee5\u5e73\u6ed1\u7684\u8bad\u7ec3\u3002  auxiliary_output = Dense(1, activation='sigmoid', name='aux_output')(lstm_out)  \u518d\u7136\u540e\uff0c\u6211\u4eec\u5c06LSTM\u4e0e\u989d\u5916\u7684\u8f93\u5165\u6570\u636e\u4e32\u8054\u8d77\u6765\u7ec4\u6210\u8f93\u5165\uff0c\u9001\u5165\u6a21\u578b\u4e2d\uff1a  auxiliary_input = Input(shape=(5,), name='aux_input')\nx = merge([lstm_out, auxiliary_input], mode='concat')\n\n# we stack a deep fully-connected network on top\nx = Dense(64, activation='relu')(x)\nx = Dense(64, activation='relu')(x)\nx = Dense(64, activation='relu')(x)\n\n# and finally we add the main logistic regression layer\nmain_output = Dense(1, activation='sigmoid', name='main_output')(x)  \u6700\u540e\uff0c\u6211\u4eec\u5b9a\u4e49\u6574\u4e2a2\u8f93\u5165\uff0c2\u8f93\u51fa\u7684\u6a21\u578b\uff1a  model = Model(input=[main_input, auxiliary_input], output=[main_output, auxiliary_output])  \u6a21\u578b\u5b9a\u4e49\u5b8c\u6bd5\uff0c\u4e0b\u4e00\u6b65\u7f16\u8bd1\u6a21\u578b\u3002\u6211\u4eec\u7ed9\u989d\u5916\u7684\u635f\u5931\u8d4b0.2\u7684\u6743\u91cd\u3002\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u5173\u952e\u5b57\u53c2\u6570 loss_weights \u6216 loss \u6765\u4e3a\u4e0d\u540c\u7684\u8f93\u51fa\u8bbe\u7f6e\u4e0d\u540c\u7684\u635f\u5931\u51fd\u6570\u6216\u6743\u503c\u3002\u8fd9\u4e24\u4e2a\u53c2\u6570\u5747\u53ef\u4e3aPython\u7684\u5217\u8868\u6216\u5b57\u5178\u3002\u8fd9\u91cc\u6211\u4eec\u7ed9 loss \u4f20\u9012\u5355\u4e2a\u635f\u5931\u51fd\u6570\uff0c\u8fd9\u4e2a\u635f\u5931\u51fd\u6570\u4f1a\u88ab\u5e94\u7528\u4e8e\u6240\u6709\u8f93\u51fa\u4e0a\u3002  model.compile(optimizer='rmsprop', loss='binary_crossentropy',\n              loss_weights=[1., 0.2])  \u7f16\u8bd1\u5b8c\u6210\u540e\uff0c\u6211\u4eec\u901a\u8fc7\u4f20\u9012\u8bad\u7ec3\u6570\u636e\u548c\u76ee\u6807\u503c\u8bad\u7ec3\u8be5\u6a21\u578b\uff1a  model.fit([headline_data, additional_data], [labels, labels],\n          nb_epoch=50, batch_size=32)  \u56e0\u4e3a\u6211\u4eec\u8f93\u5165\u548c\u8f93\u51fa\u662f\u88ab\u547d\u540d\u8fc7\u7684\uff08\u5728\u5b9a\u4e49\u65f6\u4f20\u9012\u4e86\u201cname\u201d\u53c2\u6570\uff09\uff0c\u6211\u4eec\u4e5f\u53ef\u4ee5\u7528\u4e0b\u9762\u7684\u65b9\u5f0f\u7f16\u8bd1\u548c\u8bad\u7ec3\u6a21\u578b\uff1a  model.compile(optimizer='rmsprop',\n              loss={'main_output': 'binary_crossentropy', 'aux_output': 'binary_crossentropy'},\n              loss_weights={'main_output': 1., 'aux_output': 0.2})\n\n# and trained it via:\nmodel.fit({'main_input': headline_data, 'aux_input': additional_data},\n          {'main_output': labels, 'aux_output': labels},\n          nb_epoch=50, batch_size=32)", 
            "title": "\u591a\u8f93\u5165\u548c\u591a\u8f93\u51fa\u6a21\u578b"
        }, 
        {
            "location": "/getting_started/functional_API/#_5", 
            "text": "\u53e6\u4e00\u4e2a\u4f7f\u7528\u6cdb\u578b\u6a21\u578b\u7684\u573a\u5408\u662f\u4f7f\u7528\u5171\u4eab\u5c42\u7684\u65f6\u5019\u3002  \u8003\u8651\u5fae\u535a\u6570\u636e\uff0c\u6211\u4eec\u5e0c\u671b\u5efa\u7acb\u6a21\u578b\u6765\u5224\u522b\u4e24\u6761\u5fae\u535a\u662f\u5426\u662f\u6765\u81ea\u540c\u4e00\u4e2a\u7528\u6237\uff0c\u8fd9\u4e2a\u9700\u6c42\u540c\u6837\u53ef\u4ee5\u7528\u6765\u5224\u65ad\u4e00\u4e2a\u7528\u6237\u7684\u4e24\u6761\u5fae\u535a\u7684\u76f8\u4f3c\u6027\u3002  \u4e00\u79cd\u5b9e\u73b0\u65b9\u5f0f\u662f\uff0c\u6211\u4eec\u5efa\u7acb\u4e00\u4e2a\u6a21\u578b\uff0c\u5b83\u5206\u522b\u5c06\u4e24\u6761\u5fae\u535a\u7684\u6570\u636e\u6620\u5c04\u5230\u4e24\u4e2a\u7279\u5f81\u5411\u91cf\u4e0a\uff0c\u7136\u540e\u5c06\u7279\u5f81\u5411\u91cf\u4e32\u8054\u5e76\u52a0\u4e00\u4e2alogistic\u56de\u5f52\u5c42\uff0c\u8f93\u51fa\u5b83\u4eec\u6765\u81ea\u540c\u4e00\u4e2a\u7528\u6237\u7684\u6982\u7387\u3002\u8fd9\u79cd\u6a21\u578b\u7684\u8bad\u7ec3\u6570\u636e\u662f\u4e00\u5bf9\u5bf9\u7684\u5fae\u535a\u3002  \u56e0\u4e3a\u8fd9\u4e2a\u95ee\u9898\u662f\u5bf9\u79f0\u7684\uff0c\u6240\u4ee5\u5904\u7406\u7b2c\u4e00\u6761\u5fae\u535a\u7684\u6a21\u578b\u5f53\u7136\u4e5f\u80fd\u91cd\u7528\u4e8e\u5904\u7406\u7b2c\u4e8c\u6761\u5fae\u535a\u3002\u6240\u4ee5\u8fd9\u91cc\u6211\u4eec\u4f7f\u7528\u4e00\u4e2a\u5171\u4eab\u7684LSTM\u5c42\u6765\u8fdb\u884c\u6620\u5c04\u3002  \u9996\u5148\uff0c\u6211\u4eec\u5c06\u5fae\u535a\u7684\u6570\u636e\u8f6c\u4e3a\uff08140\uff0c256\uff09\u7684\u77e9\u9635\uff0c\u5373\u6bcf\u6761\u5fae\u535a\u6709140\u4e2a\u5b57\u7b26\uff0c\u6bcf\u4e2a\u5355\u8bcd\u7684\u7279\u5f81\u7531\u4e00\u4e2a256\u7ef4\u7684\u8bcd\u5411\u91cf\u8868\u793a\uff0c\u5411\u91cf\u7684\u6bcf\u4e2a\u5143\u7d20\u4e3a1\u8868\u793a\u67d0\u4e2a\u5b57\u7b26\u51fa\u73b0\uff0c\u4e3a0\u8868\u793a\u4e0d\u51fa\u73b0\uff0c\u8fd9\u662f\u4e00\u4e2aone-hot\u7f16\u7801\u3002  \u3010Tips\u3011\u4e4b\u6240\u4ee5\u662f\uff08140\uff0c256\uff09\u662f\u56e0\u4e3a\u4e00\u6761\u5fae\u535a\u6700\u591a\u6709140\u4e2a\u5b57\u7b26\uff08\u636e\u8bf4\u73b0\u5728\u8981\u53d6\u6d88\u8fd9\u4e2a\u9650\u5236\u4e86\uff09\uff0c\u800c\u6269\u5c55\u7684ASCII\u7801\u8868\u7f16\u7801\u4e86\u5e38\u89c1\u7684256\u4e2a\u5b57\u7b26\u3002\u539f\u6587\u4e2d\u6b64\u5904\u4e3aTweet\uff0c\u6240\u4ee5\u5bf9\u5916\u56fd\u4eba\u800c\u8a00\u8fd9\u662f\u5408\u7406\u7684\u3002\u5982\u679c\u8003\u8651\u4e2d\u6587\u5b57\u7b26\uff0c\u90a3\u4e00\u4e2a\u5355\u8bcd\u7684\u8bcd\u5411\u91cf\u5c31\u4e0d\u6b62256\u4e86\u3002\u3010@Bigmoyan\u3011  from keras.layers import Input, LSTM, Dense, merge\nfrom keras.models import Model\n\ntweet_a = Input(shape=(140, 256))\ntweet_b = Input(shape=(140, 256))     \u82e5\u8981\u5bf9\u4e0d\u540c\u7684\u8f93\u5165\u5171\u4eab\u540c\u4e00\u5c42\uff0c\u5c31\u521d\u59cb\u5316\u8be5\u5c42\u4e00\u6b21\uff0c\u7136\u540e\u591a\u6b21\u8c03\u7528\u5b83  # this layer can take as input a matrix\n# and will return a vector of size 64\nshared_lstm = LSTM(64)\n\n# when we reuse the same layer instance\n# multiple times, the weights of the layer\n# are also being reused\n# (it is effectively *the same* layer)\nencoded_a = shared_lstm(tweet_a)\nencoded_b = shared_lstm(tweet_b)\n\n# we can then concatenate the two vectors:\nmerged_vector = merge([encoded_a, encoded_b], mode='concat', concat_axis=-1)\n\n# and add a logistic regression on top\npredictions = Dense(1, activation='sigmoid')(merged_vector)\n\n# we define a trainable model linking the\n# tweet inputs to the predictions\nmodel = Model(input=[tweet_a, tweet_b], output=predictions)\n\nmodel.compile(optimizer='rmsprop',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\nmodel.fit([data_a, data_b], labels, nb_epoch=10)  \u5148\u6682\u505c\u4e00\u4e0b\uff0c\u770b\u770b\u5171\u4eab\u5c42\u5230\u5e95\u8f93\u51fa\u4e86\u4ec0\u4e48\uff0c\u5b83\u7684\u8f93\u51fa\u6570\u636eshape\u53c8\u662f\u4ec0\u4e48", 
            "title": "\u5171\u4eab\u5c42"
        }, 
        {
            "location": "/getting_started/functional_API/#_6", 
            "text": "\u65e0\u8bba\u4f55\u65f6\uff0c\u5f53\u4f60\u5728\u67d0\u4e2a\u8f93\u5165\u4e0a\u8c03\u7528\u5c42\u65f6\uff0c\u4f60\u5c31\u521b\u5efa\u4e86\u4e00\u4e2a\u65b0\u7684\u5f20\u91cf\uff08\u5373\u8be5\u5c42\u7684\u8f93\u51fa\uff09\uff0c\u540c\u65f6\u4f60\u4e5f\u5728\u4e3a\u8fd9\u4e2a\u5c42\u589e\u52a0\u4e00\u4e2a\u201c\uff08\u8ba1\u7b97\uff09\u8282\u70b9\u201d\u3002\u8fd9\u4e2a\u8282\u70b9\u5c06\u8f93\u5165\u5f20\u91cf\u6620\u5c04\u4e3a\u8f93\u51fa\u5f20\u91cf\u3002\u5f53\u4f60\u591a\u6b21\u8c03\u7528\u8be5\u5c42\u65f6\uff0c\u8fd9\u4e2a\u5c42\u5c31\u6709\u4e86\u591a\u4e2a\u8282\u70b9\uff0c\u5176\u4e0b\u6807\u5206\u522b\u4e3a0\uff0c1\uff0c2...  \u5728\u4e0a\u4e00\u7248\u672c\u7684Keras\u4e2d\uff0c\u4f60\u53ef\u4ee5\u901a\u8fc7 layer.get_output() \u65b9\u6cd5\u6765\u83b7\u5f97\u5c42\u7684\u8f93\u51fa\u5f20\u91cf\uff0c\u6216\u8005\u901a\u8fc7 layer.output_shape \u83b7\u5f97\u5176\u8f93\u51fa\u5f20\u91cf\u7684shape\u3002\u8fd9\u4e2a\u7248\u672c\u7684Keras\u4f60\u4ecd\u7136\u53ef\u4ee5\u8fd9\u4e48\u505a\uff08\u9664\u4e86 layer.get_output() \u88ab output() \u66ff\u6362\uff09\u3002\u4f46\u5982\u679c\u4e00\u4e2a\u5c42\u4e0e\u591a\u4e2a\u8f93\u5165\u76f8\u8fde\uff0c\u4f1a\u51fa\u73b0\u4ec0\u4e48\u60c5\u51b5\u5462\uff1f  \u5982\u679c\u5c42\u53ea\u4e0e\u4e00\u4e2a\u8f93\u5165\u76f8\u8fde\uff0c\u90a3\u6ca1\u6709\u4efb\u4f55\u56f0\u60d1\u7684\u5730\u65b9\u3002 .output() \u5c06\u4f1a\u8fd4\u56de\u8be5\u5c42\u552f\u4e00\u7684\u8f93\u51fa  a = Input(shape=(140, 256))\n\nlstm = LSTM(32)\nencoded_a = lstm(a)\n\nassert lstm.output == encoded_a  \u4f46\u5f53\u5c42\u4e0e\u591a\u4e2a\u8f93\u5165\u76f8\u8fde\u65f6\uff0c\u4f1a\u51fa\u73b0\u95ee\u9898  a = Input(shape=(140, 256))\nb = Input(shape=(140, 256))\n\nlstm = LSTM(32)\nencoded_a = lstm(a)\nencoded_b = lstm(b)\n\nlstm.output  \u4e0a\u9762\u8fd9\u6bb5\u4ee3\u7801\u4f1a\u62a5\u9519   AssertionError: Layer lstm_1 has multiple inbound nodes,\nhence the notion of  layer output  is ill-defined.\nUse `get_output_at(node_index)` instead.  \u901a\u8fc7\u4e0b\u9762\u8fd9\u79cd\u8c03\u7528\u65b9\u5f0f\u5373\u53ef\u89e3\u51b3  assert lstm.get_output_at(0) == encoded_a\nassert lstm.get_output_at(1) == encoded_b    \u591f\u7b80\u5355\u5427\uff1f  \u5bf9\u4e8e input_shape \u548c output_shape \u4e5f\u662f\u4e00\u6837\uff0c\u5982\u679c\u4e00\u4e2a\u5c42\u53ea\u6709\u4e00\u4e2a\u8282\u70b9\uff0c\u6216\u6240\u6709\u7684\u8282\u70b9\u90fd\u6709\u76f8\u540c\u7684\u8f93\u5165\u6216\u8f93\u51fashape\uff0c\u90a3\u4e48 input_shape \u548c output_shape \u90fd\u662f\u6ca1\u6709\u6b67\u4e49\u7684\uff0c\u5e76\u4e5f\u53ea\u8fd4\u56de\u4e00\u4e2a\u503c\u3002\u4f46\u662f\uff0c\u4f8b\u5982\u4f60\u628a\u4e00\u4e2a\u76f8\u540c\u7684 Convolution2D \u5e94\u7528\u4e8e\u4e00\u4e2a\u5927\u5c0f\u4e3a(3,32,32)\u7684\u6570\u636e\uff0c\u7136\u540e\u53c8\u5c06\u5176\u5e94\u7528\u4e8e\u4e00\u4e2a(3,64,64)\u7684\u6570\u636e\uff0c\u90a3\u4e48\u6b64\u65f6\u8be5\u5c42\u5c31\u5177\u6709\u4e86\u591a\u4e2a\u8f93\u5165\u548c\u8f93\u51fa\u7684shape\uff0c\u4f60\u5c31\u9700\u8981\u663e\u5f0f\u7684\u6307\u5b9a\u8282\u70b9\u7684\u4e0b\u6807\uff0c\u6765\u8868\u660e\u4f60\u60f3\u53d6\u7684\u662f\u54ea\u4e2a\u4e86  a = Input(shape=(3, 32, 32))\nb = Input(shape=(3, 64, 64))\n\nconv = Convolution2D(16, 3, 3, border_mode='same')\nconved_a = conv(a)\n\n# only one input so far, the following will work:\nassert conv.input_shape == (None, 3, 32, 32)\n\nconved_b = conv(b)\n# now the `.input_shape` property wouldn't work, but this does:\nassert conv.get_input_shape_at(0) == (None, 3, 32, 32)\nassert conv.get_input_shape_at(1) == (None, 3, 64, 64)", 
            "title": "\u5c42\u201c\u8282\u70b9\u201d\u7684\u6982\u5ff5"
        }, 
        {
            "location": "/getting_started/functional_API/#_7", 
            "text": "\u4ee3\u7801\u793a\u4f8b\u4f9d\u7136\u662f\u5b66\u4e60\u7684\u6700\u4f73\u65b9\u5f0f\uff0c\u8fd9\u91cc\u662f\u66f4\u591a\u7684\u4f8b\u5b50", 
            "title": "\u66f4\u591a\u7684\u4f8b\u5b50"
        }, 
        {
            "location": "/getting_started/functional_API/#inception", 
            "text": "inception\u7684\u8be6\u7ec6\u7ed3\u6784\u53c2\u89c1Google\u7684\u8fd9\u7bc7\u8bba\u6587\uff1a Going Deeper with Convolutions  from keras.layers import merge, Convolution2D, MaxPooling2D, Input\n\ninput_img = Input(shape=(3, 256, 256))\n\ntower_1 = Convolution2D(64, 1, 1, border_mode='same', activation='relu')(input_img)\ntower_1 = Convolution2D(64, 3, 3, border_mode='same', activation='relu')(tower_1)\n\ntower_2 = Convolution2D(64, 1, 1, border_mode='same', activation='relu')(input_img)\ntower_2 = Convolution2D(64, 5, 5, border_mode='same', activation='relu')(tower_2)\n\ntower_3 = MaxPooling2D((3, 3), strides=(1, 1), border_mode='same')(input_img)\ntower_3 = Convolution2D(64, 1, 1, border_mode='same', activation='relu')(tower_3)\n\noutput = merge([tower_1, tower_2, tower_3], mode='concat', concat_axis=1)", 
            "title": "inception\u6a21\u578b"
        }, 
        {
            "location": "/getting_started/functional_API/#_8", 
            "text": "\u6b8b\u5dee\u7f51\u7edc\uff08Residual Network\uff09\u7684\u8be6\u7ec6\u4fe1\u606f\u8bf7\u53c2\u8003\u8fd9\u7bc7\u6587\u7ae0\uff1a Deep Residual Learning for Image Recognition  from keras.layers import merge, Convolution2D, Input\n\n# input tensor for a 3-channel 256x256 image\nx = Input(shape=(3, 256, 256))\n# 3x3 conv with 3 output channels(same as input channels)\ny = Convolution2D(3, 3, 3, border_mode='same')(x)\n# this returns x + y.\nz = merge([x, y], mode='sum')", 
            "title": "\u5377\u79ef\u5c42\u7684\u6b8b\u5dee\u8fde\u63a5"
        }, 
        {
            "location": "/getting_started/functional_API/#_9", 
            "text": "\u8be5\u6a21\u578b\u5728\u4e24\u4e2a\u8f93\u5165\u4e0a\u91cd\u7528\u4e86\u56fe\u50cf\u5904\u7406\u7684\u6a21\u578b\uff0c\u7528\u6765\u5224\u522b\u4e24\u4e2aMNIST\u6570\u5b57\u662f\u5426\u662f\u76f8\u540c\u7684\u6570\u5b57  from keras.layers import merge, Convolution2D, MaxPooling2D, Input, Dense, Flatten\nfrom keras.models import Model\n\n# first, define the vision modules\ndigit_input = Input(shape=(1, 27, 27))\nx = Convolution2D(64, 3, 3)(digit_input)\nx = Convolution2D(64, 3, 3)(x)\nx = MaxPooling2D((2, 2))(x)\nout = Flatten()(x)\n\nvision_model = Model(digit_input, out)\n\n# then define the tell-digits-apart model\ndigit_a = Input(shape=(1, 27, 27))\ndigit_b = Input(shape=(1, 27, 27))\n\n# the vision model will be shared, weights and all\nout_a = vision_model(digit_a)\nout_b = vision_model(digit_b)\n\nconcatenated = merge([out_a, out_b], mode='concat')\nout = Dense(1, activation='sigmoid')(concatenated)\n\nclassification_model = Model([digit_a, digit_b], out)", 
            "title": "\u5171\u4eab\u89c6\u89c9\u6a21\u578b"
        }, 
        {
            "location": "/getting_started/functional_API/#_10", 
            "text": "\u5728\u9488\u5bf9\u4e00\u5e45\u56fe\u7247\u4f7f\u7528\u81ea\u7136\u8bed\u8a00\u8fdb\u884c\u63d0\u95ee\u65f6\uff0c\u8be5\u6a21\u578b\u80fd\u591f\u63d0\u4f9b\u5173\u4e8e\u8be5\u56fe\u7247\u7684\u4e00\u4e2a\u5355\u8bcd\u7684\u7b54\u6848  \u8fd9\u4e2a\u6a21\u578b\u5c06\u81ea\u7136\u8bed\u8a00\u7684\u95ee\u9898\u548c\u56fe\u7247\u5206\u522b\u6620\u5c04\u4e3a\u7279\u5f81\u5411\u91cf\uff0c\u5c06\u4e8c\u8005\u5408\u5e76\u540e\u8bad\u7ec3\u4e00\u4e2alogistic\u56de\u5f52\u5c42\uff0c\u4ece\u4e00\u7cfb\u5217\u53ef\u80fd\u7684\u56de\u7b54\u4e2d\u6311\u9009\u4e00\u4e2a\u3002  from keras.layers import Convolution2D, MaxPooling2D, Flatten\nfrom keras.layers import Input, LSTM, Embedding, Dense, merge\nfrom keras.models import Model, Sequential\n\n# first, let's define a vision model using a Sequential model.\n# this model will encode an image into a vector.\nvision_model = Sequential()\nvision_model.add(Convolution2D(64, 3, 3, activation='relu', border_mode='same', input_shape=(3, 224, 224)))\nvision_model.add(Convolution2D(64, 3, 3, activation='relu'))\nvision_model.add(MaxPooling2D((2, 2)))\nvision_model.add(Convolution2D(128, 3, 3, activation='relu', border_mode='same'))\nvision_model.add(Convolution2D(128, 3, 3, activation='relu'))\nvision_model.add(MaxPooling2D((2, 2)))\nvision_model.add(Convolution2D(256, 3, 3, activation='relu', border_mode='same'))\nvision_model.add(Convolution2D(256, 3, 3, activation='relu'))\nvision_model.add(Convolution2D(256, 3, 3, activation='relu'))\nvision_model.add(MaxPooling2D((2, 2)))\nvision_model.add(Flatten())\n\n# now let's get a tensor with the output of our vision model:\nimage_input = Input(shape=(3, 224, 224))\nencoded_image = vision_model(image_input)\n\n# next, let's define a language model to encode the question into a vector.\n# each question will be at most 100 word long,\n# and we will index words as integers from 1 to 9999.\nquestion_input = Input(shape=(100,), dtype='int32')\nembedded_question = Embedding(input_dim=10000, output_dim=256, input_length=100)(question_input)\nencoded_question = LSTM(256)(embedded_question)\n\n# let's concatenate the question vector and the image vector:\nmerged = merge([encoded_question, encoded_image], mode='concat')\n\n# and let's train a logistic regression over 1000 words on top:\noutput = Dense(1000, activation='softmax')(merged)\n\n# this is our final model:\nvqa_model = Model(input=[image_input, question_input], output=output)\n\n# the next stage would be training this model on actual data.", 
            "title": "\u89c6\u89c9\u95ee\u7b54\u6a21\u578b"
        }, 
        {
            "location": "/getting_started/functional_API/#_11", 
            "text": "\u5728\u505a\u5b8c\u56fe\u7247\u95ee\u7b54\u6a21\u578b\u540e\uff0c\u6211\u4eec\u53ef\u4ee5\u5feb\u901f\u5c06\u5176\u8f6c\u4e3a\u89c6\u9891\u95ee\u7b54\u7684\u6a21\u578b\u3002\u5728\u9002\u5f53\u7684\u8bad\u7ec3\u4e0b\uff0c\u4f60\u53ef\u4ee5\u4e3a\u6a21\u578b\u63d0\u4f9b\u4e00\u4e2a\u77ed\u89c6\u9891\uff08\u5982100\u5e27\uff09\u7136\u540e\u5411\u6a21\u578b\u63d0\u95ee\u4e00\u4e2a\u5173\u4e8e\u8be5\u89c6\u9891\u7684\u95ee\u9898\uff0c\u5982\u201cwhat sport is the boy playing\uff1f\u201d- \u201cfootball\u201d  from keras.layers import TimeDistributed\n\nvideo_input = Input(shape=(100, 3, 224, 224))\n# this is our video encoded via the previously trained vision_model (weights are reused)\nencoded_frame_sequence = TimeDistributed(vision_model)(video_input)  # the output will be a sequence of vectors\nencoded_video = LSTM(256)(encoded_frame_sequence)  # the output will be a vector\n\n# this is a model-level representation of the question encoder, reusing the same weights as before:\nquestion_encoder = Model(input=question_input, output=encoded_question)\n\n# let's use it to encode the question:\nvideo_question_input = Input(shape=(100,), dtype='int32')\nencoded_video_question = question_encoder(video_question_input)\n\n# and this is our video question answering model:\nmerged = merge([encoded_video, encoded_video_question], mode='concat')\noutput = Dense(1000, activation='softmax')(merged)\nvideo_qa_model = Model(input=[video_input, video_question_input], output=output)", 
            "title": "\u89c6\u9891\u95ee\u7b54\u6a21\u578b"
        }, 
        {
            "location": "/getting_started/FAQ/", 
            "text": "Keras FAQ\uff1a\u5e38\u89c1\u95ee\u9898\n\n\n\n\n\u5982\u4f55\u5f15\u7528Keras\uff1f\n\n\n\u5982\u4f55\u4f7fKeras\u8c03\u7528GPU\uff1f\n\n\n\u5982\u4f55\u4fdd\u5b58Keras\u6a21\u578b\uff1f\n\n\n\u4e3a\u4ec0\u4e48\u8bad\u7ec3\u8bef\u5dee(loss)\u6bd4\u6d4b\u8bd5\u8bef\u5dee\u9ad8\u5f88\u591a\uff1f\n\n\n\u5982\u4f55\u83b7\u53d6\u4e2d\u95f4\u5c42\u7684\u8f93\u51fa\uff1f\n\n\n\u5982\u4f55\u5229\u7528Keras\u5904\u7406\u8d85\u8fc7\u673a\u5668\u5185\u5b58\u7684\u6570\u636e\u96c6\uff1f\n\n\n\u5f53\u9a8c\u8bc1\u96c6\u7684loss\u4e0d\u518d\u4e0b\u964d\u65f6\uff0c\u5982\u4f55\u4e2d\u65ad\u8bad\u7ec3\uff1f\n\n\n\u9a8c\u8bc1\u96c6\u662f\u5982\u4f55\u4ece\u8bad\u7ec3\u96c6\u4e2d\u5206\u5272\u51fa\u6765\u7684\uff1f\n\n\n\u8bad\u7ec3\u6570\u636e\u5728\u8bad\u7ec3\u65f6\u4f1a\u88ab\u968f\u673a\u6d17\u4e71\u5417\uff1f\n\n\n\u5982\u4f55\u5728\u6bcf\u4e2aepoch\u540e\u8bb0\u5f55\u8bad\u7ec3/\u6d4b\u8bd5\u7684loss\u548c\u6b63\u786e\u7387\uff1f\n\n\n\u5982\u4f55\u4f7f\u7528\u72b6\u6001RNN\uff08statful RNN\uff09\uff1f\n\n\n\u5982\u4f55\u4f7f\u7528Keras\u8fdb\u884c\u5206\u5e03\u5f0f/\u591aGPU\u8fd0\u7b97\uff1f\n\n\n\u5982\u4f55\u201c\u51bb\u7ed3\u201d\u7f51\u7edc\u7684\u5c42\uff1f\n\n\n\u5982\u4f55\u4eceSequential\u6a21\u578b\u4e2d\u53bb\u9664\u4e00\u4e2a\u5c42\uff1f\n\n\n\u5982\u4f55\u5728Keras\u4e2d\u4f7f\u7528\u9884\u8bad\u7ec3\u7684\u6a21\u578b\n\n\n\n\n\n\n\n\n\n\n\u5982\u4f55\u5f15\u7528Keras\uff1f\n\n\n\n\n\n\n\u5982\u679cKeras\u5bf9\u4f60\u7684\u7814\u7a76\u6709\u5e2e\u52a9\u7684\u8bdd\uff0c\u8bf7\u5728\u4f60\u7684\u6587\u7ae0\u4e2d\u5f15\u7528Keras\u3002\u8fd9\u91cc\u662f\u4e00\u4e2a\u4f7f\u7528BibTex\u7684\u4f8b\u5b50\n\n\n@misc{chollet2015keras,\n  author = {Chollet, Fran\u00e7ois},\n  title = {Keras},\n  year = {2015},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  howpublished = {\\url{https://github.com/fchollet/keras}}\n}\n\n\n\n\n\n\n\n\n\n\n\u5982\u4f55\u4f7fKeras\u8c03\u7528GPU\uff1f\n\n\n\n\n\n\n\u5982\u679c\u91c7\u7528TensorFlow\u4f5c\u4e3a\u540e\u7aef\uff0c\u5f53\u673a\u5668\u4e0a\u6709\u53ef\u7528\u7684GPU\u65f6\uff0c\u4ee3\u7801\u4f1a\u81ea\u52a8\u8c03\u7528GPU\u8fdb\u884c\u5e76\u884c\u8ba1\u7b97\u3002\u5982\u679c\u4f7f\u7528Theano\u4f5c\u4e3a\u540e\u7aef\uff0c\u53ef\u4ee5\u901a\u8fc7\u4ee5\u4e0b\u65b9\u6cd5\u8bbe\u7f6e\uff1a\n\n\n\u65b9\u6cd51\uff1a\u4f7f\u7528Theano\u6807\u8bb0\n\n\n\u5728\u6267\u884cpython\u811a\u672c\u65f6\u4f7f\u7528\u4e0b\u9762\u7684\u547d\u4ee4\uff1a\n\n\nTHEANO_FLAGS=device=gpu,floatX=float32 python my_keras_script.py\n\n\n\n\n\u65b9\u6cd52\uff1a\u8bbe\u7f6e\n.theano\n\u6587\u4ef6\n\n\n\u70b9\u51fb\n\u8fd9\u91cc\n\u67e5\u770b\u6307\u5bfc\u6559\u7a0b\n\n\n\u65b9\u6cd53\uff1a\u5728\u4ee3\u7801\u7684\u5f00\u5934\u5904\u624b\u52a8\u8bbe\u7f6e\ntheano.config.device\n\u548c\ntheano.config.floatX\n\n\n    import theano\n    theano.config.device = 'gpu'\n    theano.config.floatX = 'float32'\n\n\n\n\n\n\n\n\n\n\n\u5982\u4f55\u4fdd\u5b58Keras\u6a21\u578b\uff1f\n\n\n\n\n\n\n\u6211\u4eec\u4e0d\u63a8\u8350\u4f7f\u7528pickle\u6216cPickle\u6765\u4fdd\u5b58Keras\u6a21\u578b\n\n\n\u4f60\u53ef\u4ee5\u4f7f\u7528\nmodel.save(filepath)\n\u5c06Keras\u6a21\u578b\u548c\u6743\u91cd\u4fdd\u5b58\u5728\u4e00\u4e2aHDF5\u6587\u4ef6\u4e2d\uff0c\u8be5\u6587\u4ef6\u5c06\u5305\u542b\uff1a\n\n\n\n\n\u6a21\u578b\u7684\u7ed3\u6784\uff0c\u4ee5\u4fbf\u91cd\u6784\u8be5\u6a21\u578b\n\n\n\u6a21\u578b\u7684\u6743\u91cd\n\n\n\u8bad\u7ec3\u914d\u7f6e\uff08\u635f\u5931\u51fd\u6570\uff0c\u4f18\u5316\u5668\u7b49\uff09\n\n\n\u4f18\u5316\u5668\u7684\u72b6\u6001\uff0c\u4ee5\u4fbf\u4e8e\u4ece\u4e0a\u6b21\u8bad\u7ec3\u4e2d\u65ad\u7684\u5730\u65b9\u5f00\u59cb\n\n\n\n\n\u4f7f\u7528\nkeras.models.load_model(filepath)\n\u6765\u91cd\u65b0\u5b9e\u4f8b\u5316\u4f60\u7684\u6a21\u578b\uff0c\u5982\u679c\u6587\u4ef6\u4e2d\u5b58\u50a8\u4e86\u8bad\u7ec3\u914d\u7f6e\u7684\u8bdd\uff0c\u8be5\u51fd\u6570\u8fd8\u4f1a\u540c\u65f6\u5b8c\u6210\u6a21\u578b\u7684\u7f16\u8bd1\n\n\n\u4f8b\u5b50\uff1a\n\n\nfrom keras.models import load_model\n\nmodel.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\ndel model  # deletes the existing model\n\n# returns a compiled model\n# identical to the previous one\nmodel = load_model('my_model.h5')\n\n\n\n\n\u5982\u679c\u4f60\u53ea\u662f\u5e0c\u671b\u4fdd\u5b58\u6a21\u578b\u7684\u7ed3\u6784\uff0c\u800c\u4e0d\u5305\u542b\u5176\u6743\u91cd\u6216\u914d\u7f6e\u4fe1\u606f\uff0c\u53ef\u4ee5\u4f7f\u7528\uff1a\n\n\n# save as JSON\njson_string = model.to_json()\n\n# save as YAML\nyaml_string = model.to_yaml()\n\n\n\n\n\u8fd9\u9879\u64cd\u4f5c\u5c06\u628a\u6a21\u578b\u5e8f\u5217\u5316\u4e3ajson\u6216yaml\u6587\u4ef6\uff0c\u8fd9\u4e9b\u6587\u4ef6\u5bf9\u4eba\u800c\u8a00\u4e5f\u662f\u53cb\u597d\u7684\uff0c\u5982\u679c\u9700\u8981\u7684\u8bdd\u4f60\u751a\u81f3\u53ef\u4ee5\u624b\u52a8\u6253\u5f00\u8fd9\u4e9b\u6587\u4ef6\u5e76\u8fdb\u884c\u7f16\u8f91\u3002\n\n\n\u5f53\u7136\uff0c\u4f60\u4e5f\u53ef\u4ee5\u4ece\u4fdd\u5b58\u597d\u7684json\u6587\u4ef6\u6216yaml\u6587\u4ef6\u4e2d\u8f7d\u5165\u6a21\u578b\uff1a\n\n\n# model reconstruction from JSON:\nfrom keras.models import model_from_json\nmodel = model_from_json(json_string)\n\n# model reconstruction from YAML\nmodel = model_from_yaml(yaml_string)\n\n\n\n\n\u5982\u679c\u9700\u8981\u4fdd\u5b58\u6a21\u578b\u7684\u6743\u91cd\uff0c\u53ef\u901a\u8fc7\u4e0b\u9762\u7684\u4ee3\u7801\u5229\u7528HDF5\u8fdb\u884c\u4fdd\u5b58\u3002\u6ce8\u610f\uff0c\u5728\u4f7f\u7528\u524d\u9700\u8981\u786e\u4fdd\u4f60\u5df2\u5b89\u88c5\u4e86HDF5\u548c\u5176Python\u5e93h5py\n\n\nmodel.save_weights('my_model_weights.h5')\n\n\n\n\n\u5982\u679c\u4f60\u9700\u8981\u5728\u4ee3\u7801\u4e2d\u521d\u59cb\u5316\u4e00\u4e2a\u5b8c\u5168\u76f8\u540c\u7684\u6a21\u578b\uff0c\u8bf7\u4f7f\u7528\uff1a\n\n\nmodel.load_weights('my_model_weights.h5')\n\n\n\n\n\u5982\u679c\u4f60\u9700\u8981\u52a0\u8f7d\u6743\u91cd\u5230\u4e0d\u540c\u7684\u7f51\u7edc\u7ed3\u6784\uff08\u6709\u4e9b\u5c42\u4e00\u6837\uff09\u4e2d\uff0c\u4f8b\u5982fine-tune\u6216transfer-learning\uff0c\u4f60\u53ef\u4ee5\u901a\u8fc7\u5c42\u540d\u5b57\u6765\u52a0\u8f7d\u6a21\u578b\uff1a\n\n\nmodel.load_weights('my_model_weights.h5', by_name=True)\n\n\n\n\n\u4f8b\u5982\uff1a\n\n\n\n\u5047\u5982\u539f\u6a21\u578b\u4e3a\uff1a\n    model = Sequential()\n    model.add(Dense(2, input_dim=3, name=\ndense_1\n))\n    model.add(Dense(3, name=\ndense_2\n))\n    ...\n    model.save_weights(fname)\n\n\n# new model\nmodel = Sequential()\nmodel.add(Dense(2, input_dim=3, name=\ndense_1\n))  # will be loaded\nmodel.add(Dense(10, name=\nnew_dense\n))  # will not be loaded\n\n# load weights from first model; will only affect the first layer, dense_1.\nmodel.load_weights(fname, by_name=True)\n\n\n\n\n\n\n\n\n\n\n\n\u4e3a\u4ec0\u4e48\u8bad\u7ec3\u8bef\u5dee\u6bd4\u6d4b\u8bd5\u8bef\u5dee\u9ad8\u5f88\u591a\uff1f\n\n\n\n\n\n\n\u4e00\u4e2aKeras\u7684\u6a21\u578b\u6709\u4e24\u4e2a\u6a21\u5f0f\uff1a\u8bad\u7ec3\u6a21\u5f0f\u548c\u6d4b\u8bd5\u6a21\u5f0f\u3002\u4e00\u4e9b\u6b63\u5219\u673a\u5236\uff0c\u5982Dropout\uff0cL1/L2\u6b63\u5219\u9879\u5728\u6d4b\u8bd5\u6a21\u5f0f\u4e0b\u5c06\u4e0d\u88ab\u542f\u7528\u3002\n\n\n\u53e6\u5916\uff0c\u8bad\u7ec3\u8bef\u5dee\u662f\u8bad\u7ec3\u6570\u636e\u6bcf\u4e2abatch\u7684\u8bef\u5dee\u7684\u5e73\u5747\u3002\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u6bcf\u4e2aepoch\u8d77\u59cb\u65f6\u7684batch\u7684\u8bef\u5dee\u8981\u5927\u4e00\u4e9b\uff0c\u800c\u540e\u9762\u7684batch\u7684\u8bef\u5dee\u8981\u5c0f\u4e00\u4e9b\u3002\u53e6\u4e00\u65b9\u9762\uff0c\u6bcf\u4e2aepoch\u7ed3\u675f\u65f6\u8ba1\u7b97\u7684\u6d4b\u8bd5\u8bef\u5dee\u662f\u7531\u6a21\u578b\u5728epoch\u7ed3\u675f\u65f6\u7684\u72b6\u6001\u51b3\u5b9a\u7684\uff0c\u8fd9\u65f6\u5019\u7684\u7f51\u7edc\u5c06\u4ea7\u751f\u8f83\u5c0f\u7684\u8bef\u5dee\u3002\n\n\n\u3010Tips\u3011\u53ef\u4ee5\u901a\u8fc7\u5b9a\u4e49\u56de\u8c03\u51fd\u6570\u5c06\u6bcf\u4e2aepoch\u7684\u8bad\u7ec3\u8bef\u5dee\u548c\u6d4b\u8bd5\u8bef\u5dee\u5e76\u4f5c\u56fe\uff0c\u5982\u679c\u8bad\u7ec3\u8bef\u5dee\u66f2\u7ebf\u548c\u6d4b\u8bd5\u8bef\u5dee\u66f2\u7ebf\u4e4b\u95f4\u6709\u5f88\u5927\u7684\u7a7a\u9699\uff0c\u8bf4\u660e\u4f60\u7684\u6a21\u578b\u53ef\u80fd\u6709\u8fc7\u62df\u5408\u7684\u95ee\u9898\u3002\u5f53\u7136\uff0c\u8fd9\u4e2a\u95ee\u9898\u4e0eKeras\u65e0\u5173\u3002\u3010@BigMoyan\u3011\n\n\n\n\n\n\n\n\n\u5982\u4f55\u83b7\u53d6\u4e2d\u95f4\u5c42\u7684\u8f93\u51fa\uff1f\n\n\n\n\n\n\n\u4e00\u79cd\u7b80\u5355\u7684\u65b9\u6cd5\u662f\u521b\u5efa\u4e00\u4e2a\u65b0\u7684\nModel\n\uff0c\u4f7f\u5f97\u5b83\u7684\u8f93\u51fa\u662f\u4f60\u60f3\u8981\u7684\u90a3\u4e2a\u8f93\u51fa\n\n\nfrom keras.models import Model\n\nmodel = ...  # create the original model\n\nlayer_name = 'my_layer'\nintermediate_layer_model = Model(input=model.input,\n                                 output=model.get_layer(layer_name).output)\nintermediate_output = intermediate_layer_model.predict(data\n\n\n\n\n\u6b64\u5916\uff0c\u6211\u4eec\u4e5f\u53ef\u4ee5\u5efa\u7acb\u4e00\u4e2aKeras\u7684\u51fd\u6570\u6765\u8fbe\u5230\u8fd9\u4e00\u76ee\u7684\uff1a\n\n\nfrom keras import backend as K\n\n# with a Sequential model\nget_3rd_layer_output = K.function([model.layers[0].input],\n                                  [model.layers[3].output])\nlayer_output = get_3rd_layer_output([X])[0]\n\n\n\n\n\u5f53\u7136\uff0c\u6211\u4eec\u4e5f\u53ef\u4ee5\u76f4\u63a5\u7f16\u5199Theano\u548cTensorFlow\u7684\u51fd\u6570\u6765\u5b8c\u6210\u8fd9\u4ef6\u4e8b\n\n\n\u6ce8\u610f\uff0c\u5982\u679c\u4f60\u7684\u6a21\u578b\u5728\u8bad\u7ec3\u548c\u6d4b\u8bd5\u4e24\u79cd\u6a21\u5f0f\u4e0b\u4e0d\u5b8c\u5168\u4e00\u81f4\uff0c\u4f8b\u5982\u4f60\u7684\u6a21\u578b\u4e2d\u542b\u6709Dropout\u5c42\uff0c\u6279\u89c4\u8303\u5316\uff08BatchNormalization\uff09\u5c42\u7b49\u7ec4\u4ef6\uff0c\u4f60\u9700\u8981\u5728\u51fd\u6570\u4e2d\u4f20\u9012\u4e00\u4e2alearning_phase\u7684\u6807\u8bb0\uff0c\u50cf\u8fd9\u6837\uff1a\n\n\nget_3rd_layer_output = K.function([model.layers[0].input, K.learning_phase()],\n                                  [model.layers[3].output])\n\n# output in test mode = 0\nlayer_output = get_3rd_layer_output([X, 0])[0]\n\n# output in train mode = 1\nlayer_output = get_3rd_layer_output([X, 1])[0]\n\n\n\n\n\n\n\n\n\n\n\u5982\u4f55\u5229\u7528Keras\u5904\u7406\u8d85\u8fc7\u673a\u5668\u5185\u5b58\u7684\u6570\u636e\u96c6\uff1f\n\n\n\n\n\n\n\u53ef\u4ee5\u4f7f\u7528\nmodel.train_on_batch(X,y)\n\u548c\nmodel.test_on_batch(X,y)\n\u3002\u8bf7\u53c2\u8003\n\u6a21\u578b\n\n\n\u53e6\u5916\uff0c\u4e5f\u53ef\u4ee5\u7f16\u5199\u4e00\u4e2a\u6bcf\u6b21\u4ea7\u751f\u4e00\u4e2abatch\u6837\u672c\u7684\u751f\u6210\u5668\u51fd\u6570\uff0c\u5e76\u8c03\u7528\nmodel.fit_generator(data_generator, samples_per_epoch, nb_epoch)\n\u8fdb\u884c\u8bad\u7ec3\n\n\n\u8fd9\u79cd\u65b9\u5f0f\u5728Keras\u4ee3\u7801\u5305\u7684example\u6587\u4ef6\u5939\u4e0bCIFAR10\u4f8b\u5b50\u91cc\u6709\u793a\u8303\uff0c\u4e5f\u53ef\u70b9\u51fb\n\u8fd9\u91cc\n\u5728github\u4e0a\u6d4f\u89c8\u3002\n\n\n\n\n\n\n\n\n\u5f53\u9a8c\u8bc1\u96c6\u7684loss\u4e0d\u518d\u4e0b\u964d\u65f6\uff0c\u5982\u4f55\u4e2d\u65ad\u8bad\u7ec3\uff1f\n\n\n\n\n\n\n\u53ef\u4ee5\u5b9a\u4e49\nEarlyStopping\n\u6765\u63d0\u524d\u7ec8\u6b62\u8bad\u7ec3\n\n\nfrom keras.callbacks import EarlyStopping\nearly_stopping = EarlyStopping(monitor='val_loss', patience=2)\nmodel.fit(X, y, validation_split=0.2, callbacks=[early_stopping])\n\n\n\n\n\u8bf7\u53c2\u8003\n\u56de\u8c03\u51fd\u6570\n\n\n\n\n\n\n\n\n\u9a8c\u8bc1\u96c6\u662f\u5982\u4f55\u4ece\u8bad\u7ec3\u96c6\u4e2d\u5206\u5272\u51fa\u6765\u7684\uff1f\n\n\n\n\n\n\n\u5982\u679c\u5728\nmodel.fit\n\u4e2d\u8bbe\u7f6e\nvalidation_spilt\n\u7684\u503c\uff0c\u5219\u53ef\u5c06\u6570\u636e\u5206\u4e3a\u8bad\u7ec3\u96c6\u548c\u9a8c\u8bc1\u96c6\uff0c\u4f8b\u5982\uff0c\u8bbe\u7f6e\u8be5\u503c\u4e3a0.1\uff0c\u5219\u8bad\u7ec3\u96c6\u7684\u6700\u540e10%\u6570\u636e\u5c06\u4f5c\u4e3a\u9a8c\u8bc1\u96c6\uff0c\u8bbe\u7f6e\u5176\u4ed6\u6570\u5b57\u540c\u7406\u3002\u6ce8\u610f\uff0c\u539f\u6570\u636e\u5728\u8fdb\u884c\u9a8c\u8bc1\u96c6\u5206\u5272\u524d\u5e76\u6ca1\u6709\u88abshuffle\uff0c\u6240\u4ee5\u8fd9\u91cc\u7684\u9a8c\u8bc1\u96c6\u4e25\u683c\u7684\u5c31\u662f\u4f60\u8f93\u5165\u6570\u636e\u6700\u672b\u7684x%\u3002\n\n\n\n\n\n\n\n\n\u8bad\u7ec3\u6570\u636e\u5728\u8bad\u7ec3\u65f6\u4f1a\u88ab\u968f\u673a\u6d17\u4e71\u5417\uff1f\n\n\n\n\n\n\n\u662f\u7684\uff0c\u5982\u679c\nmodel.fit\n\u7684\nshuffle\n\u53c2\u6570\u4e3a\u771f\uff0c\u8bad\u7ec3\u7684\u6570\u636e\u5c31\u4f1a\u88ab\u968f\u673a\u6d17\u4e71\u3002\u4e0d\u8bbe\u7f6e\u65f6\u9ed8\u8ba4\u4e3a\u771f\u3002\u8bad\u7ec3\u6570\u636e\u4f1a\u5728\u6bcf\u4e2aepoch\u7684\u8bad\u7ec3\u4e2d\u90fd\u91cd\u65b0\u6d17\u4e71\u4e00\u6b21\u3002\n\n\n\u9a8c\u8bc1\u96c6\u7684\u6570\u636e\u4e0d\u4f1a\u88ab\u6d17\u4e71\n\n\n\n\n\n\n\n\n\u5982\u4f55\u5728\u6bcf\u4e2aepoch\u540e\u8bb0\u5f55\u8bad\u7ec3/\u6d4b\u8bd5\u7684loss\u548c\u6b63\u786e\u7387\uff1f\n\n\n\n\n\n\nmodel.fit\n\u5728\u8fd0\u884c\u7ed3\u675f\u540e\u8fd4\u56de\u4e00\u4e2a\nHistory\n\u5bf9\u8c61\uff0c\u5176\u4e2d\u542b\u6709\u7684\nhistory\n\u5c5e\u6027\u5305\u542b\u4e86\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u635f\u5931\u51fd\u6570\u7684\u503c\u4ee5\u53ca\u5176\u4ed6\u5ea6\u91cf\u6307\u6807\u3002\n\n\nhist = model.fit(X, y, validation_split=0.2)\nprint(hist.history)\n\n\n\n\n\n\n\n\n\n\n\u5982\u4f55\u4f7f\u7528\u72b6\u6001RNN\uff08statful RNN\uff09\uff1f\n\n\n\n\n\n\n\u4e00\u4e2aRNN\u662f\u72b6\u6001RNN\uff0c\u610f\u5473\u7740\u8bad\u7ec3\u65f6\u6bcf\u4e2abatch\u7684\u72b6\u6001\u90fd\u4f1a\u88ab\u91cd\u7528\u4e8e\u521d\u59cb\u5316\u4e0b\u4e00\u4e2abatch\u7684\u521d\u59cb\u72b6\u6001\u3002\n\n\n\u5f53\u4f7f\u7528\u72b6\u6001RNN\u65f6\uff0c\u6709\u5982\u4e0b\u5047\u8bbe\n\n\n\n\n\n\n\u6240\u6709\u7684batch\u90fd\u5177\u6709\u76f8\u540c\u6570\u76ee\u7684\u6837\u672c\n\n\n\n\n\n\n\u5982\u679c\nX1\n\u548c\nX2\n\u662f\u4e24\u4e2a\u76f8\u90bb\u7684batch\uff0c\u90a3\u4e48\u5bf9\u4e8e\u4efb\u4f55\ni\n\uff0c\nX2[i]\n\u90fd\u662f\nX1[i]\n\u7684\u540e\u7eed\u5e8f\u5217\n\n\n\n\n\n\n\u8981\u4f7f\u7528\u72b6\u6001RNN\uff0c\u6211\u4eec\u9700\u8981\n\n\n\n\n\n\n\u663e\u5f0f\u7684\u6307\u5b9a\u6bcf\u4e2abatch\u7684\u5927\u5c0f\u3002\u53ef\u4ee5\u901a\u8fc7\u6a21\u578b\u7684\u9996\u5c42\u53c2\u6570\nbatch_input_shape\n\u6765\u5b8c\u6210\u3002\nbatch_input_shape\n\u662f\u4e00\u4e2a\u6574\u6570tuple\uff0c\u4f8b\u5982(32,10,16)\u4ee3\u8868\u4e00\u4e2a\u5177\u670910\u4e2a\u65f6\u95f4\u6b65\uff0c\u6bcf\u6b65\u5411\u91cf\u957f\u4e3a16\uff0c\u6bcf32\u4e2a\u6837\u672c\u6784\u6210\u4e00\u4e2abatch\u7684\u8f93\u5165\u6570\u636e\u683c\u5f0f\u3002\n\n\n\n\n\n\n\u5728RNN\u5c42\u4e2d\uff0c\u8bbe\u7f6e\nstateful=True\n\n\n\n\n\n\n\u8981\u91cd\u7f6e\u7f51\u7edc\u7684\u72b6\u6001\uff0c\u4f7f\u7528\uff1a\n\n\n\n\n\n\nmodel.reset_states()\n\u6765\u91cd\u7f6e\u7f51\u7edc\u4e2d\u6240\u6709\u5c42\u7684\u72b6\u6001\n\n\n\n\n\n\nlayer.reset_states()\n\u6765\u91cd\u7f6e\u6307\u5b9a\u5c42\u7684\u72b6\u6001\n\n\n\n\n\n\n\u4f8b\u5b50\uff1a\n\n\nX  # this is our input data, of shape (32, 21, 16)\n# we will feed it to our model in sequences of length 10\n\nmodel = Sequential()\nmodel.add(LSTM(32, batch_input_shape=(32, 10, 16), stateful=True))\nmodel.add(Dense(16, activation='softmax'))\n\nmodel.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n\n# we train the network to predict the 11th timestep given the first 10:\nmodel.train_on_batch(X[:, :10, :], np.reshape(X[:, 10, :], (32, 16)))\n\n# the state of the network has changed. We can feed the follow-up sequences:\nmodel.train_on_batch(X[:, 10:20, :], np.reshape(X[:, 20, :], (32, 16)))\n\n# let's reset the states of the LSTM layer:\nmodel.reset_states()\n\n# another way to do it in this case:\nmodel.layers[0].reset_states()\n\n\n\n\n\u6ce8\u610f\uff0c\npredict\n\uff0c\nfit\n\uff0c\ntrain_on_batch\n\n\uff0c\npredict_classes\n\u7b49\u65b9\u6cd5\u90fd\u4f1a\u66f4\u65b0\u6a21\u578b\u4e2d\u72b6\u6001\u5c42\u7684\u72b6\u6001\u3002\u8fd9\u4f7f\u5f97\u4f60\u53ef\u4ee5\u4e0d\u4f46\u53ef\u4ee5\u8fdb\u884c\u72b6\u6001\u7f51\u7edc\u7684\u8bad\u7ec3\uff0c\u4e5f\u53ef\u4ee5\u8fdb\u884c\u72b6\u6001\u7f51\u7edc\u7684\u9884\u6d4b\u3002\n\n\n\n\n\n\n\n\n\u5982\u4f55\u4f7f\u7528Keras\u8fdb\u884c\u5206\u5e03\u5f0f/\u591aGPU\u8fd0\u7b97\uff1f\n\n\n\n\n\n\nKeras\u5728\u4f7f\u7528TensorFlow\u4f5c\u4e3a\u540e\u7aef\u7684\u65f6\u5019\u53ef\u4ee5\u8fdb\u884c\u5206\u5e03\u5f0f/\u591aGPU\u7684\u8fd0\u7b97\uff0cKeras\u5bf9\u591aGPU\u548c\u5206\u5e03\u5f0f\u7684\u652f\u6301\u662f\u901a\u8fc7TF\u5b8c\u6210\u7684\u3002\n\n\nwith tf.device('/gpu:0'):\n    x = tf.placeholder(tf.float32, shape=(None, 20, 64))\n    y = LSTM(32)(x)  # all ops in the LSTM layer will live on GPU:0\n\nwith tf.device('/gpu:1'):\n    x = tf.placeholder(tf.float32, shape=(None, 20, 64))\n    y = LSTM(32)(x)  # all ops in the LSTM layer will live on GPU:1\n\n\n\n\n\u6ce8\u610f\uff0c\u4e0a\u4f8b\u4e2d\u7531LSTM\u521b\u5efa\u7684\u53d8\u91cf\u4e0d\u5728GPU\u4e0a\uff1a\u6240\u6709\u7684TensorFlow\u53d8\u91cf\u603b\u662f\u5728CPU\u4e0a\u751f\u5b58\uff0c\u800c\u4e0e\u5b83\u4eec\u5728\u54ea\u521b\u5efa\u65e0\u5173\u3002\u5404\u4e2a\u8bbe\u5907\u4e0a\u7684\u53d8\u91cf\u8f6c\u6362TensorFlow\u4f1a\u81ea\u52a8\u5b8c\u6210\u3002\n\n\n\u5982\u679c\u4f60\u60f3\u5728\u4e0d\u540c\u7684GPU\u4e0a\u8bad\u7ec3\u540c\u4e00\u4e2a\u6a21\u578b\u7684\u4e0d\u540c\u526f\u672c\uff0c\u4f46\u5728\u4e0d\u540c\u7684\u526f\u672c\u4e2d\u5171\u4eab\u6743\u91cd\uff0c\u4f60\u5e94\u8be5\u9996\u5148\u5728\u4e00\u4e2a\u8bbe\u5907\u4e0a\u5b9e\u4f8b\u5316\u4f60\u7684\u6a21\u578b\uff0c\u7136\u540e\u5728\u4e0d\u540c\u7684\u8bbe\u5907\u4e0a\u591a\u6b21\u8c03\u7528\u8be5\u5bf9\u8c61\uff0c\u4f8b\u5982\uff1a\n\n\nwith tf.device('/cpu:0'):\n    x = tf.placeholder(tf.float32, shape=(None, 784))\n\n    # shared model living on CPU:0\n    # it won't actually be run during training; it acts as an op template\n    # and as a repository for shared variables\n    model = Sequential()\n    model.add(Dense(32, activation='relu', input_dim=784))\n    model.add(Dense(10, activation='softmax'))\n\n# replica 0\nwith tf.device('/gpu:0'):\n    output_0 = model(x)  # all ops in the replica will live on GPU:0\n\n# replica 1\nwith tf.device('/gpu:1'):\n    output_1 = model(x)  # all ops in the replica will live on GPU:1\n\n# merge outputs on CPU\nwith tf.device('/cpu:0'):\n    preds = 0.5 * (output_0 + output_1)\n\n# we only run the `preds` tensor, so that only the two\n# replicas on GPU get run (plus the merge op on CPU)\noutput_value = sess.run([preds], feed_dict={x: data})\n\n\n\n\n\n\u8981\u60f3\u5b8c\u6210\u5206\u5e03\u5f0f\u7684\u8bad\u7ec3\uff0c\u4f60\u9700\u8981\u5c06Keras\u6ce8\u518c\u5728\u8fde\u63a5\u4e00\u4e2a\u96c6\u7fa4\u7684TensorFlow\u4f1a\u8bdd\u4e0a\uff1a\n\n\nserver = tf.train.Server.create_local_server()\nsess = tf.Session(server.target)\n\nfrom keras import backend as K\nK.set_session(sess)\n\n\n\n\n\u5173\u4e8e\u5206\u5e03\u5f0f\u8bad\u7ec3\u7684\u66f4\u591a\u4fe1\u606f\uff0c\u8bf7\u53c2\u8003\n\u8fd9\u91cc\n\n\n\n\n\n\n\n\n\u5982\u4f55\u201c\u51bb\u7ed3\u201d\u7f51\u7edc\u7684\u5c42\uff1f\n\n\n\n\n\n\n\u201c\u51bb\u7ed3\u201d\u4e00\u4e2a\u5c42\u6307\u7684\u662f\u8be5\u5c42\u5c06\u4e0d\u53c2\u52a0\u7f51\u7edc\u8bad\u7ec3\uff0c\u5373\u8be5\u5c42\u7684\u6743\u91cd\u6c38\u4e0d\u4f1a\u66f4\u65b0\u3002\u5728\u8fdb\u884cfine-tune\u65f6\u6211\u4eec\u7ecf\u5e38\u4f1a\u9700\u8981\u8fd9\u9879\u64cd\u4f5c\u3002\n\u5728\u4f7f\u7528\u56fa\u5b9a\u7684embedding\u5c42\u5904\u7406\u6587\u672c\u8f93\u5165\u65f6\uff0c\u4e5f\u9700\u8981\u8fd9\u4e2a\u6280\u672f\u3002\n\n\n\u53ef\u4ee5\u901a\u8fc7\u5411\u5c42\u7684\u6784\u9020\u51fd\u6570\u4f20\u9012\ntrainable\n\u53c2\u6570\u6765\u6307\u5b9a\u4e00\u4e2a\u5c42\u662f\u4e0d\u662f\u53ef\u8bad\u7ec3\u7684\uff0c\u5982\uff1a\n\n\nfrozen_layer = Dense(32,trainable=False)\n\n\n\n\n\u6b64\u5916\uff0c\u4e5f\u53ef\u4ee5\u901a\u8fc7\u5c06\u5c42\u5bf9\u8c61\u7684\ntrainable\n\u5c5e\u6027\u8bbe\u4e3a\nTrue\n\u6216\nFalse\n\u6765\u4e3a\u5df2\u7ecf\u642d\u5efa\u597d\u7684\u6a21\u578b\u8bbe\u7f6e\u8981\u51bb\u7ed3\u7684\u5c42\u3002\n\u5728\u8bbe\u7f6e\u5b8c\u540e\uff0c\u9700\u8981\u8fd0\u884c\ncompile\n\u6765\u4f7f\u8bbe\u7f6e\u751f\u6548\uff0c\u4f8b\u5982\uff1a\n\n\nx = Input(shape=(32,))\nlayer = Dense(32)\nlayer.trainable = False\ny = layer(x)\n\nfrozen_model = Model(x, y)\n# in the model below, the weights of `layer` will not be updated during training\nfrozen_model.compile(optimizer='rmsprop', loss='mse')\n\nlayer.trainable = True\ntrainable_model = Model(x, y)\n# with this model the weights of the layer will be updated during training\n# (which will also affect the above model since it uses the same layer instance)\ntrainable_model.compile(optimizer='rmsprop', loss='mse')\n\nfrozen_model.fit(data, labels)  # this does NOT update the weights of `layer`\ntrainable_model.fit(data, labels)  # this updates the weights of `layer`\n\n\n\n\n\n\n\n\n\n\n\u5982\u4f55\u4eceSequential\u6a21\u578b\u4e2d\u53bb\u9664\u4e00\u4e2a\u5c42\uff1f\n\n\n\n\n\n\n\u53ef\u4ee5\u901a\u8fc7\u8c03\u7528\n.pop()\n\u6765\u53bb\u9664\u6a21\u578b\u7684\u6700\u540e\u4e00\u4e2a\u5c42\uff0c\u53cd\u590d\u8c03\u7528n\u6b21\u5373\u53ef\u53bb\u9664\u6a21\u578b\u540e\u9762\u7684n\u4e2a\u5c42\n\n\nmodel = Sequential()\nmodel.add(Dense(32, activation='relu', input_dim=784))\nmodel.add(Dense(32, activation='relu'))\n\nprint(len(model.layers))  # \n2\n\n\nmodel.pop()\nprint(len(model.layers))  # \n1\n\n\n\n\n\n\u3010Tips\u3011\u6a21\u578b\u7684.layers\u5c5e\u6027\u4fdd\u5b58\u4e86\u6a21\u578b\u4e2d\u7684\u5c42\u5bf9\u8c61\uff0c\u6570\u636e\u7c7b\u578b\u662flist\uff0c\u5728model\u6ca1\u6709\n.pop()\n\u65b9\u6cd5\u524d\uff0c\u6211\u4e00\u822c\u901a\u8fc7model.layers.pop()\u5b8c\u6210\u76f8\u540c\u7684\u529f\u80fd\u3002\n\u4f46\u663e\u7136\uff0c\u4f7f\u7528keras\u63d0\u4f9b\u7684\u65b9\u6cd5\u4f1a\u5b89\u5168\u7684\u591a\u3010@bigmoyan\u3011\n\n\n\n\n\n\n\n\n\u5982\u4f55\u5728Keras\u4e2d\u4f7f\u7528\u9884\u8bad\u7ec3\u7684\u6a21\u578b\uff1f\n\n\n\n\n\n\n\u6211\u4eec\u63d0\u4f9b\u4e86\u4e0b\u9762\u8fd9\u4e9b\u56fe\u50cf\u5206\u7c7b\u7684\u6a21\u578b\u4ee3\u7801\u53ca\u9884\u8bad\u7ec3\u6743\u91cd\uff1a\n\n\n\n\nVGG16\n\n\nVGG19\n\n\nResNet50\n\n\nInception v3\n\n\n\n\n\u53ef\u901a\u8fc7\nkeras.applications\n\u8f7d\u5165\u8fd9\u4e9b\u6a21\u578b\uff1a\n\n\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.vgg19 import VGG19\nfrom keras.applications.resnet50 import ResNet50\nfrom keras.applications.inception_v3 import InceptionV3\n\nmodel = VGG16(weights='imagenet', include_top=True)\n\n\n\n\n\u8fd9\u4e9b\u4ee3\u7801\u7684\u4f7f\u7528\u793a\u4f8b\u8bf7\u53c2\u8003\n.Application\n\u6a21\u578b\u7684\n\u6587\u6863\n\n\n\u4f7f\u7528\u8fd9\u4e9b\u9884\u8bad\u7ec3\u6a21\u578b\u8fdb\u884c\u7279\u5f81\u62bd\u53d6\u6216fine-tune\u7684\u4f8b\u5b50\u53ef\u4ee5\u53c2\u8003\n\u6b64\u535a\u5ba2\n\n\nVGG\u6a21\u578b\u4e5f\u662f\u5f88\u591aKeras\u4f8b\u5b50\u7684\u57fa\u7840\u6a21\u578b\uff0c\u5982\uff1a\n\n\n\n\nStyle-transfer\n\n\nFeature visualization\n\n\nDeep dream", 
            "title": "FAQ"
        }, 
        {
            "location": "/getting_started/FAQ/#keras-faq", 
            "text": "\u5982\u4f55\u5f15\u7528Keras\uff1f  \u5982\u4f55\u4f7fKeras\u8c03\u7528GPU\uff1f  \u5982\u4f55\u4fdd\u5b58Keras\u6a21\u578b\uff1f  \u4e3a\u4ec0\u4e48\u8bad\u7ec3\u8bef\u5dee(loss)\u6bd4\u6d4b\u8bd5\u8bef\u5dee\u9ad8\u5f88\u591a\uff1f  \u5982\u4f55\u83b7\u53d6\u4e2d\u95f4\u5c42\u7684\u8f93\u51fa\uff1f  \u5982\u4f55\u5229\u7528Keras\u5904\u7406\u8d85\u8fc7\u673a\u5668\u5185\u5b58\u7684\u6570\u636e\u96c6\uff1f  \u5f53\u9a8c\u8bc1\u96c6\u7684loss\u4e0d\u518d\u4e0b\u964d\u65f6\uff0c\u5982\u4f55\u4e2d\u65ad\u8bad\u7ec3\uff1f  \u9a8c\u8bc1\u96c6\u662f\u5982\u4f55\u4ece\u8bad\u7ec3\u96c6\u4e2d\u5206\u5272\u51fa\u6765\u7684\uff1f  \u8bad\u7ec3\u6570\u636e\u5728\u8bad\u7ec3\u65f6\u4f1a\u88ab\u968f\u673a\u6d17\u4e71\u5417\uff1f  \u5982\u4f55\u5728\u6bcf\u4e2aepoch\u540e\u8bb0\u5f55\u8bad\u7ec3/\u6d4b\u8bd5\u7684loss\u548c\u6b63\u786e\u7387\uff1f  \u5982\u4f55\u4f7f\u7528\u72b6\u6001RNN\uff08statful RNN\uff09\uff1f  \u5982\u4f55\u4f7f\u7528Keras\u8fdb\u884c\u5206\u5e03\u5f0f/\u591aGPU\u8fd0\u7b97\uff1f  \u5982\u4f55\u201c\u51bb\u7ed3\u201d\u7f51\u7edc\u7684\u5c42\uff1f  \u5982\u4f55\u4eceSequential\u6a21\u578b\u4e2d\u53bb\u9664\u4e00\u4e2a\u5c42\uff1f  \u5982\u4f55\u5728Keras\u4e2d\u4f7f\u7528\u9884\u8bad\u7ec3\u7684\u6a21\u578b", 
            "title": "Keras FAQ\uff1a\u5e38\u89c1\u95ee\u9898"
        }, 
        {
            "location": "/getting_started/FAQ/#keras", 
            "text": "\u5982\u679cKeras\u5bf9\u4f60\u7684\u7814\u7a76\u6709\u5e2e\u52a9\u7684\u8bdd\uff0c\u8bf7\u5728\u4f60\u7684\u6587\u7ae0\u4e2d\u5f15\u7528Keras\u3002\u8fd9\u91cc\u662f\u4e00\u4e2a\u4f7f\u7528BibTex\u7684\u4f8b\u5b50  @misc{chollet2015keras,\n  author = {Chollet, Fran\u00e7ois},\n  title = {Keras},\n  year = {2015},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  howpublished = {\\url{https://github.com/fchollet/keras}}\n}", 
            "title": "\u5982\u4f55\u5f15\u7528Keras\uff1f"
        }, 
        {
            "location": "/getting_started/FAQ/#kerasgpu", 
            "text": "\u5982\u679c\u91c7\u7528TensorFlow\u4f5c\u4e3a\u540e\u7aef\uff0c\u5f53\u673a\u5668\u4e0a\u6709\u53ef\u7528\u7684GPU\u65f6\uff0c\u4ee3\u7801\u4f1a\u81ea\u52a8\u8c03\u7528GPU\u8fdb\u884c\u5e76\u884c\u8ba1\u7b97\u3002\u5982\u679c\u4f7f\u7528Theano\u4f5c\u4e3a\u540e\u7aef\uff0c\u53ef\u4ee5\u901a\u8fc7\u4ee5\u4e0b\u65b9\u6cd5\u8bbe\u7f6e\uff1a  \u65b9\u6cd51\uff1a\u4f7f\u7528Theano\u6807\u8bb0  \u5728\u6267\u884cpython\u811a\u672c\u65f6\u4f7f\u7528\u4e0b\u9762\u7684\u547d\u4ee4\uff1a  THEANO_FLAGS=device=gpu,floatX=float32 python my_keras_script.py  \u65b9\u6cd52\uff1a\u8bbe\u7f6e .theano \u6587\u4ef6  \u70b9\u51fb \u8fd9\u91cc \u67e5\u770b\u6307\u5bfc\u6559\u7a0b  \u65b9\u6cd53\uff1a\u5728\u4ee3\u7801\u7684\u5f00\u5934\u5904\u624b\u52a8\u8bbe\u7f6e theano.config.device \u548c theano.config.floatX      import theano\n    theano.config.device = 'gpu'\n    theano.config.floatX = 'float32'", 
            "title": "\u5982\u4f55\u4f7fKeras\u8c03\u7528GPU\uff1f"
        }, 
        {
            "location": "/getting_started/FAQ/#keras_1", 
            "text": "\u6211\u4eec\u4e0d\u63a8\u8350\u4f7f\u7528pickle\u6216cPickle\u6765\u4fdd\u5b58Keras\u6a21\u578b  \u4f60\u53ef\u4ee5\u4f7f\u7528 model.save(filepath) \u5c06Keras\u6a21\u578b\u548c\u6743\u91cd\u4fdd\u5b58\u5728\u4e00\u4e2aHDF5\u6587\u4ef6\u4e2d\uff0c\u8be5\u6587\u4ef6\u5c06\u5305\u542b\uff1a   \u6a21\u578b\u7684\u7ed3\u6784\uff0c\u4ee5\u4fbf\u91cd\u6784\u8be5\u6a21\u578b  \u6a21\u578b\u7684\u6743\u91cd  \u8bad\u7ec3\u914d\u7f6e\uff08\u635f\u5931\u51fd\u6570\uff0c\u4f18\u5316\u5668\u7b49\uff09  \u4f18\u5316\u5668\u7684\u72b6\u6001\uff0c\u4ee5\u4fbf\u4e8e\u4ece\u4e0a\u6b21\u8bad\u7ec3\u4e2d\u65ad\u7684\u5730\u65b9\u5f00\u59cb   \u4f7f\u7528 keras.models.load_model(filepath) \u6765\u91cd\u65b0\u5b9e\u4f8b\u5316\u4f60\u7684\u6a21\u578b\uff0c\u5982\u679c\u6587\u4ef6\u4e2d\u5b58\u50a8\u4e86\u8bad\u7ec3\u914d\u7f6e\u7684\u8bdd\uff0c\u8be5\u51fd\u6570\u8fd8\u4f1a\u540c\u65f6\u5b8c\u6210\u6a21\u578b\u7684\u7f16\u8bd1  \u4f8b\u5b50\uff1a  from keras.models import load_model\n\nmodel.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\ndel model  # deletes the existing model\n\n# returns a compiled model\n# identical to the previous one\nmodel = load_model('my_model.h5')  \u5982\u679c\u4f60\u53ea\u662f\u5e0c\u671b\u4fdd\u5b58\u6a21\u578b\u7684\u7ed3\u6784\uff0c\u800c\u4e0d\u5305\u542b\u5176\u6743\u91cd\u6216\u914d\u7f6e\u4fe1\u606f\uff0c\u53ef\u4ee5\u4f7f\u7528\uff1a  # save as JSON\njson_string = model.to_json()\n\n# save as YAML\nyaml_string = model.to_yaml()  \u8fd9\u9879\u64cd\u4f5c\u5c06\u628a\u6a21\u578b\u5e8f\u5217\u5316\u4e3ajson\u6216yaml\u6587\u4ef6\uff0c\u8fd9\u4e9b\u6587\u4ef6\u5bf9\u4eba\u800c\u8a00\u4e5f\u662f\u53cb\u597d\u7684\uff0c\u5982\u679c\u9700\u8981\u7684\u8bdd\u4f60\u751a\u81f3\u53ef\u4ee5\u624b\u52a8\u6253\u5f00\u8fd9\u4e9b\u6587\u4ef6\u5e76\u8fdb\u884c\u7f16\u8f91\u3002  \u5f53\u7136\uff0c\u4f60\u4e5f\u53ef\u4ee5\u4ece\u4fdd\u5b58\u597d\u7684json\u6587\u4ef6\u6216yaml\u6587\u4ef6\u4e2d\u8f7d\u5165\u6a21\u578b\uff1a  # model reconstruction from JSON:\nfrom keras.models import model_from_json\nmodel = model_from_json(json_string)\n\n# model reconstruction from YAML\nmodel = model_from_yaml(yaml_string)  \u5982\u679c\u9700\u8981\u4fdd\u5b58\u6a21\u578b\u7684\u6743\u91cd\uff0c\u53ef\u901a\u8fc7\u4e0b\u9762\u7684\u4ee3\u7801\u5229\u7528HDF5\u8fdb\u884c\u4fdd\u5b58\u3002\u6ce8\u610f\uff0c\u5728\u4f7f\u7528\u524d\u9700\u8981\u786e\u4fdd\u4f60\u5df2\u5b89\u88c5\u4e86HDF5\u548c\u5176Python\u5e93h5py  model.save_weights('my_model_weights.h5')  \u5982\u679c\u4f60\u9700\u8981\u5728\u4ee3\u7801\u4e2d\u521d\u59cb\u5316\u4e00\u4e2a\u5b8c\u5168\u76f8\u540c\u7684\u6a21\u578b\uff0c\u8bf7\u4f7f\u7528\uff1a  model.load_weights('my_model_weights.h5')  \u5982\u679c\u4f60\u9700\u8981\u52a0\u8f7d\u6743\u91cd\u5230\u4e0d\u540c\u7684\u7f51\u7edc\u7ed3\u6784\uff08\u6709\u4e9b\u5c42\u4e00\u6837\uff09\u4e2d\uff0c\u4f8b\u5982fine-tune\u6216transfer-learning\uff0c\u4f60\u53ef\u4ee5\u901a\u8fc7\u5c42\u540d\u5b57\u6765\u52a0\u8f7d\u6a21\u578b\uff1a  model.load_weights('my_model_weights.h5', by_name=True)  \u4f8b\u5982\uff1a  \n\u5047\u5982\u539f\u6a21\u578b\u4e3a\uff1a\n    model = Sequential()\n    model.add(Dense(2, input_dim=3, name= dense_1 ))\n    model.add(Dense(3, name= dense_2 ))\n    ...\n    model.save_weights(fname) \n# new model\nmodel = Sequential()\nmodel.add(Dense(2, input_dim=3, name= dense_1 ))  # will be loaded\nmodel.add(Dense(10, name= new_dense ))  # will not be loaded\n\n# load weights from first model; will only affect the first layer, dense_1.\nmodel.load_weights(fname, by_name=True)", 
            "title": "\u5982\u4f55\u4fdd\u5b58Keras\u6a21\u578b\uff1f"
        }, 
        {
            "location": "/getting_started/FAQ/#_1", 
            "text": "\u4e00\u4e2aKeras\u7684\u6a21\u578b\u6709\u4e24\u4e2a\u6a21\u5f0f\uff1a\u8bad\u7ec3\u6a21\u5f0f\u548c\u6d4b\u8bd5\u6a21\u5f0f\u3002\u4e00\u4e9b\u6b63\u5219\u673a\u5236\uff0c\u5982Dropout\uff0cL1/L2\u6b63\u5219\u9879\u5728\u6d4b\u8bd5\u6a21\u5f0f\u4e0b\u5c06\u4e0d\u88ab\u542f\u7528\u3002  \u53e6\u5916\uff0c\u8bad\u7ec3\u8bef\u5dee\u662f\u8bad\u7ec3\u6570\u636e\u6bcf\u4e2abatch\u7684\u8bef\u5dee\u7684\u5e73\u5747\u3002\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u6bcf\u4e2aepoch\u8d77\u59cb\u65f6\u7684batch\u7684\u8bef\u5dee\u8981\u5927\u4e00\u4e9b\uff0c\u800c\u540e\u9762\u7684batch\u7684\u8bef\u5dee\u8981\u5c0f\u4e00\u4e9b\u3002\u53e6\u4e00\u65b9\u9762\uff0c\u6bcf\u4e2aepoch\u7ed3\u675f\u65f6\u8ba1\u7b97\u7684\u6d4b\u8bd5\u8bef\u5dee\u662f\u7531\u6a21\u578b\u5728epoch\u7ed3\u675f\u65f6\u7684\u72b6\u6001\u51b3\u5b9a\u7684\uff0c\u8fd9\u65f6\u5019\u7684\u7f51\u7edc\u5c06\u4ea7\u751f\u8f83\u5c0f\u7684\u8bef\u5dee\u3002  \u3010Tips\u3011\u53ef\u4ee5\u901a\u8fc7\u5b9a\u4e49\u56de\u8c03\u51fd\u6570\u5c06\u6bcf\u4e2aepoch\u7684\u8bad\u7ec3\u8bef\u5dee\u548c\u6d4b\u8bd5\u8bef\u5dee\u5e76\u4f5c\u56fe\uff0c\u5982\u679c\u8bad\u7ec3\u8bef\u5dee\u66f2\u7ebf\u548c\u6d4b\u8bd5\u8bef\u5dee\u66f2\u7ebf\u4e4b\u95f4\u6709\u5f88\u5927\u7684\u7a7a\u9699\uff0c\u8bf4\u660e\u4f60\u7684\u6a21\u578b\u53ef\u80fd\u6709\u8fc7\u62df\u5408\u7684\u95ee\u9898\u3002\u5f53\u7136\uff0c\u8fd9\u4e2a\u95ee\u9898\u4e0eKeras\u65e0\u5173\u3002\u3010@BigMoyan\u3011", 
            "title": "\u4e3a\u4ec0\u4e48\u8bad\u7ec3\u8bef\u5dee\u6bd4\u6d4b\u8bd5\u8bef\u5dee\u9ad8\u5f88\u591a\uff1f"
        }, 
        {
            "location": "/getting_started/FAQ/#_2", 
            "text": "\u4e00\u79cd\u7b80\u5355\u7684\u65b9\u6cd5\u662f\u521b\u5efa\u4e00\u4e2a\u65b0\u7684 Model \uff0c\u4f7f\u5f97\u5b83\u7684\u8f93\u51fa\u662f\u4f60\u60f3\u8981\u7684\u90a3\u4e2a\u8f93\u51fa  from keras.models import Model\n\nmodel = ...  # create the original model\n\nlayer_name = 'my_layer'\nintermediate_layer_model = Model(input=model.input,\n                                 output=model.get_layer(layer_name).output)\nintermediate_output = intermediate_layer_model.predict(data  \u6b64\u5916\uff0c\u6211\u4eec\u4e5f\u53ef\u4ee5\u5efa\u7acb\u4e00\u4e2aKeras\u7684\u51fd\u6570\u6765\u8fbe\u5230\u8fd9\u4e00\u76ee\u7684\uff1a  from keras import backend as K\n\n# with a Sequential model\nget_3rd_layer_output = K.function([model.layers[0].input],\n                                  [model.layers[3].output])\nlayer_output = get_3rd_layer_output([X])[0]  \u5f53\u7136\uff0c\u6211\u4eec\u4e5f\u53ef\u4ee5\u76f4\u63a5\u7f16\u5199Theano\u548cTensorFlow\u7684\u51fd\u6570\u6765\u5b8c\u6210\u8fd9\u4ef6\u4e8b  \u6ce8\u610f\uff0c\u5982\u679c\u4f60\u7684\u6a21\u578b\u5728\u8bad\u7ec3\u548c\u6d4b\u8bd5\u4e24\u79cd\u6a21\u5f0f\u4e0b\u4e0d\u5b8c\u5168\u4e00\u81f4\uff0c\u4f8b\u5982\u4f60\u7684\u6a21\u578b\u4e2d\u542b\u6709Dropout\u5c42\uff0c\u6279\u89c4\u8303\u5316\uff08BatchNormalization\uff09\u5c42\u7b49\u7ec4\u4ef6\uff0c\u4f60\u9700\u8981\u5728\u51fd\u6570\u4e2d\u4f20\u9012\u4e00\u4e2alearning_phase\u7684\u6807\u8bb0\uff0c\u50cf\u8fd9\u6837\uff1a  get_3rd_layer_output = K.function([model.layers[0].input, K.learning_phase()],\n                                  [model.layers[3].output])\n\n# output in test mode = 0\nlayer_output = get_3rd_layer_output([X, 0])[0]\n\n# output in train mode = 1\nlayer_output = get_3rd_layer_output([X, 1])[0]", 
            "title": "\u5982\u4f55\u83b7\u53d6\u4e2d\u95f4\u5c42\u7684\u8f93\u51fa\uff1f"
        }, 
        {
            "location": "/getting_started/FAQ/#keras_2", 
            "text": "\u53ef\u4ee5\u4f7f\u7528 model.train_on_batch(X,y) \u548c model.test_on_batch(X,y) \u3002\u8bf7\u53c2\u8003 \u6a21\u578b  \u53e6\u5916\uff0c\u4e5f\u53ef\u4ee5\u7f16\u5199\u4e00\u4e2a\u6bcf\u6b21\u4ea7\u751f\u4e00\u4e2abatch\u6837\u672c\u7684\u751f\u6210\u5668\u51fd\u6570\uff0c\u5e76\u8c03\u7528 model.fit_generator(data_generator, samples_per_epoch, nb_epoch) \u8fdb\u884c\u8bad\u7ec3  \u8fd9\u79cd\u65b9\u5f0f\u5728Keras\u4ee3\u7801\u5305\u7684example\u6587\u4ef6\u5939\u4e0bCIFAR10\u4f8b\u5b50\u91cc\u6709\u793a\u8303\uff0c\u4e5f\u53ef\u70b9\u51fb \u8fd9\u91cc \u5728github\u4e0a\u6d4f\u89c8\u3002", 
            "title": "\u5982\u4f55\u5229\u7528Keras\u5904\u7406\u8d85\u8fc7\u673a\u5668\u5185\u5b58\u7684\u6570\u636e\u96c6\uff1f"
        }, 
        {
            "location": "/getting_started/FAQ/#loss", 
            "text": "\u53ef\u4ee5\u5b9a\u4e49 EarlyStopping \u6765\u63d0\u524d\u7ec8\u6b62\u8bad\u7ec3  from keras.callbacks import EarlyStopping\nearly_stopping = EarlyStopping(monitor='val_loss', patience=2)\nmodel.fit(X, y, validation_split=0.2, callbacks=[early_stopping])  \u8bf7\u53c2\u8003 \u56de\u8c03\u51fd\u6570", 
            "title": "\u5f53\u9a8c\u8bc1\u96c6\u7684loss\u4e0d\u518d\u4e0b\u964d\u65f6\uff0c\u5982\u4f55\u4e2d\u65ad\u8bad\u7ec3\uff1f"
        }, 
        {
            "location": "/getting_started/FAQ/#_3", 
            "text": "\u5982\u679c\u5728 model.fit \u4e2d\u8bbe\u7f6e validation_spilt \u7684\u503c\uff0c\u5219\u53ef\u5c06\u6570\u636e\u5206\u4e3a\u8bad\u7ec3\u96c6\u548c\u9a8c\u8bc1\u96c6\uff0c\u4f8b\u5982\uff0c\u8bbe\u7f6e\u8be5\u503c\u4e3a0.1\uff0c\u5219\u8bad\u7ec3\u96c6\u7684\u6700\u540e10%\u6570\u636e\u5c06\u4f5c\u4e3a\u9a8c\u8bc1\u96c6\uff0c\u8bbe\u7f6e\u5176\u4ed6\u6570\u5b57\u540c\u7406\u3002\u6ce8\u610f\uff0c\u539f\u6570\u636e\u5728\u8fdb\u884c\u9a8c\u8bc1\u96c6\u5206\u5272\u524d\u5e76\u6ca1\u6709\u88abshuffle\uff0c\u6240\u4ee5\u8fd9\u91cc\u7684\u9a8c\u8bc1\u96c6\u4e25\u683c\u7684\u5c31\u662f\u4f60\u8f93\u5165\u6570\u636e\u6700\u672b\u7684x%\u3002", 
            "title": "\u9a8c\u8bc1\u96c6\u662f\u5982\u4f55\u4ece\u8bad\u7ec3\u96c6\u4e2d\u5206\u5272\u51fa\u6765\u7684\uff1f"
        }, 
        {
            "location": "/getting_started/FAQ/#_4", 
            "text": "\u662f\u7684\uff0c\u5982\u679c model.fit \u7684 shuffle \u53c2\u6570\u4e3a\u771f\uff0c\u8bad\u7ec3\u7684\u6570\u636e\u5c31\u4f1a\u88ab\u968f\u673a\u6d17\u4e71\u3002\u4e0d\u8bbe\u7f6e\u65f6\u9ed8\u8ba4\u4e3a\u771f\u3002\u8bad\u7ec3\u6570\u636e\u4f1a\u5728\u6bcf\u4e2aepoch\u7684\u8bad\u7ec3\u4e2d\u90fd\u91cd\u65b0\u6d17\u4e71\u4e00\u6b21\u3002  \u9a8c\u8bc1\u96c6\u7684\u6570\u636e\u4e0d\u4f1a\u88ab\u6d17\u4e71", 
            "title": "\u8bad\u7ec3\u6570\u636e\u5728\u8bad\u7ec3\u65f6\u4f1a\u88ab\u968f\u673a\u6d17\u4e71\u5417\uff1f"
        }, 
        {
            "location": "/getting_started/FAQ/#epochloss", 
            "text": "model.fit \u5728\u8fd0\u884c\u7ed3\u675f\u540e\u8fd4\u56de\u4e00\u4e2a History \u5bf9\u8c61\uff0c\u5176\u4e2d\u542b\u6709\u7684 history \u5c5e\u6027\u5305\u542b\u4e86\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u635f\u5931\u51fd\u6570\u7684\u503c\u4ee5\u53ca\u5176\u4ed6\u5ea6\u91cf\u6307\u6807\u3002  hist = model.fit(X, y, validation_split=0.2)\nprint(hist.history)", 
            "title": "\u5982\u4f55\u5728\u6bcf\u4e2aepoch\u540e\u8bb0\u5f55\u8bad\u7ec3/\u6d4b\u8bd5\u7684loss\u548c\u6b63\u786e\u7387\uff1f"
        }, 
        {
            "location": "/getting_started/FAQ/#rnnstatful-rnn", 
            "text": "\u4e00\u4e2aRNN\u662f\u72b6\u6001RNN\uff0c\u610f\u5473\u7740\u8bad\u7ec3\u65f6\u6bcf\u4e2abatch\u7684\u72b6\u6001\u90fd\u4f1a\u88ab\u91cd\u7528\u4e8e\u521d\u59cb\u5316\u4e0b\u4e00\u4e2abatch\u7684\u521d\u59cb\u72b6\u6001\u3002  \u5f53\u4f7f\u7528\u72b6\u6001RNN\u65f6\uff0c\u6709\u5982\u4e0b\u5047\u8bbe    \u6240\u6709\u7684batch\u90fd\u5177\u6709\u76f8\u540c\u6570\u76ee\u7684\u6837\u672c    \u5982\u679c X1 \u548c X2 \u662f\u4e24\u4e2a\u76f8\u90bb\u7684batch\uff0c\u90a3\u4e48\u5bf9\u4e8e\u4efb\u4f55 i \uff0c X2[i] \u90fd\u662f X1[i] \u7684\u540e\u7eed\u5e8f\u5217    \u8981\u4f7f\u7528\u72b6\u6001RNN\uff0c\u6211\u4eec\u9700\u8981    \u663e\u5f0f\u7684\u6307\u5b9a\u6bcf\u4e2abatch\u7684\u5927\u5c0f\u3002\u53ef\u4ee5\u901a\u8fc7\u6a21\u578b\u7684\u9996\u5c42\u53c2\u6570 batch_input_shape \u6765\u5b8c\u6210\u3002 batch_input_shape \u662f\u4e00\u4e2a\u6574\u6570tuple\uff0c\u4f8b\u5982(32,10,16)\u4ee3\u8868\u4e00\u4e2a\u5177\u670910\u4e2a\u65f6\u95f4\u6b65\uff0c\u6bcf\u6b65\u5411\u91cf\u957f\u4e3a16\uff0c\u6bcf32\u4e2a\u6837\u672c\u6784\u6210\u4e00\u4e2abatch\u7684\u8f93\u5165\u6570\u636e\u683c\u5f0f\u3002    \u5728RNN\u5c42\u4e2d\uff0c\u8bbe\u7f6e stateful=True    \u8981\u91cd\u7f6e\u7f51\u7edc\u7684\u72b6\u6001\uff0c\u4f7f\u7528\uff1a    model.reset_states() \u6765\u91cd\u7f6e\u7f51\u7edc\u4e2d\u6240\u6709\u5c42\u7684\u72b6\u6001    layer.reset_states() \u6765\u91cd\u7f6e\u6307\u5b9a\u5c42\u7684\u72b6\u6001    \u4f8b\u5b50\uff1a  X  # this is our input data, of shape (32, 21, 16)\n# we will feed it to our model in sequences of length 10\n\nmodel = Sequential()\nmodel.add(LSTM(32, batch_input_shape=(32, 10, 16), stateful=True))\nmodel.add(Dense(16, activation='softmax'))\n\nmodel.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n\n# we train the network to predict the 11th timestep given the first 10:\nmodel.train_on_batch(X[:, :10, :], np.reshape(X[:, 10, :], (32, 16)))\n\n# the state of the network has changed. We can feed the follow-up sequences:\nmodel.train_on_batch(X[:, 10:20, :], np.reshape(X[:, 20, :], (32, 16)))\n\n# let's reset the states of the LSTM layer:\nmodel.reset_states()\n\n# another way to do it in this case:\nmodel.layers[0].reset_states()  \u6ce8\u610f\uff0c predict \uff0c fit \uff0c train_on_batch \n\uff0c predict_classes \u7b49\u65b9\u6cd5\u90fd\u4f1a\u66f4\u65b0\u6a21\u578b\u4e2d\u72b6\u6001\u5c42\u7684\u72b6\u6001\u3002\u8fd9\u4f7f\u5f97\u4f60\u53ef\u4ee5\u4e0d\u4f46\u53ef\u4ee5\u8fdb\u884c\u72b6\u6001\u7f51\u7edc\u7684\u8bad\u7ec3\uff0c\u4e5f\u53ef\u4ee5\u8fdb\u884c\u72b6\u6001\u7f51\u7edc\u7684\u9884\u6d4b\u3002", 
            "title": "\u5982\u4f55\u4f7f\u7528\u72b6\u6001RNN\uff08statful RNN\uff09\uff1f"
        }, 
        {
            "location": "/getting_started/FAQ/#kerasgpu_1", 
            "text": "Keras\u5728\u4f7f\u7528TensorFlow\u4f5c\u4e3a\u540e\u7aef\u7684\u65f6\u5019\u53ef\u4ee5\u8fdb\u884c\u5206\u5e03\u5f0f/\u591aGPU\u7684\u8fd0\u7b97\uff0cKeras\u5bf9\u591aGPU\u548c\u5206\u5e03\u5f0f\u7684\u652f\u6301\u662f\u901a\u8fc7TF\u5b8c\u6210\u7684\u3002  with tf.device('/gpu:0'):\n    x = tf.placeholder(tf.float32, shape=(None, 20, 64))\n    y = LSTM(32)(x)  # all ops in the LSTM layer will live on GPU:0\n\nwith tf.device('/gpu:1'):\n    x = tf.placeholder(tf.float32, shape=(None, 20, 64))\n    y = LSTM(32)(x)  # all ops in the LSTM layer will live on GPU:1  \u6ce8\u610f\uff0c\u4e0a\u4f8b\u4e2d\u7531LSTM\u521b\u5efa\u7684\u53d8\u91cf\u4e0d\u5728GPU\u4e0a\uff1a\u6240\u6709\u7684TensorFlow\u53d8\u91cf\u603b\u662f\u5728CPU\u4e0a\u751f\u5b58\uff0c\u800c\u4e0e\u5b83\u4eec\u5728\u54ea\u521b\u5efa\u65e0\u5173\u3002\u5404\u4e2a\u8bbe\u5907\u4e0a\u7684\u53d8\u91cf\u8f6c\u6362TensorFlow\u4f1a\u81ea\u52a8\u5b8c\u6210\u3002  \u5982\u679c\u4f60\u60f3\u5728\u4e0d\u540c\u7684GPU\u4e0a\u8bad\u7ec3\u540c\u4e00\u4e2a\u6a21\u578b\u7684\u4e0d\u540c\u526f\u672c\uff0c\u4f46\u5728\u4e0d\u540c\u7684\u526f\u672c\u4e2d\u5171\u4eab\u6743\u91cd\uff0c\u4f60\u5e94\u8be5\u9996\u5148\u5728\u4e00\u4e2a\u8bbe\u5907\u4e0a\u5b9e\u4f8b\u5316\u4f60\u7684\u6a21\u578b\uff0c\u7136\u540e\u5728\u4e0d\u540c\u7684\u8bbe\u5907\u4e0a\u591a\u6b21\u8c03\u7528\u8be5\u5bf9\u8c61\uff0c\u4f8b\u5982\uff1a  with tf.device('/cpu:0'):\n    x = tf.placeholder(tf.float32, shape=(None, 784))\n\n    # shared model living on CPU:0\n    # it won't actually be run during training; it acts as an op template\n    # and as a repository for shared variables\n    model = Sequential()\n    model.add(Dense(32, activation='relu', input_dim=784))\n    model.add(Dense(10, activation='softmax'))\n\n# replica 0\nwith tf.device('/gpu:0'):\n    output_0 = model(x)  # all ops in the replica will live on GPU:0\n\n# replica 1\nwith tf.device('/gpu:1'):\n    output_1 = model(x)  # all ops in the replica will live on GPU:1\n\n# merge outputs on CPU\nwith tf.device('/cpu:0'):\n    preds = 0.5 * (output_0 + output_1)\n\n# we only run the `preds` tensor, so that only the two\n# replicas on GPU get run (plus the merge op on CPU)\noutput_value = sess.run([preds], feed_dict={x: data})  \u8981\u60f3\u5b8c\u6210\u5206\u5e03\u5f0f\u7684\u8bad\u7ec3\uff0c\u4f60\u9700\u8981\u5c06Keras\u6ce8\u518c\u5728\u8fde\u63a5\u4e00\u4e2a\u96c6\u7fa4\u7684TensorFlow\u4f1a\u8bdd\u4e0a\uff1a  server = tf.train.Server.create_local_server()\nsess = tf.Session(server.target)\n\nfrom keras import backend as K\nK.set_session(sess)  \u5173\u4e8e\u5206\u5e03\u5f0f\u8bad\u7ec3\u7684\u66f4\u591a\u4fe1\u606f\uff0c\u8bf7\u53c2\u8003 \u8fd9\u91cc", 
            "title": "\u5982\u4f55\u4f7f\u7528Keras\u8fdb\u884c\u5206\u5e03\u5f0f/\u591aGPU\u8fd0\u7b97\uff1f"
        }, 
        {
            "location": "/getting_started/FAQ/#_5", 
            "text": "\u201c\u51bb\u7ed3\u201d\u4e00\u4e2a\u5c42\u6307\u7684\u662f\u8be5\u5c42\u5c06\u4e0d\u53c2\u52a0\u7f51\u7edc\u8bad\u7ec3\uff0c\u5373\u8be5\u5c42\u7684\u6743\u91cd\u6c38\u4e0d\u4f1a\u66f4\u65b0\u3002\u5728\u8fdb\u884cfine-tune\u65f6\u6211\u4eec\u7ecf\u5e38\u4f1a\u9700\u8981\u8fd9\u9879\u64cd\u4f5c\u3002\n\u5728\u4f7f\u7528\u56fa\u5b9a\u7684embedding\u5c42\u5904\u7406\u6587\u672c\u8f93\u5165\u65f6\uff0c\u4e5f\u9700\u8981\u8fd9\u4e2a\u6280\u672f\u3002  \u53ef\u4ee5\u901a\u8fc7\u5411\u5c42\u7684\u6784\u9020\u51fd\u6570\u4f20\u9012 trainable \u53c2\u6570\u6765\u6307\u5b9a\u4e00\u4e2a\u5c42\u662f\u4e0d\u662f\u53ef\u8bad\u7ec3\u7684\uff0c\u5982\uff1a  frozen_layer = Dense(32,trainable=False)  \u6b64\u5916\uff0c\u4e5f\u53ef\u4ee5\u901a\u8fc7\u5c06\u5c42\u5bf9\u8c61\u7684 trainable \u5c5e\u6027\u8bbe\u4e3a True \u6216 False \u6765\u4e3a\u5df2\u7ecf\u642d\u5efa\u597d\u7684\u6a21\u578b\u8bbe\u7f6e\u8981\u51bb\u7ed3\u7684\u5c42\u3002\n\u5728\u8bbe\u7f6e\u5b8c\u540e\uff0c\u9700\u8981\u8fd0\u884c compile \u6765\u4f7f\u8bbe\u7f6e\u751f\u6548\uff0c\u4f8b\u5982\uff1a  x = Input(shape=(32,))\nlayer = Dense(32)\nlayer.trainable = False\ny = layer(x)\n\nfrozen_model = Model(x, y)\n# in the model below, the weights of `layer` will not be updated during training\nfrozen_model.compile(optimizer='rmsprop', loss='mse')\n\nlayer.trainable = True\ntrainable_model = Model(x, y)\n# with this model the weights of the layer will be updated during training\n# (which will also affect the above model since it uses the same layer instance)\ntrainable_model.compile(optimizer='rmsprop', loss='mse')\n\nfrozen_model.fit(data, labels)  # this does NOT update the weights of `layer`\ntrainable_model.fit(data, labels)  # this updates the weights of `layer`", 
            "title": "\u5982\u4f55\u201c\u51bb\u7ed3\u201d\u7f51\u7edc\u7684\u5c42\uff1f"
        }, 
        {
            "location": "/getting_started/FAQ/#sequential", 
            "text": "\u53ef\u4ee5\u901a\u8fc7\u8c03\u7528 .pop() \u6765\u53bb\u9664\u6a21\u578b\u7684\u6700\u540e\u4e00\u4e2a\u5c42\uff0c\u53cd\u590d\u8c03\u7528n\u6b21\u5373\u53ef\u53bb\u9664\u6a21\u578b\u540e\u9762\u7684n\u4e2a\u5c42  model = Sequential()\nmodel.add(Dense(32, activation='relu', input_dim=784))\nmodel.add(Dense(32, activation='relu'))\n\nprint(len(model.layers))  #  2 \n\nmodel.pop()\nprint(len(model.layers))  #  1   \u3010Tips\u3011\u6a21\u578b\u7684.layers\u5c5e\u6027\u4fdd\u5b58\u4e86\u6a21\u578b\u4e2d\u7684\u5c42\u5bf9\u8c61\uff0c\u6570\u636e\u7c7b\u578b\u662flist\uff0c\u5728model\u6ca1\u6709 .pop() \u65b9\u6cd5\u524d\uff0c\u6211\u4e00\u822c\u901a\u8fc7model.layers.pop()\u5b8c\u6210\u76f8\u540c\u7684\u529f\u80fd\u3002\n\u4f46\u663e\u7136\uff0c\u4f7f\u7528keras\u63d0\u4f9b\u7684\u65b9\u6cd5\u4f1a\u5b89\u5168\u7684\u591a\u3010@bigmoyan\u3011", 
            "title": "\u5982\u4f55\u4eceSequential\u6a21\u578b\u4e2d\u53bb\u9664\u4e00\u4e2a\u5c42\uff1f"
        }, 
        {
            "location": "/getting_started/FAQ/#keras_3", 
            "text": "\u6211\u4eec\u63d0\u4f9b\u4e86\u4e0b\u9762\u8fd9\u4e9b\u56fe\u50cf\u5206\u7c7b\u7684\u6a21\u578b\u4ee3\u7801\u53ca\u9884\u8bad\u7ec3\u6743\u91cd\uff1a   VGG16  VGG19  ResNet50  Inception v3   \u53ef\u901a\u8fc7 keras.applications \u8f7d\u5165\u8fd9\u4e9b\u6a21\u578b\uff1a  from keras.applications.vgg16 import VGG16\nfrom keras.applications.vgg19 import VGG19\nfrom keras.applications.resnet50 import ResNet50\nfrom keras.applications.inception_v3 import InceptionV3\n\nmodel = VGG16(weights='imagenet', include_top=True)  \u8fd9\u4e9b\u4ee3\u7801\u7684\u4f7f\u7528\u793a\u4f8b\u8bf7\u53c2\u8003 .Application \u6a21\u578b\u7684 \u6587\u6863  \u4f7f\u7528\u8fd9\u4e9b\u9884\u8bad\u7ec3\u6a21\u578b\u8fdb\u884c\u7279\u5f81\u62bd\u53d6\u6216fine-tune\u7684\u4f8b\u5b50\u53ef\u4ee5\u53c2\u8003 \u6b64\u535a\u5ba2  VGG\u6a21\u578b\u4e5f\u662f\u5f88\u591aKeras\u4f8b\u5b50\u7684\u57fa\u7840\u6a21\u578b\uff0c\u5982\uff1a   Style-transfer  Feature visualization  Deep dream", 
            "title": "\u5982\u4f55\u5728Keras\u4e2d\u4f7f\u7528\u9884\u8bad\u7ec3\u7684\u6a21\u578b\uff1f"
        }, 
        {
            "location": "/getting_started/trap/", 
            "text": "Keras\u4f7f\u7528\u9677\u9631\n\n\n\u8fd9\u91cc\u5f52\u7eb3\u4e86Keras\u4f7f\u7528\u8fc7\u7a0b\u4e2d\u7684\u4e00\u4e9b\u5e38\u89c1\u9677\u9631\u548c\u89e3\u51b3\u65b9\u6cd5\uff0c\u5982\u679c\u4f60\u7684\u6a21\u578b\u600e\u4e48\u8c03\u90fd\u641e\u4e0d\u5bf9\uff0c\u6216\u8bb8\u4f60\u6709\u5fc5\u8981\u770b\u770b\u662f\u4e0d\u662f\u6389\u8fdb\u4e86\u54ea\u4e2a\u730e\u4eba\u7684\u9677\u9631\uff0c\u6210\u4e3a\u4e86\u4e00\u53ea\u55f7\u55f7\u5f85\u5bb0\uff08\uff1f\uff09\u7684\u730e\u7269\n\n\nKeras\u9677\u9631\u4e0d\u591a\uff0c\u6211\u4eec\u4fdd\u6301\u66f4\u65b0\uff0c\u5e0c\u671b\u80fd\u505a\u4e00\u4e2a\u9677\u9631\u5927\u5168\n\n\n\u5185\u6709\u6076\u72ac\uff0c\u5c0f\u5fc3\u54df\n\n\nTF\u5377\u79ef\u6838\u4e0eTH\u5377\u79ef\u6838\n\n\nKeras\u63d0\u4f9b\u4e86\u4e24\u5957\u540e\u7aef\uff0cTheano\u548cTensorflow\uff0c\u8fd9\u662f\u4e00\u4ef6\u5e78\u798f\u7684\u4e8b\uff0c\u5c31\u50cf\u624b\u4e2d\u62ff\u7740\u9992\u5934\uff0c\u60f3\u8638\u7ea2\u7cd6\u8638\u7ea2\u7cd6\uff0c\u60f3\u8638\u767d\u7cd6\u8638\u767d\u7cd6\n\n\n\u5982\u679c\u4f60\u4ece\u65e0\u5230\u6709\u642d\u5efa\u81ea\u5df1\u7684\u4e00\u5957\u7f51\u7edc\uff0c\u5219\u5927\u53ef\u653e\u5fc3\u3002\u4f46\u5982\u679c\u4f60\u60f3\u4f7f\u7528\u4e00\u4e2a\u5df2\u6709\u7f51\u7edc\uff0c\u6216\u628a\u4e00\u4e2a\u7528th/tf\n\u8bad\u7ec3\u7684\u7f51\u7edc\u4ee5\u53e6\u4e00\u79cd\u540e\u7aef\u5e94\u7528\uff0c\u5728\u8f7d\u5165\u7684\u65f6\u5019\u4f60\u5c31\u5e94\u8be5\u7279\u522b\u5c0f\u5fc3\u4e86\u3002\n\n\n\u5377\u79ef\u6838\u4e0e\u6240\u4f7f\u7528\u7684\u540e\u7aef\u4e0d\u5339\u914d\uff0c\u4e0d\u4f1a\u62a5\u4efb\u4f55\u9519\u8bef\uff0c\u56e0\u4e3a\u5b83\u4eec\u7684shape\u662f\u5b8c\u5168\u4e00\u81f4\u7684\uff0c\u6ca1\u6709\u65b9\u6cd5\u80fd\u591f\u68c0\u6d4b\u51fa\u8fd9\u79cd\u9519\u8bef\u3002\n\n\n\u5728\u4f7f\u7528\u9884\u8bad\u7ec3\u6a21\u578b\u65f6\uff0c\u4e00\u4e2a\u5efa\u8bae\u662f\u9996\u5148\u627e\u4e00\u4e9b\u6d4b\u8bd5\u6837\u672c\uff0c\u770b\u770b\u6a21\u578b\u7684\u8868\u73b0\u662f\u5426\u4e0e\u9884\u8ba1\u7684\u4e00\u81f4\u3002\n\n\n\u5982\u9700\u5bf9\u5377\u79ef\u6838\u8fdb\u884c\u8f6c\u6362\uff0c\u53ef\u4ee5\u4f7f\u7528utils.np_utils.kernel_convert\uff0c\u6216\u4f7f\u7528utils.layer_utils.convert_all_kernels_in_model\u6765\u5bf9\u6a21\u578b\u7684\u6240\u6709\u5377\u79ef\u6838\u8fdb\u884c\u8f6c\u6362\n\n\n\u5411BN\u5c42\u4e2d\u8f7d\u5165\u6743\u91cd\n\n\n\u5982\u679c\u4f60\u4e0d\u77e5\u9053\u4ece\u54ea\u91cc\u6dd8\u6765\u4e00\u4e2a\u9884\u8bad\u7ec3\u597d\u7684BN\u5c42\uff0c\u60f3\u628a\u5b83\u7684\u6743\u91cd\u8f7d\u5165\u5230Keras\u4e2d\uff0c\u8981\u5c0f\u5fc3\u53c2\u6570\u7684\u8f7d\u5165\u987a\u5e8f\u3002\n\n\n\u4e00\u4e2a\u5178\u578b\u7684\u4f8b\u5b50\u662f\uff0c\u5c06caffe\u7684BN\u5c42\u53c2\u6570\u8f7d\u5165Keras\u4e2d\uff0ccaffe\u7684BN\u7531\u4e24\u90e8\u5206\u6784\u6210\uff0cbn\u5c42\u7684\u53c2\u6570\u662fmean\uff0cstd\uff0cscale\u5c42\u7684\u53c2\u6570\u662fgamma\uff0cbeta\n\n\n\u6309\u7167BN\u7684\u6587\u7ae0\u987a\u5e8f\uff0c\u4f3c\u4e4e\u8f7d\u5165Keras BN\u5c42\u7684\u53c2\u6570\u5e94\u8be5\u662f[mean, std, gamma, beta]\n\n\n\u7136\u800c\u4e0d\u662f\u7684\uff0cKeras\u7684BN\u5c42\u53c2\u6570\u987a\u5e8f\u5e94\u8be5\u662f[gamma, beta, mean, std]\uff0c\u8fd9\u662f\u56e0\u4e3agamma\u548cbeta\u662f\u53ef\u8bad\u7ec3\u7684\u53c2\u6570\uff0c\u800cmean\u548cstd\u4e0d\u662f\n\n\nKeras\u7684\u53ef\u8bad\u7ec3\u53c2\u6570\u5728\u524d\uff0c\u4e0d\u53ef\u8bad\u7ec3\u53c2\u6570\u5728\u540e\n\n\n\u9519\u8bef\u7684\u6743\u91cd\u987a\u5e8f\u4e0d\u4f1a\u5f15\u8d77\u4efb\u4f55\u62a5\u9519\uff0c\u56e0\u4e3a\u5b83\u4eec\u7684shape\u5b8c\u5168\u76f8\u540c\n\n\nshuffle\u548cvalidation_split\u7684\u987a\u5e8f\n\n\n\u6a21\u578b\u7684fit\u51fd\u6570\u6709\u4e24\u4e2a\u53c2\u6570\uff0cshuffle\u7528\u4e8e\u5c06\u6570\u636e\u6253\u4e71\uff0cvalidation_split\u7528\u4e8e\u5728\u6ca1\u6709\u63d0\u4f9b\u9a8c\u8bc1\u96c6\u7684\u65f6\u5019\uff0c\u6309\u4e00\u5b9a\u6bd4\u4f8b\u4ece\u8bad\u7ec3\u96c6\u4e2d\u53d6\u51fa\u4e00\u90e8\u5206\u4f5c\u4e3a\u9a8c\u8bc1\u96c6\n\n\n\u8fd9\u91cc\u6709\u4e2a\u9677\u9631\u662f\uff0c\u7a0b\u5e8f\u662f\u5148\u6267\u884cvalidation_split\uff0c\u518d\u6267\u884cshuffle\u7684\uff0c\u6240\u4ee5\u4f1a\u51fa\u73b0\u8fd9\u79cd\u60c5\u51b5\uff1a\n\n\n\u5047\u5982\u4f60\u7684\u8bad\u7ec3\u96c6\u662f\u6709\u5e8f\u7684\uff0c\u6bd4\u65b9\u8bf4\u6b63\u6837\u672c\u5728\u524d\u8d1f\u6837\u672c\u5728\u540e\uff0c\u53c8\u8bbe\u7f6e\u4e86validation_split\uff0c\u90a3\u4e48\u4f60\u7684\u9a8c\u8bc1\u96c6\u4e2d\u5f88\u53ef\u80fd\u5c06\u5168\u90e8\u662f\u8d1f\u6837\u672c\n\n\n\u540c\u6837\u7684\uff0c\u8fd9\u4e2a\u4e1c\u897f\u4e0d\u4f1a\u6709\u4efb\u4f55\u9519\u8bef\u62a5\u51fa\u6765\uff0c\u56e0\u4e3aKeras\u4e0d\u53ef\u80fd\u77e5\u9053\u4f60\u7684\u6570\u636e\u6709\u6ca1\u6709\u7ecf\u8fc7shuffle\uff0c\u4fdd\u9669\u8d77\u89c1\u5982\u679c\u4f60\u7684\u6570\u636e\u662f\u6ca1shuffle\u8fc7\u7684\uff0c\u6700\u597d\u624b\u52a8shuffle\u4e00\u4e0b\n\n\nmerge \u548c Merge\n\n\nKeras\u6709\u4e24\u4e2a\u5f88\u7c7b\u4f3c\u7684\u7528\u4e8e\u5f20\u91cf\u878d\u5408\u7684\u5de5\u5177\uff0c\u5728\u8fd9\u91cc\u52a0\u4ee5\u8fa8\u6790\u3002\n\n\nmerge\u662f\u4e00\u4e2a\u51fd\u6570\uff0c\u63a5\u53d7\u4e00\u4e2atensor\u5217\u8868\uff0c\u5e76\u5c06\u5217\u8868\u4e2d\u7684tensor\u6309\u7167\u7ed9\u5b9a\u7684\u65b9\u5f0f\u878d\u5408\u5728\u4e00\u8d77\u5f62\u6210\u8f93\u51fa\uff0c\u591a\u7528\u4e8e\u4ee5Model\u4f5c\u4e3a\u6a21\u578b\u7684\u60c5\u51b5\n\n\nMerge\u662f\u4e00\u4e2a\u5c42\u5bf9\u8c61\uff0c\u5b83\u63a5\u6536\u4e00\u4e2a\u5c42\u5bf9\u8c61\u7684\u5217\u8868\uff0c\u5e76\u6309\u7167\u7ed9\u5b9a\u7684\u65b9\u5f0f\u5c06\u5b83\u4eec\u7684\u8f93\u51fatensor\u878d\u5408\u8d77\u6765\u3002\u5178\u578b\u7684\u4f7f\u7528\u573a\u666f\u662f\u5728Sequential\u4e2d\u5904\u7406\u591a\u8f93\u5165\u7684\u60c5\u51b5\n\n\n\u672a\u5b8c\u5f85\u7eed\n\n\n\u5982\u679c\u4f60\u5728\u4f7f\u7528Keras\u4e2d\u9047\u5230\u96be\u4ee5\u5bdf\u89c9\u7684\u9677\u9631\uff0c\u8bf7\u53d1\u4fe1\u5230moyan_work@foxmail.com\u8bf4\u660e~\u8d60\u4eba\u73ab\u7470\uff0c\u624b\u6709\u4f59\u9999\uff0c\u524d\u4eba\u8e29\u5751\uff0c\u540e\u4eba\u6cbe\u5149\uff0c\u6709\u9053\u662f\u6211\u4e0d\u5165\u5730\u72f1\u8c01\u5165\u5730\u72f1\uff0c\u613f\u5404\u4f4dKeras\u4f7f\u7528\u8005\u79ef\u6781\u8d21\u732eKeras\u9677\u9631\u3002\u8001\u89c4\u77e9\uff0c\u9677\u9631\u8d21\u732e\u8005\u5c06\u88ab\u5217\u5165\u81f4\u8c22\u4e00\u680f", 
            "title": "Keras\u4f7f\u7528\u9677\u9631"
        }, 
        {
            "location": "/getting_started/trap/#keras", 
            "text": "\u8fd9\u91cc\u5f52\u7eb3\u4e86Keras\u4f7f\u7528\u8fc7\u7a0b\u4e2d\u7684\u4e00\u4e9b\u5e38\u89c1\u9677\u9631\u548c\u89e3\u51b3\u65b9\u6cd5\uff0c\u5982\u679c\u4f60\u7684\u6a21\u578b\u600e\u4e48\u8c03\u90fd\u641e\u4e0d\u5bf9\uff0c\u6216\u8bb8\u4f60\u6709\u5fc5\u8981\u770b\u770b\u662f\u4e0d\u662f\u6389\u8fdb\u4e86\u54ea\u4e2a\u730e\u4eba\u7684\u9677\u9631\uff0c\u6210\u4e3a\u4e86\u4e00\u53ea\u55f7\u55f7\u5f85\u5bb0\uff08\uff1f\uff09\u7684\u730e\u7269  Keras\u9677\u9631\u4e0d\u591a\uff0c\u6211\u4eec\u4fdd\u6301\u66f4\u65b0\uff0c\u5e0c\u671b\u80fd\u505a\u4e00\u4e2a\u9677\u9631\u5927\u5168  \u5185\u6709\u6076\u72ac\uff0c\u5c0f\u5fc3\u54df", 
            "title": "Keras\u4f7f\u7528\u9677\u9631"
        }, 
        {
            "location": "/getting_started/trap/#tfth", 
            "text": "Keras\u63d0\u4f9b\u4e86\u4e24\u5957\u540e\u7aef\uff0cTheano\u548cTensorflow\uff0c\u8fd9\u662f\u4e00\u4ef6\u5e78\u798f\u7684\u4e8b\uff0c\u5c31\u50cf\u624b\u4e2d\u62ff\u7740\u9992\u5934\uff0c\u60f3\u8638\u7ea2\u7cd6\u8638\u7ea2\u7cd6\uff0c\u60f3\u8638\u767d\u7cd6\u8638\u767d\u7cd6  \u5982\u679c\u4f60\u4ece\u65e0\u5230\u6709\u642d\u5efa\u81ea\u5df1\u7684\u4e00\u5957\u7f51\u7edc\uff0c\u5219\u5927\u53ef\u653e\u5fc3\u3002\u4f46\u5982\u679c\u4f60\u60f3\u4f7f\u7528\u4e00\u4e2a\u5df2\u6709\u7f51\u7edc\uff0c\u6216\u628a\u4e00\u4e2a\u7528th/tf\n\u8bad\u7ec3\u7684\u7f51\u7edc\u4ee5\u53e6\u4e00\u79cd\u540e\u7aef\u5e94\u7528\uff0c\u5728\u8f7d\u5165\u7684\u65f6\u5019\u4f60\u5c31\u5e94\u8be5\u7279\u522b\u5c0f\u5fc3\u4e86\u3002  \u5377\u79ef\u6838\u4e0e\u6240\u4f7f\u7528\u7684\u540e\u7aef\u4e0d\u5339\u914d\uff0c\u4e0d\u4f1a\u62a5\u4efb\u4f55\u9519\u8bef\uff0c\u56e0\u4e3a\u5b83\u4eec\u7684shape\u662f\u5b8c\u5168\u4e00\u81f4\u7684\uff0c\u6ca1\u6709\u65b9\u6cd5\u80fd\u591f\u68c0\u6d4b\u51fa\u8fd9\u79cd\u9519\u8bef\u3002  \u5728\u4f7f\u7528\u9884\u8bad\u7ec3\u6a21\u578b\u65f6\uff0c\u4e00\u4e2a\u5efa\u8bae\u662f\u9996\u5148\u627e\u4e00\u4e9b\u6d4b\u8bd5\u6837\u672c\uff0c\u770b\u770b\u6a21\u578b\u7684\u8868\u73b0\u662f\u5426\u4e0e\u9884\u8ba1\u7684\u4e00\u81f4\u3002  \u5982\u9700\u5bf9\u5377\u79ef\u6838\u8fdb\u884c\u8f6c\u6362\uff0c\u53ef\u4ee5\u4f7f\u7528utils.np_utils.kernel_convert\uff0c\u6216\u4f7f\u7528utils.layer_utils.convert_all_kernels_in_model\u6765\u5bf9\u6a21\u578b\u7684\u6240\u6709\u5377\u79ef\u6838\u8fdb\u884c\u8f6c\u6362", 
            "title": "TF\u5377\u79ef\u6838\u4e0eTH\u5377\u79ef\u6838"
        }, 
        {
            "location": "/getting_started/trap/#bn", 
            "text": "\u5982\u679c\u4f60\u4e0d\u77e5\u9053\u4ece\u54ea\u91cc\u6dd8\u6765\u4e00\u4e2a\u9884\u8bad\u7ec3\u597d\u7684BN\u5c42\uff0c\u60f3\u628a\u5b83\u7684\u6743\u91cd\u8f7d\u5165\u5230Keras\u4e2d\uff0c\u8981\u5c0f\u5fc3\u53c2\u6570\u7684\u8f7d\u5165\u987a\u5e8f\u3002  \u4e00\u4e2a\u5178\u578b\u7684\u4f8b\u5b50\u662f\uff0c\u5c06caffe\u7684BN\u5c42\u53c2\u6570\u8f7d\u5165Keras\u4e2d\uff0ccaffe\u7684BN\u7531\u4e24\u90e8\u5206\u6784\u6210\uff0cbn\u5c42\u7684\u53c2\u6570\u662fmean\uff0cstd\uff0cscale\u5c42\u7684\u53c2\u6570\u662fgamma\uff0cbeta  \u6309\u7167BN\u7684\u6587\u7ae0\u987a\u5e8f\uff0c\u4f3c\u4e4e\u8f7d\u5165Keras BN\u5c42\u7684\u53c2\u6570\u5e94\u8be5\u662f[mean, std, gamma, beta]  \u7136\u800c\u4e0d\u662f\u7684\uff0cKeras\u7684BN\u5c42\u53c2\u6570\u987a\u5e8f\u5e94\u8be5\u662f[gamma, beta, mean, std]\uff0c\u8fd9\u662f\u56e0\u4e3agamma\u548cbeta\u662f\u53ef\u8bad\u7ec3\u7684\u53c2\u6570\uff0c\u800cmean\u548cstd\u4e0d\u662f  Keras\u7684\u53ef\u8bad\u7ec3\u53c2\u6570\u5728\u524d\uff0c\u4e0d\u53ef\u8bad\u7ec3\u53c2\u6570\u5728\u540e  \u9519\u8bef\u7684\u6743\u91cd\u987a\u5e8f\u4e0d\u4f1a\u5f15\u8d77\u4efb\u4f55\u62a5\u9519\uff0c\u56e0\u4e3a\u5b83\u4eec\u7684shape\u5b8c\u5168\u76f8\u540c", 
            "title": "\u5411BN\u5c42\u4e2d\u8f7d\u5165\u6743\u91cd"
        }, 
        {
            "location": "/getting_started/trap/#shufflevalidation_split", 
            "text": "\u6a21\u578b\u7684fit\u51fd\u6570\u6709\u4e24\u4e2a\u53c2\u6570\uff0cshuffle\u7528\u4e8e\u5c06\u6570\u636e\u6253\u4e71\uff0cvalidation_split\u7528\u4e8e\u5728\u6ca1\u6709\u63d0\u4f9b\u9a8c\u8bc1\u96c6\u7684\u65f6\u5019\uff0c\u6309\u4e00\u5b9a\u6bd4\u4f8b\u4ece\u8bad\u7ec3\u96c6\u4e2d\u53d6\u51fa\u4e00\u90e8\u5206\u4f5c\u4e3a\u9a8c\u8bc1\u96c6  \u8fd9\u91cc\u6709\u4e2a\u9677\u9631\u662f\uff0c\u7a0b\u5e8f\u662f\u5148\u6267\u884cvalidation_split\uff0c\u518d\u6267\u884cshuffle\u7684\uff0c\u6240\u4ee5\u4f1a\u51fa\u73b0\u8fd9\u79cd\u60c5\u51b5\uff1a  \u5047\u5982\u4f60\u7684\u8bad\u7ec3\u96c6\u662f\u6709\u5e8f\u7684\uff0c\u6bd4\u65b9\u8bf4\u6b63\u6837\u672c\u5728\u524d\u8d1f\u6837\u672c\u5728\u540e\uff0c\u53c8\u8bbe\u7f6e\u4e86validation_split\uff0c\u90a3\u4e48\u4f60\u7684\u9a8c\u8bc1\u96c6\u4e2d\u5f88\u53ef\u80fd\u5c06\u5168\u90e8\u662f\u8d1f\u6837\u672c  \u540c\u6837\u7684\uff0c\u8fd9\u4e2a\u4e1c\u897f\u4e0d\u4f1a\u6709\u4efb\u4f55\u9519\u8bef\u62a5\u51fa\u6765\uff0c\u56e0\u4e3aKeras\u4e0d\u53ef\u80fd\u77e5\u9053\u4f60\u7684\u6570\u636e\u6709\u6ca1\u6709\u7ecf\u8fc7shuffle\uff0c\u4fdd\u9669\u8d77\u89c1\u5982\u679c\u4f60\u7684\u6570\u636e\u662f\u6ca1shuffle\u8fc7\u7684\uff0c\u6700\u597d\u624b\u52a8shuffle\u4e00\u4e0b", 
            "title": "shuffle\u548cvalidation_split\u7684\u987a\u5e8f"
        }, 
        {
            "location": "/getting_started/trap/#merge-merge", 
            "text": "Keras\u6709\u4e24\u4e2a\u5f88\u7c7b\u4f3c\u7684\u7528\u4e8e\u5f20\u91cf\u878d\u5408\u7684\u5de5\u5177\uff0c\u5728\u8fd9\u91cc\u52a0\u4ee5\u8fa8\u6790\u3002  merge\u662f\u4e00\u4e2a\u51fd\u6570\uff0c\u63a5\u53d7\u4e00\u4e2atensor\u5217\u8868\uff0c\u5e76\u5c06\u5217\u8868\u4e2d\u7684tensor\u6309\u7167\u7ed9\u5b9a\u7684\u65b9\u5f0f\u878d\u5408\u5728\u4e00\u8d77\u5f62\u6210\u8f93\u51fa\uff0c\u591a\u7528\u4e8e\u4ee5Model\u4f5c\u4e3a\u6a21\u578b\u7684\u60c5\u51b5  Merge\u662f\u4e00\u4e2a\u5c42\u5bf9\u8c61\uff0c\u5b83\u63a5\u6536\u4e00\u4e2a\u5c42\u5bf9\u8c61\u7684\u5217\u8868\uff0c\u5e76\u6309\u7167\u7ed9\u5b9a\u7684\u65b9\u5f0f\u5c06\u5b83\u4eec\u7684\u8f93\u51fatensor\u878d\u5408\u8d77\u6765\u3002\u5178\u578b\u7684\u4f7f\u7528\u573a\u666f\u662f\u5728Sequential\u4e2d\u5904\u7406\u591a\u8f93\u5165\u7684\u60c5\u51b5", 
            "title": "merge \u548c Merge"
        }, 
        {
            "location": "/getting_started/trap/#_1", 
            "text": "\u5982\u679c\u4f60\u5728\u4f7f\u7528Keras\u4e2d\u9047\u5230\u96be\u4ee5\u5bdf\u89c9\u7684\u9677\u9631\uff0c\u8bf7\u53d1\u4fe1\u5230moyan_work@foxmail.com\u8bf4\u660e~\u8d60\u4eba\u73ab\u7470\uff0c\u624b\u6709\u4f59\u9999\uff0c\u524d\u4eba\u8e29\u5751\uff0c\u540e\u4eba\u6cbe\u5149\uff0c\u6709\u9053\u662f\u6211\u4e0d\u5165\u5730\u72f1\u8c01\u5165\u5730\u72f1\uff0c\u613f\u5404\u4f4dKeras\u4f7f\u7528\u8005\u79ef\u6781\u8d21\u732eKeras\u9677\u9631\u3002\u8001\u89c4\u77e9\uff0c\u9677\u9631\u8d21\u732e\u8005\u5c06\u88ab\u5217\u5165\u81f4\u8c22\u4e00\u680f", 
            "title": "\u672a\u5b8c\u5f85\u7eed"
        }, 
        {
            "location": "/getting_started/examples/", 
            "text": "Keras \u793a\u4f8b\u7a0b\u5e8f\n\n\nKeras\u793a\u4f8b\u7a0b\u5e8f\n\n\n\n\n\n\naddition_rnn.py: \u5e8f\u5217\u5230\u5e8f\u5217\u5b66\u4e60, \u5b9e\u73b0\u4e24\u4e2a\u6570\u7684\u52a0\u6cd5\n\n\n\n\n\n\nantirectifier.py: \u5c55\u793a\u4e86\u5982\u4f55\u5728Keras\u4e2d\u5b9a\u5236\u81ea\u5df1\u7684\u5c42\n\n\n\n\n\n\nbabi_memnn.py: \u5728bAbI\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u4e00\u4e2a\u8bb0\u5fc6\u7f51\u7edc,\u7528\u4e8e\u9605\u8bfb\u7406\u89e3\n\n\n\n\n\n\nbabi_rnn.py: \u5728bAbI\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u4e00\u4e2a\u5faa\u73af\u7f51\u7edc,\u7528\u4e8e\u9605\u8bfb\u7406\u89e3\n\n\n\n\n\n\ncifar10_cnn.py: \u5728CIFAR10\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u4e00\u4e2a\u7b80\u5355\u7684\u6df1\u5ea6CNN\u7f51\u7edc,\u7528\u4e8e\u5c0f\u56fe\u7247\u8bc6\u522b\n\n\n\n\n\n\nconv_filter_visualization.py: \u901a\u8fc7\u5728\u8f93\u5165\u7a7a\u95f4\u4e0a\u68af\u5ea6\u4e0a\u5347\u53ef\u89c6\u5316VGG16\u7684\u6ee4\u6ce2\u5668\n\n\n\n\n\n\nconv_lstm.py: \u5c55\u793a\u4e86\u4e00\u4e2a\u5377\u79efLSTM\u7f51\u7edc\u7684\u5e94\u7528\n\n\n\n\n\n\ndeep_dream.py: Google DeepDream\u7684Keras\u5b9e\u73b0\n\n\n\n\n\n\nimage_ocr.py:\u8bad\u7ec3\u4e86\u4e00\u4e2a\u5377\u79ef+\u5faa\u73af\u7f51\u7edc+CTC logloss\u6765\u8fdb\u884cOCR\n\n\n\n\n\n\nimdb_bidirectional_lstm.py: \u5728IMDB\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u4e00\u4e2a\u53cc\u5411LSTM\u7f51\u7edc,\u7528\u4e8e\u60c5\u611f\u5206\u7c7b.\n\n\n\n\n\n\nimdb_cnn.py: \u5c55\u793a\u4e86\u5982\u4f55\u5728\u6587\u672c\u5206\u7c7b\u4e0a\u5982\u4f55\u4f7f\u7528Covolution1D\n\n\n\n\n\n\nimdb_cnn_lstm.py: \u8bad\u7ec3\u4e86\u4e00\u4e2a\u6808\u5f0f\u7684\u5377\u79ef\u7f51\u7edc+\u5faa\u73af\u7f51\u7edc\u8fdb\u884cIMDB\u60c5\u611f\u5206\u7c7b.\n\n\n\n\n\n\nimdb_fasttext.py: \u8bad\u7ec3\u4e86\u4e00\u4e2aFastText\u6a21\u578b\u7528\u4e8eIMDB\u60c5\u611f\u5206\u7c7b\n\n\n\n\n\n\nimdb_lstm.py: \u8bad\u7ec3\u4e86\u4e00\u4e2aLSTM\u7f51\u7edc\u7528\u4e8eIMDB\u60c5\u611f\u5206\u7c7b.\n\n\n\n\n\n\nlstm_benchmark.py: \u5728IMDB\u60c5\u611f\u5206\u7c7b\u4e0a\u6bd4\u8f83\u4e86LSTM\u7684\u4e0d\u540c\u5b9e\u73b0\u7684\u6027\u80fd\n\n\n\n\n\n\nlstm_text_generation.py: \u4ece\u5c3c\u91c7\u7684\u4f5c\u54c1\u4e2d\u751f\u6210\u6587\u672c\n\n\n\n\n\n\nmnist_acgan.py\uff1aAC-GAN(Auxiliary Classifier GAN)\u5b9e\u73b0\u7684\u793a\u4f8b\n\n\n\n\n\n\nmnist_cnn.py: \u8bad\u7ec3\u4e00\u4e2a\u7528\u4e8emnist\u6570\u636e\u96c6\u8bc6\u522b\u7684\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\n\n\n\n\n\n\nmnist_hierarchical_rnn.py: \u8bad\u7ec3\u4e86\u4e00\u4e2aHRNN\u7f51\u7edc\u7528\u4e8eMNIST\u6570\u5b57\u8bc6\u522b\n\n\n\n\n\n\nmnist_irnn.py: \u91cd\u73b0\u4e86\u57fa\u4e8e\u9010\u50cf\u7d20\u70b9\u5e8f\u5217\u7684IRNN\u5b9e\u9a8c,\u6587\u7ae0\u89c1Le et al. \"A Simple Way to Initialize Recurrent Networks of Rectified Linear Units\"\n\n\n\n\n\n\nmnist_mlp.py: \u8bad\u7ec3\u4e86\u4e00\u4e2a\u7b80\u5355\u7684\u591a\u5c42\u611f\u77e5\u5668\u7528\u4e8eMNIST\u5206\u7c7b\n\n\n\n\n\n\nmnist_net2net.py: \u5728mnist\u4e0a\u91cd\u73b0\u4e86\u6587\u7ae0\u4e2d\u7684Net2Net\u5b9e\u9a8c,\u6587\u7ae0\u4e3a\"Net2Net: Accelerating Learning via Knowledge Transfer\".\n\n\n\n\n\n\nmnist_siamese_graph.py:\u57fa\u4e8eMNIST\u8bad\u7ec3\u4e86\u4e00\u4e2a\u591a\u5c42\u611f\u77e5\u5668\u7684Siamese\u7f51\u7edc\n\n\n\n\n\n\nmnist_sklearn_wrapper.py: \u5c55\u793a\u4e86\u5982\u4f55\u4f7f\u7528sklearn\u5305\u88c5\u5668\n\n\n\n\n\n\nmnist_swwae.py: \u57fa\u4e8e\u6b8b\u5dee\u7f51\u7edc\u548cMNIST\u8bad\u7ec3\u4e86\u4e00\u4e2a\u6808\u5f0f\u7684What-Where\u81ea\u52a8\u7f16\u7801\u5668\n\n\n\n\n\n\nmnist_transfer_cnn.py: \u8fc1\u79fb\u5b66\u4e60\u7684\u5c0f\u4f8b\u5b50\n\n\n\n\n\n\nneural_doodle.py:\u795e\u7ecf\u7f51\u7edc\u7ed8\u753b\n\n\n\n\n\n\nneural_style_transfer.py: \u56fe\u50cf\u98ce\u683c\u8f6c\u79fb\n\n\n\n\n\n\npretrained_word_embeddings.py: \u5c06GloVe\u5d4c\u5165\u5c42\u8f7d\u5165\u56fa\u5316\u7684Keras Embedding\u5c42\u4e2d, \u5e76\u7528\u4ee5\u5728\u65b0\u95fb\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u6587\u672c\u5206\u7c7b\u6a21\u578b\n\n\n\n\n\n\nreuters_mlp.py: \u8bad\u7ec3\u5e76\u8bc4\u4f30\u4e00\u4e2a\u7b80\u5355\u7684\u591a\u5c42\u611f\u77e5\u5668\u8fdb\u884c\u8def\u900f\u793e\u65b0\u95fb\u4e3b\u9898\u5206\u7c7b\n\n\n\n\n\n\nstateful_lstm.py: \u5c55\u793a\u4e86\u5982\u4f55\u4f7f\u7528\u72b6\u6001RNN\u5bf9\u957f\u5e8f\u5217\u8fdb\u884c\u5efa\u6a21\n\n\n\n\n\n\nvariational_autoencoder.py: \u5c55\u793a\u4e86\u5982\u4f55\u642d\u5efa\u53d8\u5206\u7f16\u7801\u5668\n\n\n\n\n\n\nvariational_autoencoder_deconv.py Demonstrates how to build a variational autoencoder with Keras using deconvolution layers.", 
            "title": "Keras\u793a\u4f8b\u5217\u8868"
        }, 
        {
            "location": "/getting_started/examples/#keras", 
            "text": "", 
            "title": "Keras \u793a\u4f8b\u7a0b\u5e8f"
        }, 
        {
            "location": "/getting_started/examples/#keras_1", 
            "text": "addition_rnn.py: \u5e8f\u5217\u5230\u5e8f\u5217\u5b66\u4e60, \u5b9e\u73b0\u4e24\u4e2a\u6570\u7684\u52a0\u6cd5    antirectifier.py: \u5c55\u793a\u4e86\u5982\u4f55\u5728Keras\u4e2d\u5b9a\u5236\u81ea\u5df1\u7684\u5c42    babi_memnn.py: \u5728bAbI\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u4e00\u4e2a\u8bb0\u5fc6\u7f51\u7edc,\u7528\u4e8e\u9605\u8bfb\u7406\u89e3    babi_rnn.py: \u5728bAbI\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u4e00\u4e2a\u5faa\u73af\u7f51\u7edc,\u7528\u4e8e\u9605\u8bfb\u7406\u89e3    cifar10_cnn.py: \u5728CIFAR10\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u4e00\u4e2a\u7b80\u5355\u7684\u6df1\u5ea6CNN\u7f51\u7edc,\u7528\u4e8e\u5c0f\u56fe\u7247\u8bc6\u522b    conv_filter_visualization.py: \u901a\u8fc7\u5728\u8f93\u5165\u7a7a\u95f4\u4e0a\u68af\u5ea6\u4e0a\u5347\u53ef\u89c6\u5316VGG16\u7684\u6ee4\u6ce2\u5668    conv_lstm.py: \u5c55\u793a\u4e86\u4e00\u4e2a\u5377\u79efLSTM\u7f51\u7edc\u7684\u5e94\u7528    deep_dream.py: Google DeepDream\u7684Keras\u5b9e\u73b0    image_ocr.py:\u8bad\u7ec3\u4e86\u4e00\u4e2a\u5377\u79ef+\u5faa\u73af\u7f51\u7edc+CTC logloss\u6765\u8fdb\u884cOCR    imdb_bidirectional_lstm.py: \u5728IMDB\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u4e00\u4e2a\u53cc\u5411LSTM\u7f51\u7edc,\u7528\u4e8e\u60c5\u611f\u5206\u7c7b.    imdb_cnn.py: \u5c55\u793a\u4e86\u5982\u4f55\u5728\u6587\u672c\u5206\u7c7b\u4e0a\u5982\u4f55\u4f7f\u7528Covolution1D    imdb_cnn_lstm.py: \u8bad\u7ec3\u4e86\u4e00\u4e2a\u6808\u5f0f\u7684\u5377\u79ef\u7f51\u7edc+\u5faa\u73af\u7f51\u7edc\u8fdb\u884cIMDB\u60c5\u611f\u5206\u7c7b.    imdb_fasttext.py: \u8bad\u7ec3\u4e86\u4e00\u4e2aFastText\u6a21\u578b\u7528\u4e8eIMDB\u60c5\u611f\u5206\u7c7b    imdb_lstm.py: \u8bad\u7ec3\u4e86\u4e00\u4e2aLSTM\u7f51\u7edc\u7528\u4e8eIMDB\u60c5\u611f\u5206\u7c7b.    lstm_benchmark.py: \u5728IMDB\u60c5\u611f\u5206\u7c7b\u4e0a\u6bd4\u8f83\u4e86LSTM\u7684\u4e0d\u540c\u5b9e\u73b0\u7684\u6027\u80fd    lstm_text_generation.py: \u4ece\u5c3c\u91c7\u7684\u4f5c\u54c1\u4e2d\u751f\u6210\u6587\u672c    mnist_acgan.py\uff1aAC-GAN(Auxiliary Classifier GAN)\u5b9e\u73b0\u7684\u793a\u4f8b    mnist_cnn.py: \u8bad\u7ec3\u4e00\u4e2a\u7528\u4e8emnist\u6570\u636e\u96c6\u8bc6\u522b\u7684\u5377\u79ef\u795e\u7ecf\u7f51\u7edc    mnist_hierarchical_rnn.py: \u8bad\u7ec3\u4e86\u4e00\u4e2aHRNN\u7f51\u7edc\u7528\u4e8eMNIST\u6570\u5b57\u8bc6\u522b    mnist_irnn.py: \u91cd\u73b0\u4e86\u57fa\u4e8e\u9010\u50cf\u7d20\u70b9\u5e8f\u5217\u7684IRNN\u5b9e\u9a8c,\u6587\u7ae0\u89c1Le et al. \"A Simple Way to Initialize Recurrent Networks of Rectified Linear Units\"    mnist_mlp.py: \u8bad\u7ec3\u4e86\u4e00\u4e2a\u7b80\u5355\u7684\u591a\u5c42\u611f\u77e5\u5668\u7528\u4e8eMNIST\u5206\u7c7b    mnist_net2net.py: \u5728mnist\u4e0a\u91cd\u73b0\u4e86\u6587\u7ae0\u4e2d\u7684Net2Net\u5b9e\u9a8c,\u6587\u7ae0\u4e3a\"Net2Net: Accelerating Learning via Knowledge Transfer\".    mnist_siamese_graph.py:\u57fa\u4e8eMNIST\u8bad\u7ec3\u4e86\u4e00\u4e2a\u591a\u5c42\u611f\u77e5\u5668\u7684Siamese\u7f51\u7edc    mnist_sklearn_wrapper.py: \u5c55\u793a\u4e86\u5982\u4f55\u4f7f\u7528sklearn\u5305\u88c5\u5668    mnist_swwae.py: \u57fa\u4e8e\u6b8b\u5dee\u7f51\u7edc\u548cMNIST\u8bad\u7ec3\u4e86\u4e00\u4e2a\u6808\u5f0f\u7684What-Where\u81ea\u52a8\u7f16\u7801\u5668    mnist_transfer_cnn.py: \u8fc1\u79fb\u5b66\u4e60\u7684\u5c0f\u4f8b\u5b50    neural_doodle.py:\u795e\u7ecf\u7f51\u7edc\u7ed8\u753b    neural_style_transfer.py: \u56fe\u50cf\u98ce\u683c\u8f6c\u79fb    pretrained_word_embeddings.py: \u5c06GloVe\u5d4c\u5165\u5c42\u8f7d\u5165\u56fa\u5316\u7684Keras Embedding\u5c42\u4e2d, \u5e76\u7528\u4ee5\u5728\u65b0\u95fb\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u6587\u672c\u5206\u7c7b\u6a21\u578b    reuters_mlp.py: \u8bad\u7ec3\u5e76\u8bc4\u4f30\u4e00\u4e2a\u7b80\u5355\u7684\u591a\u5c42\u611f\u77e5\u5668\u8fdb\u884c\u8def\u900f\u793e\u65b0\u95fb\u4e3b\u9898\u5206\u7c7b    stateful_lstm.py: \u5c55\u793a\u4e86\u5982\u4f55\u4f7f\u7528\u72b6\u6001RNN\u5bf9\u957f\u5e8f\u5217\u8fdb\u884c\u5efa\u6a21    variational_autoencoder.py: \u5c55\u793a\u4e86\u5982\u4f55\u642d\u5efa\u53d8\u5206\u7f16\u7801\u5668    variational_autoencoder_deconv.py Demonstrates how to build a variational autoencoder with Keras using deconvolution layers.", 
            "title": "Keras\u793a\u4f8b\u7a0b\u5e8f"
        }, 
        {
            "location": "/models/about_model/", 
            "text": "\u5173\u4e8eKeras\u6a21\u578b\n\n\nKeras\u6709\u4e24\u79cd\u7c7b\u578b\u7684\u6a21\u578b\uff0c\n\u987a\u5e8f\u6a21\u578b\uff08Sequential\uff09\n\u548c\n\u6cdb\u578b\u6a21\u578b\uff08Model\uff09\n\n\n\u4e24\u7c7b\u6a21\u578b\u6709\u4e00\u4e9b\u65b9\u6cd5\u662f\u76f8\u540c\u7684\uff1a\n\n\n\n\n\n\nmodel.summary()\n\uff1a\u6253\u5370\u51fa\u6a21\u578b\u6982\u51b5\n\n\n\n\n\n\nmodel.get_config()\n:\u8fd4\u56de\u5305\u542b\u6a21\u578b\u914d\u7f6e\u4fe1\u606f\u7684Python\u5b57\u5178\u3002\u6a21\u578b\u4e5f\u53ef\u4ee5\u4ece\u5b83\u7684config\u4fe1\u606f\u4e2d\u91cd\u6784\u56de\u53bb\n\n\n\n\n\n\nconfig = model.get_config()\nmodel = Model.from_config(config)\n# or, for Sequential\nmodel = Sequential.from_config(config)\n\n\n\n\n\n\n\n\nmodel.get_weights()\n\uff1a\u8fd4\u56de\u6a21\u578b\u6743\u91cd\u5f20\u91cf\u7684\u5217\u8868\uff0c\u7c7b\u578b\u4e3anumpy array\n\n\n\n\n\n\nmodel.set_weights()\n\uff1a\u4ecenumpy array\u91cc\u5c06\u6743\u91cd\u8f7d\u5165\u7ed9\u6a21\u578b\uff0c\u8981\u6c42\u6570\u7ec4\u5177\u6709\u4e0e\nmodel.get_weights()\n\u76f8\u540c\u7684\u5f62\u72b6\u3002\n\n\n\n\n\n\nmodel.to_json\n\uff1a\u8fd4\u56de\u4ee3\u8868\u6a21\u578b\u7684JSON\u5b57\u7b26\u4e32\uff0c\u4ec5\u5305\u542b\u7f51\u7edc\u7ed3\u6784\uff0c\u4e0d\u5305\u542b\u6743\u503c\u3002\u53ef\u4ee5\u4eceJSON\u5b57\u7b26\u4e32\u4e2d\u91cd\u6784\u539f\u6a21\u578b\uff1a\n\n\n\n\n\n\nfrom models import model_from_json\n\njson_string = model.to_json()\nmodel = model_from_json(json_string)\n\n\n\n\n\n\nmodel.to_yaml\n\uff1a\u4e0e\nmodel.to_json\n\u7c7b\u4f3c\uff0c\u540c\u6837\u53ef\u4ee5\u4ece\u4ea7\u751f\u7684YAML\u5b57\u7b26\u4e32\u4e2d\u91cd\u6784\u6a21\u578b\n\n\n\n\nfrom models import model_from_yaml\n\nyaml_string = model.to_yaml()\nmodel = model_from_yaml(yaml_string)\n\n\n\n\n\n\n\n\nmodel.save_weights(filepath)\n\uff1a\u5c06\u6a21\u578b\u6743\u91cd\u4fdd\u5b58\u5230\u6307\u5b9a\u8def\u5f84\uff0c\u6587\u4ef6\u7c7b\u578b\u662fHDF5\uff08\u540e\u7f00\u662f.h5\uff09\n\n\n\n\n\n\nmodel.load_weights(filepath, by_name=False)\n\uff1a\u4eceHDF5\u6587\u4ef6\u4e2d\u52a0\u8f7d\u6743\u91cd\u5230\u5f53\u524d\u6a21\u578b\u4e2d, \u9ed8\u8ba4\u60c5\u51b5\u4e0b\u6a21\u578b\u7684\u7ed3\u6784\u5c06\u4fdd\u6301\u4e0d\u53d8\u3002\u5982\u679c\u60f3\u5c06\u6743\u91cd\u8f7d\u5165\u4e0d\u540c\u7684\u6a21\u578b\uff08\u6709\u4e9b\u5c42\u76f8\u540c\uff09\u4e2d\uff0c\u5219\u8bbe\u7f6e\nby_name=True\n\uff0c\u53ea\u6709\u540d\u5b57\u5339\u914d\u7684\u5c42\u624d\u4f1a\u8f7d\u5165\u6743\u91cd", 
            "title": "\u5173\u4e8eKeras\u6a21\u578b"
        }, 
        {
            "location": "/models/about_model/#keras", 
            "text": "Keras\u6709\u4e24\u79cd\u7c7b\u578b\u7684\u6a21\u578b\uff0c \u987a\u5e8f\u6a21\u578b\uff08Sequential\uff09 \u548c \u6cdb\u578b\u6a21\u578b\uff08Model\uff09  \u4e24\u7c7b\u6a21\u578b\u6709\u4e00\u4e9b\u65b9\u6cd5\u662f\u76f8\u540c\u7684\uff1a    model.summary() \uff1a\u6253\u5370\u51fa\u6a21\u578b\u6982\u51b5    model.get_config() :\u8fd4\u56de\u5305\u542b\u6a21\u578b\u914d\u7f6e\u4fe1\u606f\u7684Python\u5b57\u5178\u3002\u6a21\u578b\u4e5f\u53ef\u4ee5\u4ece\u5b83\u7684config\u4fe1\u606f\u4e2d\u91cd\u6784\u56de\u53bb    config = model.get_config()\nmodel = Model.from_config(config)\n# or, for Sequential\nmodel = Sequential.from_config(config)    model.get_weights() \uff1a\u8fd4\u56de\u6a21\u578b\u6743\u91cd\u5f20\u91cf\u7684\u5217\u8868\uff0c\u7c7b\u578b\u4e3anumpy array    model.set_weights() \uff1a\u4ecenumpy array\u91cc\u5c06\u6743\u91cd\u8f7d\u5165\u7ed9\u6a21\u578b\uff0c\u8981\u6c42\u6570\u7ec4\u5177\u6709\u4e0e model.get_weights() \u76f8\u540c\u7684\u5f62\u72b6\u3002    model.to_json \uff1a\u8fd4\u56de\u4ee3\u8868\u6a21\u578b\u7684JSON\u5b57\u7b26\u4e32\uff0c\u4ec5\u5305\u542b\u7f51\u7edc\u7ed3\u6784\uff0c\u4e0d\u5305\u542b\u6743\u503c\u3002\u53ef\u4ee5\u4eceJSON\u5b57\u7b26\u4e32\u4e2d\u91cd\u6784\u539f\u6a21\u578b\uff1a    from models import model_from_json\n\njson_string = model.to_json()\nmodel = model_from_json(json_string)   model.to_yaml \uff1a\u4e0e model.to_json \u7c7b\u4f3c\uff0c\u540c\u6837\u53ef\u4ee5\u4ece\u4ea7\u751f\u7684YAML\u5b57\u7b26\u4e32\u4e2d\u91cd\u6784\u6a21\u578b   from models import model_from_yaml\n\nyaml_string = model.to_yaml()\nmodel = model_from_yaml(yaml_string)    model.save_weights(filepath) \uff1a\u5c06\u6a21\u578b\u6743\u91cd\u4fdd\u5b58\u5230\u6307\u5b9a\u8def\u5f84\uff0c\u6587\u4ef6\u7c7b\u578b\u662fHDF5\uff08\u540e\u7f00\u662f.h5\uff09    model.load_weights(filepath, by_name=False) \uff1a\u4eceHDF5\u6587\u4ef6\u4e2d\u52a0\u8f7d\u6743\u91cd\u5230\u5f53\u524d\u6a21\u578b\u4e2d, \u9ed8\u8ba4\u60c5\u51b5\u4e0b\u6a21\u578b\u7684\u7ed3\u6784\u5c06\u4fdd\u6301\u4e0d\u53d8\u3002\u5982\u679c\u60f3\u5c06\u6743\u91cd\u8f7d\u5165\u4e0d\u540c\u7684\u6a21\u578b\uff08\u6709\u4e9b\u5c42\u76f8\u540c\uff09\u4e2d\uff0c\u5219\u8bbe\u7f6e by_name=True \uff0c\u53ea\u6709\u540d\u5b57\u5339\u914d\u7684\u5c42\u624d\u4f1a\u8f7d\u5165\u6743\u91cd", 
            "title": "\u5173\u4e8eKeras\u6a21\u578b"
        }, 
        {
            "location": "/models/sequential/", 
            "text": "Sequential\u6a21\u578b\u63a5\u53e3\n\n\n\u5982\u679c\u521a\u5f00\u59cb\u5b66\u4e60Sequential\u6a21\u578b\uff0c\u8bf7\u9996\u5148\u79fb\u6b65\n\u8fd9\u91cc\n\u9605\u8bfb\u6587\u6863\n\n\n\u5e38\u7528Sequential\u5c5e\u6027\n\n\n\n\nmodel.layers\n\u662f\u6dfb\u52a0\u5230\u6a21\u578b\u4e0a\u7684\u5c42\u7684list\n\n\n\n\n\n\nSequential\u6a21\u578b\u65b9\u6cd5\n\n\ncompile\n\n\ncompile(self, optimizer, loss, metrics=[], sample_weight_mode=None)\n\n\n\n\n\u7f16\u8bd1\u7528\u6765\u914d\u7f6e\u6a21\u578b\u7684\u5b66\u4e60\u8fc7\u7a0b\uff0c\u5176\u53c2\u6570\u6709\n\n\n\n\n\n\noptimizer\uff1a\u5b57\u7b26\u4e32\uff08\u9884\u5b9a\u4e49\u4f18\u5316\u5668\u540d\uff09\u6216\u4f18\u5316\u5668\u5bf9\u8c61\uff0c\u53c2\u8003\n\u4f18\u5316\u5668\n\n\n\n\n\n\nloss\uff1a\u5b57\u7b26\u4e32\uff08\u9884\u5b9a\u4e49\u635f\u5931\u51fd\u6570\u540d\uff09\u6216\u76ee\u6807\u51fd\u6570\uff0c\u53c2\u8003\n\u76ee\u6807\u51fd\u6570\n\n\n\n\n\n\nmetrics\uff1a\u5217\u8868\uff0c\u5305\u542b\u8bc4\u4f30\u6a21\u578b\u5728\u8bad\u7ec3\u548c\u6d4b\u8bd5\u65f6\u7684\u7f51\u7edc\u6027\u80fd\u7684\u6307\u6807\uff0c\u5178\u578b\u7528\u6cd5\u662f\nmetrics=['accuracy']\n\n\n\n\n\n\nsample_weight_mode\uff1a\u5982\u679c\u4f60\u9700\u8981\u6309\u65f6\u95f4\u6b65\u4e3a\u6837\u672c\u8d4b\u6743\uff082D\u6743\u77e9\u9635\uff09\uff0c\u5c06\u8be5\u503c\u8bbe\u4e3a\u201ctemporal\u201d\u3002\u9ed8\u8ba4\u4e3a\u201cNone\u201d\uff0c\u4ee3\u8868\u6309\u6837\u672c\u8d4b\u6743\uff081D\u6743\uff09\u3002\u5728\u4e0b\u9762\nfit\n\u51fd\u6570\u7684\u89e3\u91ca\u4e2d\u6709\u76f8\u5173\u7684\u53c2\u8003\u5185\u5bb9\u3002\n\n\n\n\n\n\nkwargs\uff1a\u4f7f\u7528TensorFlow\u4f5c\u4e3a\u540e\u7aef\u8bf7\u5ffd\u7565\u8be5\u53c2\u6570\uff0c\u82e5\u4f7f\u7528Theano\u4f5c\u4e3a\u540e\u7aef\uff0ckwargs\u7684\u503c\u5c06\u4f1a\u4f20\u9012\u7ed9 K.function\n\n\n\n\n\n\nmodel = Sequential()\nmodel.add(Dense(32, input_shape=(500,)))\nmodel.add(Dense(10, activation='softmax'))\nmodel.compile(optimizer='rmsprop',\n      loss='categorical_crossentropy',\n      metrics=['accuracy'])\n\n\n\n\nfit\n\n\nfit(self, x, y, batch_size=32, nb_epoch=10, verbose=1, callbacks=[], validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None)\n\n\n\n\n\u672c\u51fd\u6570\u5c06\u6a21\u578b\u8bad\u7ec3\nnb_epoch\n\u8f6e\uff0c\u5176\u53c2\u6570\u6709\uff1a\n\n\n\n\n\n\nx\uff1a\u8f93\u5165\u6570\u636e\u3002\u5982\u679c\u6a21\u578b\u53ea\u6709\u4e00\u4e2a\u8f93\u5165\uff0c\u90a3\u4e48x\u7684\u7c7b\u578b\u662fnumpy array\uff0c\u5982\u679c\u6a21\u578b\u6709\u591a\u4e2a\u8f93\u5165\uff0c\u90a3\u4e48x\u7684\u7c7b\u578b\u5e94\u5f53\u4e3alist\uff0clist\u7684\u5143\u7d20\u662f\u5bf9\u5e94\u4e8e\u5404\u4e2a\u8f93\u5165\u7684numpy array\n\n\n\n\n\n\ny\uff1a\u6807\u7b7e\uff0cnumpy array\n\n\n\n\n\n\nbatch_size\uff1a\u6574\u6570\uff0c\u6307\u5b9a\u8fdb\u884c\u68af\u5ea6\u4e0b\u964d\u65f6\u6bcf\u4e2abatch\u5305\u542b\u7684\u6837\u672c\u6570\u3002\u8bad\u7ec3\u65f6\u4e00\u4e2abatch\u7684\u6837\u672c\u4f1a\u88ab\u8ba1\u7b97\u4e00\u6b21\u68af\u5ea6\u4e0b\u964d\uff0c\u4f7f\u76ee\u6807\u51fd\u6570\u4f18\u5316\u4e00\u6b65\u3002\n\n\n\n\n\n\nnb_epoch\uff1a\u6574\u6570\uff0c\u8bad\u7ec3\u7684\u8f6e\u6570\uff0c\u8bad\u7ec3\u6570\u636e\u5c06\u4f1a\u88ab\u904d\u5386nb_epoch\u6b21\u3002Keras\u4e2dnb\u5f00\u5934\u7684\u53d8\u91cf\u5747\u4e3a\"number of\"\u7684\u610f\u601d\n\n\n\n\n\n\nverbose\uff1a\u65e5\u5fd7\u663e\u793a\uff0c0\u4e3a\u4e0d\u5728\u6807\u51c6\u8f93\u51fa\u6d41\u8f93\u51fa\u65e5\u5fd7\u4fe1\u606f\uff0c1\u4e3a\u8f93\u51fa\u8fdb\u5ea6\u6761\u8bb0\u5f55\uff0c2\u4e3a\u6bcf\u4e2aepoch\u8f93\u51fa\u4e00\u884c\u8bb0\u5f55\n\n\n\n\n\n\ncallbacks\uff1alist\uff0c\u5176\u4e2d\u7684\u5143\u7d20\u662f\nkeras.callbacks.Callback\n\u7684\u5bf9\u8c61\u3002\u8fd9\u4e2alist\u4e2d\u7684\u56de\u8c03\u51fd\u6570\u5c06\u4f1a\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u9002\u5f53\u65f6\u673a\u88ab\u8c03\u7528\uff0c\u53c2\u8003\n\u56de\u8c03\u51fd\u6570\n\n\n\n\n\n\nvalidation_split\uff1a0~1\u4e4b\u95f4\u7684\u6d6e\u70b9\u6570\uff0c\u7528\u6765\u6307\u5b9a\u8bad\u7ec3\u96c6\u7684\u4e00\u5b9a\u6bd4\u4f8b\u6570\u636e\u4f5c\u4e3a\u9a8c\u8bc1\u96c6\u3002\u9a8c\u8bc1\u96c6\u5c06\u4e0d\u53c2\u4e0e\u8bad\u7ec3\uff0c\u5e76\u5728\u6bcf\u4e2aepoch\u7ed3\u675f\u540e\u6d4b\u8bd5\u7684\u6a21\u578b\u7684\u6307\u6807\uff0c\u5982\u635f\u5931\u51fd\u6570\u3001\u7cbe\u786e\u5ea6\u7b49\u3002\n\n\n\n\n\n\nvalidation_data\uff1a\u5f62\u5f0f\u4e3a\uff08X\uff0cy\uff09\u7684tuple\uff0c\u662f\u6307\u5b9a\u7684\u9a8c\u8bc1\u96c6\u3002\u6b64\u53c2\u6570\u5c06\u8986\u76d6validation_spilt\u3002\n\n\n\n\n\n\nshuffle\uff1a\u5e03\u5c14\u503c\u6216\u5b57\u7b26\u4e32\uff0c\u4e00\u822c\u4e3a\u5e03\u5c14\u503c\uff0c\u8868\u793a\u662f\u5426\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u968f\u673a\u6253\u4e71\u8f93\u5165\u6837\u672c\u7684\u987a\u5e8f\u3002\u82e5\u4e3a\u5b57\u7b26\u4e32\u201cbatch\u201d\uff0c\u5219\u662f\u7528\u6765\u5904\u7406HDF5\u6570\u636e\u7684\u7279\u6b8a\u60c5\u51b5\uff0c\u5b83\u5c06\u5728batch\u5185\u90e8\u5c06\u6570\u636e\u6253\u4e71\u3002\n\n\n\n\n\n\nclass_weight\uff1a\u5b57\u5178\uff0c\u5c06\u4e0d\u540c\u7684\u7c7b\u522b\u6620\u5c04\u4e3a\u4e0d\u540c\u7684\u6743\u503c\uff0c\u8be5\u53c2\u6570\u7528\u6765\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u8c03\u6574\u635f\u5931\u51fd\u6570\uff08\u53ea\u80fd\u7528\u4e8e\u8bad\u7ec3\uff09\n\n\n\n\n\n\nsample_weight\uff1a\u6743\u503c\u7684numpy array\uff0c\u7528\u4e8e\u5728\u8bad\u7ec3\u65f6\u8c03\u6574\u635f\u5931\u51fd\u6570\uff08\u4ec5\u7528\u4e8e\u8bad\u7ec3\uff09\u3002\u53ef\u4ee5\u4f20\u9012\u4e00\u4e2a1D\u7684\u4e0e\u6837\u672c\u7b49\u957f\u7684\u5411\u91cf\u7528\u4e8e\u5bf9\u6837\u672c\u8fdb\u884c1\u5bf91\u7684\u52a0\u6743\uff0c\u6216\u8005\u5728\u9762\u5bf9\u65f6\u5e8f\u6570\u636e\u65f6\uff0c\u4f20\u9012\u4e00\u4e2a\u7684\u5f62\u5f0f\u4e3a\uff08samples\uff0csequence_length\uff09\u7684\u77e9\u9635\u6765\u4e3a\u6bcf\u4e2a\u65f6\u95f4\u6b65\u4e0a\u7684\u6837\u672c\u8d4b\u4e0d\u540c\u7684\u6743\u3002\u8fd9\u79cd\u60c5\u51b5\u4e0b\u8bf7\u786e\u5b9a\u5728\u7f16\u8bd1\u6a21\u578b\u65f6\u6dfb\u52a0\u4e86\nsample_weight_mode='temporal'\n\u3002\n\n\n\n\n\n\nfit\n\u51fd\u6570\u8fd4\u56de\u4e00\u4e2a\nHistory\n\u7684\u5bf9\u8c61\uff0c\u5176\nHistory.history\n\u5c5e\u6027\u8bb0\u5f55\u4e86\u635f\u5931\u51fd\u6570\u548c\u5176\u4ed6\u6307\u6807\u7684\u6570\u503c\u968fepoch\u53d8\u5316\u7684\u60c5\u51b5\uff0c\u5982\u679c\u6709\u9a8c\u8bc1\u96c6\u7684\u8bdd\uff0c\u4e5f\u5305\u542b\u4e86\u9a8c\u8bc1\u96c6\u7684\u8fd9\u4e9b\u6307\u6807\u53d8\u5316\u60c5\u51b5\n\n\n\n\n\n\n\n\nevaluate\n\n\n\n\n\n\nevaluate(self, x, y, batch_size=32, verbose=1, sample_weight=None)\n\n\n\n\n\u672c\u51fd\u6570\u6309batch\u8ba1\u7b97\u5728\u67d0\u4e9b\u8f93\u5165\u6570\u636e\u4e0a\u6a21\u578b\u7684\u8bef\u5dee\uff0c\u5176\u53c2\u6570\u6709\uff1a\n\n\n\n\n\n\nx\uff1a\u8f93\u5165\u6570\u636e\uff0c\u4e0e\nfit\n\u4e00\u6837\uff0c\u662fnumpy array\u6216numpy array\u7684list\n\n\n\n\n\n\ny\uff1a\u6807\u7b7e\uff0cnumpy array\n\n\n\n\n\n\nbatch_size\uff1a\u6574\u6570\uff0c\u542b\u4e49\u540c\nfit\n\u7684\u540c\u540d\u53c2\u6570\n\n\n\n\n\n\nverbose\uff1a\u542b\u4e49\u540c\nfit\n\u7684\u540c\u540d\u53c2\u6570\uff0c\u4f46\u53ea\u80fd\u53d60\u62161\n\n\n\n\n\n\nsample_weight\uff1anumpy array\uff0c\u542b\u4e49\u540c\nfit\n\u7684\u540c\u540d\u53c2\u6570\n\n\n\n\n\n\n\u672c\u51fd\u6570\u8fd4\u56de\u4e00\u4e2a\u6d4b\u8bd5\u8bef\u5dee\u7684\u6807\u91cf\u503c\uff08\u5982\u679c\u6a21\u578b\u6ca1\u6709\u5176\u4ed6\u8bc4\u4ef7\u6307\u6807\uff09\uff0c\u6216\u4e00\u4e2a\u6807\u91cf\u7684list\uff08\u5982\u679c\u6a21\u578b\u8fd8\u6709\u5176\u4ed6\u7684\u8bc4\u4ef7\u6307\u6807\uff09\u3002\nmodel.metrics_names\n\u5c06\u7ed9\u51falist\u4e2d\u5404\u4e2a\u503c\u7684\u542b\u4e49\u3002\n\n\n\u5982\u679c\u6ca1\u6709\u7279\u6b8a\u8bf4\u660e\uff0c\u4ee5\u4e0b\u51fd\u6570\u7684\u53c2\u6570\u5747\u4fdd\u6301\u4e0e\nfit\n\u7684\u540c\u540d\u53c2\u6570\u76f8\u540c\u7684\u542b\u4e49\n\n\n\u5982\u679c\u6ca1\u6709\u7279\u6b8a\u8bf4\u660e\uff0c\u4ee5\u4e0b\u51fd\u6570\u7684verbose\u53c2\u6570\uff08\u5982\u679c\u6709\uff09\u5747\u53ea\u80fd\u53d60\u62161\n\n\n\n\npredict\n\n\npredict(self, x, batch_size=32, verbose=0)\n\n\n\n\n\u672c\u51fd\u6570\u6309batch\u83b7\u5f97\u8f93\u5165\u6570\u636e\u5bf9\u5e94\u7684\u8f93\u51fa\uff0c\u5176\u53c2\u6570\u6709\uff1a\n\n\n\u51fd\u6570\u7684\u8fd4\u56de\u503c\u662f\u9884\u6d4b\u503c\u7684numpy array\n\n\n\n\npredict_classes\n\n\npredict_classes(self, x, batch_size=32, verbose=1)\n\n\n\n\n\u672c\u51fd\u6570\u6309batch\u4ea7\u751f\u8f93\u5165\u6570\u636e\u7684\u7c7b\u522b\u9884\u6d4b\u7ed3\u679c\n\n\n\u51fd\u6570\u7684\u8fd4\u56de\u503c\u662f\u7c7b\u522b\u9884\u6d4b\u7ed3\u679c\u7684numpy array\u6216numpy\n\n\n\n\npredict_proba\n\n\npredict_proba(self, x, batch_size=32, verbose=1)\n\n\n\n\n\u672c\u51fd\u6570\u6309batch\u4ea7\u751f\u8f93\u5165\u6570\u636e\u5c5e\u4e8e\u5404\u4e2a\u7c7b\u522b\u7684\u6982\u7387\n\n\n\u51fd\u6570\u7684\u8fd4\u56de\u503c\u662f\u7c7b\u522b\u6982\u7387\u7684numpy array\n\n\n\n\ntrain_on_batch\n\n\ntrain_on_batch(self, x, y, class_weight=None, sample_weight=None)\n\n\n\n\n\u672c\u51fd\u6570\u5728\u4e00\u4e2abatch\u7684\u6570\u636e\u4e0a\u8fdb\u884c\u4e00\u6b21\u53c2\u6570\u66f4\u65b0\n\n\n\u51fd\u6570\u8fd4\u56de\u8bad\u7ec3\u8bef\u5dee\u7684\u6807\u91cf\u503c\u6216\u6807\u91cf\u503c\u7684list\uff0c\u4e0e\nevaluate\n\u7684\u60c5\u5f62\u76f8\u540c\u3002\n\n\n\n\ntest_on_batch\n\n\ntest_on_batch(self, x, y, sample_weight=None)\n\n\n\n\n\u672c\u51fd\u6570\u5728\u4e00\u4e2abatch\u7684\u6837\u672c\u4e0a\u5bf9\u6a21\u578b\u8fdb\u884c\u8bc4\u4f30\n\n\n\u51fd\u6570\u7684\u8fd4\u56de\u4e0e\nevaluate\n\u7684\u60c5\u5f62\u76f8\u540c\n\n\n\n\npredict_on_batch\n\n\npredict_on_batch(self, x)\n\n\n\n\n\u672c\u51fd\u6570\u5728\u4e00\u4e2abatch\u7684\u6837\u672c\u4e0a\u5bf9\u6a21\u578b\u8fdb\u884c\u6d4b\u8bd5\n\n\n\u51fd\u6570\u8fd4\u56de\u6a21\u578b\u5728\u4e00\u4e2abatch\u4e0a\u7684\u9884\u6d4b\u7ed3\u679c\n\n\n\n\nfit_generator\n\n\nfit_generator(self, generator, samples_per_epoch, nb_epoch, verbose=1, callbacks=[], validation_data=None, nb_val_samples=None, class_weight=None, max_q_size=10)\n\n\n\n\n\u5229\u7528Python\u7684\u751f\u6210\u5668\uff0c\u9010\u4e2a\u751f\u6210\u6570\u636e\u7684batch\u5e76\u8fdb\u884c\u8bad\u7ec3\u3002\u751f\u6210\u5668\u4e0e\u6a21\u578b\u5c06\u5e76\u884c\u6267\u884c\u4ee5\u63d0\u9ad8\u6548\u7387\u3002\u4f8b\u5982\uff0c\u8be5\u51fd\u6570\u5141\u8bb8\u6211\u4eec\u5728CPU\u4e0a\u8fdb\u884c\u5b9e\u65f6\u7684\u6570\u636e\u63d0\u5347\uff0c\u540c\u65f6\u5728GPU\u4e0a\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\n\n\n\u51fd\u6570\u7684\u53c2\u6570\u662f\uff1a\n\n\n\n\n\n\ngenerator\uff1a\u751f\u6210\u5668\u51fd\u6570\uff0c\u751f\u6210\u5668\u7684\u8f93\u51fa\u5e94\u8be5\u4e3a\uff1a\n\n\n\n\n\n\n\u4e00\u4e2a\u5f62\u5982\uff08inputs\uff0ctargets\uff09\u7684tuple\n\n\n\n\n\n\n\u4e00\u4e2a\u5f62\u5982\uff08inputs, targets,sample_weight\uff09\u7684tuple\u3002\u6240\u6709\u7684\u8fd4\u56de\u503c\u90fd\u5e94\u8be5\u5305\u542b\u76f8\u540c\u6570\u76ee\u7684\u6837\u672c\u3002\u751f\u6210\u5668\u5c06\u65e0\u9650\u5728\u6570\u636e\u96c6\u4e0a\u5faa\u73af\u3002\u6bcf\u4e2aepoch\u4ee5\u7ecf\u8fc7\u6a21\u578b\u7684\u6837\u672c\u6570\u8fbe\u5230\nsamples_per_epoch\n\u65f6\uff0c\u8bb0\u4e00\u4e2aepoch\u7ed3\u675f\n\n\n\n\n\n\n\n\n\n\nsamples_per_epoch\uff1a\u6574\u6570\uff0c\u5f53\u6a21\u578b\u5904\u7406\u7684\u6837\u672c\u8fbe\u5230\u6b64\u6570\u76ee\u65f6\u8ba1\u4e00\u4e2aepoch\u7ed3\u675f\uff0c\u6267\u884c\u4e0b\u4e00\u4e2aepoch\n\n\n\n\n\n\nverbose\uff1a\u65e5\u5fd7\u663e\u793a\uff0c0\u4e3a\u4e0d\u5728\u6807\u51c6\u8f93\u51fa\u6d41\u8f93\u51fa\u65e5\u5fd7\u4fe1\u606f\uff0c1\u4e3a\u8f93\u51fa\u8fdb\u5ea6\u6761\u8bb0\u5f55\uff0c2\u4e3a\u6bcf\u4e2aepoch\u8f93\u51fa\u4e00\u884c\u8bb0\u5f55\n\n\n\n\n\n\nvalidation_data\uff1a\u5177\u6709\u4ee5\u4e0b\u4e09\u79cd\u5f62\u5f0f\u4e4b\u4e00\n\n\n\n\n\n\n\u751f\u6210\u9a8c\u8bc1\u96c6\u7684\u751f\u6210\u5668\n\n\n\n\n\n\n\u4e00\u4e2a\u5f62\u5982\uff08inputs,targets\uff09\u7684tuple\n\n\n\n\n\n\n\u4e00\u4e2a\u5f62\u5982\uff08inputs,targets\uff0csample_weights\uff09\u7684tuple\n\n\n\n\n\n\n\n\n\n\nnb_val_samples\uff1a\u4ec5\u5f53\nvalidation_data\n\u662f\u751f\u6210\u5668\u65f6\u4f7f\u7528\uff0c\u7528\u4ee5\u9650\u5236\u5728\u6bcf\u4e2aepoch\u7ed3\u675f\u65f6\u7528\u6765\u9a8c\u8bc1\u6a21\u578b\u7684\u9a8c\u8bc1\u96c6\u6837\u672c\u6570\uff0c\u529f\u80fd\u7c7b\u4f3c\u4e8e\nsamples_per_epoch\n\n\n\n\n\n\nmax_q_size\uff1a\u751f\u6210\u5668\u961f\u5217\u7684\u6700\u5927\u5bb9\u91cf\n\n\n\n\n\n\n\u51fd\u6570\u8fd4\u56de\u4e00\u4e2a\nHistory\n\u5bf9\u8c61\n\n\n\u4f8b\u5b50\uff1a\n\n\ndef generate_arrays_from_file(path):\n    while 1:\n        f = open(path)\n        for line in f:\n            # create numpy arrays of input data\n            # and labels, from each line in the file\n            x, y = process_line(line)\n            yield (x, y)\n        f.close()\n\nmodel.fit_generator(generate_arrays_from_file('/my_file.txt'),\n        samples_per_epoch=10000, nb_epoch=10)\n\n\n\n\n\n\nevaluate_generator\n\n\nevaluate_generator(self, generator, val_samples, max_q_size=10)\n\n\n\n\n\u672c\u51fd\u6570\u4f7f\u7528\u4e00\u4e2a\u751f\u6210\u5668\u4f5c\u4e3a\u6570\u636e\u6e90\u8bc4\u4f30\u6a21\u578b\uff0c\u751f\u6210\u5668\u5e94\u8fd4\u56de\u4e0e\ntest_on_batch\n\u7684\u8f93\u5165\u6570\u636e\u76f8\u540c\u7c7b\u578b\u7684\u6570\u636e\u3002\u8be5\u51fd\u6570\u7684\u53c2\u6570\u4e0e\nfit_generator\n\u540c\u540d\u53c2\u6570\u542b\u4e49\u76f8\u540c", 
            "title": "Sequential\u6a21\u578b"
        }, 
        {
            "location": "/models/sequential/#sequential", 
            "text": "\u5982\u679c\u521a\u5f00\u59cb\u5b66\u4e60Sequential\u6a21\u578b\uff0c\u8bf7\u9996\u5148\u79fb\u6b65 \u8fd9\u91cc \u9605\u8bfb\u6587\u6863", 
            "title": "Sequential\u6a21\u578b\u63a5\u53e3"
        }, 
        {
            "location": "/models/sequential/#sequential_1", 
            "text": "model.layers \u662f\u6dfb\u52a0\u5230\u6a21\u578b\u4e0a\u7684\u5c42\u7684list", 
            "title": "\u5e38\u7528Sequential\u5c5e\u6027"
        }, 
        {
            "location": "/models/sequential/#sequential_2", 
            "text": "", 
            "title": "Sequential\u6a21\u578b\u65b9\u6cd5"
        }, 
        {
            "location": "/models/sequential/#compile", 
            "text": "compile(self, optimizer, loss, metrics=[], sample_weight_mode=None)  \u7f16\u8bd1\u7528\u6765\u914d\u7f6e\u6a21\u578b\u7684\u5b66\u4e60\u8fc7\u7a0b\uff0c\u5176\u53c2\u6570\u6709    optimizer\uff1a\u5b57\u7b26\u4e32\uff08\u9884\u5b9a\u4e49\u4f18\u5316\u5668\u540d\uff09\u6216\u4f18\u5316\u5668\u5bf9\u8c61\uff0c\u53c2\u8003 \u4f18\u5316\u5668    loss\uff1a\u5b57\u7b26\u4e32\uff08\u9884\u5b9a\u4e49\u635f\u5931\u51fd\u6570\u540d\uff09\u6216\u76ee\u6807\u51fd\u6570\uff0c\u53c2\u8003 \u76ee\u6807\u51fd\u6570    metrics\uff1a\u5217\u8868\uff0c\u5305\u542b\u8bc4\u4f30\u6a21\u578b\u5728\u8bad\u7ec3\u548c\u6d4b\u8bd5\u65f6\u7684\u7f51\u7edc\u6027\u80fd\u7684\u6307\u6807\uff0c\u5178\u578b\u7528\u6cd5\u662f metrics=['accuracy']    sample_weight_mode\uff1a\u5982\u679c\u4f60\u9700\u8981\u6309\u65f6\u95f4\u6b65\u4e3a\u6837\u672c\u8d4b\u6743\uff082D\u6743\u77e9\u9635\uff09\uff0c\u5c06\u8be5\u503c\u8bbe\u4e3a\u201ctemporal\u201d\u3002\u9ed8\u8ba4\u4e3a\u201cNone\u201d\uff0c\u4ee3\u8868\u6309\u6837\u672c\u8d4b\u6743\uff081D\u6743\uff09\u3002\u5728\u4e0b\u9762 fit \u51fd\u6570\u7684\u89e3\u91ca\u4e2d\u6709\u76f8\u5173\u7684\u53c2\u8003\u5185\u5bb9\u3002    kwargs\uff1a\u4f7f\u7528TensorFlow\u4f5c\u4e3a\u540e\u7aef\u8bf7\u5ffd\u7565\u8be5\u53c2\u6570\uff0c\u82e5\u4f7f\u7528Theano\u4f5c\u4e3a\u540e\u7aef\uff0ckwargs\u7684\u503c\u5c06\u4f1a\u4f20\u9012\u7ed9 K.function    model = Sequential()\nmodel.add(Dense(32, input_shape=(500,)))\nmodel.add(Dense(10, activation='softmax'))\nmodel.compile(optimizer='rmsprop',\n      loss='categorical_crossentropy',\n      metrics=['accuracy'])", 
            "title": "compile"
        }, 
        {
            "location": "/models/sequential/#fit", 
            "text": "fit(self, x, y, batch_size=32, nb_epoch=10, verbose=1, callbacks=[], validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None)  \u672c\u51fd\u6570\u5c06\u6a21\u578b\u8bad\u7ec3 nb_epoch \u8f6e\uff0c\u5176\u53c2\u6570\u6709\uff1a    x\uff1a\u8f93\u5165\u6570\u636e\u3002\u5982\u679c\u6a21\u578b\u53ea\u6709\u4e00\u4e2a\u8f93\u5165\uff0c\u90a3\u4e48x\u7684\u7c7b\u578b\u662fnumpy array\uff0c\u5982\u679c\u6a21\u578b\u6709\u591a\u4e2a\u8f93\u5165\uff0c\u90a3\u4e48x\u7684\u7c7b\u578b\u5e94\u5f53\u4e3alist\uff0clist\u7684\u5143\u7d20\u662f\u5bf9\u5e94\u4e8e\u5404\u4e2a\u8f93\u5165\u7684numpy array    y\uff1a\u6807\u7b7e\uff0cnumpy array    batch_size\uff1a\u6574\u6570\uff0c\u6307\u5b9a\u8fdb\u884c\u68af\u5ea6\u4e0b\u964d\u65f6\u6bcf\u4e2abatch\u5305\u542b\u7684\u6837\u672c\u6570\u3002\u8bad\u7ec3\u65f6\u4e00\u4e2abatch\u7684\u6837\u672c\u4f1a\u88ab\u8ba1\u7b97\u4e00\u6b21\u68af\u5ea6\u4e0b\u964d\uff0c\u4f7f\u76ee\u6807\u51fd\u6570\u4f18\u5316\u4e00\u6b65\u3002    nb_epoch\uff1a\u6574\u6570\uff0c\u8bad\u7ec3\u7684\u8f6e\u6570\uff0c\u8bad\u7ec3\u6570\u636e\u5c06\u4f1a\u88ab\u904d\u5386nb_epoch\u6b21\u3002Keras\u4e2dnb\u5f00\u5934\u7684\u53d8\u91cf\u5747\u4e3a\"number of\"\u7684\u610f\u601d    verbose\uff1a\u65e5\u5fd7\u663e\u793a\uff0c0\u4e3a\u4e0d\u5728\u6807\u51c6\u8f93\u51fa\u6d41\u8f93\u51fa\u65e5\u5fd7\u4fe1\u606f\uff0c1\u4e3a\u8f93\u51fa\u8fdb\u5ea6\u6761\u8bb0\u5f55\uff0c2\u4e3a\u6bcf\u4e2aepoch\u8f93\u51fa\u4e00\u884c\u8bb0\u5f55    callbacks\uff1alist\uff0c\u5176\u4e2d\u7684\u5143\u7d20\u662f keras.callbacks.Callback \u7684\u5bf9\u8c61\u3002\u8fd9\u4e2alist\u4e2d\u7684\u56de\u8c03\u51fd\u6570\u5c06\u4f1a\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u9002\u5f53\u65f6\u673a\u88ab\u8c03\u7528\uff0c\u53c2\u8003 \u56de\u8c03\u51fd\u6570    validation_split\uff1a0~1\u4e4b\u95f4\u7684\u6d6e\u70b9\u6570\uff0c\u7528\u6765\u6307\u5b9a\u8bad\u7ec3\u96c6\u7684\u4e00\u5b9a\u6bd4\u4f8b\u6570\u636e\u4f5c\u4e3a\u9a8c\u8bc1\u96c6\u3002\u9a8c\u8bc1\u96c6\u5c06\u4e0d\u53c2\u4e0e\u8bad\u7ec3\uff0c\u5e76\u5728\u6bcf\u4e2aepoch\u7ed3\u675f\u540e\u6d4b\u8bd5\u7684\u6a21\u578b\u7684\u6307\u6807\uff0c\u5982\u635f\u5931\u51fd\u6570\u3001\u7cbe\u786e\u5ea6\u7b49\u3002    validation_data\uff1a\u5f62\u5f0f\u4e3a\uff08X\uff0cy\uff09\u7684tuple\uff0c\u662f\u6307\u5b9a\u7684\u9a8c\u8bc1\u96c6\u3002\u6b64\u53c2\u6570\u5c06\u8986\u76d6validation_spilt\u3002    shuffle\uff1a\u5e03\u5c14\u503c\u6216\u5b57\u7b26\u4e32\uff0c\u4e00\u822c\u4e3a\u5e03\u5c14\u503c\uff0c\u8868\u793a\u662f\u5426\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u968f\u673a\u6253\u4e71\u8f93\u5165\u6837\u672c\u7684\u987a\u5e8f\u3002\u82e5\u4e3a\u5b57\u7b26\u4e32\u201cbatch\u201d\uff0c\u5219\u662f\u7528\u6765\u5904\u7406HDF5\u6570\u636e\u7684\u7279\u6b8a\u60c5\u51b5\uff0c\u5b83\u5c06\u5728batch\u5185\u90e8\u5c06\u6570\u636e\u6253\u4e71\u3002    class_weight\uff1a\u5b57\u5178\uff0c\u5c06\u4e0d\u540c\u7684\u7c7b\u522b\u6620\u5c04\u4e3a\u4e0d\u540c\u7684\u6743\u503c\uff0c\u8be5\u53c2\u6570\u7528\u6765\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u8c03\u6574\u635f\u5931\u51fd\u6570\uff08\u53ea\u80fd\u7528\u4e8e\u8bad\u7ec3\uff09    sample_weight\uff1a\u6743\u503c\u7684numpy array\uff0c\u7528\u4e8e\u5728\u8bad\u7ec3\u65f6\u8c03\u6574\u635f\u5931\u51fd\u6570\uff08\u4ec5\u7528\u4e8e\u8bad\u7ec3\uff09\u3002\u53ef\u4ee5\u4f20\u9012\u4e00\u4e2a1D\u7684\u4e0e\u6837\u672c\u7b49\u957f\u7684\u5411\u91cf\u7528\u4e8e\u5bf9\u6837\u672c\u8fdb\u884c1\u5bf91\u7684\u52a0\u6743\uff0c\u6216\u8005\u5728\u9762\u5bf9\u65f6\u5e8f\u6570\u636e\u65f6\uff0c\u4f20\u9012\u4e00\u4e2a\u7684\u5f62\u5f0f\u4e3a\uff08samples\uff0csequence_length\uff09\u7684\u77e9\u9635\u6765\u4e3a\u6bcf\u4e2a\u65f6\u95f4\u6b65\u4e0a\u7684\u6837\u672c\u8d4b\u4e0d\u540c\u7684\u6743\u3002\u8fd9\u79cd\u60c5\u51b5\u4e0b\u8bf7\u786e\u5b9a\u5728\u7f16\u8bd1\u6a21\u578b\u65f6\u6dfb\u52a0\u4e86 sample_weight_mode='temporal' \u3002    fit \u51fd\u6570\u8fd4\u56de\u4e00\u4e2a History \u7684\u5bf9\u8c61\uff0c\u5176 History.history \u5c5e\u6027\u8bb0\u5f55\u4e86\u635f\u5931\u51fd\u6570\u548c\u5176\u4ed6\u6307\u6807\u7684\u6570\u503c\u968fepoch\u53d8\u5316\u7684\u60c5\u51b5\uff0c\u5982\u679c\u6709\u9a8c\u8bc1\u96c6\u7684\u8bdd\uff0c\u4e5f\u5305\u542b\u4e86\u9a8c\u8bc1\u96c6\u7684\u8fd9\u4e9b\u6307\u6807\u53d8\u5316\u60c5\u51b5", 
            "title": "fit"
        }, 
        {
            "location": "/models/sequential/#evaluate", 
            "text": "evaluate(self, x, y, batch_size=32, verbose=1, sample_weight=None)  \u672c\u51fd\u6570\u6309batch\u8ba1\u7b97\u5728\u67d0\u4e9b\u8f93\u5165\u6570\u636e\u4e0a\u6a21\u578b\u7684\u8bef\u5dee\uff0c\u5176\u53c2\u6570\u6709\uff1a    x\uff1a\u8f93\u5165\u6570\u636e\uff0c\u4e0e fit \u4e00\u6837\uff0c\u662fnumpy array\u6216numpy array\u7684list    y\uff1a\u6807\u7b7e\uff0cnumpy array    batch_size\uff1a\u6574\u6570\uff0c\u542b\u4e49\u540c fit \u7684\u540c\u540d\u53c2\u6570    verbose\uff1a\u542b\u4e49\u540c fit \u7684\u540c\u540d\u53c2\u6570\uff0c\u4f46\u53ea\u80fd\u53d60\u62161    sample_weight\uff1anumpy array\uff0c\u542b\u4e49\u540c fit \u7684\u540c\u540d\u53c2\u6570    \u672c\u51fd\u6570\u8fd4\u56de\u4e00\u4e2a\u6d4b\u8bd5\u8bef\u5dee\u7684\u6807\u91cf\u503c\uff08\u5982\u679c\u6a21\u578b\u6ca1\u6709\u5176\u4ed6\u8bc4\u4ef7\u6307\u6807\uff09\uff0c\u6216\u4e00\u4e2a\u6807\u91cf\u7684list\uff08\u5982\u679c\u6a21\u578b\u8fd8\u6709\u5176\u4ed6\u7684\u8bc4\u4ef7\u6307\u6807\uff09\u3002 model.metrics_names \u5c06\u7ed9\u51falist\u4e2d\u5404\u4e2a\u503c\u7684\u542b\u4e49\u3002  \u5982\u679c\u6ca1\u6709\u7279\u6b8a\u8bf4\u660e\uff0c\u4ee5\u4e0b\u51fd\u6570\u7684\u53c2\u6570\u5747\u4fdd\u6301\u4e0e fit \u7684\u540c\u540d\u53c2\u6570\u76f8\u540c\u7684\u542b\u4e49  \u5982\u679c\u6ca1\u6709\u7279\u6b8a\u8bf4\u660e\uff0c\u4ee5\u4e0b\u51fd\u6570\u7684verbose\u53c2\u6570\uff08\u5982\u679c\u6709\uff09\u5747\u53ea\u80fd\u53d60\u62161", 
            "title": "evaluate"
        }, 
        {
            "location": "/models/sequential/#predict", 
            "text": "predict(self, x, batch_size=32, verbose=0)  \u672c\u51fd\u6570\u6309batch\u83b7\u5f97\u8f93\u5165\u6570\u636e\u5bf9\u5e94\u7684\u8f93\u51fa\uff0c\u5176\u53c2\u6570\u6709\uff1a  \u51fd\u6570\u7684\u8fd4\u56de\u503c\u662f\u9884\u6d4b\u503c\u7684numpy array", 
            "title": "predict"
        }, 
        {
            "location": "/models/sequential/#predict_classes", 
            "text": "predict_classes(self, x, batch_size=32, verbose=1)  \u672c\u51fd\u6570\u6309batch\u4ea7\u751f\u8f93\u5165\u6570\u636e\u7684\u7c7b\u522b\u9884\u6d4b\u7ed3\u679c  \u51fd\u6570\u7684\u8fd4\u56de\u503c\u662f\u7c7b\u522b\u9884\u6d4b\u7ed3\u679c\u7684numpy array\u6216numpy", 
            "title": "predict_classes"
        }, 
        {
            "location": "/models/sequential/#predict_proba", 
            "text": "predict_proba(self, x, batch_size=32, verbose=1)  \u672c\u51fd\u6570\u6309batch\u4ea7\u751f\u8f93\u5165\u6570\u636e\u5c5e\u4e8e\u5404\u4e2a\u7c7b\u522b\u7684\u6982\u7387  \u51fd\u6570\u7684\u8fd4\u56de\u503c\u662f\u7c7b\u522b\u6982\u7387\u7684numpy array", 
            "title": "predict_proba"
        }, 
        {
            "location": "/models/sequential/#train_on_batch", 
            "text": "train_on_batch(self, x, y, class_weight=None, sample_weight=None)  \u672c\u51fd\u6570\u5728\u4e00\u4e2abatch\u7684\u6570\u636e\u4e0a\u8fdb\u884c\u4e00\u6b21\u53c2\u6570\u66f4\u65b0  \u51fd\u6570\u8fd4\u56de\u8bad\u7ec3\u8bef\u5dee\u7684\u6807\u91cf\u503c\u6216\u6807\u91cf\u503c\u7684list\uff0c\u4e0e evaluate \u7684\u60c5\u5f62\u76f8\u540c\u3002", 
            "title": "train_on_batch"
        }, 
        {
            "location": "/models/sequential/#test_on_batch", 
            "text": "test_on_batch(self, x, y, sample_weight=None)  \u672c\u51fd\u6570\u5728\u4e00\u4e2abatch\u7684\u6837\u672c\u4e0a\u5bf9\u6a21\u578b\u8fdb\u884c\u8bc4\u4f30  \u51fd\u6570\u7684\u8fd4\u56de\u4e0e evaluate \u7684\u60c5\u5f62\u76f8\u540c", 
            "title": "test_on_batch"
        }, 
        {
            "location": "/models/sequential/#predict_on_batch", 
            "text": "predict_on_batch(self, x)  \u672c\u51fd\u6570\u5728\u4e00\u4e2abatch\u7684\u6837\u672c\u4e0a\u5bf9\u6a21\u578b\u8fdb\u884c\u6d4b\u8bd5  \u51fd\u6570\u8fd4\u56de\u6a21\u578b\u5728\u4e00\u4e2abatch\u4e0a\u7684\u9884\u6d4b\u7ed3\u679c", 
            "title": "predict_on_batch"
        }, 
        {
            "location": "/models/sequential/#fit_generator", 
            "text": "fit_generator(self, generator, samples_per_epoch, nb_epoch, verbose=1, callbacks=[], validation_data=None, nb_val_samples=None, class_weight=None, max_q_size=10)  \u5229\u7528Python\u7684\u751f\u6210\u5668\uff0c\u9010\u4e2a\u751f\u6210\u6570\u636e\u7684batch\u5e76\u8fdb\u884c\u8bad\u7ec3\u3002\u751f\u6210\u5668\u4e0e\u6a21\u578b\u5c06\u5e76\u884c\u6267\u884c\u4ee5\u63d0\u9ad8\u6548\u7387\u3002\u4f8b\u5982\uff0c\u8be5\u51fd\u6570\u5141\u8bb8\u6211\u4eec\u5728CPU\u4e0a\u8fdb\u884c\u5b9e\u65f6\u7684\u6570\u636e\u63d0\u5347\uff0c\u540c\u65f6\u5728GPU\u4e0a\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3  \u51fd\u6570\u7684\u53c2\u6570\u662f\uff1a    generator\uff1a\u751f\u6210\u5668\u51fd\u6570\uff0c\u751f\u6210\u5668\u7684\u8f93\u51fa\u5e94\u8be5\u4e3a\uff1a    \u4e00\u4e2a\u5f62\u5982\uff08inputs\uff0ctargets\uff09\u7684tuple    \u4e00\u4e2a\u5f62\u5982\uff08inputs, targets,sample_weight\uff09\u7684tuple\u3002\u6240\u6709\u7684\u8fd4\u56de\u503c\u90fd\u5e94\u8be5\u5305\u542b\u76f8\u540c\u6570\u76ee\u7684\u6837\u672c\u3002\u751f\u6210\u5668\u5c06\u65e0\u9650\u5728\u6570\u636e\u96c6\u4e0a\u5faa\u73af\u3002\u6bcf\u4e2aepoch\u4ee5\u7ecf\u8fc7\u6a21\u578b\u7684\u6837\u672c\u6570\u8fbe\u5230 samples_per_epoch \u65f6\uff0c\u8bb0\u4e00\u4e2aepoch\u7ed3\u675f      samples_per_epoch\uff1a\u6574\u6570\uff0c\u5f53\u6a21\u578b\u5904\u7406\u7684\u6837\u672c\u8fbe\u5230\u6b64\u6570\u76ee\u65f6\u8ba1\u4e00\u4e2aepoch\u7ed3\u675f\uff0c\u6267\u884c\u4e0b\u4e00\u4e2aepoch    verbose\uff1a\u65e5\u5fd7\u663e\u793a\uff0c0\u4e3a\u4e0d\u5728\u6807\u51c6\u8f93\u51fa\u6d41\u8f93\u51fa\u65e5\u5fd7\u4fe1\u606f\uff0c1\u4e3a\u8f93\u51fa\u8fdb\u5ea6\u6761\u8bb0\u5f55\uff0c2\u4e3a\u6bcf\u4e2aepoch\u8f93\u51fa\u4e00\u884c\u8bb0\u5f55    validation_data\uff1a\u5177\u6709\u4ee5\u4e0b\u4e09\u79cd\u5f62\u5f0f\u4e4b\u4e00    \u751f\u6210\u9a8c\u8bc1\u96c6\u7684\u751f\u6210\u5668    \u4e00\u4e2a\u5f62\u5982\uff08inputs,targets\uff09\u7684tuple    \u4e00\u4e2a\u5f62\u5982\uff08inputs,targets\uff0csample_weights\uff09\u7684tuple      nb_val_samples\uff1a\u4ec5\u5f53 validation_data \u662f\u751f\u6210\u5668\u65f6\u4f7f\u7528\uff0c\u7528\u4ee5\u9650\u5236\u5728\u6bcf\u4e2aepoch\u7ed3\u675f\u65f6\u7528\u6765\u9a8c\u8bc1\u6a21\u578b\u7684\u9a8c\u8bc1\u96c6\u6837\u672c\u6570\uff0c\u529f\u80fd\u7c7b\u4f3c\u4e8e samples_per_epoch    max_q_size\uff1a\u751f\u6210\u5668\u961f\u5217\u7684\u6700\u5927\u5bb9\u91cf    \u51fd\u6570\u8fd4\u56de\u4e00\u4e2a History \u5bf9\u8c61  \u4f8b\u5b50\uff1a  def generate_arrays_from_file(path):\n    while 1:\n        f = open(path)\n        for line in f:\n            # create numpy arrays of input data\n            # and labels, from each line in the file\n            x, y = process_line(line)\n            yield (x, y)\n        f.close()\n\nmodel.fit_generator(generate_arrays_from_file('/my_file.txt'),\n        samples_per_epoch=10000, nb_epoch=10)", 
            "title": "fit_generator"
        }, 
        {
            "location": "/models/sequential/#evaluate_generator", 
            "text": "evaluate_generator(self, generator, val_samples, max_q_size=10)  \u672c\u51fd\u6570\u4f7f\u7528\u4e00\u4e2a\u751f\u6210\u5668\u4f5c\u4e3a\u6570\u636e\u6e90\u8bc4\u4f30\u6a21\u578b\uff0c\u751f\u6210\u5668\u5e94\u8fd4\u56de\u4e0e test_on_batch \u7684\u8f93\u5165\u6570\u636e\u76f8\u540c\u7c7b\u578b\u7684\u6570\u636e\u3002\u8be5\u51fd\u6570\u7684\u53c2\u6570\u4e0e fit_generator \u540c\u540d\u53c2\u6570\u542b\u4e49\u76f8\u540c", 
            "title": "evaluate_generator"
        }, 
        {
            "location": "/models/model/", 
            "text": "\u6cdb\u578b\u6a21\u578b\u63a5\u53e3\n\n\n\u4e3a\u4ec0\u4e48\u53eb\u201c\u6cdb\u578b\u6a21\u578b\u201d\uff0c\u8bf7\u67e5\u770b\n\u4e00\u4e9b\u57fa\u672c\u6982\u5ff5\n\n\nKeras\u7684\u6cdb\u578b\u6a21\u578b\u4e3a\nModel\n\uff0c\u5373\u5e7f\u4e49\u7684\u62e5\u6709\u8f93\u5165\u548c\u8f93\u51fa\u7684\u6a21\u578b\uff0c\u6211\u4eec\u4f7f\u7528\nModel\n\u6765\u521d\u59cb\u5316\u4e00\u4e2a\u6cdb\u578b\u6a21\u578b\n\n\nfrom keras.models import Model\nfrom keras.layers import Input, Dense\n\na = Input(shape=(32,))\nb = Dense(32)(a)\nmodel = Model(input=a, output=b)\n\n\n\n\n\u5728\u8fd9\u91cc\uff0c\u6211\u4eec\u7684\u6a21\u578b\u4ee5\na\n\u4e3a\u8f93\u5165\uff0c\u4ee5\nb\n\u4e3a\u8f93\u51fa\uff0c\u540c\u6837\u6211\u4eec\u53ef\u4ee5\u6784\u9020\u62e5\u6709\u591a\u8f93\u5165\u548c\u591a\u8f93\u51fa\u7684\u6a21\u578b\n\n\nmodel = Model(input=[a1, a2], output=[b1, b3, b3])\n\n\n\n\n\u5e38\u7528Model\u5c5e\u6027\n\n\n\n\nmodel.layers\n\uff1a\u7ec4\u6210\u6a21\u578b\u56fe\u7684\u5404\u4e2a\u5c42\n\n\nmodel.inputs\n\uff1a\u6a21\u578b\u7684\u8f93\u5165\u5f20\u91cf\u5217\u8868\n\n\nmodel.outputs\n\uff1a\u6a21\u578b\u7684\u8f93\u51fa\u5f20\u91cf\u5217\u8868\n\n\n\n\n\n\nModel\u6a21\u578b\u65b9\u6cd5\n\n\ncompile\n\n\ncompile(self, optimizer, loss, metrics=[], loss_weights=None, sample_weight_mode=None)\n\n\n\n\n\u672c\u51fd\u6570\u7f16\u8bd1\u6a21\u578b\u4ee5\u4f9b\u8bad\u7ec3\uff0c\u53c2\u6570\u6709\n\n\n\n\n\n\noptimizer\uff1a\u4f18\u5316\u5668\uff0c\u4e3a\u9884\u5b9a\u4e49\u4f18\u5316\u5668\u540d\u6216\u4f18\u5316\u5668\u5bf9\u8c61\uff0c\u53c2\u8003\n\u4f18\u5316\u5668\n\n\n\n\n\n\nloss\uff1a\u76ee\u6807\u51fd\u6570\uff0c\u4e3a\u9884\u5b9a\u4e49\u635f\u5931\u51fd\u6570\u540d\u6216\u4e00\u4e2a\u76ee\u6807\u51fd\u6570\uff0c\u53c2\u8003\n\u76ee\u6807\u51fd\u6570\n\n\n\n\n\n\nmetrics\uff1a\u5217\u8868\uff0c\u5305\u542b\u8bc4\u4f30\u6a21\u578b\u5728\u8bad\u7ec3\u548c\u6d4b\u8bd5\u65f6\u7684\u6027\u80fd\u7684\u6307\u6807\uff0c\u5178\u578b\u7528\u6cd5\u662f\nmetrics=['accuracy']\n\u5982\u679c\u8981\u5728\u591a\u8f93\u51fa\u6a21\u578b\u4e2d\u4e3a\u4e0d\u540c\u7684\u8f93\u51fa\u6307\u5b9a\u4e0d\u540c\u7684\u6307\u6807\uff0c\u53ef\u50cf\u8be5\u53c2\u6570\u4f20\u9012\u4e00\u4e2a\u5b57\u5178\uff0c\u4f8b\u5982\nmetrics={'ouput_a': 'accuracy'}\n\n\n\n\n\n\nsample_weight_mode\uff1a\u5982\u679c\u4f60\u9700\u8981\u6309\u65f6\u95f4\u6b65\u4e3a\u6837\u672c\u8d4b\u6743\uff082D\u6743\u77e9\u9635\uff09\uff0c\u5c06\u8be5\u503c\u8bbe\u4e3a\u201ctemporal\u201d\u3002\u9ed8\u8ba4\u4e3a\u201cNone\u201d\uff0c\u4ee3\u8868\u6309\u6837\u672c\u8d4b\u6743\uff081D\u6743\uff09\u3002\u5982\u679c\u6a21\u578b\u6709\u591a\u4e2a\u8f93\u51fa\uff0c\u53ef\u4ee5\u5411\u8be5\u53c2\u6570\u4f20\u5165\u6307\u5b9asample_weight_mode\u7684\u5b57\u5178\u6216\u5217\u8868\u3002\u5728\u4e0b\u9762\nfit\n\u51fd\u6570\u7684\u89e3\u91ca\u4e2d\u6709\u76f8\u5173\u7684\u53c2\u8003\u5185\u5bb9\u3002\n\n\n\n\n\n\nkwargs\uff1a\u4f7f\u7528TensorFlow\u4f5c\u4e3a\u540e\u7aef\u8bf7\u5ffd\u7565\u8be5\u53c2\u6570\uff0c\u82e5\u4f7f\u7528Theano\u4f5c\u4e3a\u540e\u7aef\uff0ckwargs\u7684\u503c\u5c06\u4f1a\u4f20\u9012\u7ed9 K.function\n\n\n\n\n\n\n\u3010Tips\u3011\u5982\u679c\u4f60\u53ea\u662f\u8f7d\u5165\u6a21\u578b\u5e76\u5229\u7528\u5176predict\uff0c\u53ef\u4ee5\u4e0d\u7528\u8fdb\u884ccompile\u3002\u5728Keras\u4e2d\uff0ccompile\u4e3b\u8981\u5b8c\u6210\u635f\u5931\u51fd\u6570\u548c\u4f18\u5316\u5668\u7684\u4e00\u4e9b\u914d\u7f6e\uff0c\u662f\u4e3a\u8bad\u7ec3\u670d\u52a1\u7684\u3002predict\u4f1a\u5728\u5185\u90e8\u8fdb\u884c\u7b26\u53f7\u51fd\u6570\u7684\u7f16\u8bd1\u5de5\u4f5c\uff08\u901a\u8fc7\u8c03\u7528_make_predict_function\u751f\u6210\u51fd\u6570\uff09\u3010@\u767d\u83dc\uff0c@\u6211\u662f\u5c0f\u5c06\u3011\n\n\n\n\nfit\n\n\nfit(self, x, y, batch_size=32, nb_epoch=10, verbose=1, callbacks=[], validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None)\n\n\n\n\n\u672c\u51fd\u6570\u7528\u4ee5\u8bad\u7ec3\u6a21\u578b\uff0c\u53c2\u6570\u6709\uff1a\n\n\n\n\n\n\nx\uff1a\u8f93\u5165\u6570\u636e\u3002\u5982\u679c\u6a21\u578b\u53ea\u6709\u4e00\u4e2a\u8f93\u5165\uff0c\u90a3\u4e48x\u7684\u7c7b\u578b\u662fnumpy array\uff0c\u5982\u679c\u6a21\u578b\u6709\u591a\u4e2a\u8f93\u5165\uff0c\u90a3\u4e48x\u7684\u7c7b\u578b\u5e94\u5f53\u4e3alist\uff0clist\u7684\u5143\u7d20\u662f\u5bf9\u5e94\u4e8e\u5404\u4e2a\u8f93\u5165\u7684numpy array\u3002\u5982\u679c\u6a21\u578b\u7684\u6bcf\u4e2a\u8f93\u5165\u90fd\u6709\u540d\u5b57\uff0c\u5219\u53ef\u4ee5\u4f20\u5165\u4e00\u4e2a\u5b57\u5178\uff0c\u5c06\u8f93\u5165\u540d\u4e0e\u5176\u8f93\u5165\u6570\u636e\u5bf9\u5e94\u8d77\u6765\u3002\n\n\n\n\n\n\ny\uff1a\u6807\u7b7e\uff0cnumpy array\u3002\u5982\u679c\u6a21\u578b\u6709\u591a\u4e2a\u8f93\u51fa\uff0c\u53ef\u4ee5\u4f20\u5165\u4e00\u4e2anumpy array\u7684list\u3002\u5982\u679c\u6a21\u578b\u7684\u8f93\u51fa\u62e5\u6709\u540d\u5b57\uff0c\u5219\u53ef\u4ee5\u4f20\u5165\u4e00\u4e2a\u5b57\u5178\uff0c\u5c06\u8f93\u51fa\u540d\u4e0e\u5176\u6807\u7b7e\u5bf9\u5e94\u8d77\u6765\u3002\n\n\n\n\n\n\nbatch_size\uff1a\u6574\u6570\uff0c\u6307\u5b9a\u8fdb\u884c\u68af\u5ea6\u4e0b\u964d\u65f6\u6bcf\u4e2abatch\u5305\u542b\u7684\u6837\u672c\u6570\u3002\u8bad\u7ec3\u65f6\u4e00\u4e2abatch\u7684\u6837\u672c\u4f1a\u88ab\u8ba1\u7b97\u4e00\u6b21\u68af\u5ea6\u4e0b\u964d\uff0c\u4f7f\u76ee\u6807\u51fd\u6570\u4f18\u5316\u4e00\u6b65\u3002\n\n\n\n\n\n\nnb_epoch\uff1a\u6574\u6570\uff0c\u8bad\u7ec3\u7684\u8f6e\u6570\uff0c\u8bad\u7ec3\u6570\u636e\u5c06\u4f1a\u88ab\u904d\u5386nb_epoch\u6b21\u3002Keras\u4e2dnb\u5f00\u5934\u7684\u53d8\u91cf\u5747\u4e3a\"number of\"\u7684\u610f\u601d\n\n\n\n\n\n\nverbose\uff1a\u65e5\u5fd7\u663e\u793a\uff0c0\u4e3a\u4e0d\u5728\u6807\u51c6\u8f93\u51fa\u6d41\u8f93\u51fa\u65e5\u5fd7\u4fe1\u606f\uff0c1\u4e3a\u8f93\u51fa\u8fdb\u5ea6\u6761\u8bb0\u5f55\uff0c2\u4e3a\u6bcf\u4e2aepoch\u8f93\u51fa\u4e00\u884c\u8bb0\u5f55\n\n\n\n\n\n\ncallbacks\uff1alist\uff0c\u5176\u4e2d\u7684\u5143\u7d20\u662f\nkeras.callbacks.Callback\n\u7684\u5bf9\u8c61\u3002\u8fd9\u4e2alist\u4e2d\u7684\u56de\u8c03\u51fd\u6570\u5c06\u4f1a\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u9002\u5f53\u65f6\u673a\u88ab\u8c03\u7528\uff0c\u53c2\u8003\n\u56de\u8c03\u51fd\u6570\n\n\n\n\n\n\nvalidation_split\uff1a0~1\u4e4b\u95f4\u7684\u6d6e\u70b9\u6570\uff0c\u7528\u6765\u6307\u5b9a\u8bad\u7ec3\u96c6\u7684\u4e00\u5b9a\u6bd4\u4f8b\u6570\u636e\u4f5c\u4e3a\u9a8c\u8bc1\u96c6\u3002\u9a8c\u8bc1\u96c6\u5c06\u4e0d\u53c2\u4e0e\u8bad\u7ec3\uff0c\u5e76\u5728\u6bcf\u4e2aepoch\u7ed3\u675f\u540e\u6d4b\u8bd5\u7684\u6a21\u578b\u7684\u6307\u6807\uff0c\u5982\u635f\u5931\u51fd\u6570\u3001\u7cbe\u786e\u5ea6\u7b49\u3002\n\n\n\n\n\n\nvalidation_data\uff1a\u5f62\u5f0f\u4e3a\uff08X\uff0cy\uff09\u6216\uff08X\uff0cy\uff0csample_weights\uff09\u7684tuple\uff0c\u662f\u6307\u5b9a\u7684\u9a8c\u8bc1\u96c6\u3002\u6b64\u53c2\u6570\u5c06\u8986\u76d6validation_spilt\u3002\n\n\n\n\n\n\nshuffle\uff1a\u5e03\u5c14\u503c\uff0c\u8868\u793a\u662f\u5426\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u6bcf\u4e2aepoch\u524d\u968f\u673a\u6253\u4e71\u8f93\u5165\u6837\u672c\u7684\u987a\u5e8f\u3002\n\n\n\n\n\n\nclass_weight\uff1a\u5b57\u5178\uff0c\u5c06\u4e0d\u540c\u7684\u7c7b\u522b\u6620\u5c04\u4e3a\u4e0d\u540c\u7684\u6743\u503c\uff0c\u8be5\u53c2\u6570\u7528\u6765\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u8c03\u6574\u635f\u5931\u51fd\u6570\uff08\u53ea\u80fd\u7528\u4e8e\u8bad\u7ec3\uff09\u3002\u8be5\u53c2\u6570\u5728\u5904\u7406\u975e\u5e73\u8861\u7684\u8bad\u7ec3\u6570\u636e\uff08\u67d0\u4e9b\u7c7b\u7684\u8bad\u7ec3\u6837\u672c\u6570\u5f88\u5c11\uff09\u65f6\uff0c\u53ef\u4ee5\u4f7f\u5f97\u635f\u5931\u51fd\u6570\u5bf9\u6837\u672c\u6570\u4e0d\u8db3\u7684\u6570\u636e\u66f4\u52a0\u5173\u6ce8\u3002\n\n\n\n\n\n\nsample_weight\uff1a\u6743\u503c\u7684numpy array\uff0c\u7528\u4e8e\u5728\u8bad\u7ec3\u65f6\u8c03\u6574\u635f\u5931\u51fd\u6570\uff08\u4ec5\u7528\u4e8e\u8bad\u7ec3\uff09\u3002\u53ef\u4ee5\u4f20\u9012\u4e00\u4e2a1D\u7684\u4e0e\u6837\u672c\u7b49\u957f\u7684\u5411\u91cf\u7528\u4e8e\u5bf9\u6837\u672c\u8fdb\u884c1\u5bf91\u7684\u52a0\u6743\uff0c\u6216\u8005\u5728\u9762\u5bf9\u65f6\u5e8f\u6570\u636e\u65f6\uff0c\u4f20\u9012\u4e00\u4e2a\u7684\u5f62\u5f0f\u4e3a\uff08samples\uff0csequence_length\uff09\u7684\u77e9\u9635\u6765\u4e3a\u6bcf\u4e2a\u65f6\u95f4\u6b65\u4e0a\u7684\u6837\u672c\u8d4b\u4e0d\u540c\u7684\u6743\u3002\u8fd9\u79cd\u60c5\u51b5\u4e0b\u8bf7\u786e\u5b9a\u5728\u7f16\u8bd1\u6a21\u578b\u65f6\u6dfb\u52a0\u4e86\nsample_weight_mode='temporal'\n\u3002\n\n\n\n\n\n\nfit\n\u51fd\u6570\u8fd4\u56de\u4e00\u4e2a\nHistory\n\u7684\u5bf9\u8c61\uff0c\u5176\nHistory.history\n\u5c5e\u6027\u8bb0\u5f55\u4e86\u635f\u5931\u51fd\u6570\u548c\u5176\u4ed6\u6307\u6807\u7684\u6570\u503c\u968fepoch\u53d8\u5316\u7684\u60c5\u51b5\uff0c\u5982\u679c\u6709\u9a8c\u8bc1\u96c6\u7684\u8bdd\uff0c\u4e5f\u5305\u542b\u4e86\u9a8c\u8bc1\u96c6\u7684\u8fd9\u4e9b\u6307\u6807\u53d8\u5316\u60c5\u51b5\n\n\n\n\n\n\n\n\nevaluate\n\n\n\n\n\n\nevaluate(self, x, y, batch_size=32, verbose=1, sample_weight=None)\n\n\n\n\n\u672c\u51fd\u6570\u6309batch\u8ba1\u7b97\u5728\u67d0\u4e9b\u8f93\u5165\u6570\u636e\u4e0a\u6a21\u578b\u7684\u8bef\u5dee\uff0c\u5176\u53c2\u6570\u6709\uff1a\n\n\n\n\n\n\nx\uff1a\u8f93\u5165\u6570\u636e\uff0c\u4e0e\nfit\n\u4e00\u6837\uff0c\u662fnumpy array\u6216numpy array\u7684list\n\n\n\n\n\n\ny\uff1a\u6807\u7b7e\uff0cnumpy array\n\n\n\n\n\n\nbatch_size\uff1a\u6574\u6570\uff0c\u542b\u4e49\u540c\nfit\n\u7684\u540c\u540d\u53c2\u6570\n\n\n\n\n\n\nverbose\uff1a\u542b\u4e49\u540c\nfit\n\u7684\u540c\u540d\u53c2\u6570\uff0c\u4f46\u53ea\u80fd\u53d60\u62161\n\n\n\n\n\n\nsample_weight\uff1anumpy array\uff0c\u542b\u4e49\u540c\nfit\n\u7684\u540c\u540d\u53c2\u6570\n\n\n\n\n\n\n\u672c\u51fd\u6570\u8fd4\u56de\u4e00\u4e2a\u6d4b\u8bd5\u8bef\u5dee\u7684\u6807\u91cf\u503c\uff08\u5982\u679c\u6a21\u578b\u6ca1\u6709\u5176\u4ed6\u8bc4\u4ef7\u6307\u6807\uff09\uff0c\u6216\u4e00\u4e2a\u6807\u91cf\u7684list\uff08\u5982\u679c\u6a21\u578b\u8fd8\u6709\u5176\u4ed6\u7684\u8bc4\u4ef7\u6307\u6807\uff09\u3002\nmodel.metrics_names\n\u5c06\u7ed9\u51falist\u4e2d\u5404\u4e2a\u503c\u7684\u542b\u4e49\u3002\n\n\n\u5982\u679c\u6ca1\u6709\u7279\u6b8a\u8bf4\u660e\uff0c\u4ee5\u4e0b\u51fd\u6570\u7684\u53c2\u6570\u5747\u4fdd\u6301\u4e0e\nfit\n\u7684\u540c\u540d\u53c2\u6570\u76f8\u540c\u7684\u542b\u4e49\n\n\n\u5982\u679c\u6ca1\u6709\u7279\u6b8a\u8bf4\u660e\uff0c\u4ee5\u4e0b\u51fd\u6570\u7684verbose\u53c2\u6570\uff08\u5982\u679c\u6709\uff09\u5747\u53ea\u80fd\u53d60\u62161\n\n\n\n\npredict\n\n\npredict(self, x, batch_size=32, verbose=0)\n\n\n\n\n\u672c\u51fd\u6570\u6309batch\u83b7\u5f97\u8f93\u5165\u6570\u636e\u5bf9\u5e94\u7684\u8f93\u51fa\uff0c\u5176\u53c2\u6570\u6709\uff1a\n\n\n\u51fd\u6570\u7684\u8fd4\u56de\u503c\u662f\u9884\u6d4b\u503c\u7684numpy array\n\n\n\n\ntrain_on_batch\n\n\ntrain_on_batch(self, x, y, class_weight=None, sample_weight=None)\n\n\n\n\n\u672c\u51fd\u6570\u5728\u4e00\u4e2abatch\u7684\u6570\u636e\u4e0a\u8fdb\u884c\u4e00\u6b21\u53c2\u6570\u66f4\u65b0\n\n\n\u51fd\u6570\u8fd4\u56de\u8bad\u7ec3\u8bef\u5dee\u7684\u6807\u91cf\u503c\u6216\u6807\u91cf\u503c\u7684list\uff0c\u4e0e\nevaluate\n\u7684\u60c5\u5f62\u76f8\u540c\u3002\n\n\n\n\ntest_on_batch\n\n\ntest_on_batch(self, x, y, sample_weight=None)\n\n\n\n\n\u672c\u51fd\u6570\u5728\u4e00\u4e2abatch\u7684\u6837\u672c\u4e0a\u5bf9\u6a21\u578b\u8fdb\u884c\u8bc4\u4f30\n\n\n\u51fd\u6570\u7684\u8fd4\u56de\u4e0e\nevaluate\n\u7684\u60c5\u5f62\u76f8\u540c\n\n\n\n\npredict_on_batch\n\n\npredict_on_batch(self, x)\n\n\n\n\n\u672c\u51fd\u6570\u5728\u4e00\u4e2abatch\u7684\u6837\u672c\u4e0a\u5bf9\u6a21\u578b\u8fdb\u884c\u6d4b\u8bd5\n\n\n\u51fd\u6570\u8fd4\u56de\u6a21\u578b\u5728\u4e00\u4e2abatch\u4e0a\u7684\u9884\u6d4b\u7ed3\u679c\n\n\n\n\nfit_generator\n\n\nfit_generator(self, generator, samples_per_epoch, nb_epoch, verbose=1, callbacks=[], validation_data=None, nb_val_samples=None, class_weight={}, max_q_size=10)\n\n\n\n\n\u5229\u7528Python\u7684\u751f\u6210\u5668\uff0c\u9010\u4e2a\u751f\u6210\u6570\u636e\u7684batch\u5e76\u8fdb\u884c\u8bad\u7ec3\u3002\u751f\u6210\u5668\u4e0e\u6a21\u578b\u5c06\u5e76\u884c\u6267\u884c\u4ee5\u63d0\u9ad8\u6548\u7387\u3002\u4f8b\u5982\uff0c\u8be5\u51fd\u6570\u5141\u8bb8\u6211\u4eec\u5728CPU\u4e0a\u8fdb\u884c\u5b9e\u65f6\u7684\u6570\u636e\u63d0\u5347\uff0c\u540c\u65f6\u5728GPU\u4e0a\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\n\n\n\u51fd\u6570\u7684\u53c2\u6570\u662f\uff1a\n\n\n\n\n\n\ngenerator\uff1a\u751f\u6210\u5668\u51fd\u6570\uff0c\u751f\u6210\u5668\u7684\u8f93\u51fa\u5e94\u8be5\u4e3a\uff1a\n\n\n\n\n\n\n\u4e00\u4e2a\u5f62\u5982\uff08inputs\uff0ctargets\uff09\u7684tuple\n\n\n\n\n\n\n\u4e00\u4e2a\u5f62\u5982\uff08inputs, targets,sample_weight\uff09\u7684tuple\u3002\u6240\u6709\u7684\u8fd4\u56de\u503c\u90fd\u5e94\u8be5\u5305\u542b\u76f8\u540c\u6570\u76ee\u7684\u6837\u672c\u3002\u751f\u6210\u5668\u5c06\u65e0\u9650\u5728\u6570\u636e\u96c6\u4e0a\u5faa\u73af\u3002\u6bcf\u4e2aepoch\u4ee5\u7ecf\u8fc7\u6a21\u578b\u7684\u6837\u672c\u6570\u8fbe\u5230\nsamples_per_epoch\n\u65f6\uff0c\u8bb0\u4e00\u4e2aepoch\u7ed3\u675f\n\n\n\n\n\n\n\n\n\n\nsamples_per_epoch\uff1a\u6574\u6570\uff0c\u5f53\u6a21\u578b\u5904\u7406\u7684\u6837\u672c\u8fbe\u5230\u6b64\u6570\u76ee\u65f6\u8ba1\u4e00\u4e2aepoch\u7ed3\u675f\uff0c\u6267\u884c\u4e0b\u4e00\u4e2aepoch\n\n\n\n\n\n\nverbose\uff1a\u65e5\u5fd7\u663e\u793a\uff0c0\u4e3a\u4e0d\u5728\u6807\u51c6\u8f93\u51fa\u6d41\u8f93\u51fa\u65e5\u5fd7\u4fe1\u606f\uff0c1\u4e3a\u8f93\u51fa\u8fdb\u5ea6\u6761\u8bb0\u5f55\uff0c2\u4e3a\u6bcf\u4e2aepoch\u8f93\u51fa\u4e00\u884c\u8bb0\u5f55\n\n\n\n\n\n\nvalidation_data\uff1a\u5177\u6709\u4ee5\u4e0b\u4e09\u79cd\u5f62\u5f0f\u4e4b\u4e00\n\n\n\n\n\n\n\u751f\u6210\u9a8c\u8bc1\u96c6\u7684\u751f\u6210\u5668\n\n\n\n\n\n\n\u4e00\u4e2a\u5f62\u5982\uff08inputs,targets\uff09\u7684tuple\n\n\n\n\n\n\n\u4e00\u4e2a\u5f62\u5982\uff08inputs,targets\uff0csample_weights\uff09\u7684tuple\n\n\n\n\n\n\n\n\n\n\nnb_val_samples\uff1a\u4ec5\u5f53\nvalidation_data\n\u662f\u751f\u6210\u5668\u65f6\u4f7f\u7528\uff0c\u7528\u4ee5\u9650\u5236\u5728\u6bcf\u4e2aepoch\u7ed3\u675f\u65f6\u7528\u6765\u9a8c\u8bc1\u6a21\u578b\u7684\u9a8c\u8bc1\u96c6\u6837\u672c\u6570\uff0c\u529f\u80fd\u7c7b\u4f3c\u4e8e\nsamples_per_epoch\n\n\n\n\n\n\nmax_q_size\uff1a\u751f\u6210\u5668\u961f\u5217\u7684\u6700\u5927\u5bb9\u91cf\n\n\n\n\n\n\n\u51fd\u6570\u8fd4\u56de\u4e00\u4e2a\nHistory\n\u5bf9\u8c61\n\n\n\u4f8b\u5b50\n\n\ndef generate_arrays_from_file(path):\n    while 1:\n    f = open(path)\n    for line in f:\n        # create numpy arrays of input data\n        # and labels, from each line in the file\n        x, y = process_line(line)\n        yield (x, y)\n    f.close()\n\nmodel.fit_generator(generate_arrays_from_file('/my_file.txt'),\n        samples_per_epoch=10000, nb_epoch=10)\n\n\n\n\n\n\nevaluate_generator\n\n\nevaluate_generator(self, generator, val_samples, max_q_size=10)\n\n\n\n\n\u672c\u51fd\u6570\u4f7f\u7528\u4e00\u4e2a\u751f\u6210\u5668\u4f5c\u4e3a\u6570\u636e\u6e90\uff0c\u6765\u8bc4\u4f30\u6a21\u578b\uff0c\u751f\u6210\u5668\u5e94\u8fd4\u56de\u4e0e\ntest_on_batch\n\u7684\u8f93\u5165\u6570\u636e\u76f8\u540c\u7c7b\u578b\u7684\u6570\u636e\u3002\n\n\n\u51fd\u6570\u7684\u53c2\u6570\u662f\uff1a\n\n\n\n\n\n\ngenerator\uff1a\u751f\u6210\u8f93\u5165batch\u6570\u636e\u7684\u751f\u6210\u5668\n\n\n\n\n\n\nval_samples\uff1a\u751f\u6210\u5668\u5e94\u8be5\u8fd4\u56de\u7684\u603b\u6837\u672c\u6570\n\n\n\n\n\n\nmax_q_size\uff1a\u751f\u6210\u5668\u961f\u5217\u7684\u6700\u5927\u5bb9\u91cf\n\n\n\n\n\n\nnb_worker\uff1a\u4f7f\u7528\u57fa\u4e8e\u8fdb\u7a0b\u7684\u591a\u7ebf\u7a0b\u5904\u7406\u65f6\u7684\u8fdb\u7a0b\u6570\n\n\n\n\n\n\npickle_safe\uff1a\u82e5\u8bbe\u7f6e\u4e3aTrue\uff0c\u5219\u4f7f\u7528\u57fa\u4e8e\u8fdb\u7a0b\u7684\u7ebf\u7a0b\u3002\u6ce8\u610f\u56e0\u4e3a\u5b83\u7684\u5b9e\u73b0\u4f9d\u8d56\u4e8e\u591a\u8fdb\u7a0b\u5904\u7406\uff0c\u4e0d\u53ef\u4f20\u9012\u4e0d\u53efpickle\u7684\u53c2\u6570\u5230\u751f\u6210\u5668\u4e2d\uff0c\u56e0\u4e3a\u5b83\u4eec\u4e0d\u80fd\u8f7b\u6613\u7684\u4f20\u9012\u5230\u5b50\u8fdb\u7a0b\u4e2d\u3002\n\n\n\n\n\n\n\n\npredict_generator\n\n\npredict_generator(self, generator, val_samples, max_q_size=10, nb_worker=1, pickle_safe=False)\n\n\n\n\n\u4ece\u4e00\u4e2a\u751f\u6210\u5668\u4e0a\u83b7\u53d6\u6570\u636e\u5e76\u8fdb\u884c\u9884\u6d4b\uff0c\u751f\u6210\u5668\u5e94\u8fd4\u56de\u4e0e\npredict_on_batch\n\u8f93\u5165\u7c7b\u4f3c\u7684\u6570\u636e\n\n\n\u51fd\u6570\u7684\u53c2\u6570\u662f\uff1a\n\n\n\n\n\n\ngenerator\uff1a\u751f\u6210\u8f93\u5165batch\u6570\u636e\u7684\u751f\u6210\u5668\n\n\n\n\n\n\nval_samples\uff1a\u751f\u6210\u5668\u5e94\u8be5\u8fd4\u56de\u7684\u603b\u6837\u672c\u6570\n\n\n\n\n\n\nmax_q_size\uff1a\u751f\u6210\u5668\u961f\u5217\u7684\u6700\u5927\u5bb9\u91cf\n\n\n\n\n\n\nnb_worker\uff1a\u4f7f\u7528\u57fa\u4e8e\u8fdb\u7a0b\u7684\u591a\u7ebf\u7a0b\u5904\u7406\u65f6\u7684\u8fdb\u7a0b\u6570\n\n\n\n\n\n\npickle_safe\uff1a\u82e5\u8bbe\u7f6e\u4e3aTrue\uff0c\u5219\u4f7f\u7528\u57fa\u4e8e\u8fdb\u7a0b\u7684\u7ebf\u7a0b\u3002\u6ce8\u610f\u56e0\u4e3a\u5b83\u7684\u5b9e\u73b0\u4f9d\u8d56\u4e8e\u591a\u8fdb\u7a0b\u5904\u7406\uff0c\u4e0d\u53ef\u4f20\u9012\u4e0d\u53efpickle\u7684\u53c2\u6570\u5230\u751f\u6210\u5668\u4e2d\uff0c\u56e0\u4e3a\u5b83\u4eec\u4e0d\u80fd\u8f7b\u6613\u7684\u4f20\u9012\u5230\u5b50\u8fdb\u7a0b\u4e2d\u3002\n\n\n\n\n\n\n\n\nget_layer\n\n\nget_layer(self, name=None, index=None)\n\n\n\n\n\u672c\u51fd\u6570\u4f9d\u636e\u6a21\u578b\u4e2d\u5c42\u7684\u4e0b\u6807\u6216\u540d\u5b57\u83b7\u5f97\u5c42\u5bf9\u8c61\uff0c\u6cdb\u578b\u6a21\u578b\u4e2d\u5c42\u7684\u4e0b\u6807\u4f9d\u636e\u81ea\u5e95\u5411\u4e0a\uff0c\u6c34\u5e73\u904d\u5386\u7684\u987a\u5e8f\u3002\n\n\n\n\n\n\nname\uff1a\u5b57\u7b26\u4e32\uff0c\u5c42\u7684\u540d\u5b57\n\n\n\n\n\n\nindex\uff1a \u6574\u6570\uff0c\u5c42\u7684\u4e0b\u6807\n\n\n\n\n\n\n\u51fd\u6570\u7684\u8fd4\u56de\u503c\u662f\u5c42\u5bf9\u8c61", 
            "title": "\u6cdb\u578b\u6a21\u578b"
        }, 
        {
            "location": "/models/model/#_1", 
            "text": "\u4e3a\u4ec0\u4e48\u53eb\u201c\u6cdb\u578b\u6a21\u578b\u201d\uff0c\u8bf7\u67e5\u770b \u4e00\u4e9b\u57fa\u672c\u6982\u5ff5  Keras\u7684\u6cdb\u578b\u6a21\u578b\u4e3a Model \uff0c\u5373\u5e7f\u4e49\u7684\u62e5\u6709\u8f93\u5165\u548c\u8f93\u51fa\u7684\u6a21\u578b\uff0c\u6211\u4eec\u4f7f\u7528 Model \u6765\u521d\u59cb\u5316\u4e00\u4e2a\u6cdb\u578b\u6a21\u578b  from keras.models import Model\nfrom keras.layers import Input, Dense\n\na = Input(shape=(32,))\nb = Dense(32)(a)\nmodel = Model(input=a, output=b)  \u5728\u8fd9\u91cc\uff0c\u6211\u4eec\u7684\u6a21\u578b\u4ee5 a \u4e3a\u8f93\u5165\uff0c\u4ee5 b \u4e3a\u8f93\u51fa\uff0c\u540c\u6837\u6211\u4eec\u53ef\u4ee5\u6784\u9020\u62e5\u6709\u591a\u8f93\u5165\u548c\u591a\u8f93\u51fa\u7684\u6a21\u578b  model = Model(input=[a1, a2], output=[b1, b3, b3])", 
            "title": "\u6cdb\u578b\u6a21\u578b\u63a5\u53e3"
        }, 
        {
            "location": "/models/model/#model", 
            "text": "model.layers \uff1a\u7ec4\u6210\u6a21\u578b\u56fe\u7684\u5404\u4e2a\u5c42  model.inputs \uff1a\u6a21\u578b\u7684\u8f93\u5165\u5f20\u91cf\u5217\u8868  model.outputs \uff1a\u6a21\u578b\u7684\u8f93\u51fa\u5f20\u91cf\u5217\u8868", 
            "title": "\u5e38\u7528Model\u5c5e\u6027"
        }, 
        {
            "location": "/models/model/#model_1", 
            "text": "", 
            "title": "Model\u6a21\u578b\u65b9\u6cd5"
        }, 
        {
            "location": "/models/model/#compile", 
            "text": "compile(self, optimizer, loss, metrics=[], loss_weights=None, sample_weight_mode=None)  \u672c\u51fd\u6570\u7f16\u8bd1\u6a21\u578b\u4ee5\u4f9b\u8bad\u7ec3\uff0c\u53c2\u6570\u6709    optimizer\uff1a\u4f18\u5316\u5668\uff0c\u4e3a\u9884\u5b9a\u4e49\u4f18\u5316\u5668\u540d\u6216\u4f18\u5316\u5668\u5bf9\u8c61\uff0c\u53c2\u8003 \u4f18\u5316\u5668    loss\uff1a\u76ee\u6807\u51fd\u6570\uff0c\u4e3a\u9884\u5b9a\u4e49\u635f\u5931\u51fd\u6570\u540d\u6216\u4e00\u4e2a\u76ee\u6807\u51fd\u6570\uff0c\u53c2\u8003 \u76ee\u6807\u51fd\u6570    metrics\uff1a\u5217\u8868\uff0c\u5305\u542b\u8bc4\u4f30\u6a21\u578b\u5728\u8bad\u7ec3\u548c\u6d4b\u8bd5\u65f6\u7684\u6027\u80fd\u7684\u6307\u6807\uff0c\u5178\u578b\u7528\u6cd5\u662f metrics=['accuracy'] \u5982\u679c\u8981\u5728\u591a\u8f93\u51fa\u6a21\u578b\u4e2d\u4e3a\u4e0d\u540c\u7684\u8f93\u51fa\u6307\u5b9a\u4e0d\u540c\u7684\u6307\u6807\uff0c\u53ef\u50cf\u8be5\u53c2\u6570\u4f20\u9012\u4e00\u4e2a\u5b57\u5178\uff0c\u4f8b\u5982 metrics={'ouput_a': 'accuracy'}    sample_weight_mode\uff1a\u5982\u679c\u4f60\u9700\u8981\u6309\u65f6\u95f4\u6b65\u4e3a\u6837\u672c\u8d4b\u6743\uff082D\u6743\u77e9\u9635\uff09\uff0c\u5c06\u8be5\u503c\u8bbe\u4e3a\u201ctemporal\u201d\u3002\u9ed8\u8ba4\u4e3a\u201cNone\u201d\uff0c\u4ee3\u8868\u6309\u6837\u672c\u8d4b\u6743\uff081D\u6743\uff09\u3002\u5982\u679c\u6a21\u578b\u6709\u591a\u4e2a\u8f93\u51fa\uff0c\u53ef\u4ee5\u5411\u8be5\u53c2\u6570\u4f20\u5165\u6307\u5b9asample_weight_mode\u7684\u5b57\u5178\u6216\u5217\u8868\u3002\u5728\u4e0b\u9762 fit \u51fd\u6570\u7684\u89e3\u91ca\u4e2d\u6709\u76f8\u5173\u7684\u53c2\u8003\u5185\u5bb9\u3002    kwargs\uff1a\u4f7f\u7528TensorFlow\u4f5c\u4e3a\u540e\u7aef\u8bf7\u5ffd\u7565\u8be5\u53c2\u6570\uff0c\u82e5\u4f7f\u7528Theano\u4f5c\u4e3a\u540e\u7aef\uff0ckwargs\u7684\u503c\u5c06\u4f1a\u4f20\u9012\u7ed9 K.function    \u3010Tips\u3011\u5982\u679c\u4f60\u53ea\u662f\u8f7d\u5165\u6a21\u578b\u5e76\u5229\u7528\u5176predict\uff0c\u53ef\u4ee5\u4e0d\u7528\u8fdb\u884ccompile\u3002\u5728Keras\u4e2d\uff0ccompile\u4e3b\u8981\u5b8c\u6210\u635f\u5931\u51fd\u6570\u548c\u4f18\u5316\u5668\u7684\u4e00\u4e9b\u914d\u7f6e\uff0c\u662f\u4e3a\u8bad\u7ec3\u670d\u52a1\u7684\u3002predict\u4f1a\u5728\u5185\u90e8\u8fdb\u884c\u7b26\u53f7\u51fd\u6570\u7684\u7f16\u8bd1\u5de5\u4f5c\uff08\u901a\u8fc7\u8c03\u7528_make_predict_function\u751f\u6210\u51fd\u6570\uff09\u3010@\u767d\u83dc\uff0c@\u6211\u662f\u5c0f\u5c06\u3011", 
            "title": "compile"
        }, 
        {
            "location": "/models/model/#fit", 
            "text": "fit(self, x, y, batch_size=32, nb_epoch=10, verbose=1, callbacks=[], validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None)  \u672c\u51fd\u6570\u7528\u4ee5\u8bad\u7ec3\u6a21\u578b\uff0c\u53c2\u6570\u6709\uff1a    x\uff1a\u8f93\u5165\u6570\u636e\u3002\u5982\u679c\u6a21\u578b\u53ea\u6709\u4e00\u4e2a\u8f93\u5165\uff0c\u90a3\u4e48x\u7684\u7c7b\u578b\u662fnumpy array\uff0c\u5982\u679c\u6a21\u578b\u6709\u591a\u4e2a\u8f93\u5165\uff0c\u90a3\u4e48x\u7684\u7c7b\u578b\u5e94\u5f53\u4e3alist\uff0clist\u7684\u5143\u7d20\u662f\u5bf9\u5e94\u4e8e\u5404\u4e2a\u8f93\u5165\u7684numpy array\u3002\u5982\u679c\u6a21\u578b\u7684\u6bcf\u4e2a\u8f93\u5165\u90fd\u6709\u540d\u5b57\uff0c\u5219\u53ef\u4ee5\u4f20\u5165\u4e00\u4e2a\u5b57\u5178\uff0c\u5c06\u8f93\u5165\u540d\u4e0e\u5176\u8f93\u5165\u6570\u636e\u5bf9\u5e94\u8d77\u6765\u3002    y\uff1a\u6807\u7b7e\uff0cnumpy array\u3002\u5982\u679c\u6a21\u578b\u6709\u591a\u4e2a\u8f93\u51fa\uff0c\u53ef\u4ee5\u4f20\u5165\u4e00\u4e2anumpy array\u7684list\u3002\u5982\u679c\u6a21\u578b\u7684\u8f93\u51fa\u62e5\u6709\u540d\u5b57\uff0c\u5219\u53ef\u4ee5\u4f20\u5165\u4e00\u4e2a\u5b57\u5178\uff0c\u5c06\u8f93\u51fa\u540d\u4e0e\u5176\u6807\u7b7e\u5bf9\u5e94\u8d77\u6765\u3002    batch_size\uff1a\u6574\u6570\uff0c\u6307\u5b9a\u8fdb\u884c\u68af\u5ea6\u4e0b\u964d\u65f6\u6bcf\u4e2abatch\u5305\u542b\u7684\u6837\u672c\u6570\u3002\u8bad\u7ec3\u65f6\u4e00\u4e2abatch\u7684\u6837\u672c\u4f1a\u88ab\u8ba1\u7b97\u4e00\u6b21\u68af\u5ea6\u4e0b\u964d\uff0c\u4f7f\u76ee\u6807\u51fd\u6570\u4f18\u5316\u4e00\u6b65\u3002    nb_epoch\uff1a\u6574\u6570\uff0c\u8bad\u7ec3\u7684\u8f6e\u6570\uff0c\u8bad\u7ec3\u6570\u636e\u5c06\u4f1a\u88ab\u904d\u5386nb_epoch\u6b21\u3002Keras\u4e2dnb\u5f00\u5934\u7684\u53d8\u91cf\u5747\u4e3a\"number of\"\u7684\u610f\u601d    verbose\uff1a\u65e5\u5fd7\u663e\u793a\uff0c0\u4e3a\u4e0d\u5728\u6807\u51c6\u8f93\u51fa\u6d41\u8f93\u51fa\u65e5\u5fd7\u4fe1\u606f\uff0c1\u4e3a\u8f93\u51fa\u8fdb\u5ea6\u6761\u8bb0\u5f55\uff0c2\u4e3a\u6bcf\u4e2aepoch\u8f93\u51fa\u4e00\u884c\u8bb0\u5f55    callbacks\uff1alist\uff0c\u5176\u4e2d\u7684\u5143\u7d20\u662f keras.callbacks.Callback \u7684\u5bf9\u8c61\u3002\u8fd9\u4e2alist\u4e2d\u7684\u56de\u8c03\u51fd\u6570\u5c06\u4f1a\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u9002\u5f53\u65f6\u673a\u88ab\u8c03\u7528\uff0c\u53c2\u8003 \u56de\u8c03\u51fd\u6570    validation_split\uff1a0~1\u4e4b\u95f4\u7684\u6d6e\u70b9\u6570\uff0c\u7528\u6765\u6307\u5b9a\u8bad\u7ec3\u96c6\u7684\u4e00\u5b9a\u6bd4\u4f8b\u6570\u636e\u4f5c\u4e3a\u9a8c\u8bc1\u96c6\u3002\u9a8c\u8bc1\u96c6\u5c06\u4e0d\u53c2\u4e0e\u8bad\u7ec3\uff0c\u5e76\u5728\u6bcf\u4e2aepoch\u7ed3\u675f\u540e\u6d4b\u8bd5\u7684\u6a21\u578b\u7684\u6307\u6807\uff0c\u5982\u635f\u5931\u51fd\u6570\u3001\u7cbe\u786e\u5ea6\u7b49\u3002    validation_data\uff1a\u5f62\u5f0f\u4e3a\uff08X\uff0cy\uff09\u6216\uff08X\uff0cy\uff0csample_weights\uff09\u7684tuple\uff0c\u662f\u6307\u5b9a\u7684\u9a8c\u8bc1\u96c6\u3002\u6b64\u53c2\u6570\u5c06\u8986\u76d6validation_spilt\u3002    shuffle\uff1a\u5e03\u5c14\u503c\uff0c\u8868\u793a\u662f\u5426\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u6bcf\u4e2aepoch\u524d\u968f\u673a\u6253\u4e71\u8f93\u5165\u6837\u672c\u7684\u987a\u5e8f\u3002    class_weight\uff1a\u5b57\u5178\uff0c\u5c06\u4e0d\u540c\u7684\u7c7b\u522b\u6620\u5c04\u4e3a\u4e0d\u540c\u7684\u6743\u503c\uff0c\u8be5\u53c2\u6570\u7528\u6765\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u8c03\u6574\u635f\u5931\u51fd\u6570\uff08\u53ea\u80fd\u7528\u4e8e\u8bad\u7ec3\uff09\u3002\u8be5\u53c2\u6570\u5728\u5904\u7406\u975e\u5e73\u8861\u7684\u8bad\u7ec3\u6570\u636e\uff08\u67d0\u4e9b\u7c7b\u7684\u8bad\u7ec3\u6837\u672c\u6570\u5f88\u5c11\uff09\u65f6\uff0c\u53ef\u4ee5\u4f7f\u5f97\u635f\u5931\u51fd\u6570\u5bf9\u6837\u672c\u6570\u4e0d\u8db3\u7684\u6570\u636e\u66f4\u52a0\u5173\u6ce8\u3002    sample_weight\uff1a\u6743\u503c\u7684numpy array\uff0c\u7528\u4e8e\u5728\u8bad\u7ec3\u65f6\u8c03\u6574\u635f\u5931\u51fd\u6570\uff08\u4ec5\u7528\u4e8e\u8bad\u7ec3\uff09\u3002\u53ef\u4ee5\u4f20\u9012\u4e00\u4e2a1D\u7684\u4e0e\u6837\u672c\u7b49\u957f\u7684\u5411\u91cf\u7528\u4e8e\u5bf9\u6837\u672c\u8fdb\u884c1\u5bf91\u7684\u52a0\u6743\uff0c\u6216\u8005\u5728\u9762\u5bf9\u65f6\u5e8f\u6570\u636e\u65f6\uff0c\u4f20\u9012\u4e00\u4e2a\u7684\u5f62\u5f0f\u4e3a\uff08samples\uff0csequence_length\uff09\u7684\u77e9\u9635\u6765\u4e3a\u6bcf\u4e2a\u65f6\u95f4\u6b65\u4e0a\u7684\u6837\u672c\u8d4b\u4e0d\u540c\u7684\u6743\u3002\u8fd9\u79cd\u60c5\u51b5\u4e0b\u8bf7\u786e\u5b9a\u5728\u7f16\u8bd1\u6a21\u578b\u65f6\u6dfb\u52a0\u4e86 sample_weight_mode='temporal' \u3002    fit \u51fd\u6570\u8fd4\u56de\u4e00\u4e2a History \u7684\u5bf9\u8c61\uff0c\u5176 History.history \u5c5e\u6027\u8bb0\u5f55\u4e86\u635f\u5931\u51fd\u6570\u548c\u5176\u4ed6\u6307\u6807\u7684\u6570\u503c\u968fepoch\u53d8\u5316\u7684\u60c5\u51b5\uff0c\u5982\u679c\u6709\u9a8c\u8bc1\u96c6\u7684\u8bdd\uff0c\u4e5f\u5305\u542b\u4e86\u9a8c\u8bc1\u96c6\u7684\u8fd9\u4e9b\u6307\u6807\u53d8\u5316\u60c5\u51b5", 
            "title": "fit"
        }, 
        {
            "location": "/models/model/#evaluate", 
            "text": "evaluate(self, x, y, batch_size=32, verbose=1, sample_weight=None)  \u672c\u51fd\u6570\u6309batch\u8ba1\u7b97\u5728\u67d0\u4e9b\u8f93\u5165\u6570\u636e\u4e0a\u6a21\u578b\u7684\u8bef\u5dee\uff0c\u5176\u53c2\u6570\u6709\uff1a    x\uff1a\u8f93\u5165\u6570\u636e\uff0c\u4e0e fit \u4e00\u6837\uff0c\u662fnumpy array\u6216numpy array\u7684list    y\uff1a\u6807\u7b7e\uff0cnumpy array    batch_size\uff1a\u6574\u6570\uff0c\u542b\u4e49\u540c fit \u7684\u540c\u540d\u53c2\u6570    verbose\uff1a\u542b\u4e49\u540c fit \u7684\u540c\u540d\u53c2\u6570\uff0c\u4f46\u53ea\u80fd\u53d60\u62161    sample_weight\uff1anumpy array\uff0c\u542b\u4e49\u540c fit \u7684\u540c\u540d\u53c2\u6570    \u672c\u51fd\u6570\u8fd4\u56de\u4e00\u4e2a\u6d4b\u8bd5\u8bef\u5dee\u7684\u6807\u91cf\u503c\uff08\u5982\u679c\u6a21\u578b\u6ca1\u6709\u5176\u4ed6\u8bc4\u4ef7\u6307\u6807\uff09\uff0c\u6216\u4e00\u4e2a\u6807\u91cf\u7684list\uff08\u5982\u679c\u6a21\u578b\u8fd8\u6709\u5176\u4ed6\u7684\u8bc4\u4ef7\u6307\u6807\uff09\u3002 model.metrics_names \u5c06\u7ed9\u51falist\u4e2d\u5404\u4e2a\u503c\u7684\u542b\u4e49\u3002  \u5982\u679c\u6ca1\u6709\u7279\u6b8a\u8bf4\u660e\uff0c\u4ee5\u4e0b\u51fd\u6570\u7684\u53c2\u6570\u5747\u4fdd\u6301\u4e0e fit \u7684\u540c\u540d\u53c2\u6570\u76f8\u540c\u7684\u542b\u4e49  \u5982\u679c\u6ca1\u6709\u7279\u6b8a\u8bf4\u660e\uff0c\u4ee5\u4e0b\u51fd\u6570\u7684verbose\u53c2\u6570\uff08\u5982\u679c\u6709\uff09\u5747\u53ea\u80fd\u53d60\u62161", 
            "title": "evaluate"
        }, 
        {
            "location": "/models/model/#predict", 
            "text": "predict(self, x, batch_size=32, verbose=0)  \u672c\u51fd\u6570\u6309batch\u83b7\u5f97\u8f93\u5165\u6570\u636e\u5bf9\u5e94\u7684\u8f93\u51fa\uff0c\u5176\u53c2\u6570\u6709\uff1a  \u51fd\u6570\u7684\u8fd4\u56de\u503c\u662f\u9884\u6d4b\u503c\u7684numpy array", 
            "title": "predict"
        }, 
        {
            "location": "/models/model/#train_on_batch", 
            "text": "train_on_batch(self, x, y, class_weight=None, sample_weight=None)  \u672c\u51fd\u6570\u5728\u4e00\u4e2abatch\u7684\u6570\u636e\u4e0a\u8fdb\u884c\u4e00\u6b21\u53c2\u6570\u66f4\u65b0  \u51fd\u6570\u8fd4\u56de\u8bad\u7ec3\u8bef\u5dee\u7684\u6807\u91cf\u503c\u6216\u6807\u91cf\u503c\u7684list\uff0c\u4e0e evaluate \u7684\u60c5\u5f62\u76f8\u540c\u3002", 
            "title": "train_on_batch"
        }, 
        {
            "location": "/models/model/#test_on_batch", 
            "text": "test_on_batch(self, x, y, sample_weight=None)  \u672c\u51fd\u6570\u5728\u4e00\u4e2abatch\u7684\u6837\u672c\u4e0a\u5bf9\u6a21\u578b\u8fdb\u884c\u8bc4\u4f30  \u51fd\u6570\u7684\u8fd4\u56de\u4e0e evaluate \u7684\u60c5\u5f62\u76f8\u540c", 
            "title": "test_on_batch"
        }, 
        {
            "location": "/models/model/#predict_on_batch", 
            "text": "predict_on_batch(self, x)  \u672c\u51fd\u6570\u5728\u4e00\u4e2abatch\u7684\u6837\u672c\u4e0a\u5bf9\u6a21\u578b\u8fdb\u884c\u6d4b\u8bd5  \u51fd\u6570\u8fd4\u56de\u6a21\u578b\u5728\u4e00\u4e2abatch\u4e0a\u7684\u9884\u6d4b\u7ed3\u679c", 
            "title": "predict_on_batch"
        }, 
        {
            "location": "/models/model/#fit_generator", 
            "text": "fit_generator(self, generator, samples_per_epoch, nb_epoch, verbose=1, callbacks=[], validation_data=None, nb_val_samples=None, class_weight={}, max_q_size=10)  \u5229\u7528Python\u7684\u751f\u6210\u5668\uff0c\u9010\u4e2a\u751f\u6210\u6570\u636e\u7684batch\u5e76\u8fdb\u884c\u8bad\u7ec3\u3002\u751f\u6210\u5668\u4e0e\u6a21\u578b\u5c06\u5e76\u884c\u6267\u884c\u4ee5\u63d0\u9ad8\u6548\u7387\u3002\u4f8b\u5982\uff0c\u8be5\u51fd\u6570\u5141\u8bb8\u6211\u4eec\u5728CPU\u4e0a\u8fdb\u884c\u5b9e\u65f6\u7684\u6570\u636e\u63d0\u5347\uff0c\u540c\u65f6\u5728GPU\u4e0a\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3  \u51fd\u6570\u7684\u53c2\u6570\u662f\uff1a    generator\uff1a\u751f\u6210\u5668\u51fd\u6570\uff0c\u751f\u6210\u5668\u7684\u8f93\u51fa\u5e94\u8be5\u4e3a\uff1a    \u4e00\u4e2a\u5f62\u5982\uff08inputs\uff0ctargets\uff09\u7684tuple    \u4e00\u4e2a\u5f62\u5982\uff08inputs, targets,sample_weight\uff09\u7684tuple\u3002\u6240\u6709\u7684\u8fd4\u56de\u503c\u90fd\u5e94\u8be5\u5305\u542b\u76f8\u540c\u6570\u76ee\u7684\u6837\u672c\u3002\u751f\u6210\u5668\u5c06\u65e0\u9650\u5728\u6570\u636e\u96c6\u4e0a\u5faa\u73af\u3002\u6bcf\u4e2aepoch\u4ee5\u7ecf\u8fc7\u6a21\u578b\u7684\u6837\u672c\u6570\u8fbe\u5230 samples_per_epoch \u65f6\uff0c\u8bb0\u4e00\u4e2aepoch\u7ed3\u675f      samples_per_epoch\uff1a\u6574\u6570\uff0c\u5f53\u6a21\u578b\u5904\u7406\u7684\u6837\u672c\u8fbe\u5230\u6b64\u6570\u76ee\u65f6\u8ba1\u4e00\u4e2aepoch\u7ed3\u675f\uff0c\u6267\u884c\u4e0b\u4e00\u4e2aepoch    verbose\uff1a\u65e5\u5fd7\u663e\u793a\uff0c0\u4e3a\u4e0d\u5728\u6807\u51c6\u8f93\u51fa\u6d41\u8f93\u51fa\u65e5\u5fd7\u4fe1\u606f\uff0c1\u4e3a\u8f93\u51fa\u8fdb\u5ea6\u6761\u8bb0\u5f55\uff0c2\u4e3a\u6bcf\u4e2aepoch\u8f93\u51fa\u4e00\u884c\u8bb0\u5f55    validation_data\uff1a\u5177\u6709\u4ee5\u4e0b\u4e09\u79cd\u5f62\u5f0f\u4e4b\u4e00    \u751f\u6210\u9a8c\u8bc1\u96c6\u7684\u751f\u6210\u5668    \u4e00\u4e2a\u5f62\u5982\uff08inputs,targets\uff09\u7684tuple    \u4e00\u4e2a\u5f62\u5982\uff08inputs,targets\uff0csample_weights\uff09\u7684tuple      nb_val_samples\uff1a\u4ec5\u5f53 validation_data \u662f\u751f\u6210\u5668\u65f6\u4f7f\u7528\uff0c\u7528\u4ee5\u9650\u5236\u5728\u6bcf\u4e2aepoch\u7ed3\u675f\u65f6\u7528\u6765\u9a8c\u8bc1\u6a21\u578b\u7684\u9a8c\u8bc1\u96c6\u6837\u672c\u6570\uff0c\u529f\u80fd\u7c7b\u4f3c\u4e8e samples_per_epoch    max_q_size\uff1a\u751f\u6210\u5668\u961f\u5217\u7684\u6700\u5927\u5bb9\u91cf    \u51fd\u6570\u8fd4\u56de\u4e00\u4e2a History \u5bf9\u8c61  \u4f8b\u5b50  def generate_arrays_from_file(path):\n    while 1:\n    f = open(path)\n    for line in f:\n        # create numpy arrays of input data\n        # and labels, from each line in the file\n        x, y = process_line(line)\n        yield (x, y)\n    f.close()\n\nmodel.fit_generator(generate_arrays_from_file('/my_file.txt'),\n        samples_per_epoch=10000, nb_epoch=10)", 
            "title": "fit_generator"
        }, 
        {
            "location": "/models/model/#evaluate_generator", 
            "text": "evaluate_generator(self, generator, val_samples, max_q_size=10)  \u672c\u51fd\u6570\u4f7f\u7528\u4e00\u4e2a\u751f\u6210\u5668\u4f5c\u4e3a\u6570\u636e\u6e90\uff0c\u6765\u8bc4\u4f30\u6a21\u578b\uff0c\u751f\u6210\u5668\u5e94\u8fd4\u56de\u4e0e test_on_batch \u7684\u8f93\u5165\u6570\u636e\u76f8\u540c\u7c7b\u578b\u7684\u6570\u636e\u3002  \u51fd\u6570\u7684\u53c2\u6570\u662f\uff1a    generator\uff1a\u751f\u6210\u8f93\u5165batch\u6570\u636e\u7684\u751f\u6210\u5668    val_samples\uff1a\u751f\u6210\u5668\u5e94\u8be5\u8fd4\u56de\u7684\u603b\u6837\u672c\u6570    max_q_size\uff1a\u751f\u6210\u5668\u961f\u5217\u7684\u6700\u5927\u5bb9\u91cf    nb_worker\uff1a\u4f7f\u7528\u57fa\u4e8e\u8fdb\u7a0b\u7684\u591a\u7ebf\u7a0b\u5904\u7406\u65f6\u7684\u8fdb\u7a0b\u6570    pickle_safe\uff1a\u82e5\u8bbe\u7f6e\u4e3aTrue\uff0c\u5219\u4f7f\u7528\u57fa\u4e8e\u8fdb\u7a0b\u7684\u7ebf\u7a0b\u3002\u6ce8\u610f\u56e0\u4e3a\u5b83\u7684\u5b9e\u73b0\u4f9d\u8d56\u4e8e\u591a\u8fdb\u7a0b\u5904\u7406\uff0c\u4e0d\u53ef\u4f20\u9012\u4e0d\u53efpickle\u7684\u53c2\u6570\u5230\u751f\u6210\u5668\u4e2d\uff0c\u56e0\u4e3a\u5b83\u4eec\u4e0d\u80fd\u8f7b\u6613\u7684\u4f20\u9012\u5230\u5b50\u8fdb\u7a0b\u4e2d\u3002", 
            "title": "evaluate_generator"
        }, 
        {
            "location": "/models/model/#predict_generator", 
            "text": "predict_generator(self, generator, val_samples, max_q_size=10, nb_worker=1, pickle_safe=False)  \u4ece\u4e00\u4e2a\u751f\u6210\u5668\u4e0a\u83b7\u53d6\u6570\u636e\u5e76\u8fdb\u884c\u9884\u6d4b\uff0c\u751f\u6210\u5668\u5e94\u8fd4\u56de\u4e0e predict_on_batch \u8f93\u5165\u7c7b\u4f3c\u7684\u6570\u636e  \u51fd\u6570\u7684\u53c2\u6570\u662f\uff1a    generator\uff1a\u751f\u6210\u8f93\u5165batch\u6570\u636e\u7684\u751f\u6210\u5668    val_samples\uff1a\u751f\u6210\u5668\u5e94\u8be5\u8fd4\u56de\u7684\u603b\u6837\u672c\u6570    max_q_size\uff1a\u751f\u6210\u5668\u961f\u5217\u7684\u6700\u5927\u5bb9\u91cf    nb_worker\uff1a\u4f7f\u7528\u57fa\u4e8e\u8fdb\u7a0b\u7684\u591a\u7ebf\u7a0b\u5904\u7406\u65f6\u7684\u8fdb\u7a0b\u6570    pickle_safe\uff1a\u82e5\u8bbe\u7f6e\u4e3aTrue\uff0c\u5219\u4f7f\u7528\u57fa\u4e8e\u8fdb\u7a0b\u7684\u7ebf\u7a0b\u3002\u6ce8\u610f\u56e0\u4e3a\u5b83\u7684\u5b9e\u73b0\u4f9d\u8d56\u4e8e\u591a\u8fdb\u7a0b\u5904\u7406\uff0c\u4e0d\u53ef\u4f20\u9012\u4e0d\u53efpickle\u7684\u53c2\u6570\u5230\u751f\u6210\u5668\u4e2d\uff0c\u56e0\u4e3a\u5b83\u4eec\u4e0d\u80fd\u8f7b\u6613\u7684\u4f20\u9012\u5230\u5b50\u8fdb\u7a0b\u4e2d\u3002", 
            "title": "predict_generator"
        }, 
        {
            "location": "/models/model/#get_layer", 
            "text": "get_layer(self, name=None, index=None)  \u672c\u51fd\u6570\u4f9d\u636e\u6a21\u578b\u4e2d\u5c42\u7684\u4e0b\u6807\u6216\u540d\u5b57\u83b7\u5f97\u5c42\u5bf9\u8c61\uff0c\u6cdb\u578b\u6a21\u578b\u4e2d\u5c42\u7684\u4e0b\u6807\u4f9d\u636e\u81ea\u5e95\u5411\u4e0a\uff0c\u6c34\u5e73\u904d\u5386\u7684\u987a\u5e8f\u3002    name\uff1a\u5b57\u7b26\u4e32\uff0c\u5c42\u7684\u540d\u5b57    index\uff1a \u6574\u6570\uff0c\u5c42\u7684\u4e0b\u6807    \u51fd\u6570\u7684\u8fd4\u56de\u503c\u662f\u5c42\u5bf9\u8c61", 
            "title": "get_layer"
        }, 
        {
            "location": "/layers/about_layer/", 
            "text": "\u5173\u4e8eKeras\u7684\u201c\u5c42\u201d\uff08Layer\uff09\n\n\n\u6240\u6709\u7684Keras\u5c42\u5bf9\u8c61\u90fd\u6709\u5982\u4e0b\u65b9\u6cd5\uff1a\n\n\n\n\n\n\nlayer.get_weights()\n\uff1a\u8fd4\u56de\u5c42\u7684\u6743\u91cd\uff08numpy array\uff09\n\n\n\n\n\n\nlayer.set_weights(weights)\n\uff1a\u4ecenumpy array\u4e2d\u5c06\u6743\u91cd\u52a0\u8f7d\u5230\u8be5\u5c42\u4e2d\uff0c\u8981\u6c42numpy array\u7684\u5f62\u72b6\u4e0e* \nlayer.get_weights()\n\u7684\u5f62\u72b6\u76f8\u540c\n\n\n\n\n\n\nlayer.get_config()\n\uff1a\u8fd4\u56de\u5f53\u524d\u5c42\u914d\u7f6e\u4fe1\u606f\u7684\u5b57\u5178\uff0c\u5c42\u4e5f\u53ef\u4ee5\u501f\u7531\u914d\u7f6e\u4fe1\u606f\u91cd\u6784\n\n\n\n\n\n\nfrom keras.utils.layer_utils import layer_from_config\n\nconfig = layer.get_config()\nlayer = layer_from_config(config)\n\n\n\n\n\u5982\u679c\u5c42\u4ec5\u6709\u4e00\u4e2a\u8ba1\u7b97\u8282\u70b9\uff08\u5373\u8be5\u5c42\u4e0d\u662f\u5171\u4eab\u5c42\uff09\uff0c\u5219\u53ef\u4ee5\u901a\u8fc7\u4e0b\u5217\u65b9\u6cd5\u83b7\u5f97\u8f93\u5165\u5f20\u91cf\u3001\u8f93\u51fa\u5f20\u91cf\u3001\u8f93\u5165\u6570\u636e\u7684\u5f62\u72b6\u548c\u8f93\u51fa\u6570\u636e\u7684\u5f62\u72b6\uff1a\n\n\n\n\n\n\nlayer.input\n\n\n\n\n\n\nlayer.output\n\n\n\n\n\n\nlayer.input_shape\n\n\n\n\n\n\nlayer.output_shape\n\n\n\n\n\n\n\u5982\u679c\u8be5\u5c42\u6709\u591a\u4e2a\u8ba1\u7b97\u8282\u70b9\uff08\u53c2\u8003\n\u5c42\u8ba1\u7b97\u8282\u70b9\u548c\u5171\u4eab\u5c42\n\uff09\u3002\u53ef\u4ee5\u4f7f\u7528\u4e0b\u9762\u7684\u65b9\u6cd5\n\n\n\n\n\n\nlayer.get_input_at(node_index)\n\n\n\n\n\n\nlayer.get_output_at(node_index)\n\n\n\n\n\n\nlayer.get_input_shape_at(node_index)\n\n\n\n\n\n\nlayer.get_output_shape_at(node_index)", 
            "title": "\u5173\u4e8eKeras\u5c42"
        }, 
        {
            "location": "/layers/about_layer/#keraslayer", 
            "text": "\u6240\u6709\u7684Keras\u5c42\u5bf9\u8c61\u90fd\u6709\u5982\u4e0b\u65b9\u6cd5\uff1a    layer.get_weights() \uff1a\u8fd4\u56de\u5c42\u7684\u6743\u91cd\uff08numpy array\uff09    layer.set_weights(weights) \uff1a\u4ecenumpy array\u4e2d\u5c06\u6743\u91cd\u52a0\u8f7d\u5230\u8be5\u5c42\u4e2d\uff0c\u8981\u6c42numpy array\u7684\u5f62\u72b6\u4e0e*  layer.get_weights() \u7684\u5f62\u72b6\u76f8\u540c    layer.get_config() \uff1a\u8fd4\u56de\u5f53\u524d\u5c42\u914d\u7f6e\u4fe1\u606f\u7684\u5b57\u5178\uff0c\u5c42\u4e5f\u53ef\u4ee5\u501f\u7531\u914d\u7f6e\u4fe1\u606f\u91cd\u6784    from keras.utils.layer_utils import layer_from_config\n\nconfig = layer.get_config()\nlayer = layer_from_config(config)  \u5982\u679c\u5c42\u4ec5\u6709\u4e00\u4e2a\u8ba1\u7b97\u8282\u70b9\uff08\u5373\u8be5\u5c42\u4e0d\u662f\u5171\u4eab\u5c42\uff09\uff0c\u5219\u53ef\u4ee5\u901a\u8fc7\u4e0b\u5217\u65b9\u6cd5\u83b7\u5f97\u8f93\u5165\u5f20\u91cf\u3001\u8f93\u51fa\u5f20\u91cf\u3001\u8f93\u5165\u6570\u636e\u7684\u5f62\u72b6\u548c\u8f93\u51fa\u6570\u636e\u7684\u5f62\u72b6\uff1a    layer.input    layer.output    layer.input_shape    layer.output_shape    \u5982\u679c\u8be5\u5c42\u6709\u591a\u4e2a\u8ba1\u7b97\u8282\u70b9\uff08\u53c2\u8003 \u5c42\u8ba1\u7b97\u8282\u70b9\u548c\u5171\u4eab\u5c42 \uff09\u3002\u53ef\u4ee5\u4f7f\u7528\u4e0b\u9762\u7684\u65b9\u6cd5    layer.get_input_at(node_index)    layer.get_output_at(node_index)    layer.get_input_shape_at(node_index)    layer.get_output_shape_at(node_index)", 
            "title": "\u5173\u4e8eKeras\u7684\u201c\u5c42\u201d\uff08Layer\uff09"
        }, 
        {
            "location": "/layers/core_layer/", 
            "text": "\u5e38\u7528\u5c42\n\n\n\u5e38\u7528\u5c42\u5bf9\u5e94\u4e8ecore\u6a21\u5757\uff0ccore\u5185\u90e8\u5b9a\u4e49\u4e86\u4e00\u7cfb\u5217\u5e38\u7528\u7684\u7f51\u7edc\u5c42\uff0c\u5305\u62ec\u5168\u8fde\u63a5\u3001\u6fc0\u6d3b\u5c42\u7b49\n\n\nDense\u5c42\n\n\nkeras.layers.core.Dense(output_dim, init='glorot_uniform', activation='linear', weights=None, W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None, bias=True, input_dim=None)\n\n\n\n\nDense\u5c31\u662f\u5e38\u7528\u7684\u5168\u8fde\u63a5\u5c42\uff0c\u8fd9\u91cc\u662f\u4e00\u4e2a\u4f7f\u7528\u793a\u4f8b\uff1a\n\n\n# as first layer in a sequential model:\nmodel = Sequential()\nmodel.add(Dense(32, input_dim=16))\n# now the model will take as input arrays of shape (*, 16)\n# and output arrays of shape (*, 32)\n\n# this is equivalent to the above:\nmodel = Sequential()\nmodel.add(Dense(32, input_shape=(16,)))\n\n# after the first layer, you don't need to specify\n# the size of the input anymore:\nmodel.add(Dense(32))\n\n\n\n\n\u53c2\u6570\uff1a\n\n\n\n\n\n\noutput_dim\uff1a\u5927\u4e8e0\u7684\u6574\u6570\uff0c\u4ee3\u8868\u8be5\u5c42\u7684\u8f93\u51fa\u7ef4\u5ea6\u3002\u6a21\u578b\u4e2d\u975e\u9996\u5c42\u7684\u5168\u8fde\u63a5\u5c42\u5176\u8f93\u5165\u7ef4\u5ea6\u53ef\u4ee5\u81ea\u52a8\u63a8\u65ad\uff0c\u56e0\u6b64\u975e\u9996\u5c42\u7684\u5168\u8fde\u63a5\u5b9a\u4e49\u65f6\u4e0d\u9700\u8981\u6307\u5b9a\u8f93\u5165\u7ef4\u5ea6\u3002\n\n\n\n\n\n\ninit\uff1a\u521d\u59cb\u5316\u65b9\u6cd5\uff0c\u4e3a\u9884\u5b9a\u4e49\u521d\u59cb\u5316\u65b9\u6cd5\u540d\u7684\u5b57\u7b26\u4e32\uff0c\u6216\u7528\u4e8e\u521d\u59cb\u5316\u6743\u91cd\u7684Theano\u51fd\u6570\u3002\u8be5\u53c2\u6570\u4ec5\u5728\u4e0d\u4f20\u9012\nweights\n\u53c2\u6570\u65f6\u624d\u6709\u610f\u4e49\u3002\n\n\n\n\n\n\nactivation\uff1a\u6fc0\u6d3b\u51fd\u6570\uff0c\u4e3a\u9884\u5b9a\u4e49\u7684\u6fc0\u6d3b\u51fd\u6570\u540d\uff08\u53c2\u8003\n\u6fc0\u6d3b\u51fd\u6570\n\uff09\uff0c\u6216\u9010\u5143\u7d20\uff08element-wise\uff09\u7684Theano\u51fd\u6570\u3002\u5982\u679c\u4e0d\u6307\u5b9a\u8be5\u53c2\u6570\uff0c\u5c06\u4e0d\u4f1a\u4f7f\u7528\u4efb\u4f55\u6fc0\u6d3b\u51fd\u6570\uff08\u5373\u4f7f\u7528\u7ebf\u6027\u6fc0\u6d3b\u51fd\u6570\uff1aa(x)=x\uff09\n\n\n\n\n\n\nweights\uff1a\u6743\u503c\uff0c\u4e3anumpy array\u7684list\u3002\u8be5list\u5e94\u542b\u6709\u4e00\u4e2a\u5f62\u5982\uff08input_dim,output_dim\uff09\u7684\u6743\u91cd\u77e9\u9635\u548c\u4e00\u4e2a\u5f62\u5982(output_dim,)\u7684\u504f\u7f6e\u5411\u91cf\u3002\n\n\n\n\n\n\nW_regularizer\uff1a\u65bd\u52a0\u5728\u6743\u91cd\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a\nWeightRegularizer\n\u5bf9\u8c61\n\n\n\n\n\n\nb_regularizer\uff1a\u65bd\u52a0\u5728\u504f\u7f6e\u5411\u91cf\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a\nWeightRegularizer\n\u5bf9\u8c61\n\n\n\n\n\n\nactivity_regularizer\uff1a\u65bd\u52a0\u5728\u8f93\u51fa\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a\nActivityRegularizer\n\u5bf9\u8c61\n\n\n\n\n\n\nW_constraints\uff1a\u65bd\u52a0\u5728\u6743\u91cd\u4e0a\u7684\u7ea6\u675f\u9879\uff0c\u4e3a\nConstraints\n\u5bf9\u8c61\n\n\n\n\n\n\nb_constraints\uff1a\u65bd\u52a0\u5728\u504f\u7f6e\u4e0a\u7684\u7ea6\u675f\u9879\uff0c\u4e3a\nConstraints\n\u5bf9\u8c61\n\n\n\n\n\n\nbias\uff1a\u5e03\u5c14\u503c\uff0c\u662f\u5426\u5305\u542b\u504f\u7f6e\u5411\u91cf\uff08\u5373\u5c42\u5bf9\u8f93\u5165\u505a\u7ebf\u6027\u53d8\u6362\u8fd8\u662f\u4eff\u5c04\u53d8\u6362\uff09\n\n\n\n\n\n\ninput_dim\uff1a\u6574\u6570\uff0c\u8f93\u5165\u6570\u636e\u7684\u7ef4\u5ea6\u3002\u5f53Dense\u5c42\u4f5c\u4e3a\u7f51\u7edc\u7684\u7b2c\u4e00\u5c42\u65f6\uff0c\u5fc5\u987b\u6307\u5b9a\u8be5\u53c2\u6570\u6216\ninput_shape\n\u53c2\u6570\u3002\n\n\n\n\n\n\n\u8f93\u5165\n\n\n\u5f62\u5982(nb_samples, ..., input_dim)\u7684nD\u5f20\u91cf\uff0c\u6700\u5e38\u89c1\u7684\u60c5\u51b5\u4e3a(nb_samples, input_dim)\u76842D\u5f20\u91cf\n\n\n\u8f93\u51fa\n\n\n\u5f62\u5982(nb_samples, ..., output_dim)\u7684nD\u5f20\u91cf\uff0c\u6700\u5e38\u89c1\u7684\u60c5\u51b5\u4e3a(nb_samples, output_dim)\u76842D\u5f20\u91cf\n\n\n\n\n\n\n\n\nActivation\u5c42\n\n\n\n\nkeras.layers.core.Activation(activation)\n\n\n\n\n\u6fc0\u6d3b\u5c42\u5bf9\u4e00\u4e2a\u5c42\u7684\u8f93\u51fa\u65bd\u52a0\u6fc0\u6d3b\u51fd\u6570\n\n\n\u53c2\u6570\n\n\n\n\nactivation\uff1a\u5c06\u8981\u4f7f\u7528\u7684\u6fc0\u6d3b\u51fd\u6570\uff0c\u4e3a\u9884\u5b9a\u4e49\u6fc0\u6d3b\u51fd\u6570\u540d\u6216\u4e00\u4e2aTensorflow/Theano\u7684\u51fd\u6570\u3002\u53c2\u8003\n\u6fc0\u6d3b\u51fd\u6570\n\n\n\n\n\u8f93\u5165shape\n\n\n\u4efb\u610f\uff0c\u5f53\u4f7f\u7528\u6fc0\u6d3b\u5c42\u4f5c\u4e3a\u7b2c\u4e00\u5c42\u65f6\uff0c\u8981\u6307\u5b9a\ninput_shape\n\n\n\u8f93\u51fashape\n\n\n\u4e0e\u8f93\u5165shape\u76f8\u540c\n\n\n\n\n\n\n\n\nDropout\u5c42\n\n\n\n\nkeras.layers.core.Dropout(p)\n\n\n\n\n\u4e3a\u8f93\u5165\u6570\u636e\u65bd\u52a0Dropout\u3002Dropout\u5c06\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u6bcf\u6b21\u66f4\u65b0\u53c2\u6570\u65f6\u968f\u673a\u65ad\u5f00\u4e00\u5b9a\u767e\u5206\u6bd4\uff08p\uff09\u7684\u8f93\u5165\u795e\u7ecf\u5143\u8fde\u63a5\uff0cDropout\u5c42\u7528\u4e8e\u9632\u6b62\u8fc7\u62df\u5408\u3002\n\n\n\u53c2\u6570\n\n\n\n\np\uff1a0~1\u7684\u6d6e\u70b9\u6570\uff0c\u63a7\u5236\u9700\u8981\u65ad\u5f00\u7684\u94fe\u63a5\u7684\u6bd4\u4f8b\n\n\n\n\n\u53c2\u8003\u6587\u732e\n\n\n\n\nDropout: A Simple Way to Prevent Neural Networks from Overfitting\n\n\n\n\n\n\nFlatten\u5c42\n\n\nkeras.layers.core.Flatten()\n\n\n\n\nFlatten\u5c42\u7528\u6765\u5c06\u8f93\u5165\u201c\u538b\u5e73\u201d\uff0c\u5373\u628a\u591a\u7ef4\u7684\u8f93\u5165\u4e00\u7ef4\u5316\uff0c\u5e38\u7528\u5728\u4ece\u5377\u79ef\u5c42\u5230\u5168\u8fde\u63a5\u5c42\u7684\u8fc7\u6e21\u3002Flatten\u4e0d\u5f71\u54cdbatch\u7684\u5927\u5c0f\u3002\n\n\n\u4f8b\u5b50\n\n\nmodel = Sequential()\nmodel.add(Convolution2D(64, 3, 3, border_mode='same', input_shape=(3, 32, 32)))\n# now: model.output_shape == (None, 64, 32, 32)\n\nmodel.add(Flatten())\n# now: model.output_shape == (None, 65536)\n\n\n\n\n\n\nReshape\u5c42\n\n\nkeras.layers.core.Reshape(target_shape)\n\n\n\n\nReshape\u5c42\u7528\u6765\u5c06\u8f93\u5165shape\u8f6c\u6362\u4e3a\u7279\u5b9a\u7684shape\n\n\n\u53c2\u6570\n\n\n\n\ntarget_shape\uff1a\u76ee\u6807shape\uff0c\u4e3a\u6574\u6570\u7684tuple\uff0c\u4e0d\u5305\u542b\u6837\u672c\u6570\u76ee\u7684\u7ef4\u5ea6\uff08batch\u5927\u5c0f\uff09\n\n\n\n\n\u8f93\u5165shape\n\n\n\u4efb\u610f\uff0c\u4f46\u8f93\u5165\u7684shape\u5fc5\u987b\u56fa\u5b9a\u3002\u5f53\u4f7f\u7528\u8be5\u5c42\u4e3a\u6a21\u578b\u9996\u5c42\u65f6\uff0c\u9700\u8981\u6307\u5b9a\ninput_shape\n\u53c2\u6570\n\n\n\u8f93\u51fashape\n\n\n(batch_size,)+target_shape\n\n\n\u4f8b\u5b50\n\n\n# as first layer in a Sequential model\nmodel = Sequential()\nmodel.add(Reshape((3, 4), input_shape=(12,)))\n# now: model.output_shape == (None, 3, 4)\n# note: `None` is the batch dimension\n\n# as intermediate layer in a Sequential model\nmodel.add(Reshape((6, 2)))\n# now: model.output_shape == (None, 6, 2)\n\n\n\n\n\n\nPermute\u5c42\n\n\nkeras.layers.core.Permute(dims)\n\n\n\n\nPermute\u5c42\u5c06\u8f93\u5165\u7684\u7ef4\u5ea6\u6309\u7167\u7ed9\u5b9a\u6a21\u5f0f\u8fdb\u884c\u91cd\u6392\uff0c\u4f8b\u5982\uff0c\u5f53\u9700\u8981\u5c06RNN\u548cCNN\u7f51\u7edc\u8fde\u63a5\u65f6\uff0c\u53ef\u80fd\u4f1a\u7528\u5230\u8be5\u5c42\u3002\n\n\n\u53c2\u6570\n\n\n\n\ndims\uff1a\u6574\u6570tuple\uff0c\u6307\u5b9a\u91cd\u6392\u7684\u6a21\u5f0f\uff0c\u4e0d\u5305\u542b\u6837\u672c\u6570\u7684\u7ef4\u5ea6\u3002\u91cd\u62cd\u6a21\u5f0f\u7684\u4e0b\u6807\u4ece1\u5f00\u59cb\u3002\u4f8b\u5982\uff082\uff0c1\uff09\u4ee3\u8868\u5c06\u8f93\u5165\u7684\u7b2c\u4e8c\u4e2a\u7ef4\u5ea6\u91cd\u62cd\u5230\u8f93\u51fa\u7684\u7b2c\u4e00\u4e2a\u7ef4\u5ea6\uff0c\u800c\u5c06\u8f93\u5165\u7684\u7b2c\u4e00\u4e2a\u7ef4\u5ea6\u91cd\u6392\u5230\u7b2c\u4e8c\u4e2a\u7ef4\u5ea6\n\n\n\n\n\u4f8b\u5b50\n\n\nmodel = Sequential()\nmodel.add(Permute((2, 1), input_shape=(10, 64)))\n# now: model.output_shape == (None, 64, 10)\n# note: `None` is the batch dimension\n\n\n\n\n\u8f93\u5165shape\n\n\n\u4efb\u610f\uff0c\u5f53\u4f7f\u7528\u6fc0\u6d3b\u5c42\u4f5c\u4e3a\u7b2c\u4e00\u5c42\u65f6\uff0c\u8981\u6307\u5b9a\ninput_shape\n\n\n\u8f93\u51fashape\n\n\n\u4e0e\u8f93\u5165\u76f8\u540c\uff0c\u4f46\u662f\u5176\u7ef4\u5ea6\u6309\u7167\u6307\u5b9a\u7684\u6a21\u5f0f\u91cd\u65b0\u6392\u5217\n\n\n\n\nRepeatVector\u5c42\n\n\nkeras.layers.core.RepeatVector(n)\n\n\n\n\nRepeatVector\u5c42\u5c06\u8f93\u5165\u91cd\u590dn\u6b21\n\n\n\u53c2\u6570\n\n\n\n\nn\uff1a\u6574\u6570\uff0c\u91cd\u590d\u7684\u6b21\u6570\n\n\n\n\n\u8f93\u5165shape\n\n\n\u5f62\u5982\uff08nb_samples, features\uff09\u76842D\u5f20\u91cf\n\n\n\u8f93\u51fashape\n\n\n\u5f62\u5982\uff08nb_samples, n, features\uff09\u76843D\u5f20\u91cf\n\n\n\u4f8b\u5b50\n\n\nmodel = Sequential()\nmodel.add(Dense(32, input_dim=32))\n# now: model.output_shape == (None, 32)\n# note: `None` is the batch dimension\n\nmodel.add(RepeatVector(3))\n# now: model.output_shape == (None, 3, 32)\n\n\n\n\n\n\nMerge\u5c42\n\n\nkeras.engine.topology.Merge(layers=None, mode='sum', concat_axis=-1, dot_axes=-1, output_shape=None, node_indices=None, tensor_indices=None, name=None)\n\n\n\n\nMerge\u5c42\u6839\u636e\u7ed9\u5b9a\u7684\u6a21\u5f0f\uff0c\u5c06\u4e00\u4e2a\u5f20\u91cf\u5217\u8868\u4e2d\u7684\u82e5\u5e72\u5f20\u91cf\u5408\u5e76\u4e3a\u4e00\u4e2a\u5355\u72ec\u7684\u5f20\u91cf\n\n\n\u53c2\u6570\n\n\n\n\nlayers\uff1a\u8be5\u53c2\u6570\u4e3aKeras\u5f20\u91cf\u7684\u5217\u8868\uff0c\u6216Keras\u5c42\u5bf9\u8c61\u7684\u5217\u8868\u3002\u8be5\u5217\u8868\u7684\u5143\u7d20\u6570\u76ee\u5fc5\u987b\u5927\u4e8e1\u3002\n\n\n\n\nmode\uff1a\u5408\u5e76\u6a21\u5f0f\uff0c\u4e3a\u9884\u5b9a\u4e49\u5408\u5e76\u6a21\u5f0f\u540d\u7684\u5b57\u7b26\u4e32\u6216lambda\u51fd\u6570\u6216\u666e\u901a\u51fd\u6570\uff0c\u5982\u679c\u4e3alambda\u51fd\u6570\u6216\u666e\u901a\u51fd\u6570\uff0c\u5219\u8be5\u51fd\u6570\u5fc5\u987b\u63a5\u53d7\u4e00\u4e2a\u5f20\u91cf\u7684list\u4f5c\u4e3a\u8f93\u5165\uff0c\u5e76\u8fd4\u56de\u4e00\u4e2a\u5f20\u91cf\u3002\u5982\u679c\u4e3a\u5b57\u7b26\u4e32\uff0c\u5219\u5fc5\u987b\u662f\u4e0b\u5217\u503c\u4e4b\u4e00\uff1a\n\n\n\n\n\u201csum\u201d\uff0c\u201cmul\u201d\uff0c\u201cconcat\u201d\uff0c\u201cave\u201d\uff0c\u201ccos\u201d\uff0c\u201cdot\u201d\n\n\n\n\n\n\n\n\nconcat_axis\uff1a\u6574\u6570\uff0c\u5f53\nmode=concat\n\u65f6\u6307\u5b9a\u9700\u8981\u4e32\u8054\u7684\u8f74\n\n\n\n\n\n\ndot_axes\uff1a\u6574\u6570\u6216\u6574\u6570tuple\uff0c\u5f53\nmode=dot\n\u65f6\uff0c\u6307\u5b9a\u8981\u6d88\u53bb\u7684\u8f74\n\n\n\n\n\n\noutput_shape\uff1a\u6574\u6570tuple\u6216lambda\u51fd\u6570/\u666e\u901a\u51fd\u6570\uff08\u5f53mode\u4e3a\u51fd\u6570\u65f6\uff09\u3002\u5982\u679coutput_shape\u662f\u51fd\u6570\u65f6\uff0c\u8be5\u51fd\u6570\u7684\u8f93\u5165\u503c\u5e94\u4e3a\u4e00\u4e00\u5bf9\u5e94\u4e8e\u8f93\u5165shape\u7684list\uff0c\u5e76\u8fd4\u56de\u8f93\u51fa\u5f20\u91cf\u7684shape\u3002\n\n\n\n\n\n\nnode_indices\uff1a\u53ef\u9009\uff0c\u4e3a\u6574\u6570list\uff0c\u5982\u679c\u6709\u4e9b\u5c42\u5177\u6709\u591a\u4e2a\u8f93\u51fa\u8282\u70b9\uff08node\uff09\u7684\u8bdd\uff0c\u8be5\u53c2\u6570\u53ef\u4ee5\u6307\u5b9a\u9700\u8981merge\u7684\u90a3\u4e9b\u8282\u70b9\u7684\u4e0b\u6807\u3002\u5982\u679c\u6ca1\u6709\u63d0\u4f9b\uff0c\u8be5\u53c2\u6570\u7684\u9ed8\u8ba4\u503c\u4e3a\u51680\u5411\u91cf\uff0c\u5373\u5408\u5e76\u8f93\u5165\u5c420\u53f7\u8282\u70b9\u7684\u8f93\u51fa\u503c\u3002\n\n\n\n\n\n\ntensor_indices\uff1a\u53ef\u9009\uff0c\u4e3a\u6574\u6570list\uff0c\u5982\u679c\u6709\u4e9b\u5c42\u8fd4\u56de\u591a\u4e2a\u8f93\u51fa\u5f20\u91cf\u7684\u8bdd\uff0c\u8be5\u53c2\u6570\u7528\u4ee5\u6307\u5b9a\u9700\u8981\u5408\u5e76\u7684\u90a3\u4e9b\u5f20\u91cf\u3002\n\n\n\n\n\n\n\u4f8b\u5b50\n\n\nmodel1 = Sequential()\nmodel1.add(Dense(32))\n\nmodel2 = Sequential()\nmodel2.add(Dense(32))\n\nmerged_model = Sequential()\nmerged_model.add(Merge([model1, model2], mode='concat', concat_axis=1)\n- ____TODO__: would this actually work? it needs to.__\n\n# achieve this with get_source_inputs in Sequential.\n\n\n\n\n\n\nLambda\u5c42\n\n\nkeras.layers.core.Lambda(function, output_shape=None, arguments={})\n\n\n\n\n\u672c\u51fd\u6570\u7528\u4ee5\u5bf9\u4e0a\u4e00\u5c42\u7684\u8f93\u51fa\u65bd\u4ee5\u4efb\u4f55Theano/TensorFlow\u8868\u8fbe\u5f0f\n\n\n\u53c2\u6570\n\n\n\n\n\n\nfunction\uff1a\u8981\u5b9e\u73b0\u7684\u51fd\u6570\uff0c\u8be5\u51fd\u6570\u4ec5\u63a5\u53d7\u4e00\u4e2a\u53d8\u91cf\uff0c\u5373\u4e0a\u4e00\u5c42\u7684\u8f93\u51fa\n\n\n\n\n\n\noutput_shape\uff1a\u51fd\u6570\u5e94\u8be5\u8fd4\u56de\u7684\u503c\u7684shape\uff0c\u53ef\u4ee5\u662f\u4e00\u4e2atuple\uff0c\u4e5f\u53ef\u4ee5\u662f\u4e00\u4e2a\u6839\u636e\u8f93\u5165shape\u8ba1\u7b97\u8f93\u51fashape\u7684\u51fd\u6570\n\n\n\n\n\n\narguments\uff1a\u53ef\u9009\uff0c\u5b57\u5178\uff0c\u7528\u6765\u8bb0\u5f55\u5411\u51fd\u6570\u4e2d\u4f20\u9012\u7684\u5176\u4ed6\u5173\u952e\u5b57\u53c2\u6570\n\n\n\n\n\n\n\u4f8b\u5b50\n\n\n# add a x -\n x^2 layer\nmodel.add(Lambda(lambda x: x ** 2))\n\n\n\n\n# add a layer that returns the concatenation\n# of the positive part of the input and\n# the opposite of the negative part\n\ndef antirectifier(x):\n    x -= K.mean(x, axis=1, keepdims=True)\n    x = K.l2_normalize(x, axis=1)\n    pos = K.relu(x)\n    neg = K.relu(-x)\n    return K.concatenate([pos, neg], axis=1)\n\ndef antirectifier_output_shape(input_shape):\n    shape = list(input_shape)\n    assert len(shape) == 2  # only valid for 2D tensors\n    shape[-1] *= 2\n    return tuple(shape)\n\nmodel.add(Lambda(antirectifier, output_shape=antirectifier_output_shape))\n\n\n\n\n\u8f93\u5165shape\n\n\n\u4efb\u610f\uff0c\u5f53\u4f7f\u7528\u8be5\u5c42\u4f5c\u4e3a\u7b2c\u4e00\u5c42\u65f6\uff0c\u8981\u6307\u5b9a\ninput_shape\n\n\n\u8f93\u51fashape\n\n\n\u7531\noutput_shape\n\u53c2\u6570\u6307\u5b9a\u7684\u8f93\u51fashape\n\n\n\n\nActivityRegularizer\u5c42\n\n\nkeras.layers.core.ActivityRegularization(l1=0.0, l2=0.0)\n\n\n\n\n\u7ecf\u8fc7\u672c\u5c42\u7684\u6570\u636e\u4e0d\u4f1a\u6709\u4efb\u4f55\u53d8\u5316\uff0c\u4f46\u4f1a\u57fa\u4e8e\u5176\u6fc0\u6d3b\u503c\u66f4\u65b0\u635f\u5931\u51fd\u6570\u503c\n\n\n\u53c2\u6570\n\n\n\n\n\n\nl1\uff1a1\u8303\u6570\u6b63\u5219\u56e0\u5b50\uff08\u6b63\u6d6e\u70b9\u6570\uff09\n\n\n\n\n\n\nl2\uff1a2\u8303\u6570\u6b63\u5219\u56e0\u5b50\uff08\u6b63\u6d6e\u70b9\u6570\uff09\n\n\n\n\n\n\n\u8f93\u5165shape\n\n\n\u4efb\u610f\uff0c\u5f53\u4f7f\u7528\u8be5\u5c42\u4f5c\u4e3a\u7b2c\u4e00\u5c42\u65f6\uff0c\u8981\u6307\u5b9a\ninput_shape\n\n\n\u8f93\u51fashape\n\n\n\u4e0e\u8f93\u5165shape\u76f8\u540c\n\n\n\n\nMasking\u5c42\n\n\nkeras.layers.core.Masking(mask_value=0.0)\n\n\n\n\n\u4f7f\u7528\u7ed9\u5b9a\u7684\u503c\u5bf9\u8f93\u5165\u7684\u5e8f\u5217\u4fe1\u53f7\u8fdb\u884c\u201c\u5c4f\u853d\u201d\uff0c\u7528\u4ee5\u5b9a\u4f4d\u9700\u8981\u8df3\u8fc7\u7684\u65f6\u95f4\u6b65\n\n\n\u5bf9\u4e8e\u8f93\u5165\u5f20\u91cf\u7684\u65f6\u95f4\u6b65\uff0c\u5373\u8f93\u5165\u5f20\u91cf\u7684\u7b2c1\u7ef4\u5ea6\uff08\u7ef4\u5ea6\u4ece0\u5f00\u59cb\u7b97\uff0c\u89c1\u4f8b\u5b50\uff09\uff0c\u5982\u679c\u8f93\u5165\u5f20\u91cf\u5728\u8be5\u65f6\u95f4\u6b65\u4e0a\u90fd\u7b49\u4e8e\nmask_value\n\uff0c\u5219\u8be5\u65f6\u95f4\u6b65\u5c06\u5728\u6a21\u578b\u63a5\u4e0b\u6765\u7684\u6240\u6709\u5c42\uff08\u53ea\u8981\u652f\u6301masking\uff09\u88ab\u8df3\u8fc7\uff08\u5c4f\u853d\uff09\u3002\n\n\n\u5982\u679c\u6a21\u578b\u63a5\u4e0b\u6765\u7684\u4e00\u4e9b\u5c42\u4e0d\u652f\u6301masking\uff0c\u5374\u63a5\u53d7\u5230masking\u8fc7\u7684\u6570\u636e\uff0c\u5219\u629b\u51fa\u5f02\u5e38\u3002\n\n\n\u4f8b\u5b50\n\n\n\u8003\u8651\u8f93\u5165\u6570\u636e\nx\n\u662f\u4e00\u4e2a\u5f62\u5982(samples,timesteps,features)\u7684\u5f20\u91cf\uff0c\u73b0\u5c06\u5176\u9001\u5165LSTM\u5c42\u3002\u56e0\u4e3a\u4f60\u7f3a\u5c11\u65f6\u95f4\u6b65\u4e3a3\u548c5\u7684\u4fe1\u53f7\uff0c\u6240\u4ee5\u4f60\u5e0c\u671b\u5c06\u5176\u63a9\u76d6\u3002\u8fd9\u65f6\u5019\u5e94\u8be5\uff1a\n\n\n\n\n\n\n\u8d4b\u503c\nx[:,3,:] = 0.\n\uff0c\nx[:,5,:] = 0.\n\n\n\n\n\n\n\u5728LSTM\u5c42\u4e4b\u524d\u63d2\u5165\nmask_value=0.\n\u7684\nMasking\n\u5c42\n\n\n\n\n\n\nmodel = Sequential()\nmodel.add(Masking(mask_value=0., input_shape=(timesteps, features)))\nmodel.add(LSTM(32))\n\n\n\n\n\n\nHighway\u5c42\n\n\nkeras.layers.core.Highway(init='glorot_uniform', transform_bias=-2, activation='linear', weights=None, W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None, bias=True, input_dim=None)\n\n\n\n\nHighway\u5c42\u5efa\u7acb\u5168\u8fde\u63a5\u7684Highway\u7f51\u7edc\uff0c\u8fd9\u662fLSTM\u5728\u524d\u9988\u795e\u7ecf\u7f51\u7edc\u4e2d\u7684\u63a8\u5e7f\n\n\n\u53c2\u6570\uff1a\n\n\n\n\n\n\noutput_dim\uff1a\u5927\u4e8e0\u7684\u6574\u6570\uff0c\u4ee3\u8868\u8be5\u5c42\u7684\u8f93\u51fa\u7ef4\u5ea6\u3002\u6a21\u578b\u4e2d\u975e\u9996\u5c42\u7684\u5168\u8fde\u63a5\u5c42\u5176\u8f93\u5165\u7ef4\u5ea6\u53ef\u4ee5\u81ea\u52a8\u63a8\u65ad\uff0c\u56e0\u6b64\u975e\u9996\u5c42\u7684\u5168\u8fde\u63a5\u5b9a\u4e49\u65f6\u4e0d\u9700\u8981\u6307\u5b9a\u8f93\u5165\u7ef4\u5ea6\u3002\n\n\n\n\n\n\ninit\uff1a\u521d\u59cb\u5316\u65b9\u6cd5\uff0c\u4e3a\u9884\u5b9a\u4e49\u521d\u59cb\u5316\u65b9\u6cd5\u540d\u7684\u5b57\u7b26\u4e32\uff0c\u6216\u7528\u4e8e\u521d\u59cb\u5316\u6743\u91cd\u7684Theano\u51fd\u6570\u3002\u8be5\u53c2\u6570\u4ec5\u5728\u4e0d\u4f20\u9012\nweights\n\u53c2\u6570\u65f6\u6709\u610f\u4e49\u3002\n\n\n\n\n\n\nactivation\uff1a\u6fc0\u6d3b\u51fd\u6570\uff0c\u4e3a\u9884\u5b9a\u4e49\u7684\u6fc0\u6d3b\u51fd\u6570\u540d\uff08\u53c2\u8003\n\u6fc0\u6d3b\u51fd\u6570\n\uff09\uff0c\u6216\u9010\u5143\u7d20\uff08element-wise\uff09\u7684Theano\u51fd\u6570\u3002\u5982\u679c\u4e0d\u6307\u5b9a\u8be5\u53c2\u6570\uff0c\u5c06\u4e0d\u4f1a\u4f7f\u7528\u4efb\u4f55\u6fc0\u6d3b\u51fd\u6570\uff08\u5373\u4f7f\u7528\u7ebf\u6027\u6fc0\u6d3b\u51fd\u6570\uff1aa(x)=x\uff09\n\n\n\n\n\n\nweights\uff1a\u6743\u503c\uff0c\u4e3anumpy array\u7684list\u3002\u8be5list\u5e94\u542b\u6709\u4e00\u4e2a\u5f62\u5982\uff08input_dim,output_dim\uff09\u7684\u6743\u91cd\u77e9\u9635\u548c\u4e00\u4e2a\u5f62\u5982(output_dim,)\u7684\u504f\u7f6e\u5411\u91cf\u3002\n\n\n\n\n\n\nW_regularizer\uff1a\u65bd\u52a0\u5728\u6743\u91cd\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a\nWeightRegularizer\n\u5bf9\u8c61\n\n\n\n\n\n\nb_regularizer\uff1a\u65bd\u52a0\u5728\u504f\u7f6e\u5411\u91cf\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a\nWeightRegularizer\n\u5bf9\u8c61\n\n\n\n\n\n\nactivity_regularizer\uff1a\u65bd\u52a0\u5728\u8f93\u51fa\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a\nActivityRegularizer\n\u5bf9\u8c61\n\n\n\n\n\n\nW_constraints\uff1a\u65bd\u52a0\u5728\u6743\u91cd\u4e0a\u7684\u7ea6\u675f\u9879\uff0c\u4e3a\nConstraints\n\u5bf9\u8c61\n\n\n\n\n\n\nb_constraints\uff1a\u65bd\u52a0\u5728\u504f\u7f6e\u4e0a\u7684\u7ea6\u675f\u9879\uff0c\u4e3a\nConstraints\n\u5bf9\u8c61\n\n\n\n\n\n\nbias\uff1a\u5e03\u5c14\u503c\uff0c\u662f\u5426\u5305\u542b\u504f\u7f6e\u5411\u91cf\uff08\u5373\u5c42\u5bf9\u8f93\u5165\u505a\u7ebf\u6027\u53d8\u6362\u8fd8\u662f\u4eff\u5c04\u53d8\u6362\uff09\n\n\n\n\n\n\ninput_dim\uff1a\u6574\u6570\uff0c\u8f93\u5165\u6570\u636e\u7684\u7ef4\u5ea6\u3002\u5f53\u8be5\u5c42\u4f5c\u4e3a\u7f51\u7edc\u7684\u7b2c\u4e00\u5c42\u65f6\uff0c\u5fc5\u987b\u6307\u5b9a\u8be5\u53c2\u6570\u6216\ninput_shape\n\u53c2\u6570\u3002\n\n\n\n\n\n\ntransform_bias\uff1a\u7528\u4ee5\u521d\u59cb\u5316\u4f20\u9012\u53c2\u6570\uff0c\u9ed8\u8ba4\u4e3a-2\uff08\u8bf7\u53c2\u8003\u6587\u732e\u7406\u89e3\u672c\u53c2\u6570\u7684\u542b\u4e49\uff09\n\n\n\n\n\n\n\u8f93\u5165shape\n\n\n\u5f62\u5982\uff08nb_samples, input_dim\uff09\u76842D\u5f20\u91cf\n\n\n\u8f93\u51fashape\n\n\n\u5f62\u5982\uff08nb_samples, output_dim\uff09\u76842D\u5f20\u91cf\n\n\n\u53c2\u8003\u6587\u732e\n\n\n\n\nHighway Networks\n\n\n\n\n\n\nMaxoutDense\u5c42\n\n\n\u5168\u8fde\u63a5\u7684Maxout\u5c42\n\n\nMaxoutDense\n\u5c42\u4ee5\nnb_features\n\u4e2a\nDense(input_dim,output_dim)\n\u7ebf\u6027\u5c42\u7684\u8f93\u51fa\u7684\u6700\u5927\u503c\u4e3a\u8f93\u51fa\u3002\nMaxoutDense\n\u53ef\u5bf9\u8f93\u5165\u5b66\u4e60\u51fa\u4e00\u4e2a\u51f8\u7684\u3001\u5206\u6bb5\u7ebf\u6027\u7684\u6fc0\u6d3b\u51fd\u6570\u3002\n\n\n\u53c2\u6570\n\n\n\n\nnb_features\uff1a\u5185\u90e8\u4f7f\u7528\u7684\u5168\u8fde\u63a5\u5c42\u7684\u6570\u76ee\n\n\n\n\n\u8f93\u5165shape\n\n\n\u5f62\u5982\uff08nb_samples, input_dim\uff09\u76842D\u5f20\u91cf\n\n\n\u8f93\u51fashape\n\n\n\u5f62\u5982\uff08nb_samples, output_dim\uff09\u76842D\u5f20\u91cf\n\n\n\u53c2\u8003\u6587\u732e\n\n\n\n\nMaxout Networks", 
            "title": "\u5e38\u7528\u5c42Core"
        }, 
        {
            "location": "/layers/core_layer/#_1", 
            "text": "\u5e38\u7528\u5c42\u5bf9\u5e94\u4e8ecore\u6a21\u5757\uff0ccore\u5185\u90e8\u5b9a\u4e49\u4e86\u4e00\u7cfb\u5217\u5e38\u7528\u7684\u7f51\u7edc\u5c42\uff0c\u5305\u62ec\u5168\u8fde\u63a5\u3001\u6fc0\u6d3b\u5c42\u7b49", 
            "title": "\u5e38\u7528\u5c42"
        }, 
        {
            "location": "/layers/core_layer/#dense", 
            "text": "keras.layers.core.Dense(output_dim, init='glorot_uniform', activation='linear', weights=None, W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None, bias=True, input_dim=None)  Dense\u5c31\u662f\u5e38\u7528\u7684\u5168\u8fde\u63a5\u5c42\uff0c\u8fd9\u91cc\u662f\u4e00\u4e2a\u4f7f\u7528\u793a\u4f8b\uff1a  # as first layer in a sequential model:\nmodel = Sequential()\nmodel.add(Dense(32, input_dim=16))\n# now the model will take as input arrays of shape (*, 16)\n# and output arrays of shape (*, 32)\n\n# this is equivalent to the above:\nmodel = Sequential()\nmodel.add(Dense(32, input_shape=(16,)))\n\n# after the first layer, you don't need to specify\n# the size of the input anymore:\nmodel.add(Dense(32))", 
            "title": "Dense\u5c42"
        }, 
        {
            "location": "/layers/core_layer/#_2", 
            "text": "output_dim\uff1a\u5927\u4e8e0\u7684\u6574\u6570\uff0c\u4ee3\u8868\u8be5\u5c42\u7684\u8f93\u51fa\u7ef4\u5ea6\u3002\u6a21\u578b\u4e2d\u975e\u9996\u5c42\u7684\u5168\u8fde\u63a5\u5c42\u5176\u8f93\u5165\u7ef4\u5ea6\u53ef\u4ee5\u81ea\u52a8\u63a8\u65ad\uff0c\u56e0\u6b64\u975e\u9996\u5c42\u7684\u5168\u8fde\u63a5\u5b9a\u4e49\u65f6\u4e0d\u9700\u8981\u6307\u5b9a\u8f93\u5165\u7ef4\u5ea6\u3002    init\uff1a\u521d\u59cb\u5316\u65b9\u6cd5\uff0c\u4e3a\u9884\u5b9a\u4e49\u521d\u59cb\u5316\u65b9\u6cd5\u540d\u7684\u5b57\u7b26\u4e32\uff0c\u6216\u7528\u4e8e\u521d\u59cb\u5316\u6743\u91cd\u7684Theano\u51fd\u6570\u3002\u8be5\u53c2\u6570\u4ec5\u5728\u4e0d\u4f20\u9012 weights \u53c2\u6570\u65f6\u624d\u6709\u610f\u4e49\u3002    activation\uff1a\u6fc0\u6d3b\u51fd\u6570\uff0c\u4e3a\u9884\u5b9a\u4e49\u7684\u6fc0\u6d3b\u51fd\u6570\u540d\uff08\u53c2\u8003 \u6fc0\u6d3b\u51fd\u6570 \uff09\uff0c\u6216\u9010\u5143\u7d20\uff08element-wise\uff09\u7684Theano\u51fd\u6570\u3002\u5982\u679c\u4e0d\u6307\u5b9a\u8be5\u53c2\u6570\uff0c\u5c06\u4e0d\u4f1a\u4f7f\u7528\u4efb\u4f55\u6fc0\u6d3b\u51fd\u6570\uff08\u5373\u4f7f\u7528\u7ebf\u6027\u6fc0\u6d3b\u51fd\u6570\uff1aa(x)=x\uff09    weights\uff1a\u6743\u503c\uff0c\u4e3anumpy array\u7684list\u3002\u8be5list\u5e94\u542b\u6709\u4e00\u4e2a\u5f62\u5982\uff08input_dim,output_dim\uff09\u7684\u6743\u91cd\u77e9\u9635\u548c\u4e00\u4e2a\u5f62\u5982(output_dim,)\u7684\u504f\u7f6e\u5411\u91cf\u3002    W_regularizer\uff1a\u65bd\u52a0\u5728\u6743\u91cd\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a WeightRegularizer \u5bf9\u8c61    b_regularizer\uff1a\u65bd\u52a0\u5728\u504f\u7f6e\u5411\u91cf\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a WeightRegularizer \u5bf9\u8c61    activity_regularizer\uff1a\u65bd\u52a0\u5728\u8f93\u51fa\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a ActivityRegularizer \u5bf9\u8c61    W_constraints\uff1a\u65bd\u52a0\u5728\u6743\u91cd\u4e0a\u7684\u7ea6\u675f\u9879\uff0c\u4e3a Constraints \u5bf9\u8c61    b_constraints\uff1a\u65bd\u52a0\u5728\u504f\u7f6e\u4e0a\u7684\u7ea6\u675f\u9879\uff0c\u4e3a Constraints \u5bf9\u8c61    bias\uff1a\u5e03\u5c14\u503c\uff0c\u662f\u5426\u5305\u542b\u504f\u7f6e\u5411\u91cf\uff08\u5373\u5c42\u5bf9\u8f93\u5165\u505a\u7ebf\u6027\u53d8\u6362\u8fd8\u662f\u4eff\u5c04\u53d8\u6362\uff09    input_dim\uff1a\u6574\u6570\uff0c\u8f93\u5165\u6570\u636e\u7684\u7ef4\u5ea6\u3002\u5f53Dense\u5c42\u4f5c\u4e3a\u7f51\u7edc\u7684\u7b2c\u4e00\u5c42\u65f6\uff0c\u5fc5\u987b\u6307\u5b9a\u8be5\u53c2\u6570\u6216 input_shape \u53c2\u6570\u3002", 
            "title": "\u53c2\u6570\uff1a"
        }, 
        {
            "location": "/layers/core_layer/#_3", 
            "text": "\u5f62\u5982(nb_samples, ..., input_dim)\u7684nD\u5f20\u91cf\uff0c\u6700\u5e38\u89c1\u7684\u60c5\u51b5\u4e3a(nb_samples, input_dim)\u76842D\u5f20\u91cf", 
            "title": "\u8f93\u5165"
        }, 
        {
            "location": "/layers/core_layer/#_4", 
            "text": "\u5f62\u5982(nb_samples, ..., output_dim)\u7684nD\u5f20\u91cf\uff0c\u6700\u5e38\u89c1\u7684\u60c5\u51b5\u4e3a(nb_samples, output_dim)\u76842D\u5f20\u91cf", 
            "title": "\u8f93\u51fa"
        }, 
        {
            "location": "/layers/core_layer/#activation", 
            "text": "keras.layers.core.Activation(activation)  \u6fc0\u6d3b\u5c42\u5bf9\u4e00\u4e2a\u5c42\u7684\u8f93\u51fa\u65bd\u52a0\u6fc0\u6d3b\u51fd\u6570", 
            "title": "Activation\u5c42"
        }, 
        {
            "location": "/layers/core_layer/#_5", 
            "text": "activation\uff1a\u5c06\u8981\u4f7f\u7528\u7684\u6fc0\u6d3b\u51fd\u6570\uff0c\u4e3a\u9884\u5b9a\u4e49\u6fc0\u6d3b\u51fd\u6570\u540d\u6216\u4e00\u4e2aTensorflow/Theano\u7684\u51fd\u6570\u3002\u53c2\u8003 \u6fc0\u6d3b\u51fd\u6570", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/layers/core_layer/#shape", 
            "text": "\u4efb\u610f\uff0c\u5f53\u4f7f\u7528\u6fc0\u6d3b\u5c42\u4f5c\u4e3a\u7b2c\u4e00\u5c42\u65f6\uff0c\u8981\u6307\u5b9a input_shape", 
            "title": "\u8f93\u5165shape"
        }, 
        {
            "location": "/layers/core_layer/#shape_1", 
            "text": "\u4e0e\u8f93\u5165shape\u76f8\u540c", 
            "title": "\u8f93\u51fashape"
        }, 
        {
            "location": "/layers/core_layer/#dropout", 
            "text": "keras.layers.core.Dropout(p)  \u4e3a\u8f93\u5165\u6570\u636e\u65bd\u52a0Dropout\u3002Dropout\u5c06\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u6bcf\u6b21\u66f4\u65b0\u53c2\u6570\u65f6\u968f\u673a\u65ad\u5f00\u4e00\u5b9a\u767e\u5206\u6bd4\uff08p\uff09\u7684\u8f93\u5165\u795e\u7ecf\u5143\u8fde\u63a5\uff0cDropout\u5c42\u7528\u4e8e\u9632\u6b62\u8fc7\u62df\u5408\u3002", 
            "title": "Dropout\u5c42"
        }, 
        {
            "location": "/layers/core_layer/#_6", 
            "text": "p\uff1a0~1\u7684\u6d6e\u70b9\u6570\uff0c\u63a7\u5236\u9700\u8981\u65ad\u5f00\u7684\u94fe\u63a5\u7684\u6bd4\u4f8b", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/layers/core_layer/#_7", 
            "text": "Dropout: A Simple Way to Prevent Neural Networks from Overfitting", 
            "title": "\u53c2\u8003\u6587\u732e"
        }, 
        {
            "location": "/layers/core_layer/#flatten", 
            "text": "keras.layers.core.Flatten()  Flatten\u5c42\u7528\u6765\u5c06\u8f93\u5165\u201c\u538b\u5e73\u201d\uff0c\u5373\u628a\u591a\u7ef4\u7684\u8f93\u5165\u4e00\u7ef4\u5316\uff0c\u5e38\u7528\u5728\u4ece\u5377\u79ef\u5c42\u5230\u5168\u8fde\u63a5\u5c42\u7684\u8fc7\u6e21\u3002Flatten\u4e0d\u5f71\u54cdbatch\u7684\u5927\u5c0f\u3002", 
            "title": "Flatten\u5c42"
        }, 
        {
            "location": "/layers/core_layer/#_8", 
            "text": "model = Sequential()\nmodel.add(Convolution2D(64, 3, 3, border_mode='same', input_shape=(3, 32, 32)))\n# now: model.output_shape == (None, 64, 32, 32)\n\nmodel.add(Flatten())\n# now: model.output_shape == (None, 65536)", 
            "title": "\u4f8b\u5b50"
        }, 
        {
            "location": "/layers/core_layer/#reshape", 
            "text": "keras.layers.core.Reshape(target_shape)  Reshape\u5c42\u7528\u6765\u5c06\u8f93\u5165shape\u8f6c\u6362\u4e3a\u7279\u5b9a\u7684shape", 
            "title": "Reshape\u5c42"
        }, 
        {
            "location": "/layers/core_layer/#_9", 
            "text": "target_shape\uff1a\u76ee\u6807shape\uff0c\u4e3a\u6574\u6570\u7684tuple\uff0c\u4e0d\u5305\u542b\u6837\u672c\u6570\u76ee\u7684\u7ef4\u5ea6\uff08batch\u5927\u5c0f\uff09", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/layers/core_layer/#shape_2", 
            "text": "\u4efb\u610f\uff0c\u4f46\u8f93\u5165\u7684shape\u5fc5\u987b\u56fa\u5b9a\u3002\u5f53\u4f7f\u7528\u8be5\u5c42\u4e3a\u6a21\u578b\u9996\u5c42\u65f6\uff0c\u9700\u8981\u6307\u5b9a input_shape \u53c2\u6570", 
            "title": "\u8f93\u5165shape"
        }, 
        {
            "location": "/layers/core_layer/#shape_3", 
            "text": "(batch_size,)+target_shape", 
            "title": "\u8f93\u51fashape"
        }, 
        {
            "location": "/layers/core_layer/#_10", 
            "text": "# as first layer in a Sequential model\nmodel = Sequential()\nmodel.add(Reshape((3, 4), input_shape=(12,)))\n# now: model.output_shape == (None, 3, 4)\n# note: `None` is the batch dimension\n\n# as intermediate layer in a Sequential model\nmodel.add(Reshape((6, 2)))\n# now: model.output_shape == (None, 6, 2)", 
            "title": "\u4f8b\u5b50"
        }, 
        {
            "location": "/layers/core_layer/#permute", 
            "text": "keras.layers.core.Permute(dims)  Permute\u5c42\u5c06\u8f93\u5165\u7684\u7ef4\u5ea6\u6309\u7167\u7ed9\u5b9a\u6a21\u5f0f\u8fdb\u884c\u91cd\u6392\uff0c\u4f8b\u5982\uff0c\u5f53\u9700\u8981\u5c06RNN\u548cCNN\u7f51\u7edc\u8fde\u63a5\u65f6\uff0c\u53ef\u80fd\u4f1a\u7528\u5230\u8be5\u5c42\u3002", 
            "title": "Permute\u5c42"
        }, 
        {
            "location": "/layers/core_layer/#_11", 
            "text": "dims\uff1a\u6574\u6570tuple\uff0c\u6307\u5b9a\u91cd\u6392\u7684\u6a21\u5f0f\uff0c\u4e0d\u5305\u542b\u6837\u672c\u6570\u7684\u7ef4\u5ea6\u3002\u91cd\u62cd\u6a21\u5f0f\u7684\u4e0b\u6807\u4ece1\u5f00\u59cb\u3002\u4f8b\u5982\uff082\uff0c1\uff09\u4ee3\u8868\u5c06\u8f93\u5165\u7684\u7b2c\u4e8c\u4e2a\u7ef4\u5ea6\u91cd\u62cd\u5230\u8f93\u51fa\u7684\u7b2c\u4e00\u4e2a\u7ef4\u5ea6\uff0c\u800c\u5c06\u8f93\u5165\u7684\u7b2c\u4e00\u4e2a\u7ef4\u5ea6\u91cd\u6392\u5230\u7b2c\u4e8c\u4e2a\u7ef4\u5ea6", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/layers/core_layer/#_12", 
            "text": "model = Sequential()\nmodel.add(Permute((2, 1), input_shape=(10, 64)))\n# now: model.output_shape == (None, 64, 10)\n# note: `None` is the batch dimension", 
            "title": "\u4f8b\u5b50"
        }, 
        {
            "location": "/layers/core_layer/#shape_4", 
            "text": "\u4efb\u610f\uff0c\u5f53\u4f7f\u7528\u6fc0\u6d3b\u5c42\u4f5c\u4e3a\u7b2c\u4e00\u5c42\u65f6\uff0c\u8981\u6307\u5b9a input_shape", 
            "title": "\u8f93\u5165shape"
        }, 
        {
            "location": "/layers/core_layer/#shape_5", 
            "text": "\u4e0e\u8f93\u5165\u76f8\u540c\uff0c\u4f46\u662f\u5176\u7ef4\u5ea6\u6309\u7167\u6307\u5b9a\u7684\u6a21\u5f0f\u91cd\u65b0\u6392\u5217", 
            "title": "\u8f93\u51fashape"
        }, 
        {
            "location": "/layers/core_layer/#repeatvector", 
            "text": "keras.layers.core.RepeatVector(n)  RepeatVector\u5c42\u5c06\u8f93\u5165\u91cd\u590dn\u6b21", 
            "title": "RepeatVector\u5c42"
        }, 
        {
            "location": "/layers/core_layer/#_13", 
            "text": "n\uff1a\u6574\u6570\uff0c\u91cd\u590d\u7684\u6b21\u6570", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/layers/core_layer/#shape_6", 
            "text": "\u5f62\u5982\uff08nb_samples, features\uff09\u76842D\u5f20\u91cf", 
            "title": "\u8f93\u5165shape"
        }, 
        {
            "location": "/layers/core_layer/#shape_7", 
            "text": "\u5f62\u5982\uff08nb_samples, n, features\uff09\u76843D\u5f20\u91cf", 
            "title": "\u8f93\u51fashape"
        }, 
        {
            "location": "/layers/core_layer/#_14", 
            "text": "model = Sequential()\nmodel.add(Dense(32, input_dim=32))\n# now: model.output_shape == (None, 32)\n# note: `None` is the batch dimension\n\nmodel.add(RepeatVector(3))\n# now: model.output_shape == (None, 3, 32)", 
            "title": "\u4f8b\u5b50"
        }, 
        {
            "location": "/layers/core_layer/#merge", 
            "text": "keras.engine.topology.Merge(layers=None, mode='sum', concat_axis=-1, dot_axes=-1, output_shape=None, node_indices=None, tensor_indices=None, name=None)  Merge\u5c42\u6839\u636e\u7ed9\u5b9a\u7684\u6a21\u5f0f\uff0c\u5c06\u4e00\u4e2a\u5f20\u91cf\u5217\u8868\u4e2d\u7684\u82e5\u5e72\u5f20\u91cf\u5408\u5e76\u4e3a\u4e00\u4e2a\u5355\u72ec\u7684\u5f20\u91cf", 
            "title": "Merge\u5c42"
        }, 
        {
            "location": "/layers/core_layer/#_15", 
            "text": "layers\uff1a\u8be5\u53c2\u6570\u4e3aKeras\u5f20\u91cf\u7684\u5217\u8868\uff0c\u6216Keras\u5c42\u5bf9\u8c61\u7684\u5217\u8868\u3002\u8be5\u5217\u8868\u7684\u5143\u7d20\u6570\u76ee\u5fc5\u987b\u5927\u4e8e1\u3002   mode\uff1a\u5408\u5e76\u6a21\u5f0f\uff0c\u4e3a\u9884\u5b9a\u4e49\u5408\u5e76\u6a21\u5f0f\u540d\u7684\u5b57\u7b26\u4e32\u6216lambda\u51fd\u6570\u6216\u666e\u901a\u51fd\u6570\uff0c\u5982\u679c\u4e3alambda\u51fd\u6570\u6216\u666e\u901a\u51fd\u6570\uff0c\u5219\u8be5\u51fd\u6570\u5fc5\u987b\u63a5\u53d7\u4e00\u4e2a\u5f20\u91cf\u7684list\u4f5c\u4e3a\u8f93\u5165\uff0c\u5e76\u8fd4\u56de\u4e00\u4e2a\u5f20\u91cf\u3002\u5982\u679c\u4e3a\u5b57\u7b26\u4e32\uff0c\u5219\u5fc5\u987b\u662f\u4e0b\u5217\u503c\u4e4b\u4e00\uff1a   \u201csum\u201d\uff0c\u201cmul\u201d\uff0c\u201cconcat\u201d\uff0c\u201cave\u201d\uff0c\u201ccos\u201d\uff0c\u201cdot\u201d     concat_axis\uff1a\u6574\u6570\uff0c\u5f53 mode=concat \u65f6\u6307\u5b9a\u9700\u8981\u4e32\u8054\u7684\u8f74    dot_axes\uff1a\u6574\u6570\u6216\u6574\u6570tuple\uff0c\u5f53 mode=dot \u65f6\uff0c\u6307\u5b9a\u8981\u6d88\u53bb\u7684\u8f74    output_shape\uff1a\u6574\u6570tuple\u6216lambda\u51fd\u6570/\u666e\u901a\u51fd\u6570\uff08\u5f53mode\u4e3a\u51fd\u6570\u65f6\uff09\u3002\u5982\u679coutput_shape\u662f\u51fd\u6570\u65f6\uff0c\u8be5\u51fd\u6570\u7684\u8f93\u5165\u503c\u5e94\u4e3a\u4e00\u4e00\u5bf9\u5e94\u4e8e\u8f93\u5165shape\u7684list\uff0c\u5e76\u8fd4\u56de\u8f93\u51fa\u5f20\u91cf\u7684shape\u3002    node_indices\uff1a\u53ef\u9009\uff0c\u4e3a\u6574\u6570list\uff0c\u5982\u679c\u6709\u4e9b\u5c42\u5177\u6709\u591a\u4e2a\u8f93\u51fa\u8282\u70b9\uff08node\uff09\u7684\u8bdd\uff0c\u8be5\u53c2\u6570\u53ef\u4ee5\u6307\u5b9a\u9700\u8981merge\u7684\u90a3\u4e9b\u8282\u70b9\u7684\u4e0b\u6807\u3002\u5982\u679c\u6ca1\u6709\u63d0\u4f9b\uff0c\u8be5\u53c2\u6570\u7684\u9ed8\u8ba4\u503c\u4e3a\u51680\u5411\u91cf\uff0c\u5373\u5408\u5e76\u8f93\u5165\u5c420\u53f7\u8282\u70b9\u7684\u8f93\u51fa\u503c\u3002    tensor_indices\uff1a\u53ef\u9009\uff0c\u4e3a\u6574\u6570list\uff0c\u5982\u679c\u6709\u4e9b\u5c42\u8fd4\u56de\u591a\u4e2a\u8f93\u51fa\u5f20\u91cf\u7684\u8bdd\uff0c\u8be5\u53c2\u6570\u7528\u4ee5\u6307\u5b9a\u9700\u8981\u5408\u5e76\u7684\u90a3\u4e9b\u5f20\u91cf\u3002", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/layers/core_layer/#_16", 
            "text": "model1 = Sequential()\nmodel1.add(Dense(32))\n\nmodel2 = Sequential()\nmodel2.add(Dense(32))\n\nmerged_model = Sequential()\nmerged_model.add(Merge([model1, model2], mode='concat', concat_axis=1)\n- ____TODO__: would this actually work? it needs to.__\n\n# achieve this with get_source_inputs in Sequential.", 
            "title": "\u4f8b\u5b50"
        }, 
        {
            "location": "/layers/core_layer/#lambda", 
            "text": "keras.layers.core.Lambda(function, output_shape=None, arguments={})  \u672c\u51fd\u6570\u7528\u4ee5\u5bf9\u4e0a\u4e00\u5c42\u7684\u8f93\u51fa\u65bd\u4ee5\u4efb\u4f55Theano/TensorFlow\u8868\u8fbe\u5f0f", 
            "title": "Lambda\u5c42"
        }, 
        {
            "location": "/layers/core_layer/#_17", 
            "text": "function\uff1a\u8981\u5b9e\u73b0\u7684\u51fd\u6570\uff0c\u8be5\u51fd\u6570\u4ec5\u63a5\u53d7\u4e00\u4e2a\u53d8\u91cf\uff0c\u5373\u4e0a\u4e00\u5c42\u7684\u8f93\u51fa    output_shape\uff1a\u51fd\u6570\u5e94\u8be5\u8fd4\u56de\u7684\u503c\u7684shape\uff0c\u53ef\u4ee5\u662f\u4e00\u4e2atuple\uff0c\u4e5f\u53ef\u4ee5\u662f\u4e00\u4e2a\u6839\u636e\u8f93\u5165shape\u8ba1\u7b97\u8f93\u51fashape\u7684\u51fd\u6570    arguments\uff1a\u53ef\u9009\uff0c\u5b57\u5178\uff0c\u7528\u6765\u8bb0\u5f55\u5411\u51fd\u6570\u4e2d\u4f20\u9012\u7684\u5176\u4ed6\u5173\u952e\u5b57\u53c2\u6570", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/layers/core_layer/#_18", 
            "text": "# add a x -  x^2 layer\nmodel.add(Lambda(lambda x: x ** 2))  # add a layer that returns the concatenation\n# of the positive part of the input and\n# the opposite of the negative part\n\ndef antirectifier(x):\n    x -= K.mean(x, axis=1, keepdims=True)\n    x = K.l2_normalize(x, axis=1)\n    pos = K.relu(x)\n    neg = K.relu(-x)\n    return K.concatenate([pos, neg], axis=1)\n\ndef antirectifier_output_shape(input_shape):\n    shape = list(input_shape)\n    assert len(shape) == 2  # only valid for 2D tensors\n    shape[-1] *= 2\n    return tuple(shape)\n\nmodel.add(Lambda(antirectifier, output_shape=antirectifier_output_shape))", 
            "title": "\u4f8b\u5b50"
        }, 
        {
            "location": "/layers/core_layer/#shape_8", 
            "text": "\u4efb\u610f\uff0c\u5f53\u4f7f\u7528\u8be5\u5c42\u4f5c\u4e3a\u7b2c\u4e00\u5c42\u65f6\uff0c\u8981\u6307\u5b9a input_shape", 
            "title": "\u8f93\u5165shape"
        }, 
        {
            "location": "/layers/core_layer/#shape_9", 
            "text": "\u7531 output_shape \u53c2\u6570\u6307\u5b9a\u7684\u8f93\u51fashape", 
            "title": "\u8f93\u51fashape"
        }, 
        {
            "location": "/layers/core_layer/#activityregularizer", 
            "text": "keras.layers.core.ActivityRegularization(l1=0.0, l2=0.0)  \u7ecf\u8fc7\u672c\u5c42\u7684\u6570\u636e\u4e0d\u4f1a\u6709\u4efb\u4f55\u53d8\u5316\uff0c\u4f46\u4f1a\u57fa\u4e8e\u5176\u6fc0\u6d3b\u503c\u66f4\u65b0\u635f\u5931\u51fd\u6570\u503c", 
            "title": "ActivityRegularizer\u5c42"
        }, 
        {
            "location": "/layers/core_layer/#_19", 
            "text": "l1\uff1a1\u8303\u6570\u6b63\u5219\u56e0\u5b50\uff08\u6b63\u6d6e\u70b9\u6570\uff09    l2\uff1a2\u8303\u6570\u6b63\u5219\u56e0\u5b50\uff08\u6b63\u6d6e\u70b9\u6570\uff09", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/layers/core_layer/#shape_10", 
            "text": "\u4efb\u610f\uff0c\u5f53\u4f7f\u7528\u8be5\u5c42\u4f5c\u4e3a\u7b2c\u4e00\u5c42\u65f6\uff0c\u8981\u6307\u5b9a input_shape", 
            "title": "\u8f93\u5165shape"
        }, 
        {
            "location": "/layers/core_layer/#shape_11", 
            "text": "\u4e0e\u8f93\u5165shape\u76f8\u540c", 
            "title": "\u8f93\u51fashape"
        }, 
        {
            "location": "/layers/core_layer/#masking", 
            "text": "keras.layers.core.Masking(mask_value=0.0)  \u4f7f\u7528\u7ed9\u5b9a\u7684\u503c\u5bf9\u8f93\u5165\u7684\u5e8f\u5217\u4fe1\u53f7\u8fdb\u884c\u201c\u5c4f\u853d\u201d\uff0c\u7528\u4ee5\u5b9a\u4f4d\u9700\u8981\u8df3\u8fc7\u7684\u65f6\u95f4\u6b65  \u5bf9\u4e8e\u8f93\u5165\u5f20\u91cf\u7684\u65f6\u95f4\u6b65\uff0c\u5373\u8f93\u5165\u5f20\u91cf\u7684\u7b2c1\u7ef4\u5ea6\uff08\u7ef4\u5ea6\u4ece0\u5f00\u59cb\u7b97\uff0c\u89c1\u4f8b\u5b50\uff09\uff0c\u5982\u679c\u8f93\u5165\u5f20\u91cf\u5728\u8be5\u65f6\u95f4\u6b65\u4e0a\u90fd\u7b49\u4e8e mask_value \uff0c\u5219\u8be5\u65f6\u95f4\u6b65\u5c06\u5728\u6a21\u578b\u63a5\u4e0b\u6765\u7684\u6240\u6709\u5c42\uff08\u53ea\u8981\u652f\u6301masking\uff09\u88ab\u8df3\u8fc7\uff08\u5c4f\u853d\uff09\u3002  \u5982\u679c\u6a21\u578b\u63a5\u4e0b\u6765\u7684\u4e00\u4e9b\u5c42\u4e0d\u652f\u6301masking\uff0c\u5374\u63a5\u53d7\u5230masking\u8fc7\u7684\u6570\u636e\uff0c\u5219\u629b\u51fa\u5f02\u5e38\u3002", 
            "title": "Masking\u5c42"
        }, 
        {
            "location": "/layers/core_layer/#_20", 
            "text": "\u8003\u8651\u8f93\u5165\u6570\u636e x \u662f\u4e00\u4e2a\u5f62\u5982(samples,timesteps,features)\u7684\u5f20\u91cf\uff0c\u73b0\u5c06\u5176\u9001\u5165LSTM\u5c42\u3002\u56e0\u4e3a\u4f60\u7f3a\u5c11\u65f6\u95f4\u6b65\u4e3a3\u548c5\u7684\u4fe1\u53f7\uff0c\u6240\u4ee5\u4f60\u5e0c\u671b\u5c06\u5176\u63a9\u76d6\u3002\u8fd9\u65f6\u5019\u5e94\u8be5\uff1a    \u8d4b\u503c x[:,3,:] = 0. \uff0c x[:,5,:] = 0.    \u5728LSTM\u5c42\u4e4b\u524d\u63d2\u5165 mask_value=0. \u7684 Masking \u5c42    model = Sequential()\nmodel.add(Masking(mask_value=0., input_shape=(timesteps, features)))\nmodel.add(LSTM(32))", 
            "title": "\u4f8b\u5b50"
        }, 
        {
            "location": "/layers/core_layer/#highway", 
            "text": "keras.layers.core.Highway(init='glorot_uniform', transform_bias=-2, activation='linear', weights=None, W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None, bias=True, input_dim=None)  Highway\u5c42\u5efa\u7acb\u5168\u8fde\u63a5\u7684Highway\u7f51\u7edc\uff0c\u8fd9\u662fLSTM\u5728\u524d\u9988\u795e\u7ecf\u7f51\u7edc\u4e2d\u7684\u63a8\u5e7f", 
            "title": "Highway\u5c42"
        }, 
        {
            "location": "/layers/core_layer/#_21", 
            "text": "output_dim\uff1a\u5927\u4e8e0\u7684\u6574\u6570\uff0c\u4ee3\u8868\u8be5\u5c42\u7684\u8f93\u51fa\u7ef4\u5ea6\u3002\u6a21\u578b\u4e2d\u975e\u9996\u5c42\u7684\u5168\u8fde\u63a5\u5c42\u5176\u8f93\u5165\u7ef4\u5ea6\u53ef\u4ee5\u81ea\u52a8\u63a8\u65ad\uff0c\u56e0\u6b64\u975e\u9996\u5c42\u7684\u5168\u8fde\u63a5\u5b9a\u4e49\u65f6\u4e0d\u9700\u8981\u6307\u5b9a\u8f93\u5165\u7ef4\u5ea6\u3002    init\uff1a\u521d\u59cb\u5316\u65b9\u6cd5\uff0c\u4e3a\u9884\u5b9a\u4e49\u521d\u59cb\u5316\u65b9\u6cd5\u540d\u7684\u5b57\u7b26\u4e32\uff0c\u6216\u7528\u4e8e\u521d\u59cb\u5316\u6743\u91cd\u7684Theano\u51fd\u6570\u3002\u8be5\u53c2\u6570\u4ec5\u5728\u4e0d\u4f20\u9012 weights \u53c2\u6570\u65f6\u6709\u610f\u4e49\u3002    activation\uff1a\u6fc0\u6d3b\u51fd\u6570\uff0c\u4e3a\u9884\u5b9a\u4e49\u7684\u6fc0\u6d3b\u51fd\u6570\u540d\uff08\u53c2\u8003 \u6fc0\u6d3b\u51fd\u6570 \uff09\uff0c\u6216\u9010\u5143\u7d20\uff08element-wise\uff09\u7684Theano\u51fd\u6570\u3002\u5982\u679c\u4e0d\u6307\u5b9a\u8be5\u53c2\u6570\uff0c\u5c06\u4e0d\u4f1a\u4f7f\u7528\u4efb\u4f55\u6fc0\u6d3b\u51fd\u6570\uff08\u5373\u4f7f\u7528\u7ebf\u6027\u6fc0\u6d3b\u51fd\u6570\uff1aa(x)=x\uff09    weights\uff1a\u6743\u503c\uff0c\u4e3anumpy array\u7684list\u3002\u8be5list\u5e94\u542b\u6709\u4e00\u4e2a\u5f62\u5982\uff08input_dim,output_dim\uff09\u7684\u6743\u91cd\u77e9\u9635\u548c\u4e00\u4e2a\u5f62\u5982(output_dim,)\u7684\u504f\u7f6e\u5411\u91cf\u3002    W_regularizer\uff1a\u65bd\u52a0\u5728\u6743\u91cd\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a WeightRegularizer \u5bf9\u8c61    b_regularizer\uff1a\u65bd\u52a0\u5728\u504f\u7f6e\u5411\u91cf\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a WeightRegularizer \u5bf9\u8c61    activity_regularizer\uff1a\u65bd\u52a0\u5728\u8f93\u51fa\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a ActivityRegularizer \u5bf9\u8c61    W_constraints\uff1a\u65bd\u52a0\u5728\u6743\u91cd\u4e0a\u7684\u7ea6\u675f\u9879\uff0c\u4e3a Constraints \u5bf9\u8c61    b_constraints\uff1a\u65bd\u52a0\u5728\u504f\u7f6e\u4e0a\u7684\u7ea6\u675f\u9879\uff0c\u4e3a Constraints \u5bf9\u8c61    bias\uff1a\u5e03\u5c14\u503c\uff0c\u662f\u5426\u5305\u542b\u504f\u7f6e\u5411\u91cf\uff08\u5373\u5c42\u5bf9\u8f93\u5165\u505a\u7ebf\u6027\u53d8\u6362\u8fd8\u662f\u4eff\u5c04\u53d8\u6362\uff09    input_dim\uff1a\u6574\u6570\uff0c\u8f93\u5165\u6570\u636e\u7684\u7ef4\u5ea6\u3002\u5f53\u8be5\u5c42\u4f5c\u4e3a\u7f51\u7edc\u7684\u7b2c\u4e00\u5c42\u65f6\uff0c\u5fc5\u987b\u6307\u5b9a\u8be5\u53c2\u6570\u6216 input_shape \u53c2\u6570\u3002    transform_bias\uff1a\u7528\u4ee5\u521d\u59cb\u5316\u4f20\u9012\u53c2\u6570\uff0c\u9ed8\u8ba4\u4e3a-2\uff08\u8bf7\u53c2\u8003\u6587\u732e\u7406\u89e3\u672c\u53c2\u6570\u7684\u542b\u4e49\uff09", 
            "title": "\u53c2\u6570\uff1a"
        }, 
        {
            "location": "/layers/core_layer/#shape_12", 
            "text": "\u5f62\u5982\uff08nb_samples, input_dim\uff09\u76842D\u5f20\u91cf", 
            "title": "\u8f93\u5165shape"
        }, 
        {
            "location": "/layers/core_layer/#shape_13", 
            "text": "\u5f62\u5982\uff08nb_samples, output_dim\uff09\u76842D\u5f20\u91cf", 
            "title": "\u8f93\u51fashape"
        }, 
        {
            "location": "/layers/core_layer/#_22", 
            "text": "Highway Networks", 
            "title": "\u53c2\u8003\u6587\u732e"
        }, 
        {
            "location": "/layers/core_layer/#maxoutdense", 
            "text": "\u5168\u8fde\u63a5\u7684Maxout\u5c42  MaxoutDense \u5c42\u4ee5 nb_features \u4e2a Dense(input_dim,output_dim) \u7ebf\u6027\u5c42\u7684\u8f93\u51fa\u7684\u6700\u5927\u503c\u4e3a\u8f93\u51fa\u3002 MaxoutDense \u53ef\u5bf9\u8f93\u5165\u5b66\u4e60\u51fa\u4e00\u4e2a\u51f8\u7684\u3001\u5206\u6bb5\u7ebf\u6027\u7684\u6fc0\u6d3b\u51fd\u6570\u3002", 
            "title": "MaxoutDense\u5c42"
        }, 
        {
            "location": "/layers/core_layer/#_23", 
            "text": "nb_features\uff1a\u5185\u90e8\u4f7f\u7528\u7684\u5168\u8fde\u63a5\u5c42\u7684\u6570\u76ee", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/layers/core_layer/#shape_14", 
            "text": "\u5f62\u5982\uff08nb_samples, input_dim\uff09\u76842D\u5f20\u91cf", 
            "title": "\u8f93\u5165shape"
        }, 
        {
            "location": "/layers/core_layer/#shape_15", 
            "text": "\u5f62\u5982\uff08nb_samples, output_dim\uff09\u76842D\u5f20\u91cf", 
            "title": "\u8f93\u51fashape"
        }, 
        {
            "location": "/layers/core_layer/#_24", 
            "text": "Maxout Networks", 
            "title": "\u53c2\u8003\u6587\u732e"
        }, 
        {
            "location": "/layers/convolutional_layer/", 
            "text": "\u5377\u79ef\u5c42\n\n\nConvolution1D\u5c42\n\n\nkeras.layers.convolutional.Convolution1D(nb_filter, filter_length, init='uniform', activation='linear', weights=None, border_mode='valid', subsample_length=1, W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None, bias=True, input_dim=None, input_length=None)\n\n\n\n\n\u4e00\u7ef4\u5377\u79ef\u5c42\uff0c\u7528\u4ee5\u5728\u4e00\u7ef4\u8f93\u5165\u4fe1\u53f7\u4e0a\u8fdb\u884c\u90bb\u57df\u6ee4\u6ce2\u3002\u5f53\u4f7f\u7528\u8be5\u5c42\u4f5c\u4e3a\u9996\u5c42\u65f6\uff0c\u9700\u8981\u63d0\u4f9b\u5173\u952e\u5b57\u53c2\u6570\ninput_dim\n\u6216\ninput_shape\n\u3002\u4f8b\u5982\ninput_dim=128\n\u957f\u4e3a128\u7684\u5411\u91cf\u5e8f\u5217\u8f93\u5165\uff0c\u800c\ninput_shape=(10,128)\n\u4ee3\u8868\u4e00\u4e2a\u957f\u4e3a10\u7684128\u5411\u91cf\u5e8f\u5217\n\n\n\u53c2\u6570\n\n\n\n\n\n\nnb_filter\uff1a\u5377\u79ef\u6838\u7684\u6570\u76ee\uff08\u5373\u8f93\u51fa\u7684\u7ef4\u5ea6\uff09\n\n\n\n\n\n\nfilter_length\uff1a\u5377\u79ef\u6838\u7684\u7a7a\u57df\u6216\u65f6\u57df\u957f\u5ea6\n\n\n\n\n\n\ninit\uff1a\u521d\u59cb\u5316\u65b9\u6cd5\uff0c\u4e3a\u9884\u5b9a\u4e49\u521d\u59cb\u5316\u65b9\u6cd5\u540d\u7684\u5b57\u7b26\u4e32\uff0c\u6216\u7528\u4e8e\u521d\u59cb\u5316\u6743\u91cd\u7684Theano\u51fd\u6570\u3002\u8be5\u53c2\u6570\u4ec5\u5728\u4e0d\u4f20\u9012\nweights\n\u53c2\u6570\u65f6\u6709\u610f\u4e49\u3002\n\n\n\n\n\n\nactivation\uff1a\u6fc0\u6d3b\u51fd\u6570\uff0c\u4e3a\u9884\u5b9a\u4e49\u7684\u6fc0\u6d3b\u51fd\u6570\u540d\uff08\u53c2\u8003\n\u6fc0\u6d3b\u51fd\u6570\n\uff09\uff0c\u6216\u9010\u5143\u7d20\uff08element-wise\uff09\u7684Theano\u51fd\u6570\u3002\u5982\u679c\u4e0d\u6307\u5b9a\u8be5\u53c2\u6570\uff0c\u5c06\u4e0d\u4f1a\u4f7f\u7528\u4efb\u4f55\u6fc0\u6d3b\u51fd\u6570\uff08\u5373\u4f7f\u7528\u7ebf\u6027\u6fc0\u6d3b\u51fd\u6570\uff1aa(x)=x\uff09\n\n\n\n\n\n\nweights\uff1a\u6743\u503c\uff0c\u4e3anumpy array\u7684list\u3002\u8be5list\u5e94\u542b\u6709\u4e00\u4e2a\u5f62\u5982\uff08input_dim,output_dim\uff09\u7684\u6743\u91cd\u77e9\u9635\u548c\u4e00\u4e2a\u5f62\u5982(output_dim,)\u7684\u504f\u7f6e\u5411\u91cf\u3002\n\n\n\n\n\n\nborder_mode\uff1a\u8fb9\u754c\u6a21\u5f0f\uff0c\u4e3a\u201cvalid\u201d, \u201csame\u201d \u6216\u201cfull\u201d\uff0cfull\u9700\u8981\u4ee5theano\u4e3a\u540e\u7aef\n\n\n\n\n\n\nsubsample_length\uff1a\u8f93\u51fa\u5bf9\u8f93\u5165\u7684\u4e0b\u91c7\u6837\u56e0\u5b50\n\n\n\n\n\n\nW_regularizer\uff1a\u65bd\u52a0\u5728\u6743\u91cd\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a\nWeightRegularizer\n\u5bf9\u8c61\n\n\n\n\n\n\nb_regularizer\uff1a\u65bd\u52a0\u5728\u504f\u7f6e\u5411\u91cf\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a\nWeightRegularizer\n\u5bf9\u8c61\n\n\n\n\n\n\nactivity_regularizer\uff1a\u65bd\u52a0\u5728\u8f93\u51fa\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a\nActivityRegularizer\n\u5bf9\u8c61\n\n\n\n\n\n\nW_constraints\uff1a\u65bd\u52a0\u5728\u6743\u91cd\u4e0a\u7684\u7ea6\u675f\u9879\uff0c\u4e3a\nConstraints\n\u5bf9\u8c61\n\n\n\n\n\n\nb_constraints\uff1a\u65bd\u52a0\u5728\u504f\u7f6e\u4e0a\u7684\u7ea6\u675f\u9879\uff0c\u4e3a\nConstraints\n\u5bf9\u8c61\n\n\n\n\n\n\nbias\uff1a\u5e03\u5c14\u503c\uff0c\u662f\u5426\u5305\u542b\u504f\u7f6e\u5411\u91cf\uff08\u5373\u5c42\u5bf9\u8f93\u5165\u505a\u7ebf\u6027\u53d8\u6362\u8fd8\u662f\u4eff\u5c04\u53d8\u6362\uff09\n\n\n\n\n\n\ninput_dim\uff1a\u6574\u6570\uff0c\u8f93\u5165\u6570\u636e\u7684\u7ef4\u5ea6\u3002\u5f53\u8be5\u5c42\u4f5c\u4e3a\u7f51\u7edc\u7684\u7b2c\u4e00\u5c42\u65f6\uff0c\u5fc5\u987b\u6307\u5b9a\u8be5\u53c2\u6570\u6216\ninput_shape\n\u53c2\u6570\u3002\n\n\n\n\n\n\ninput_length\uff1a\u5f53\u8f93\u5165\u5e8f\u5217\u7684\u957f\u5ea6\u56fa\u5b9a\u65f6\uff0c\u8be5\u53c2\u6570\u4e3a\u8f93\u5165\u5e8f\u5217\u7684\u957f\u5ea6\u3002\u5f53\u9700\u8981\u5728\u8be5\u5c42\u540e\u8fde\u63a5\nFlatten\n\u5c42\uff0c\u7136\u540e\u53c8\u8981\u8fde\u63a5\nDense\n\u5c42\u65f6\uff0c\u9700\u8981\u6307\u5b9a\u8be5\u53c2\u6570\uff0c\u5426\u5219\u5168\u8fde\u63a5\u7684\u8f93\u51fa\u65e0\u6cd5\u8ba1\u7b97\u51fa\u6765\u3002\n\n\n\n\n\n\n\u8f93\u5165shape\n\n\n\u5f62\u5982\uff08samples\uff0csteps\uff0cinput_dim\uff09\u76843D\u5f20\u91cf\n\n\n\u8f93\u51fashape\n\n\n\u5f62\u5982\uff08samples\uff0cnew_steps\uff0cnb_filter\uff09\u76843D\u5f20\u91cf\uff0c\u56e0\u4e3a\u6709\u5411\u91cf\u586b\u5145\u7684\u539f\u56e0\uff0c\nsteps\n\u7684\u503c\u4f1a\u6539\u53d8\n\n\n\u4f8b\u5b50\n\n\n# apply a convolution 1d of length 3 to a sequence with 10 timesteps,\n# with 64 output filters\nmodel = Sequential()\nmodel.add(Convolution1D(64, 3, border_mode='same', input_shape=(10, 32)))\n# now model.output_shape == (None, 10, 64)\n\n# add a new conv1d on top\nmodel.add(Convolution1D(32, 3, border_mode='same'))\n# now model.output_shape == (None, 10, 32)\n\n\n\n\n\u3010Tips\u3011\u53ef\u4ee5\u5c06Convolution1D\u770b\u4f5cConvolution2D\u7684\u5feb\u6377\u7248\uff0c\u5bf9\u4f8b\u5b50\u4e2d\uff0810\uff0c32\uff09\u7684\u4fe1\u53f7\u8fdb\u884c1D\u5377\u79ef\u76f8\u5f53\u4e8e\u5bf9\u5176\u8fdb\u884c\u5377\u79ef\u6838\u4e3a\uff08filter_length, 32\uff09\u76842D\u5377\u79ef\u3002\u3010@3rduncle\u3011\n\n\n\n\nAtrousConvolution1D\u5c42\n\n\nkeras.layers.convolutional.AtrousConvolution1D(nb_filter, filter_length, init='uniform', activation='linear', weights=None, border_mode='valid', subsample_length=1, atrous_rate=1, W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None, bias=True)\n\n\n\n\nAtrousConvolution1D\u5c42\u7528\u4e8e\u5bf91D\u4fe1\u53f7\u8fdb\u884c\u6ee4\u6ce2\uff0c\u662f\u81a8\u80c0/\u5e26\u5b54\u6d1e\u7684\u5377\u79ef\u3002\u5f53\u4f7f\u7528\u8be5\u5c42\u4f5c\u4e3a\u9996\u5c42\u65f6\uff0c\u9700\u8981\u63d0\u4f9b\u5173\u952e\u5b57\u53c2\u6570\ninput_dim\n\u6216\ninput_shape\n\u3002\u4f8b\u5982\ninput_dim=128\n\u957f\u4e3a128\u7684\u5411\u91cf\u5e8f\u5217\u8f93\u5165\uff0c\u800c\ninput_shape=(10,128)\n\u4ee3\u8868\u4e00\u4e2a\u957f\u4e3a10\u7684128\u5411\u91cf\u5e8f\u5217.\n\n\n\u53c2\u6570\n\n\n\n\n\n\nnb_filter\uff1a\u5377\u79ef\u6838\u7684\u6570\u76ee\uff08\u5373\u8f93\u51fa\u7684\u7ef4\u5ea6\uff09\n\n\n\n\n\n\nfilter_length\uff1a\u5377\u79ef\u6838\u7684\u7a7a\u57df\u6216\u65f6\u57df\u957f\u5ea6\n\n\n\n\n\n\ninit\uff1a\u521d\u59cb\u5316\u65b9\u6cd5\uff0c\u4e3a\u9884\u5b9a\u4e49\u521d\u59cb\u5316\u65b9\u6cd5\u540d\u7684\u5b57\u7b26\u4e32\uff0c\u6216\u7528\u4e8e\u521d\u59cb\u5316\u6743\u91cd\u7684Theano\u51fd\u6570\u3002\u8be5\u53c2\u6570\u4ec5\u5728\u4e0d\u4f20\u9012\nweights\n\u53c2\u6570\u65f6\u6709\u610f\u4e49\u3002\n\n\n\n\n\n\nactivation\uff1a\u6fc0\u6d3b\u51fd\u6570\uff0c\u4e3a\u9884\u5b9a\u4e49\u7684\u6fc0\u6d3b\u51fd\u6570\u540d\uff08\u53c2\u8003\n\u6fc0\u6d3b\u51fd\u6570\n\uff09\uff0c\u6216\u9010\u5143\u7d20\uff08element-wise\uff09\u7684Theano\u51fd\u6570\u3002\u5982\u679c\u4e0d\u6307\u5b9a\u8be5\u53c2\u6570\uff0c\u5c06\u4e0d\u4f1a\u4f7f\u7528\u4efb\u4f55\u6fc0\u6d3b\u51fd\u6570\uff08\u5373\u4f7f\u7528\u7ebf\u6027\u6fc0\u6d3b\u51fd\u6570\uff1aa(x)=x\uff09\n\n\n\n\n\n\nweights\uff1a\u6743\u503c\uff0c\u4e3anumpy array\u7684list\u3002\u8be5list\u5e94\u542b\u6709\u4e00\u4e2a\u5f62\u5982\uff08input_dim,output_dim\uff09\u7684\u6743\u91cd\u77e9\u9635\u548c\u4e00\u4e2a\u5f62\u5982(output_dim,)\u7684\u504f\u7f6e\u5411\u91cf\u3002\n\n\n\n\n\n\nborder_mode\uff1a\u8fb9\u754c\u6a21\u5f0f\uff0c\u4e3a\u201cvalid\u201d\uff0c\u201csame\u201d\u6216\u201cfull\u201d\uff0cfull\u9700\u8981\u4ee5theano\u4e3a\u540e\u7aef\n\n\n\n\n\n\nsubsample_length\uff1a\u8f93\u51fa\u5bf9\u8f93\u5165\u7684\u4e0b\u91c7\u6837\u56e0\u5b50\n\n\n\n\n\n\natrous_rate:\u5377\u79ef\u6838\u81a8\u80c0\u7684\u7cfb\u6570\uff0c\u5728\u5176\u4ed6\u5730\u65b9\u4e5f\u88ab\u79f0\u4e3a'filter_dilation'\n\n\n\n\n\n\nW_regularizer\uff1a\u65bd\u52a0\u5728\u6743\u91cd\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a\nWeightRegularizer\n\u5bf9\u8c61\n\n\n\n\n\n\nb_regularizer\uff1a\u65bd\u52a0\u5728\u504f\u7f6e\u5411\u91cf\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a\nWeightRegularizer\n\u5bf9\u8c61\n\n\n\n\n\n\nactivity_regularizer\uff1a\u65bd\u52a0\u5728\u8f93\u51fa\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a\nActivityRegularizer\n\u5bf9\u8c61\n\n\n\n\n\n\nW_constraints\uff1a\u65bd\u52a0\u5728\u6743\u91cd\u4e0a\u7684\u7ea6\u675f\u9879\uff0c\u4e3a\nConstraints\n\u5bf9\u8c61\n\n\n\n\n\n\nb_constraints\uff1a\u65bd\u52a0\u5728\u504f\u7f6e\u4e0a\u7684\u7ea6\u675f\u9879\uff0c\u4e3a\nConstraints\n\u5bf9\u8c61\n\n\n\n\n\n\nbias\uff1a\u5e03\u5c14\u503c\uff0c\u662f\u5426\u5305\u542b\u504f\u7f6e\u5411\u91cf\uff08\u5373\u5c42\u5bf9\u8f93\u5165\u505a\u7ebf\u6027\u53d8\u6362\u8fd8\u662f\u4eff\u5c04\u53d8\u6362\uff09\n\n\n\n\n\n\ninput_dim\uff1a\u6574\u6570\uff0c\u8f93\u5165\u6570\u636e\u7684\u7ef4\u5ea6\u3002\u5f53\u8be5\u5c42\u4f5c\u4e3a\u7f51\u7edc\u7684\u7b2c\u4e00\u5c42\u65f6\uff0c\u5fc5\u987b\u6307\u5b9a\u8be5\u53c2\u6570\u6216\ninput_shape\n\u53c2\u6570\u3002\n\n\n\n\n\n\ninput_length\uff1a\u5f53\u8f93\u5165\u5e8f\u5217\u7684\u957f\u5ea6\u56fa\u5b9a\u65f6\uff0c\u8be5\u53c2\u6570\u4e3a\u8f93\u5165\u5e8f\u5217\u7684\u957f\u5ea6\u3002\u5f53\u9700\u8981\u5728\u8be5\u5c42\u540e\u8fde\u63a5\nFlatten\n\u5c42\uff0c\u7136\u540e\u53c8\u8981\u8fde\u63a5\nDense\n\u5c42\u65f6\uff0c\u9700\u8981\u6307\u5b9a\u8be5\u53c2\u6570\uff0c\u5426\u5219\u5168\u8fde\u63a5\u7684\u8f93\u51fa\u65e0\u6cd5\u8ba1\u7b97\u51fa\u6765\u3002\n\n\n\n\n\n\n\u8f93\u5165shape\n\n\n\u5f62\u5982\uff08samples\uff0csteps\uff0cinput_dim\uff09\u76843D\u5f20\u91cf\n\n\n\u8f93\u51fashape\n\n\n\u5f62\u5982\uff08samples\uff0cnew_steps\uff0cnb_filter\uff09\u76843D\u5f20\u91cf\uff0c\u56e0\u4e3a\u6709\u5411\u91cf\u586b\u5145\u7684\u539f\u56e0\uff0c\nsteps\n\u7684\u503c\u4f1a\u6539\u53d8\n\n\n\u4f8b\u5b50\n\n\n# apply an atrous convolution 1d with atrous rate 2 of length 3 to a sequence with 10 timesteps,\n# with 64 output filters\nmodel = Sequential()\nmodel.add(AtrousConvolution1D(64, 3, atrous_rate=2, border_mode='same', input_shape=(10, 32)))\n# now model.output_shape == (None, 10, 64)\n\n# add a new atrous conv1d on top\nmodel.add(AtrousConvolution1D(32, 3, atrous_rate=2, border_mode='same'))\n# now model.output_shape == (None, 10, 32)\n\n\n\n\n\n\nConvolution2D\u5c42\n\n\nkeras.layers.convolutional.Convolution2D(nb_filter, nb_row, nb_col, init='glorot_uniform', activation='linear', weights=None, border_mode='valid', subsample=(1, 1), dim_ordering='th', W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None, bias=True)\n\n\n\n\n\u4e8c\u7ef4\u5377\u79ef\u5c42\u5bf9\u4e8c\u7ef4\u8f93\u5165\u8fdb\u884c\u6ed1\u52a8\u7a97\u5377\u79ef\uff0c\u5f53\u4f7f\u7528\u8be5\u5c42\u4f5c\u4e3a\u7b2c\u4e00\u5c42\u65f6\uff0c\u5e94\u63d0\u4f9b\ninput_shape\n\u53c2\u6570\u3002\u4f8b\u5982\ninput_shape = (3,128,128)\n\u4ee3\u8868128*128\u7684\u5f69\u8272RGB\u56fe\u50cf\n\n\n\u53c2\u6570\n\n\n\n\n\n\nnb_filter\uff1a\u5377\u79ef\u6838\u7684\u6570\u76ee\n\n\n\n\n\n\nnb_row\uff1a\u5377\u79ef\u6838\u7684\u884c\u6570\n\n\n\n\n\n\nnb_col\uff1a\u5377\u79ef\u6838\u7684\u5217\u6570\n\n\n\n\n\n\ninit\uff1a\u521d\u59cb\u5316\u65b9\u6cd5\uff0c\u4e3a\u9884\u5b9a\u4e49\u521d\u59cb\u5316\u65b9\u6cd5\u540d\u7684\u5b57\u7b26\u4e32\uff0c\u6216\u7528\u4e8e\u521d\u59cb\u5316\u6743\u91cd\u7684Theano\u51fd\u6570\u3002\u8be5\u53c2\u6570\u4ec5\u5728\u4e0d\u4f20\u9012\nweights\n\u53c2\u6570\u65f6\u6709\u610f\u4e49\u3002\n\n\n\n\n\n\nactivation\uff1a\u6fc0\u6d3b\u51fd\u6570\uff0c\u4e3a\u9884\u5b9a\u4e49\u7684\u6fc0\u6d3b\u51fd\u6570\u540d\uff08\u53c2\u8003\n\u6fc0\u6d3b\u51fd\u6570\n\uff09\uff0c\u6216\u9010\u5143\u7d20\uff08element-wise\uff09\u7684Theano\u51fd\u6570\u3002\u5982\u679c\u4e0d\u6307\u5b9a\u8be5\u53c2\u6570\uff0c\u5c06\u4e0d\u4f1a\u4f7f\u7528\u4efb\u4f55\u6fc0\u6d3b\u51fd\u6570\uff08\u5373\u4f7f\u7528\u7ebf\u6027\u6fc0\u6d3b\u51fd\u6570\uff1aa(x)=x\uff09\n\n\n\n\n\n\nweights\uff1a\u6743\u503c\uff0c\u4e3anumpy array\u7684list\u3002\u8be5list\u5e94\u542b\u6709\u4e00\u4e2a\u5f62\u5982\uff08input_dim,output_dim\uff09\u7684\u6743\u91cd\u77e9\u9635\u548c\u4e00\u4e2a\u5f62\u5982(output_dim,)\u7684\u504f\u7f6e\u5411\u91cf\u3002\n\n\n\n\n\n\nborder_mode\uff1a\u8fb9\u754c\u6a21\u5f0f\uff0c\u4e3a\u201cvalid\u201d\uff0c\u201csame\u201d\u6216\u201cfull\u201d\uff0cfull\u9700\u8981\u4ee5theano\u4e3a\u540e\u7aef\n\n\n\n\n\n\nsubsample\uff1a\u957f\u4e3a2\u7684tuple\uff0c\u8f93\u51fa\u5bf9\u8f93\u5165\u7684\u4e0b\u91c7\u6837\u56e0\u5b50\uff0c\u66f4\u666e\u904d\u7684\u79f0\u547c\u662f\u201cstrides\u201d\n\n\n\n\n\n\nW_regularizer\uff1a\u65bd\u52a0\u5728\u6743\u91cd\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a\nWeightRegularizer\n\u5bf9\u8c61\n\n\n\n\n\n\nb_regularizer\uff1a\u65bd\u52a0\u5728\u504f\u7f6e\u5411\u91cf\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a\nWeightRegularizer\n\u5bf9\u8c61\n\n\n\n\n\n\nactivity_regularizer\uff1a\u65bd\u52a0\u5728\u8f93\u51fa\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a\nActivityRegularizer\n\u5bf9\u8c61\n\n\n\n\n\n\nW_constraints\uff1a\u65bd\u52a0\u5728\u6743\u91cd\u4e0a\u7684\u7ea6\u675f\u9879\uff0c\u4e3a\nConstraints\n\u5bf9\u8c61\n\n\n\n\n\n\nb_constraints\uff1a\u65bd\u52a0\u5728\u504f\u7f6e\u4e0a\u7684\u7ea6\u675f\u9879\uff0c\u4e3a\nConstraints\n\u5bf9\u8c61\n\n\n\n\n\n\ndim_ordering\uff1a\u2018th\u2019\u6216\u2018tf\u2019\u3002\u2018th\u2019\u6a21\u5f0f\u4e2d\u901a\u9053\u7ef4\uff08\u5982\u5f69\u8272\u56fe\u50cf\u76843\u901a\u9053\uff09\u4f4d\u4e8e\u7b2c1\u4e2a\u4f4d\u7f6e\uff08\u7ef4\u5ea6\u4ece0\u5f00\u59cb\u7b97\uff09\uff0c\u800c\u5728\u2018tf\u2019\u6a21\u5f0f\u4e2d\uff0c\u901a\u9053\u7ef4\u4f4d\u4e8e\u7b2c3\u4e2a\u4f4d\u7f6e\u3002\u4f8b\u5982128*128\u7684\u4e09\u901a\u9053\u5f69\u8272\u56fe\u7247\uff0c\u5728\u2018th\u2019\u6a21\u5f0f\u4e2d\ninput_shape\n\u5e94\u5199\u4e3a\uff083\uff0c128\uff0c128\uff09\uff0c\u800c\u5728\u2018tf\u2019\u6a21\u5f0f\u4e2d\u5e94\u5199\u4e3a\uff08128\uff0c128\uff0c3\uff09\uff0c\u6ce8\u610f\u8fd9\u91cc3\u51fa\u73b0\u5728\u7b2c0\u4e2a\u4f4d\u7f6e\uff0c\u56e0\u4e3a\ninput_shape\n\u4e0d\u5305\u542b\u6837\u672c\u6570\u7684\u7ef4\u5ea6\uff0c\u5728\u5176\u5185\u90e8\u5b9e\u73b0\u4e2d\uff0c\u5b9e\u9645\u4e0a\u662f\uff08None\uff0c3\uff0c128\uff0c128\uff09\u548c\uff08None\uff0c128\uff0c128\uff0c3\uff09\u3002\u9ed8\u8ba4\u662f\nimage_dim_ordering\n\u6307\u5b9a\u7684\u6a21\u5f0f\uff0c\u53ef\u5728\n~/.keras/keras.json\n\u4e2d\u67e5\u770b\uff0c\u82e5\u6ca1\u6709\u8bbe\u7f6e\u8fc7\u5219\u4e3a'tf'\u3002\n\n\n\n\n\n\nbias\uff1a\u5e03\u5c14\u503c\uff0c\u662f\u5426\u5305\u542b\u504f\u7f6e\u5411\u91cf\uff08\u5373\u5c42\u5bf9\u8f93\u5165\u505a\u7ebf\u6027\u53d8\u6362\u8fd8\u662f\u4eff\u5c04\u53d8\u6362\uff09\n\n\n\n\n\n\n\u8f93\u5165shape\n\n\n\u2018th\u2019\u6a21\u5f0f\u4e0b\uff0c\u8f93\u5165\u5f62\u5982\uff08samples,channels\uff0crows\uff0ccols\uff09\u76844D\u5f20\u91cf\n\n\n\u2018tf\u2019\u6a21\u5f0f\u4e0b\uff0c\u8f93\u5165\u5f62\u5982\uff08samples\uff0crows\uff0ccols\uff0cchannels\uff09\u76844D\u5f20\u91cf\n\n\n\u6ce8\u610f\u8fd9\u91cc\u7684\u8f93\u5165shape\u6307\u7684\u662f\u51fd\u6570\u5185\u90e8\u5b9e\u73b0\u7684\u8f93\u5165shape\uff0c\u800c\u975e\u51fd\u6570\u63a5\u53e3\u5e94\u6307\u5b9a\u7684\ninput_shape\n\uff0c\u8bf7\u53c2\u8003\u4e0b\u9762\u63d0\u4f9b\u7684\u4f8b\u5b50\u3002\n\n\n\u8f93\u51fashape\n\n\n\u2018th\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples\uff0cnb_filter, new_rows, new_cols\uff09\u76844D\u5f20\u91cf\n\n\n\u2018tf\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples\uff0cnew_rows, new_cols\uff0cnb_filter\uff09\u76844D\u5f20\u91cf\n\n\n\u8f93\u51fa\u7684\u884c\u5217\u6570\u53ef\u80fd\u4f1a\u56e0\u4e3a\u586b\u5145\u65b9\u6cd5\u800c\u6539\u53d8\n\n\n\u4f8b\u5b50\n\n\n# apply a 3x3 convolution with 64 output filters on a 256x256 image:\nmodel = Sequential()\nmodel.add(Convolution2D(64, 3, 3, border_mode='same', input_shape=(3, 256, 256)))\n# now model.output_shape == (None, 64, 256, 256)\n\n# add a 3x3 convolution on top, with 32 output filters:\nmodel.add(Convolution2D(32, 3, 3, border_mode='same'))\n# now model.output_shape == (None, 32, 256, 256)\n\n\n\n\n\n\nAtrousConvolution2D\u5c42\n\n\nkeras.layers.convolutional.AtrousConvolution2D(nb_filter, nb_row, nb_col, init='glorot_uniform', activation='linear', weights=None, border_mode='valid', subsample=(1, 1), atrous_rate=(1, 1), dim_ordering='th', W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None, bias=True)\n\n\n\n\n\u8be5\u5c42\u5bf9\u4e8c\u7ef4\u8f93\u5165\u8fdb\u884cAtrous\u5377\u79ef\uff0c\u4e5f\u5373\u81a8\u80c0\u5377\u79ef\u6216\u5e26\u5b54\u6d1e\u7684\u5377\u79ef\u3002\u5f53\u4f7f\u7528\u8be5\u5c42\u4f5c\u4e3a\u7b2c\u4e00\u5c42\u65f6\uff0c\u5e94\u63d0\u4f9b\ninput_shape\n\u53c2\u6570\u3002\u4f8b\u5982\ninput_shape = (3,128,128)\n\u4ee3\u8868128*128\u7684\u5f69\u8272RGB\u56fe\u50cf\n\n\n\u53c2\u6570\n\n\n\n\n\n\nnb_filter\uff1a\u5377\u79ef\u6838\u7684\u6570\u76ee\n\n\n\n\n\n\nnb_row\uff1a\u5377\u79ef\u6838\u7684\u884c\u6570\n\n\n\n\n\n\nnb_col\uff1a\u5377\u79ef\u6838\u7684\u5217\u6570\n\n\n\n\n\n\ninit\uff1a\u521d\u59cb\u5316\u65b9\u6cd5\uff0c\u4e3a\u9884\u5b9a\u4e49\u521d\u59cb\u5316\u65b9\u6cd5\u540d\u7684\u5b57\u7b26\u4e32\uff0c\u6216\u7528\u4e8e\u521d\u59cb\u5316\u6743\u91cd\u7684Theano\u51fd\u6570\u3002\u8be5\u53c2\u6570\u4ec5\u5728\u4e0d\u4f20\u9012\nweights\n\u53c2\u6570\u65f6\u6709\u610f\u4e49\u3002\n\n\n\n\n\n\nactivation\uff1a\u6fc0\u6d3b\u51fd\u6570\uff0c\u4e3a\u9884\u5b9a\u4e49\u7684\u6fc0\u6d3b\u51fd\u6570\u540d\uff08\u53c2\u8003\n\u6fc0\u6d3b\u51fd\u6570\n\uff09\uff0c\u6216\u9010\u5143\u7d20\uff08element-wise\uff09\u7684Theano\u51fd\u6570\u3002\u5982\u679c\u4e0d\u6307\u5b9a\u8be5\u53c2\u6570\uff0c\u5c06\u4e0d\u4f1a\u4f7f\u7528\u4efb\u4f55\u6fc0\u6d3b\u51fd\u6570\uff08\u5373\u4f7f\u7528\u7ebf\u6027\u6fc0\u6d3b\u51fd\u6570\uff1aa(x)=x\uff09\n\n\n\n\n\n\nweights\uff1a\u6743\u503c\uff0c\u4e3anumpy array\u7684list\u3002\u8be5list\u5e94\u542b\u6709\u4e00\u4e2a\u5f62\u5982\uff08input_dim,output_dim\uff09\u7684\u6743\u91cd\u77e9\u9635\u548c\u4e00\u4e2a\u5f62\u5982(output_dim,)\u7684\u504f\u7f6e\u5411\u91cf\u3002\n\n\n\n\n\n\nborder_mode\uff1a\u8fb9\u754c\u6a21\u5f0f\uff0c\u4e3a\u201cvalid\u201d\uff0c\u201csame\u201d\uff0c\u6216\u201cfull\u201d\uff0cfull\u9700\u8981\u4ee5theano\u4e3a\u540e\u7aef\n\n\n\n\n\n\nsubsample\uff1a\u957f\u4e3a2\u7684tuple\uff0c\u8f93\u51fa\u5bf9\u8f93\u5165\u7684\u4e0b\u91c7\u6837\u56e0\u5b50\uff0c\u66f4\u666e\u904d\u7684\u79f0\u547c\u662f\u201cstrides\u201d\n\n\n\n\n\n\natrous_rate\uff1a\u957f\u4e3a2\u7684tuple\uff0c\u4ee3\u8868\u5377\u79ef\u6838\u81a8\u80c0\u7684\u7cfb\u6570\uff0c\u5728\u5176\u4ed6\u5730\u65b9\u4e5f\u88ab\u79f0\u4e3a'filter_dilation'\n\n\n\n\n\n\nW_regularizer\uff1a\u65bd\u52a0\u5728\u6743\u91cd\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a\nWeightRegularizer\n\u5bf9\u8c61\n\n\n\n\n\n\nb_regularizer\uff1a\u65bd\u52a0\u5728\u504f\u7f6e\u5411\u91cf\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a\nWeightRegularizer\n\u5bf9\u8c61\n\n\n\n\n\n\nactivity_regularizer\uff1a\u65bd\u52a0\u5728\u8f93\u51fa\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a\nActivityRegularizer\n\u5bf9\u8c61\n\n\n\n\n\n\nW_constraints\uff1a\u65bd\u52a0\u5728\u6743\u91cd\u4e0a\u7684\u7ea6\u675f\u9879\uff0c\u4e3a\nConstraints\n\u5bf9\u8c61\n\n\n\n\n\n\nb_constraints\uff1a\u65bd\u52a0\u5728\u504f\u7f6e\u4e0a\u7684\u7ea6\u675f\u9879\uff0c\u4e3a\nConstraints\n\u5bf9\u8c61\n\n\n\n\n\n\ndim_ordering\uff1a\u2018th\u2019\u6216\u2018tf\u2019\u3002\u2018th\u2019\u6a21\u5f0f\u4e2d\u901a\u9053\u7ef4\uff08\u5982\u5f69\u8272\u56fe\u50cf\u76843\u901a\u9053\uff09\u4f4d\u4e8e\u7b2c1\u4e2a\u4f4d\u7f6e\uff08\u7ef4\u5ea6\u4ece0\u5f00\u59cb\u7b97\uff09\uff0c\u800c\u5728\u2018tf\u2019\u6a21\u5f0f\u4e2d\uff0c\u901a\u9053\u7ef4\u4f4d\u4e8e\u7b2c3\u4e2a\u4f4d\u7f6e\u3002\u4f8b\u5982128*128\u7684\u4e09\u901a\u9053\u5f69\u8272\u56fe\u7247\uff0c\u5728\u2018th\u2019\u6a21\u5f0f\u4e2d\ninput_shape\n\u5e94\u5199\u4e3a\uff083\uff0c128\uff0c128\uff09\uff0c\u800c\u5728\u2018tf\u2019\u6a21\u5f0f\u4e2d\u5e94\u5199\u4e3a\uff08128\uff0c128\uff0c3\uff09\uff0c\u6ce8\u610f\u8fd9\u91cc3\u51fa\u73b0\u5728\u7b2c0\u4e2a\u4f4d\u7f6e\uff0c\u56e0\u4e3a\ninput_shape\n\u4e0d\u5305\u542b\u6837\u672c\u6570\u7684\u7ef4\u5ea6\uff0c\u5728\u5176\u5185\u90e8\u5b9e\u73b0\u4e2d\uff0c\u5b9e\u9645\u4e0a\u662f\uff08None\uff0c3\uff0c128\uff0c128\uff09\u548c\uff08None\uff0c128\uff0c128\uff0c3\uff09\u3002\u9ed8\u8ba4\u662f\nimage_dim_ordering\n\u6307\u5b9a\u7684\u6a21\u5f0f\uff0c\u53ef\u5728\n~/.keras/keras.json\n\u4e2d\u67e5\u770b\uff0c\u82e5\u6ca1\u6709\u8bbe\u7f6e\u8fc7\u5219\u4e3a'tf'\u3002\n\n\n\n\n\n\nbias\uff1a\u5e03\u5c14\u503c\uff0c\u662f\u5426\u5305\u542b\u504f\u7f6e\u5411\u91cf\uff08\u5373\u5c42\u5bf9\u8f93\u5165\u505a\u7ebf\u6027\u53d8\u6362\u8fd8\u662f\u4eff\u5c04\u53d8\u6362\uff09\n\n\n\n\n\n\n\u8f93\u5165shape\n\n\n\u2018th\u2019\u6a21\u5f0f\u4e0b\uff0c\u8f93\u5165\u5f62\u5982\uff08samples,channels\uff0crows\uff0ccols\uff09\u76844D\u5f20\u91cf\n\n\n\u2018tf\u2019\u6a21\u5f0f\u4e0b\uff0c\u8f93\u5165\u5f62\u5982\uff08samples\uff0crows\uff0ccols\uff0cchannels\uff09\u76844D\u5f20\u91cf\n\n\n\u6ce8\u610f\u8fd9\u91cc\u7684\u8f93\u5165shape\u6307\u7684\u662f\u51fd\u6570\u5185\u90e8\u5b9e\u73b0\u7684\u8f93\u5165shape\uff0c\u800c\u975e\u51fd\u6570\u63a5\u53e3\u5e94\u6307\u5b9a\u7684\ninput_shape\n\uff0c\u8bf7\u53c2\u8003\u4e0b\u9762\u63d0\u4f9b\u7684\u4f8b\u5b50\u3002\n\n\n\u8f93\u51fashape\n\n\n\u2018th\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples\uff0cnb_filter, new_rows, new_cols\uff09\u76844D\u5f20\u91cf\n\n\n\u2018tf\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples\uff0cnew_rows, new_cols\uff0cnb_filter\uff09\u76844D\u5f20\u91cf\n\n\n\u8f93\u51fa\u7684\u884c\u5217\u6570\u53ef\u80fd\u4f1a\u56e0\u4e3a\u586b\u5145\u800c\u6539\u53d8\n\n\n\u4f8b\u5b50\n\n\n# apply a 3x3 convolution with atrous rate 2x2 and 64 output filters on a 256x256 image:\nmodel = Sequential()\nmodel.add(AtrousConvolution2D(64, 3, 3, atrous_rate=(2,2), border_mode='valid', input_shape=(3, 256, 256)))\n# now the actual kernel size is dilated from 3x3 to 5x5 (3+(3-1)*(2-1)=5)\n# thus model.output_shape == (None, 64, 252, 252)\n\n\n\n\n\u53c2\u8003\u6587\u732e\n\n\n\n\nMulti-Scale Context Aggregation by Dilated Convolutions\n\n\n\n\n\n\nSeparableConvolution2D\u5c42\n\n\nkeras.layers.convolutional.SeparableConvolution2D(nb_filter, nb_row, nb_col, init='glorot_uniform', activation='linear', weights=None, border_mode='valid', subsample=(1, 1), depth_multiplier=1, dim_ordering='default', depthwise_regularizer=None, pointwise_regularizer=None, b_regularizer=None, activity_regularizer=None, depthwise_constraint=None, pointwise_constraint=None, b_constraint=None, bias=True)\n\n\n\n\n\u8be5\u5c42\u662f\u5bf92D\u8f93\u5165\u7684\u53ef\u5206\u79bb\u5377\u79ef\n\n\n\u53ef\u5206\u79bb\u5377\u79ef\u9996\u5148\u6309\u6df1\u5ea6\u65b9\u5411\u8fdb\u884c\u5377\u79ef\uff08\u5bf9\u6bcf\u4e2a\u8f93\u5165\u901a\u9053\u5206\u522b\u5377\u79ef\uff09\uff0c\u7136\u540e\u9010\u70b9\u8fdb\u884c\u5377\u79ef\uff0c\u5c06\u4e0a\u4e00\u6b65\u7684\u5377\u79ef\u7ed3\u679c\u6df7\u5408\u5230\u8f93\u51fa\u901a\u9053\u4e2d\u3002\u53c2\u6570\ndepth_multiplier\n\u63a7\u5236\u4e86\u5728depthwise\u5377\u79ef\uff08\u7b2c\u4e00\u6b65\uff09\u7684\u8fc7\u7a0b\u4e2d\uff0c\u6bcf\u4e2a\u8f93\u5165\u901a\u9053\u4fe1\u53f7\u4ea7\u751f\u591a\u5c11\u4e2a\u8f93\u51fa\u901a\u9053\u3002\n\n\n\u76f4\u89c2\u6765\u8bf4\uff0c\u53ef\u5206\u79bb\u5377\u79ef\u53ef\u4ee5\u770b\u505a\u8bb2\u4e00\u4e2a\u5377\u79ef\u6838\u5206\u89e3\u4e3a\u4e24\u4e2a\u5c0f\u7684\u5377\u79ef\u6838\uff0c\u6216\u770b\u4f5cInception\u6a21\u5757\u7684\u4e00\u79cd\u6781\u7aef\u60c5\u51b5\u3002\n\n\n\u5f53\u4f7f\u7528\u8be5\u5c42\u4f5c\u4e3a\u7b2c\u4e00\u5c42\u65f6\uff0c\u5e94\u63d0\u4f9b\ninput_shape\n\u53c2\u6570\u3002\u4f8b\u5982\ninput_shape = (3,128,128)\n\u4ee3\u8868128*128\u7684\u5f69\u8272RGB\u56fe\u50cf\n\n\nTheano\u8b66\u544a\n\n\n\u8be5\u5c42\u76ee\u524d\u53ea\u80fd\u5728Tensorflow\u540e\u7aef\u7684\u6761\u4ef6\u4e0b\u4f7f\u7528\n\n\n\u53c2\u6570\n\n\n\n\n\n\nnb_filter\uff1a\u5377\u79ef\u6838\u7684\u6570\u76ee\n\n\n\n\n\n\nnb_row\uff1a\u5377\u79ef\u6838\u7684\u884c\u6570\n\n\n\n\n\n\nnb_col\uff1a\u5377\u79ef\u6838\u7684\u5217\u6570\n\n\n\n\n\n\ninit\uff1a\u521d\u59cb\u5316\u65b9\u6cd5\uff0c\u4e3a\u9884\u5b9a\u4e49\u521d\u59cb\u5316\u65b9\u6cd5\u540d\u7684\u5b57\u7b26\u4e32\uff0c\u6216\u7528\u4e8e\u521d\u59cb\u5316\u6743\u91cd\u7684Theano\u51fd\u6570\u3002\u8be5\u53c2\u6570\u4ec5\u5728\u4e0d\u4f20\u9012\nweights\n\u53c2\u6570\u65f6\u6709\u610f\u4e49\u3002\n\n\n\n\n\n\nactivation\uff1a\u6fc0\u6d3b\u51fd\u6570\uff0c\u4e3a\u9884\u5b9a\u4e49\u7684\u6fc0\u6d3b\u51fd\u6570\u540d\uff08\u53c2\u8003\n\u6fc0\u6d3b\u51fd\u6570\n\uff09\uff0c\u6216\u9010\u5143\u7d20\uff08element-wise\uff09\u7684Theano\u51fd\u6570\u3002\u5982\u679c\u4e0d\u6307\u5b9a\u8be5\u53c2\u6570\uff0c\u5c06\u4e0d\u4f1a\u4f7f\u7528\u4efb\u4f55\u6fc0\u6d3b\u51fd\u6570\uff08\u5373\u4f7f\u7528\u7ebf\u6027\u6fc0\u6d3b\u51fd\u6570\uff1aa(x)=x\uff09\n\n\n\n\n\n\nweights\uff1a\u6743\u503c\uff0c\u4e3anumpy array\u7684list\u3002\u8be5list\u5e94\u542b\u6709\u4e00\u4e2a\u5f62\u5982\uff08input_dim,output_dim\uff09\u7684\u6743\u91cd\u77e9\u9635\u548c\u4e00\u4e2a\u5f62\u5982(output_dim,)\u7684\u504f\u7f6e\u5411\u91cf\u3002\n\n\n\n\n\n\nborder_mode\uff1a\u8fb9\u754c\u6a21\u5f0f\uff0c\u4e3a\u201cvalid\u201d\uff0c\u201csame\u201d\uff0c\u6216\u201cfull\u201d\uff0cfull\u9700\u8981\u4ee5theano\u4e3a\u540e\u7aef\n\n\n\n\n\n\nsubsample\uff1a\u957f\u4e3a2\u7684tuple\uff0c\u8f93\u51fa\u5bf9\u8f93\u5165\u7684\u4e0b\u91c7\u6837\u56e0\u5b50\uff0c\u66f4\u666e\u904d\u7684\u79f0\u547c\u662f\u201cstrides\u201d\n\n\n\n\n\n\ndepth_multiplier\uff1a\u5728\u6309\u6df1\u5ea6\u5377\u79ef\u7684\u6b65\u9aa4\u4e2d\uff0c\u6bcf\u4e2a\u8f93\u5165\u901a\u9053\u4f7f\u7528\u591a\u5c11\u4e2a\u8f93\u51fa\u901a\u9053\n\n\n\n\n\n\ndepthwise_regularizer\uff1a\u65bd\u52a0\u5728\u6309\u6df1\u5ea6\u5377\u79ef\u7684\u6743\u91cd\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a\nWeightRegularizer\n\u5bf9\u8c61\n\n\n\n\n\n\npointwise_regularizer\uff1a\u65bd\u52a0\u5728\u6309\u70b9\u5377\u79ef\u7684\u6743\u91cd\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a\nWeightRegularizer\n\u5bf9\u8c61\n\n\n\n\n\n\nb_regularizer\uff1a\u65bd\u52a0\u5728\u504f\u7f6e\u5411\u91cf\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a\nWeightRegularizer\n\u5bf9\u8c61\n\n\n\n\n\n\nactivity_regularizer\uff1a\u65bd\u52a0\u5728\u8f93\u51fa\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a\nActivityRegularizer\n\u5bf9\u8c61\n\n\n\n\n\n\ndepthwise_constraint\uff1a\u65bd\u52a0\u5728\u6309\u6df1\u5ea6\u5377\u79ef\u6743\u91cd\u4e0a\u7684\u7ea6\u675f\u9879\uff0c\u4e3a\nConstraints\n\u5bf9\u8c61\n\n\n\n\n\n\npointwise_constraint\u65bd\u52a0\u5728\u6309\u70b9\u5377\u79ef\u6743\u91cd\u7684\u7ea6\u675f\u9879\uff0c\u4e3a\nConstraints\n\u5bf9\u8c61\n\n\n\n\n\n\nb_constraints\uff1a\u65bd\u52a0\u5728\u504f\u7f6e\u4e0a\u7684\u7ea6\u675f\u9879\uff0c\u4e3a\nConstraints\n\u5bf9\u8c61\n\n\n\n\n\n\ndim_ordering\uff1a\u2018th\u2019\u6216\u2018tf\u2019\u3002\u2018th\u2019\u6a21\u5f0f\u4e2d\u901a\u9053\u7ef4\uff08\u5982\u5f69\u8272\u56fe\u50cf\u76843\u901a\u9053\uff09\u4f4d\u4e8e\u7b2c1\u4e2a\u4f4d\u7f6e\uff08\u7ef4\u5ea6\u4ece0\u5f00\u59cb\u7b97\uff09\uff0c\u800c\u5728\u2018tf\u2019\u6a21\u5f0f\u4e2d\uff0c\u901a\u9053\u7ef4\u4f4d\u4e8e\u7b2c3\u4e2a\u4f4d\u7f6e\u3002\u4f8b\u5982128*128\u7684\u4e09\u901a\u9053\u5f69\u8272\u56fe\u7247\uff0c\u5728\u2018th\u2019\u6a21\u5f0f\u4e2d\ninput_shape\n\u5e94\u5199\u4e3a\uff083\uff0c128\uff0c128\uff09\uff0c\u800c\u5728\u2018tf\u2019\u6a21\u5f0f\u4e2d\u5e94\u5199\u4e3a\uff08128\uff0c128\uff0c3\uff09\uff0c\u6ce8\u610f\u8fd9\u91cc3\u51fa\u73b0\u5728\u7b2c0\u4e2a\u4f4d\u7f6e\uff0c\u56e0\u4e3a\ninput_shape\n\u4e0d\u5305\u542b\u6837\u672c\u6570\u7684\u7ef4\u5ea6\uff0c\u5728\u5176\u5185\u90e8\u5b9e\u73b0\u4e2d\uff0c\u5b9e\u9645\u4e0a\u662f\uff08None\uff0c3\uff0c128\uff0c128\uff09\u548c\uff08None\uff0c128\uff0c128\uff0c3\uff09\u3002\u9ed8\u8ba4\u662f\nimage_dim_ordering\n\u6307\u5b9a\u7684\u6a21\u5f0f\uff0c\u53ef\u5728\n~/.keras/keras.json\n\u4e2d\u67e5\u770b\uff0c\u82e5\u6ca1\u6709\u8bbe\u7f6e\u8fc7\u5219\u4e3a'tf'\u3002\n\n\n\n\n\n\nbias\uff1a\u5e03\u5c14\u503c\uff0c\u662f\u5426\u5305\u542b\u504f\u7f6e\u5411\u91cf\uff08\u5373\u5c42\u5bf9\u8f93\u5165\u505a\u7ebf\u6027\u53d8\u6362\u8fd8\u662f\u4eff\u5c04\u53d8\u6362\uff09\n\n\n\n\n\n\n\u8f93\u5165shape\n\n\n\u2018th\u2019\u6a21\u5f0f\u4e0b\uff0c\u8f93\u5165\u5f62\u5982\uff08samples,channels\uff0crows\uff0ccols\uff09\u76844D\u5f20\u91cf\n\n\n\u2018tf\u2019\u6a21\u5f0f\u4e0b\uff0c\u8f93\u5165\u5f62\u5982\uff08samples\uff0crows\uff0ccols\uff0cchannels\uff09\u76844D\u5f20\u91cf\n\n\n\u6ce8\u610f\u8fd9\u91cc\u7684\u8f93\u5165shape\u6307\u7684\u662f\u51fd\u6570\u5185\u90e8\u5b9e\u73b0\u7684\u8f93\u5165shape\uff0c\u800c\u975e\u51fd\u6570\u63a5\u53e3\u5e94\u6307\u5b9a\u7684\ninput_shape\n\uff0c\u8bf7\u53c2\u8003\u4e0b\u9762\u63d0\u4f9b\u7684\u4f8b\u5b50\u3002\n\n\n\u8f93\u51fashape\n\n\n\u2018th\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples\uff0cnb_filter, new_rows, new_cols\uff09\u76844D\u5f20\u91cf\n\n\n\u2018tf\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples\uff0cnew_rows, new_cols\uff0cnb_filter\uff09\u76844D\u5f20\u91cf\n\n\n\u8f93\u51fa\u7684\u884c\u5217\u6570\u53ef\u80fd\u4f1a\u56e0\u4e3a\u586b\u5145\u65b9\u6cd5\u800c\u6539\u53d8\n\n\n\n\nDeconvolution2D\u5c42\n\n\nkeras.layers.convolutional.Deconvolution2D(nb_filter, nb_row, nb_col, output_shape, init='glorot_uniform', activation='linear', weights=None, border_mode='valid', subsample=(1, 1), dim_ordering='tf', W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None, bias=True)\n\n\n\n\n\u8be5\u5c42\u662f\u5377\u79ef\u64cd\u4f5c\u7684\u8f6c\u7f6e\uff08\u53cd\u5377\u79ef\uff09\u3002\u9700\u8981\u53cd\u5377\u79ef\u7684\u60c5\u51b5\u901a\u5e38\u53d1\u751f\u5728\u7528\u6237\u60f3\u8981\u5bf9\u4e00\u4e2a\u666e\u901a\u5377\u79ef\u7684\u7ed3\u679c\u505a\u53cd\u65b9\u5411\u7684\u53d8\u6362\u3002\u4f8b\u5982\uff0c\u5c06\u5177\u6709\u8be5\u5377\u79ef\u5c42\u8f93\u51fashape\u7684tensor\u8f6c\u6362\u4e3a\u5177\u6709\u8be5\u5377\u79ef\u5c42\u8f93\u5165shape\u7684tensor\u3002\uff0c\u540c\u65f6\u4fdd\u7559\u4e0e\u5377\u79ef\u5c42\u517c\u5bb9\u7684\u8fde\u63a5\u6a21\u5f0f\u3002\n\n\n\u5f53\u4f7f\u7528\u8be5\u5c42\u4f5c\u4e3a\u7b2c\u4e00\u5c42\u65f6\uff0c\u5e94\u63d0\u4f9b\ninput_shape\n\u53c2\u6570\u3002\u4f8b\u5982\ninput_shape = (3,128,128)\n\u4ee3\u8868128*128\u7684\u5f69\u8272RGB\u56fe\u50cf\n\n\n\u53c2\u6570\n\n\n\n\n\n\nnb_filter\uff1a\u5377\u79ef\u6838\u7684\u6570\u76ee\n\n\n\n\n\n\nnb_row\uff1a\u5377\u79ef\u6838\u7684\u884c\u6570\n\n\n\n\n\n\nnb_col\uff1a\u5377\u79ef\u6838\u7684\u5217\u6570\n\n\n\n\n\n\noutput_shape\uff1a\u53cd\u5377\u79ef\u7684\u8f93\u51fashape\uff0c\u4e3a\u6574\u6570\u7684tuple\uff0c\u5f62\u5982\uff08nb_samples,nb_filter,nb_output_rows,nb_output_cols\uff09\uff0c\u8ba1\u7b97output_shape\u7684\u516c\u5f0f\u662f\uff1ao = s (i - 1) + a + k - 2p,\u5176\u4e2da\u7684\u53d6\u503c\u8303\u56f4\u662f0~s-1\uff0c\u5176\u4e2d\uff1a\n\n\n\n\ni:\u8f93\u5165\u7684size\uff08rows\u6216cols\uff09\n\n\nk\uff1a\u5377\u79ef\u6838\u5927\u5c0f\uff08nb_filter\uff09\n\n\ns: \u6b65\u957f\uff08subsample\uff09\n\n\na\uff1a\u7528\u6237\u6307\u5b9a\u7684\u7684\u7528\u4e8e\u533a\u522bs\u4e2a\u4e0d\u540c\u7684\u53ef\u80fdoutput size\u7684\u53c2\u6570\n\n\n\n\n\n\n\n\ninit\uff1a\u521d\u59cb\u5316\u65b9\u6cd5\uff0c\u4e3a\u9884\u5b9a\u4e49\u521d\u59cb\u5316\u65b9\u6cd5\u540d\u7684\u5b57\u7b26\u4e32\uff0c\u6216\u7528\u4e8e\u521d\u59cb\u5316\u6743\u91cd\u7684Theano\u51fd\u6570\u3002\u8be5\u53c2\u6570\u4ec5\u5728\u4e0d\u4f20\u9012\nweights\n\u53c2\u6570\u65f6\u6709\u610f\u4e49\u3002\n\n\n\n\n\n\nactivation\uff1a\u6fc0\u6d3b\u51fd\u6570\uff0c\u4e3a\u9884\u5b9a\u4e49\u7684\u6fc0\u6d3b\u51fd\u6570\u540d\uff08\u53c2\u8003\n\u6fc0\u6d3b\u51fd\u6570\n\uff09\uff0c\u6216\u9010\u5143\u7d20\uff08element-wise\uff09\u7684Theano\u51fd\u6570\u3002\u5982\u679c\u4e0d\u6307\u5b9a\u8be5\u53c2\u6570\uff0c\u5c06\u4e0d\u4f1a\u4f7f\u7528\u4efb\u4f55\u6fc0\u6d3b\u51fd\u6570\uff08\u5373\u4f7f\u7528\u7ebf\u6027\u6fc0\u6d3b\u51fd\u6570\uff1aa(x)=x\uff09\n\n\n\n\n\n\nweights\uff1a\u6743\u503c\uff0c\u4e3anumpy array\u7684list\u3002\u8be5list\u5e94\u542b\u6709\u4e00\u4e2a\u5f62\u5982\uff08input_dim,output_dim\uff09\u7684\u6743\u91cd\u77e9\u9635\u548c\u4e00\u4e2a\u5f62\u5982(output_dim,)\u7684\u504f\u7f6e\u5411\u91cf\u3002\n\n\n\n\n\n\nborder_mode\uff1a\u8fb9\u754c\u6a21\u5f0f\uff0c\u4e3a\u201cvalid\u201d\uff0c\u201csame\u201d\uff0c\u6216\u201cfull\u201d\uff0cfull\u9700\u8981\u4ee5theano\u4e3a\u540e\u7aef\n\n\n\n\n\n\nsubsample\uff1a\u957f\u4e3a2\u7684tuple\uff0c\u8f93\u51fa\u5bf9\u8f93\u5165\u7684\u4e0b\u91c7\u6837\u56e0\u5b50\uff0c\u66f4\u666e\u904d\u7684\u79f0\u547c\u662f\u201cstrides\u201d\n\n\n\n\n\n\nW_regularizer\uff1a\u65bd\u52a0\u5728\u6743\u91cd\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a\nWeightRegularizer\n\u5bf9\u8c61\n\n\n\n\n\n\nb_regularizer\uff1a\u65bd\u52a0\u5728\u504f\u7f6e\u5411\u91cf\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a\nWeightRegularizer\n\u5bf9\u8c61\n\n\n\n\n\n\nactivity_regularizer\uff1a\u65bd\u52a0\u5728\u8f93\u51fa\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a\nActivityRegularizer\n\u5bf9\u8c61\n\n\n\n\n\n\nW_constraints\uff1a\u65bd\u52a0\u5728\u6743\u91cd\u4e0a\u7684\u7ea6\u675f\u9879\uff0c\u4e3a\nConstraints\n\u5bf9\u8c61\n\n\n\n\n\n\nb_constraints\uff1a\u65bd\u52a0\u5728\u504f\u7f6e\u4e0a\u7684\u7ea6\u675f\u9879\uff0c\u4e3a\nConstraints\n\u5bf9\u8c61\n\n\n\n\n\n\ndim_ordering\uff1a\u2018th\u2019\u6216\u2018tf\u2019\u3002\u2018th\u2019\u6a21\u5f0f\u4e2d\u901a\u9053\u7ef4\uff08\u5982\u5f69\u8272\u56fe\u50cf\u76843\u901a\u9053\uff09\u4f4d\u4e8e\u7b2c1\u4e2a\u4f4d\u7f6e\uff08\u7ef4\u5ea6\u4ece0\u5f00\u59cb\u7b97\uff09\uff0c\u800c\u5728\u2018tf\u2019\u6a21\u5f0f\u4e2d\uff0c\u901a\u9053\u7ef4\u4f4d\u4e8e\u7b2c3\u4e2a\u4f4d\u7f6e\u3002\u4f8b\u5982128*128\u7684\u4e09\u901a\u9053\u5f69\u8272\u56fe\u7247\uff0c\u5728\u2018th\u2019\u6a21\u5f0f\u4e2d\ninput_shape\n\u5e94\u5199\u4e3a\uff083\uff0c128\uff0c128\uff09\uff0c\u800c\u5728\u2018tf\u2019\u6a21\u5f0f\u4e2d\u5e94\u5199\u4e3a\uff08128\uff0c128\uff0c3\uff09\uff0c\u6ce8\u610f\u8fd9\u91cc3\u51fa\u73b0\u5728\u7b2c0\u4e2a\u4f4d\u7f6e\uff0c\u56e0\u4e3a\ninput_shape\n\u4e0d\u5305\u542b\u6837\u672c\u6570\u7684\u7ef4\u5ea6\uff0c\u5728\u5176\u5185\u90e8\u5b9e\u73b0\u4e2d\uff0c\u5b9e\u9645\u4e0a\u662f\uff08None\uff0c3\uff0c128\uff0c128\uff09\u548c\uff08None\uff0c128\uff0c128\uff0c3\uff09\u3002\u9ed8\u8ba4\u662f\nimage_dim_ordering\n\u6307\u5b9a\u7684\u6a21\u5f0f\uff0c\u53ef\u5728\n~/.keras/keras.json\n\u4e2d\u67e5\u770b\uff0c\u82e5\u6ca1\u6709\u8bbe\u7f6e\u8fc7\u5219\u4e3a'tf'\u3002\n\n\n\n\n\n\nbias\uff1a\u5e03\u5c14\u503c\uff0c\u662f\u5426\u5305\u542b\u504f\u7f6e\u5411\u91cf\uff08\u5373\u5c42\u5bf9\u8f93\u5165\u505a\u7ebf\u6027\u53d8\u6362\u8fd8\u662f\u4eff\u5c04\u53d8\u6362\uff09\n\n\n\n\n\n\n\u8f93\u5165shape\n\n\n\u2018th\u2019\u6a21\u5f0f\u4e0b\uff0c\u8f93\u5165\u5f62\u5982\uff08samples,channels\uff0crows\uff0ccols\uff09\u76844D\u5f20\u91cf\n\n\n\u2018tf\u2019\u6a21\u5f0f\u4e0b\uff0c\u8f93\u5165\u5f62\u5982\uff08samples\uff0crows\uff0ccols\uff0cchannels\uff09\u76844D\u5f20\u91cf\n\n\n\u6ce8\u610f\u8fd9\u91cc\u7684\u8f93\u5165shape\u6307\u7684\u662f\u51fd\u6570\u5185\u90e8\u5b9e\u73b0\u7684\u8f93\u5165shape\uff0c\u800c\u975e\u51fd\u6570\u63a5\u53e3\u5e94\u6307\u5b9a\u7684\ninput_shape\n\uff0c\u8bf7\u53c2\u8003\u4e0b\u9762\u63d0\u4f9b\u7684\u4f8b\u5b50\u3002\n\n\n\u8f93\u51fashape\n\n\n\u2018th\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples\uff0cnb_filter, new_rows, new_cols\uff09\u76844D\u5f20\u91cf\n\n\n\u2018tf\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples\uff0cnew_rows, new_cols\uff0cnb_filter\uff09\u76844D\u5f20\u91cf\n\n\n\u8f93\u51fa\u7684\u884c\u5217\u6570\u53ef\u80fd\u4f1a\u56e0\u4e3a\u586b\u5145\u65b9\u6cd5\u800c\u6539\u53d8\n\n\n\u4f8b\u5b50\n\n\n# apply a 3x3 transposed convolution with stride 1x1 and 3 output filters on a 12x12 image:\nmodel = Sequential()\nmodel.add(Deconvolution2D(3, 3, 3, output_shape=(None, 3, 14, 14), border_mode='valid', input_shape=(3, 12, 12)))\n# output_shape will be (None, 3, 14, 14)\n\n# apply a 3x3 transposed convolution with stride 2x2 and 3 output filters on a 12x12 image:\nmodel = Sequential()\nmodel.add(Deconvolution2D(3, 3, 3, output_shape=(None, 3, 25, 25), subsample=(2, 2), border_mode='valid', input_shape=(3, 12, 12)))\nmodel.summary()\n# output_shape will be (None, 3, 25, 25)\n\n\n\n\n\u53c2\u8003\u6587\u732e\n\n\n\n\nA guide to convolution arithmetic for deep learning\n\n\nTransposed convolution arithmetic \n\n\nDeconvolutional Networks \n\n\n\n\n\n\nConvolution3D\u5c42\n\n\nkeras.layers.convolutional.Convolution3D(nb_filter, kernel_dim1, kernel_dim2, kernel_dim3, init='glorot_uniform', activation='linear', weights=None, border_mode='valid', subsample=(1, 1, 1), dim_ordering='th', W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None, bias=True)\n\n\n\n\n\u4e09\u7ef4\u5377\u79ef\u5bf9\u4e09\u7ef4\u7684\u8f93\u5165\u8fdb\u884c\u6ed1\u52a8\u7a97\u5377\u79ef\uff0c\u5f53\u4f7f\u7528\u8be5\u5c42\u4f5c\u4e3a\u7b2c\u4e00\u5c42\u65f6\uff0c\u5e94\u63d0\u4f9b\ninput_shape\n\u53c2\u6570\u3002\u4f8b\u5982\ninput_shape = (3,10,128,128)\n\u4ee3\u8868\u5bf910\u5e27128*128\u7684\u5f69\u8272RGB\u56fe\u50cf\u8fdb\u884c\u5377\u79ef\n\n\n\u53c2\u6570\n\n\n\n\n\n\nnb_filter\uff1a\u5377\u79ef\u6838\u7684\u6570\u76ee\n\n\n\n\n\n\nkernel_dim1\uff1a\u5377\u79ef\u6838\u7b2c1\u7ef4\u5ea6\u7684\u957f\n\n\n\n\n\n\nkernel_dim2\uff1a\u5377\u79ef\u6838\u7b2c2\u7ef4\u5ea6\u7684\u957f\n\n\n\n\n\n\nkernel_dim3\uff1a\u5377\u79ef\u6838\u7b2c3\u7ef4\u5ea6\u7684\u957f\n\n\n\n\n\n\ninit\uff1a\u521d\u59cb\u5316\u65b9\u6cd5\uff0c\u4e3a\u9884\u5b9a\u4e49\u521d\u59cb\u5316\u65b9\u6cd5\u540d\u7684\u5b57\u7b26\u4e32\uff0c\u6216\u7528\u4e8e\u521d\u59cb\u5316\u6743\u91cd\u7684Theano\u51fd\u6570\u3002\u8be5\u53c2\u6570\u4ec5\u5728\u4e0d\u4f20\u9012\nweights\n\u53c2\u6570\u65f6\u6709\u610f\u4e49\u3002\n\n\n\n\n\n\nactivation\uff1a\u6fc0\u6d3b\u51fd\u6570\uff0c\u4e3a\u9884\u5b9a\u4e49\u7684\u6fc0\u6d3b\u51fd\u6570\u540d\uff08\u53c2\u8003\n\u6fc0\u6d3b\u51fd\u6570\n\uff09\uff0c\u6216\u9010\u5143\u7d20\uff08element-wise\uff09\u7684Theano\u51fd\u6570\u3002\u5982\u679c\u4e0d\u6307\u5b9a\u8be5\u53c2\u6570\uff0c\u5c06\u4e0d\u4f1a\u4f7f\u7528\u4efb\u4f55\u6fc0\u6d3b\u51fd\u6570\uff08\u5373\u4f7f\u7528\u7ebf\u6027\u6fc0\u6d3b\u51fd\u6570\uff1aa(x)=x\uff09\n\n\n\n\n\n\nweights\uff1a\u6743\u503c\uff0c\u4e3anumpy array\u7684list\u3002\u8be5list\u5e94\u542b\u6709\u4e00\u4e2a\u5f62\u5982\uff08input_dim,output_dim\uff09\u7684\u6743\u91cd\u77e9\u9635\u548c\u4e00\u4e2a\u5f62\u5982(output_dim,)\u7684\u504f\u7f6e\u5411\u91cf\u3002\n\n\n\n\n\n\nborder_mode\uff1a\u8fb9\u754c\u6a21\u5f0f\uff0c\u4e3a\u201cvalid\u201d\uff0c\u201csame\u201d\uff0c\u6216\u201cfull\u201d\uff0cfull\u9700\u8981\u4ee5theano\u4e3a\u540e\u7aef\n\n\n\n\n\n\nsubsample\uff1a\u957f\u4e3a3\u7684tuple\uff0c\u8f93\u51fa\u5bf9\u8f93\u5165\u7684\u4e0b\u91c7\u6837\u56e0\u5b50\uff0c\u66f4\u666e\u904d\u7684\u79f0\u547c\u662f\u201cstrides\u201d\n\n\n*\u6ce8\u610f\uff0csubsample\u901a\u8fc7\u5bf93D\u5377\u79ef\u7684\u7ed3\u679c\u4ee5strides=\uff081\uff0c1\uff0c1\uff09\u5207\u7247\u5b9e\u73b0\n\n\n\n\n\n\nW_regularizer\uff1a\u65bd\u52a0\u5728\u6743\u91cd\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a\nWeightRegularizer\n\u5bf9\u8c61\n\n\n\n\n\n\nb_regularizer\uff1a\u65bd\u52a0\u5728\u504f\u7f6e\u5411\u91cf\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a\nWeightRegularizer\n\u5bf9\u8c61\n\n\n\n\n\n\nactivity_regularizer\uff1a\u65bd\u52a0\u5728\u8f93\u51fa\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a\nActivityRegularizer\n\u5bf9\u8c61\n\n\n\n\n\n\nW_constraints\uff1a\u65bd\u52a0\u5728\u6743\u91cd\u4e0a\u7684\u7ea6\u675f\u9879\uff0c\u4e3a\nConstraints\n\u5bf9\u8c61\n\n\n\n\n\n\nb_constraints\uff1a\u65bd\u52a0\u5728\u504f\u7f6e\u4e0a\u7684\u7ea6\u675f\u9879\uff0c\u4e3a\nConstraints\n\u5bf9\u8c61\n\n\n\n\n\n\ndim_ordering\uff1a\u2018th\u2019\u6216\u2018tf\u2019\u3002\u2018th\u2019\u6a21\u5f0f\u4e2d\u901a\u9053\u7ef4\uff08\u5982\u5f69\u8272\u56fe\u50cf\u76843\u901a\u9053\uff09\u4f4d\u4e8e\u7b2c1\u4e2a\u4f4d\u7f6e\uff08\u7ef4\u5ea6\u4ece0\u5f00\u59cb\u7b97\uff09\uff0c\u800c\u5728\u2018tf\u2019\u6a21\u5f0f\u4e2d\uff0c\u901a\u9053\u7ef4\u4f4d\u4e8e\u7b2c4\u4e2a\u4f4d\u7f6e\u3002\u9ed8\u8ba4\u662f\nimage_dim_ordering\n\u6307\u5b9a\u7684\u6a21\u5f0f\uff0c\u53ef\u5728\n~/.keras/keras.json\n\u4e2d\u67e5\u770b\uff0c\u82e5\u6ca1\u6709\u8bbe\u7f6e\u8fc7\u5219\u4e3a'tf'\u3002\n\n\n\n\n\n\nbias\uff1a\u5e03\u5c14\u503c\uff0c\u662f\u5426\u5305\u542b\u504f\u7f6e\u5411\u91cf\uff08\u5373\u5c42\u5bf9\u8f93\u5165\u505a\u7ebf\u6027\u53d8\u6362\u8fd8\u662f\u4eff\u5c04\u53d8\u6362\uff09\n\n\n\n\n\n\n\u8f93\u5165shape\n\n\n\u2018th\u2019\u6a21\u5f0f\u4e0b\uff0c\u8f93\u5165\u5e94\u4e3a\u5f62\u5982\uff08samples\uff0cchannels\uff0cinput_dim1\uff0cinput_dim2, input_dim3\uff09\u76845D\u5f20\u91cf\n\n\n\u2018tf\u2019\u6a21\u5f0f\u4e0b\uff0c\u8f93\u5165\u5e94\u4e3a\u5f62\u5982\uff08samples\uff0cinput_dim1\uff0cinput_dim2, input_dim3\uff0cchannels\uff09\u76845D\u5f20\u91cf\n\n\n\u8fd9\u91cc\u7684\u8f93\u5165shape\u6307\u7684\u662f\u51fd\u6570\u5185\u90e8\u5b9e\u73b0\u7684\u8f93\u5165shape\uff0c\u800c\u975e\u51fd\u6570\u63a5\u53e3\u5e94\u6307\u5b9a\u7684\ninput_shape\n\u3002\n\n\n\n\nCropping1D\u5c42\n\n\nkeras.layers.convolutional.Cropping1D(cropping=(1, 1))\n\n\n\n\n\u5728\u65f6\u95f4\u8f74\uff08axis1\uff09\u4e0a\u5bf91D\u8f93\u5165\uff08\u5373\u65f6\u95f4\u5e8f\u5217\uff09\u8fdb\u884c\u88c1\u526a\n\n\n\u53c2\u6570\n\n\n\n\ncropping\uff1a\u957f\u4e3a2\u7684tuple\uff0c\u6307\u5b9a\u5728\u5e8f\u5217\u7684\u9996\u5c3e\u8981\u88c1\u526a\u6389\u591a\u5c11\u4e2a\u5143\u7d20\n\n\n\n\n\u8f93\u5165shape\n\n\n\n\n\u5f62\u5982\uff08samples\uff0caxis_to_crop\uff0cfeatures\uff09\u76843D\u5f20\u91cf\n\n\n\n\n\u8f93\u51fashape\n\n\n\n\n\u5f62\u5982\uff08samples\uff0ccropped_axis\uff0cfeatures\uff09\u76843D\u5f20\u91cf\n\n\n\n\n\n\nCropping2D\u5c42\n\n\nkeras.layers.convolutional.Cropping2D(cropping=((0, 0), (0, 0)), dim_ordering='default')\n\n\n\n\n\u5bf92D\u8f93\u5165\uff08\u56fe\u50cf\uff09\u8fdb\u884c\u88c1\u526a\uff0c\u5c06\u5728\u7a7a\u57df\u7ef4\u5ea6\uff0c\u5373\u5bbd\u548c\u9ad8\u7684\u65b9\u5411\u4e0a\u88c1\u526a\n\n\n\u53c2\u6570\n\n\n\n\n\n\ncropping\uff1a\u957f\u4e3a2\u7684\u6574\u6570tuple\uff0c\u5206\u522b\u4e3a\u5bbd\u548c\u9ad8\u65b9\u5411\u4e0a\u5934\u90e8\u4e0e\u5c3e\u90e8\u9700\u8981\u88c1\u526a\u6389\u7684\u5143\u7d20\u6570\n\n\n\n\n\n\ndim_ordering\uff1a\u2018th\u2019\u6216\u2018tf\u2019\u3002\u2018th\u2019\u6a21\u5f0f\u4e2d\u901a\u9053\u7ef4\uff08\u5982\u5f69\u8272\u56fe\u50cf\u76843\u901a\u9053\uff09\u4f4d\u4e8e\u7b2c1\u4e2a\u4f4d\u7f6e\uff08\u7ef4\u5ea6\u4ece0\u5f00\u59cb\u7b97\uff09\uff0c\u800c\u5728\u2018tf\u2019\u6a21\u5f0f\u4e2d\uff0c\u901a\u9053\u7ef4\u4f4d\u4e8e\u7b2c3\u4e2a\u4f4d\u7f6e\u3002\u4f8b\u5982128*128\u7684\u4e09\u901a\u9053\u5f69\u8272\u56fe\u7247\uff0c\u5728\u2018th\u2019\u6a21\u5f0f\u4e2d\ninput_shape\n\u5e94\u5199\u4e3a\uff083\uff0c128\uff0c128\uff09\uff0c\u800c\u5728\u2018tf\u2019\u6a21\u5f0f\u4e2d\u5e94\u5199\u4e3a\uff08128\uff0c128\uff0c3\uff09\uff0c\u6ce8\u610f\u8fd9\u91cc3\u51fa\u73b0\u5728\u7b2c0\u4e2a\u4f4d\u7f6e\uff0c\u56e0\u4e3a\ninput_shape\n\u4e0d\u5305\u542b\u6837\u672c\u6570\u7684\u7ef4\u5ea6\uff0c\u5728\u5176\u5185\u90e8\u5b9e\u73b0\u4e2d\uff0c\u5b9e\u9645\u4e0a\u662f\uff08None\uff0c3\uff0c128\uff0c128\uff09\u548c\uff08None\uff0c128\uff0c128\uff0c3\uff09\u3002\u9ed8\u8ba4\u662f\nimage_dim_ordering\n\u6307\u5b9a\u7684\u6a21\u5f0f\uff0c\u53ef\u5728\n~/.keras/keras.json\n\u4e2d\u67e5\u770b\uff0c\u82e5\u6ca1\u6709\u8bbe\u7f6e\u8fc7\u5219\u4e3a'tf'\u3002\n\n\n\n\n\n\n\u8f93\u5165shape\n\n\n\u5f62\u5982\uff08samples\uff0cdepth, first_axis_to_crop, second_axis_to_crop\uff09\n\n\n\u8f93\u51fashape\n\n\n\u5f62\u5982(samples, depth, first_cropped_axis, second_cropped_axis)\u76844D\u5f20\u91cf\n\n\n\n\nCropping3D\u5c42\n\n\nkeras.layers.convolutional.Cropping3D(cropping=((1, 1), (1, 1), (1, 1)), dim_ordering='default')\n\n\n\n\n\u5bf92D\u8f93\u5165\uff08\u56fe\u50cf\uff09\u8fdb\u884c\u88c1\u526a\n\n\n\u53c2\u6570\n\n\n\n\n\n\ncropping\uff1a\u957f\u4e3a3\u7684\u6574\u6570tuple\uff0c\u5206\u522b\u4e3a\u4e09\u4e2a\u65b9\u5411\u4e0a\u5934\u90e8\u4e0e\u5c3e\u90e8\u9700\u8981\u88c1\u526a\u6389\u7684\u5143\u7d20\u6570\n\n\n\n\n\n\ndim_ordering\uff1a\u2018th\u2019\u6216\u2018tf\u2019\u3002\u2018th\u2019\u6a21\u5f0f\u4e2d\u901a\u9053\u7ef4\uff08\u5982\u5f69\u8272\u56fe\u50cf\u76843\u901a\u9053\uff09\u4f4d\u4e8e\u7b2c1\u4e2a\u4f4d\u7f6e\uff08\u7ef4\u5ea6\u4ece0\u5f00\u59cb\u7b97\uff09\uff0c\u800c\u5728\u2018tf\u2019\u6a21\u5f0f\u4e2d\uff0c\u901a\u9053\u7ef4\u4f4d\u4e8e\u7b2c4\u4e2a\u4f4d\u7f6e\u3002\u9ed8\u8ba4\u662f\nimage_dim_ordering\n\u6307\u5b9a\u7684\u6a21\u5f0f\uff0c\u53ef\u5728\n~/.keras/keras.json\n\u4e2d\u67e5\u770b\uff0c\u82e5\u6ca1\u6709\u8bbe\u7f6e\u8fc7\u5219\u4e3a'tf'\u3002\n\n\n\n\n\n\n\u8f93\u5165shape\n\n\n\u5f62\u5982 (samples, depth, first_axis_to_crop, second_axis_to_crop, third_axis_to_crop)\u76845D\u5f20\u91cf\n\n\n\u8f93\u51fashape\n\n\n\u5f62\u5982(samples, depth, first_cropped_axis, second_cropped_axis, third_cropped_axis)\u76845D\u5f20\u91cf\n\n\n\n\nUpSampling1D\u5c42\n\n\nkeras.layers.convolutional.UpSampling1D(length=2)\n\n\n\n\n\u5728\u65f6\u95f4\u8f74\u4e0a\uff0c\u5c06\u6bcf\u4e2a\u65f6\u95f4\u6b65\u91cd\u590d\nlength\n\u6b21\n\n\n\u53c2\u6570\n\n\n\n\nlength\uff1a\u4e0a\u91c7\u6837\u56e0\u5b50\n\n\n\n\n\u8f93\u5165shape\n\n\n\n\n\u5f62\u5982\uff08samples\uff0csteps\uff0cfeatures\uff09\u76843D\u5f20\u91cf\n\n\n\n\n\u8f93\u51fashape\n\n\n\n\n\u5f62\u5982\uff08samples\uff0cupsampled_steps\uff0cfeatures\uff09\u76843D\u5f20\u91cf\n\n\n\n\n\n\nUpSampling2D\u5c42\n\n\nkeras.layers.convolutional.UpSampling2D(size=(2, 2), dim_ordering='th')\n\n\n\n\n\u5c06\u6570\u636e\u7684\u884c\u548c\u5217\u5206\u522b\u91cd\u590dsize[0]\u548csize[1]\u6b21\n\n\n\u53c2\u6570\n\n\n\n\n\n\nsize\uff1a\u6574\u6570tuple\uff0c\u5206\u522b\u4e3a\u884c\u548c\u5217\u4e0a\u91c7\u6837\u56e0\u5b50\n\n\n\n\n\n\ndim_ordering\uff1a\u2018th\u2019\u6216\u2018tf\u2019\u3002\u2018th\u2019\u6a21\u5f0f\u4e2d\u901a\u9053\u7ef4\uff08\u5982\u5f69\u8272\u56fe\u50cf\u76843\u901a\u9053\uff09\u4f4d\u4e8e\u7b2c1\u4e2a\u4f4d\u7f6e\uff08\u7ef4\u5ea6\u4ece0\u5f00\u59cb\u7b97\uff09\uff0c\u800c\u5728\u2018tf\u2019\u6a21\u5f0f\u4e2d\uff0c\u901a\u9053\u7ef4\u4f4d\u4e8e\u7b2c3\u4e2a\u4f4d\u7f6e\u3002\u4f8b\u5982128*128\u7684\u4e09\u901a\u9053\u5f69\u8272\u56fe\u7247\uff0c\u5728\u2018th\u2019\u6a21\u5f0f\u4e2d\ninput_shape\n\u5e94\u5199\u4e3a\uff083\uff0c128\uff0c128\uff09\uff0c\u800c\u5728\u2018tf\u2019\u6a21\u5f0f\u4e2d\u5e94\u5199\u4e3a\uff08128\uff0c128\uff0c3\uff09\uff0c\u6ce8\u610f\u8fd9\u91cc3\u51fa\u73b0\u5728\u7b2c0\u4e2a\u4f4d\u7f6e\uff0c\u56e0\u4e3a\ninput_shape\n\u4e0d\u5305\u542b\u6837\u672c\u6570\u7684\u7ef4\u5ea6\uff0c\u5728\u5176\u5185\u90e8\u5b9e\u73b0\u4e2d\uff0c\u5b9e\u9645\u4e0a\u662f\uff08None\uff0c3\uff0c128\uff0c128\uff09\u548c\uff08None\uff0c128\uff0c128\uff0c3\uff09\u3002\u9ed8\u8ba4\u662f\nimage_dim_ordering\n\u6307\u5b9a\u7684\u6a21\u5f0f\uff0c\u53ef\u5728\n~/.keras/keras.json\n\u4e2d\u67e5\u770b\uff0c\u82e5\u6ca1\u6709\u8bbe\u7f6e\u8fc7\u5219\u4e3a'tf'\u3002\n\n\n\n\n\n\n\u8f93\u5165shape\n\n\n\u2018th\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples\uff0cchannels, rows\uff0ccols\uff09\u76844D\u5f20\u91cf\n\n\n\u2018tf\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples\uff0crows, cols\uff0cchannels\uff09\u76844D\u5f20\u91cf\n\n\n\u8f93\u51fashape\n\n\n\u2018th\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples\uff0cchannels, upsampled_rows, upsampled_cols\uff09\u76844D\u5f20\u91cf\n\n\n\u2018tf\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples\uff0cupsampled_rows, upsampled_cols\uff0cchannels\uff09\u76844D\u5f20\u91cf\n\n\n\n\nUpSampling3D\u5c42\n\n\nkeras.layers.convolutional.UpSampling3D(size=(2, 2, 2), dim_ordering='th')\n\n\n\n\n\u5c06\u6570\u636e\u7684\u4e09\u4e2a\u7ef4\u5ea6\u4e0a\u5206\u522b\u91cd\u590dsize[0]\u3001size[1]\u548cize[2]\u6b21\n\n\n\u672c\u5c42\u76ee\u524d\u53ea\u80fd\u5728\u4f7f\u7528Theano\u4e3a\u540e\u7aef\u65f6\u53ef\u7528\n\n\n\u53c2\u6570\n\n\n\n\n\n\nsize\uff1a\u957f\u4e3a3\u7684\u6574\u6570tuple\uff0c\u4ee3\u8868\u5728\u4e09\u4e2a\u7ef4\u5ea6\u4e0a\u7684\u4e0a\u91c7\u6837\u56e0\u5b50\n\n\n\n\n\n\ndim_ordering\uff1a\u2018th\u2019\u6216\u2018tf\u2019\u3002\u2018th\u2019\u6a21\u5f0f\u4e2d\u901a\u9053\u7ef4\uff08\u5982\u5f69\u8272\u56fe\u50cf\u76843\u901a\u9053\uff09\u4f4d\u4e8e\u7b2c1\u4e2a\u4f4d\u7f6e\uff08\u7ef4\u5ea6\u4ece0\u5f00\u59cb\u7b97\uff09\uff0c\u800c\u5728\u2018tf\u2019\u6a21\u5f0f\u4e2d\uff0c\u901a\u9053\u7ef4\u4f4d\u4e8e\u7b2c4\u4e2a\u4f4d\u7f6e\u3002\u9ed8\u8ba4\u662f\nimage_dim_ordering\n\u6307\u5b9a\u7684\u6a21\u5f0f\uff0c\u53ef\u5728\n~/.keras/keras.json\n\u4e2d\u67e5\u770b\uff0c\u82e5\u6ca1\u6709\u8bbe\u7f6e\u8fc7\u5219\u4e3a'tf'\u3002\n\n\n\n\n\n\n\u8f93\u5165shape\n\n\n\u2018th\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples, channels, len_pool_dim1, len_pool_dim2, len_pool_dim3\uff09\u76845D\u5f20\u91cf\n\n\n\u2018tf\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples, len_pool_dim1, len_pool_dim2, len_pool_dim3\uff0cchannels, \uff09\u76845D\u5f20\u91cf\n\n\n\u8f93\u51fashape\n\n\n\u2018th\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples, channels, dim1, dim2, dim3\uff09\u76845D\u5f20\u91cf\n\n\n\u2018tf\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples, upsampled_dim1, upsampled_dim2, upsampled_dim3,channels,\uff09\u76845D\u5f20\u91cf\n\n\n\n\nZeroPadding1D\u5c42\n\n\nkeras.layers.convolutional.ZeroPadding1D(padding=1)\n\n\n\n\n\u5bf91D\u8f93\u5165\u7684\u9996\u5c3e\u7aef\uff08\u5982\u65f6\u57df\u5e8f\u5217\uff09\u586b\u51450\uff0c\u4ee5\u63a7\u5236\u5377\u79ef\u4ee5\u540e\u5411\u91cf\u7684\u957f\u5ea6\n\n\n\u53c2\u6570\n\n\n\n\npadding\uff1a\u6574\u6570\uff0c\u8868\u793a\u5728\u8981\u586b\u5145\u7684\u8f74\u7684\u8d77\u59cb\u548c\u7ed3\u675f\u5904\u586b\u51450\u7684\u6570\u76ee\uff0c\u8fd9\u91cc\u8981\u586b\u5145\u7684\u8f74\u662f\u8f741\uff08\u7b2c1\u7ef4\uff0c\u7b2c0\u7ef4\u662f\u6837\u672c\u6570\uff09\n\n\n\n\n\u8f93\u5165shape\n\n\n\u5f62\u5982\uff08samples\uff0caxis_to_pad\uff0cfeatures\uff09\u76843D\u5f20\u91cf\n\n\n\u8f93\u51fashape\n\n\n\u5f62\u5982\uff08samples\uff0cpaded_axis\uff0cfeatures\uff09\u76843D\u5f20\u91cf\n\n\n\n\nZeroPadding2D\u5c42\n\n\nkeras.layers.convolutional.ZeroPadding2D(padding=(1, 1), dim_ordering='th')\n\n\n\n\n\u5bf92D\u8f93\u5165\uff08\u5982\u56fe\u7247\uff09\u7684\u8fb9\u754c\u586b\u51450\uff0c\u4ee5\u63a7\u5236\u5377\u79ef\u4ee5\u540e\u7279\u5f81\u56fe\u7684\u5927\u5c0f\n\n\n\u53c2\u6570\n\n\n\n\npadding\uff1a\u6574\u6570tuple\uff0c\u8868\u793a\u5728\u8981\u586b\u5145\u7684\u8f74\u7684\u8d77\u59cb\u548c\u7ed3\u675f\u5904\u586b\u51450\u7684\u6570\u76ee\uff0c\u8fd9\u91cc\u8981\u586b\u5145\u7684\u8f74\u662f\u8f743\u548c\u8f744\uff08\u5373\u5728'th'\u6a21\u5f0f\u4e0b\u56fe\u50cf\u7684\u884c\u548c\u5217\uff0c\u5728\u2018tf\u2019\u6a21\u5f0f\u4e0b\u8981\u586b\u5145\u7684\u5219\u662f\u8f742\uff0c3\uff09\n\n\n\n\ndim_ordering\uff1a\u2018th\u2019\u6216\u2018tf\u2019\u3002\u2018th\u2019\u6a21\u5f0f\u4e2d\u901a\u9053\u7ef4\uff08\u5982\u5f69\u8272\u56fe\u50cf\u76843\u901a\u9053\uff09\u4f4d\u4e8e\u7b2c1\u4e2a\u4f4d\u7f6e\uff08\u7ef4\u5ea6\u4ece0\u5f00\u59cb\u7b97\uff09\uff0c\u800c\u5728\u2018tf\u2019\u6a21\u5f0f\u4e2d\uff0c\u901a\u9053\u7ef4\u4f4d\u4e8e\u7b2c3\u4e2a\u4f4d\u7f6e\u3002\u4f8b\u5982128*128\u7684\u4e09\u901a\u9053\u5f69\u8272\u56fe\u7247\uff0c\u5728\u2018th\u2019\u6a21\u5f0f\u4e2d\ninput_shape\n\u5e94\u5199\u4e3a\uff083\uff0c128\uff0c128\uff09\uff0c\u800c\u5728\u2018tf\u2019\u6a21\u5f0f\u4e2d\u5e94\u5199\u4e3a\uff08128\uff0c128\uff0c3\uff09\uff0c\u6ce8\u610f\u8fd9\u91cc3\u51fa\u73b0\u5728\u7b2c0\u4e2a\u4f4d\u7f6e\uff0c\u56e0\u4e3a\ninput_shape\n\u4e0d\u5305\u542b\u6837\u672c\u6570\u7684\u7ef4\u5ea6\uff0c\u5728\u5176\u5185\u90e8\u5b9e\u73b0\u4e2d\uff0c\u5b9e\u9645\u4e0a\u662f\uff08None\uff0c3\uff0c128\uff0c128\uff09\u548c\uff08None\uff0c128\uff0c128\uff0c3\uff09\u3002\u9ed8\u8ba4\u662f\nimage_dim_ordering\n\u6307\u5b9a\u7684\u6a21\u5f0f\uff0c\u53ef\u5728\n~/.keras/keras.json\n\u4e2d\u67e5\u770b\uff0c\u82e5\u6ca1\u6709\u8bbe\u7f6e\u8fc7\u5219\u4e3a'tf'\u3002\n\n\n\u8f93\u5165shape\n\n\n\u2018th\u2019\u6a21\u5f0f\u4e0b\uff0c\u5f62\u5982\uff08samples\uff0cchannels\uff0cfirst_axis_to_pad\uff0csecond_axis_to_pad\uff09\u76844D\u5f20\u91cf\n\n\n\u2018tf\u2019\u6a21\u5f0f\u4e0b\uff0c\u5f62\u5982\uff08samples\uff0cfirst_axis_to_pad\uff0csecond_axis_to_pad, channels\uff09\u76844D\u5f20\u91cf\n\n\n\u8f93\u51fashape\n\n\n\u2018th\u2019\u6a21\u5f0f\u4e0b\uff0c\u5f62\u5982\uff08samples\uff0cchannels\uff0cfirst_paded_axis\uff0csecond_paded_axis\uff09\u76844D\u5f20\u91cf\n\n\n\u2018tf\u2019\u6a21\u5f0f\u4e0b\uff0c\u5f62\u5982\uff08samples\uff0cfirst_paded_axis\uff0csecond_paded_axis, channels\uff09\u76844D\u5f20\u91cf\n\n\n\n\nZeroPadding3D\u5c42\n\n\nkeras.layers.convolutional.ZeroPadding3D(padding=(1, 1, 1), dim_ordering='th')\n\n\n\n\n\u5c06\u6570\u636e\u7684\u4e09\u4e2a\u7ef4\u5ea6\u4e0a\u586b\u51450\n\n\n\u672c\u5c42\u76ee\u524d\u53ea\u80fd\u5728\u4f7f\u7528Theano\u4e3a\u540e\u7aef\u65f6\u53ef\u7528\n\n\n\u53c2\u6570\n\n\npadding\uff1a\u6574\u6570tuple\uff0c\u8868\u793a\u5728\u8981\u586b\u5145\u7684\u8f74\u7684\u8d77\u59cb\u548c\u7ed3\u675f\u5904\u586b\u51450\u7684\u6570\u76ee\uff0c\u8fd9\u91cc\u8981\u586b\u5145\u7684\u8f74\u662f\u8f743\uff0c\u8f744\u548c\u8f745\uff0c\u2018tf\u2019\u6a21\u5f0f\u4e0b\u5219\u662f\u8f742\uff0c3\u548c4\n\n\n\n\ndim_ordering\uff1a\u2018th\u2019\u6216\u2018tf\u2019\u3002\u2018th\u2019\u6a21\u5f0f\u4e2d\u901a\u9053\u7ef4\uff08\u5982\u5f69\u8272\u56fe\u50cf\u76843\u901a\u9053\uff09\u4f4d\u4e8e\u7b2c1\u4e2a\u4f4d\u7f6e\uff08\u7ef4\u5ea6\u4ece0\u5f00\u59cb\u7b97\uff09\uff0c\u800c\u5728\u2018tf\u2019\u6a21\u5f0f\u4e2d\uff0c\u901a\u9053\u7ef4\u4f4d\u4e8e\u7b2c4\u4e2a\u4f4d\u7f6e\u3002\u9ed8\u8ba4\u662f\nimage_dim_ordering\n\u6307\u5b9a\u7684\u6a21\u5f0f\uff0c\u53ef\u5728\n~/.keras/keras.json\n\u4e2d\u67e5\u770b\uff0c\u82e5\u6ca1\u6709\u8bbe\u7f6e\u8fc7\u5219\u4e3a'tf'\u3002\n\n\n\n\n\u8f93\u5165shape\n\n\n\u2018th\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples, channels, first_axis_to_pad\uff0cfirst_axis_to_pad, first_axis_to_pad,\uff09\u76845D\u5f20\u91cf\n\n\n\u2018tf\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples, first_axis_to_pad\uff0cfirst_axis_to_pad, first_axis_to_pad, channels\uff09\u76845D\u5f20\u91cf\n\n\n\u8f93\u51fashape\n\n\n\u2018th\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples, channels, first_paded_axis\uff0csecond_paded_axis, third_paded_axis,\uff09\u76845D\u5f20\u91cf\n\n\n\u2018tf\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples, len_pool_dim1, len_pool_dim2, len_pool_dim3\uff0cchannels, \uff09\u76845D\u5f20\u91cf", 
            "title": "\u5377\u79ef\u5c42Convolutional"
        }, 
        {
            "location": "/layers/convolutional_layer/#_1", 
            "text": "", 
            "title": "\u5377\u79ef\u5c42"
        }, 
        {
            "location": "/layers/convolutional_layer/#convolution1d", 
            "text": "keras.layers.convolutional.Convolution1D(nb_filter, filter_length, init='uniform', activation='linear', weights=None, border_mode='valid', subsample_length=1, W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None, bias=True, input_dim=None, input_length=None)  \u4e00\u7ef4\u5377\u79ef\u5c42\uff0c\u7528\u4ee5\u5728\u4e00\u7ef4\u8f93\u5165\u4fe1\u53f7\u4e0a\u8fdb\u884c\u90bb\u57df\u6ee4\u6ce2\u3002\u5f53\u4f7f\u7528\u8be5\u5c42\u4f5c\u4e3a\u9996\u5c42\u65f6\uff0c\u9700\u8981\u63d0\u4f9b\u5173\u952e\u5b57\u53c2\u6570 input_dim \u6216 input_shape \u3002\u4f8b\u5982 input_dim=128 \u957f\u4e3a128\u7684\u5411\u91cf\u5e8f\u5217\u8f93\u5165\uff0c\u800c input_shape=(10,128) \u4ee3\u8868\u4e00\u4e2a\u957f\u4e3a10\u7684128\u5411\u91cf\u5e8f\u5217", 
            "title": "Convolution1D\u5c42"
        }, 
        {
            "location": "/layers/convolutional_layer/#_2", 
            "text": "nb_filter\uff1a\u5377\u79ef\u6838\u7684\u6570\u76ee\uff08\u5373\u8f93\u51fa\u7684\u7ef4\u5ea6\uff09    filter_length\uff1a\u5377\u79ef\u6838\u7684\u7a7a\u57df\u6216\u65f6\u57df\u957f\u5ea6    init\uff1a\u521d\u59cb\u5316\u65b9\u6cd5\uff0c\u4e3a\u9884\u5b9a\u4e49\u521d\u59cb\u5316\u65b9\u6cd5\u540d\u7684\u5b57\u7b26\u4e32\uff0c\u6216\u7528\u4e8e\u521d\u59cb\u5316\u6743\u91cd\u7684Theano\u51fd\u6570\u3002\u8be5\u53c2\u6570\u4ec5\u5728\u4e0d\u4f20\u9012 weights \u53c2\u6570\u65f6\u6709\u610f\u4e49\u3002    activation\uff1a\u6fc0\u6d3b\u51fd\u6570\uff0c\u4e3a\u9884\u5b9a\u4e49\u7684\u6fc0\u6d3b\u51fd\u6570\u540d\uff08\u53c2\u8003 \u6fc0\u6d3b\u51fd\u6570 \uff09\uff0c\u6216\u9010\u5143\u7d20\uff08element-wise\uff09\u7684Theano\u51fd\u6570\u3002\u5982\u679c\u4e0d\u6307\u5b9a\u8be5\u53c2\u6570\uff0c\u5c06\u4e0d\u4f1a\u4f7f\u7528\u4efb\u4f55\u6fc0\u6d3b\u51fd\u6570\uff08\u5373\u4f7f\u7528\u7ebf\u6027\u6fc0\u6d3b\u51fd\u6570\uff1aa(x)=x\uff09    weights\uff1a\u6743\u503c\uff0c\u4e3anumpy array\u7684list\u3002\u8be5list\u5e94\u542b\u6709\u4e00\u4e2a\u5f62\u5982\uff08input_dim,output_dim\uff09\u7684\u6743\u91cd\u77e9\u9635\u548c\u4e00\u4e2a\u5f62\u5982(output_dim,)\u7684\u504f\u7f6e\u5411\u91cf\u3002    border_mode\uff1a\u8fb9\u754c\u6a21\u5f0f\uff0c\u4e3a\u201cvalid\u201d, \u201csame\u201d \u6216\u201cfull\u201d\uff0cfull\u9700\u8981\u4ee5theano\u4e3a\u540e\u7aef    subsample_length\uff1a\u8f93\u51fa\u5bf9\u8f93\u5165\u7684\u4e0b\u91c7\u6837\u56e0\u5b50    W_regularizer\uff1a\u65bd\u52a0\u5728\u6743\u91cd\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a WeightRegularizer \u5bf9\u8c61    b_regularizer\uff1a\u65bd\u52a0\u5728\u504f\u7f6e\u5411\u91cf\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a WeightRegularizer \u5bf9\u8c61    activity_regularizer\uff1a\u65bd\u52a0\u5728\u8f93\u51fa\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a ActivityRegularizer \u5bf9\u8c61    W_constraints\uff1a\u65bd\u52a0\u5728\u6743\u91cd\u4e0a\u7684\u7ea6\u675f\u9879\uff0c\u4e3a Constraints \u5bf9\u8c61    b_constraints\uff1a\u65bd\u52a0\u5728\u504f\u7f6e\u4e0a\u7684\u7ea6\u675f\u9879\uff0c\u4e3a Constraints \u5bf9\u8c61    bias\uff1a\u5e03\u5c14\u503c\uff0c\u662f\u5426\u5305\u542b\u504f\u7f6e\u5411\u91cf\uff08\u5373\u5c42\u5bf9\u8f93\u5165\u505a\u7ebf\u6027\u53d8\u6362\u8fd8\u662f\u4eff\u5c04\u53d8\u6362\uff09    input_dim\uff1a\u6574\u6570\uff0c\u8f93\u5165\u6570\u636e\u7684\u7ef4\u5ea6\u3002\u5f53\u8be5\u5c42\u4f5c\u4e3a\u7f51\u7edc\u7684\u7b2c\u4e00\u5c42\u65f6\uff0c\u5fc5\u987b\u6307\u5b9a\u8be5\u53c2\u6570\u6216 input_shape \u53c2\u6570\u3002    input_length\uff1a\u5f53\u8f93\u5165\u5e8f\u5217\u7684\u957f\u5ea6\u56fa\u5b9a\u65f6\uff0c\u8be5\u53c2\u6570\u4e3a\u8f93\u5165\u5e8f\u5217\u7684\u957f\u5ea6\u3002\u5f53\u9700\u8981\u5728\u8be5\u5c42\u540e\u8fde\u63a5 Flatten \u5c42\uff0c\u7136\u540e\u53c8\u8981\u8fde\u63a5 Dense \u5c42\u65f6\uff0c\u9700\u8981\u6307\u5b9a\u8be5\u53c2\u6570\uff0c\u5426\u5219\u5168\u8fde\u63a5\u7684\u8f93\u51fa\u65e0\u6cd5\u8ba1\u7b97\u51fa\u6765\u3002", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/layers/convolutional_layer/#shape", 
            "text": "\u5f62\u5982\uff08samples\uff0csteps\uff0cinput_dim\uff09\u76843D\u5f20\u91cf", 
            "title": "\u8f93\u5165shape"
        }, 
        {
            "location": "/layers/convolutional_layer/#shape_1", 
            "text": "\u5f62\u5982\uff08samples\uff0cnew_steps\uff0cnb_filter\uff09\u76843D\u5f20\u91cf\uff0c\u56e0\u4e3a\u6709\u5411\u91cf\u586b\u5145\u7684\u539f\u56e0\uff0c steps \u7684\u503c\u4f1a\u6539\u53d8", 
            "title": "\u8f93\u51fashape"
        }, 
        {
            "location": "/layers/convolutional_layer/#_3", 
            "text": "# apply a convolution 1d of length 3 to a sequence with 10 timesteps,\n# with 64 output filters\nmodel = Sequential()\nmodel.add(Convolution1D(64, 3, border_mode='same', input_shape=(10, 32)))\n# now model.output_shape == (None, 10, 64)\n\n# add a new conv1d on top\nmodel.add(Convolution1D(32, 3, border_mode='same'))\n# now model.output_shape == (None, 10, 32)  \u3010Tips\u3011\u53ef\u4ee5\u5c06Convolution1D\u770b\u4f5cConvolution2D\u7684\u5feb\u6377\u7248\uff0c\u5bf9\u4f8b\u5b50\u4e2d\uff0810\uff0c32\uff09\u7684\u4fe1\u53f7\u8fdb\u884c1D\u5377\u79ef\u76f8\u5f53\u4e8e\u5bf9\u5176\u8fdb\u884c\u5377\u79ef\u6838\u4e3a\uff08filter_length, 32\uff09\u76842D\u5377\u79ef\u3002\u3010@3rduncle\u3011", 
            "title": "\u4f8b\u5b50"
        }, 
        {
            "location": "/layers/convolutional_layer/#atrousconvolution1d", 
            "text": "keras.layers.convolutional.AtrousConvolution1D(nb_filter, filter_length, init='uniform', activation='linear', weights=None, border_mode='valid', subsample_length=1, atrous_rate=1, W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None, bias=True)  AtrousConvolution1D\u5c42\u7528\u4e8e\u5bf91D\u4fe1\u53f7\u8fdb\u884c\u6ee4\u6ce2\uff0c\u662f\u81a8\u80c0/\u5e26\u5b54\u6d1e\u7684\u5377\u79ef\u3002\u5f53\u4f7f\u7528\u8be5\u5c42\u4f5c\u4e3a\u9996\u5c42\u65f6\uff0c\u9700\u8981\u63d0\u4f9b\u5173\u952e\u5b57\u53c2\u6570 input_dim \u6216 input_shape \u3002\u4f8b\u5982 input_dim=128 \u957f\u4e3a128\u7684\u5411\u91cf\u5e8f\u5217\u8f93\u5165\uff0c\u800c input_shape=(10,128) \u4ee3\u8868\u4e00\u4e2a\u957f\u4e3a10\u7684128\u5411\u91cf\u5e8f\u5217.", 
            "title": "AtrousConvolution1D\u5c42"
        }, 
        {
            "location": "/layers/convolutional_layer/#_4", 
            "text": "nb_filter\uff1a\u5377\u79ef\u6838\u7684\u6570\u76ee\uff08\u5373\u8f93\u51fa\u7684\u7ef4\u5ea6\uff09    filter_length\uff1a\u5377\u79ef\u6838\u7684\u7a7a\u57df\u6216\u65f6\u57df\u957f\u5ea6    init\uff1a\u521d\u59cb\u5316\u65b9\u6cd5\uff0c\u4e3a\u9884\u5b9a\u4e49\u521d\u59cb\u5316\u65b9\u6cd5\u540d\u7684\u5b57\u7b26\u4e32\uff0c\u6216\u7528\u4e8e\u521d\u59cb\u5316\u6743\u91cd\u7684Theano\u51fd\u6570\u3002\u8be5\u53c2\u6570\u4ec5\u5728\u4e0d\u4f20\u9012 weights \u53c2\u6570\u65f6\u6709\u610f\u4e49\u3002    activation\uff1a\u6fc0\u6d3b\u51fd\u6570\uff0c\u4e3a\u9884\u5b9a\u4e49\u7684\u6fc0\u6d3b\u51fd\u6570\u540d\uff08\u53c2\u8003 \u6fc0\u6d3b\u51fd\u6570 \uff09\uff0c\u6216\u9010\u5143\u7d20\uff08element-wise\uff09\u7684Theano\u51fd\u6570\u3002\u5982\u679c\u4e0d\u6307\u5b9a\u8be5\u53c2\u6570\uff0c\u5c06\u4e0d\u4f1a\u4f7f\u7528\u4efb\u4f55\u6fc0\u6d3b\u51fd\u6570\uff08\u5373\u4f7f\u7528\u7ebf\u6027\u6fc0\u6d3b\u51fd\u6570\uff1aa(x)=x\uff09    weights\uff1a\u6743\u503c\uff0c\u4e3anumpy array\u7684list\u3002\u8be5list\u5e94\u542b\u6709\u4e00\u4e2a\u5f62\u5982\uff08input_dim,output_dim\uff09\u7684\u6743\u91cd\u77e9\u9635\u548c\u4e00\u4e2a\u5f62\u5982(output_dim,)\u7684\u504f\u7f6e\u5411\u91cf\u3002    border_mode\uff1a\u8fb9\u754c\u6a21\u5f0f\uff0c\u4e3a\u201cvalid\u201d\uff0c\u201csame\u201d\u6216\u201cfull\u201d\uff0cfull\u9700\u8981\u4ee5theano\u4e3a\u540e\u7aef    subsample_length\uff1a\u8f93\u51fa\u5bf9\u8f93\u5165\u7684\u4e0b\u91c7\u6837\u56e0\u5b50    atrous_rate:\u5377\u79ef\u6838\u81a8\u80c0\u7684\u7cfb\u6570\uff0c\u5728\u5176\u4ed6\u5730\u65b9\u4e5f\u88ab\u79f0\u4e3a'filter_dilation'    W_regularizer\uff1a\u65bd\u52a0\u5728\u6743\u91cd\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a WeightRegularizer \u5bf9\u8c61    b_regularizer\uff1a\u65bd\u52a0\u5728\u504f\u7f6e\u5411\u91cf\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a WeightRegularizer \u5bf9\u8c61    activity_regularizer\uff1a\u65bd\u52a0\u5728\u8f93\u51fa\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a ActivityRegularizer \u5bf9\u8c61    W_constraints\uff1a\u65bd\u52a0\u5728\u6743\u91cd\u4e0a\u7684\u7ea6\u675f\u9879\uff0c\u4e3a Constraints \u5bf9\u8c61    b_constraints\uff1a\u65bd\u52a0\u5728\u504f\u7f6e\u4e0a\u7684\u7ea6\u675f\u9879\uff0c\u4e3a Constraints \u5bf9\u8c61    bias\uff1a\u5e03\u5c14\u503c\uff0c\u662f\u5426\u5305\u542b\u504f\u7f6e\u5411\u91cf\uff08\u5373\u5c42\u5bf9\u8f93\u5165\u505a\u7ebf\u6027\u53d8\u6362\u8fd8\u662f\u4eff\u5c04\u53d8\u6362\uff09    input_dim\uff1a\u6574\u6570\uff0c\u8f93\u5165\u6570\u636e\u7684\u7ef4\u5ea6\u3002\u5f53\u8be5\u5c42\u4f5c\u4e3a\u7f51\u7edc\u7684\u7b2c\u4e00\u5c42\u65f6\uff0c\u5fc5\u987b\u6307\u5b9a\u8be5\u53c2\u6570\u6216 input_shape \u53c2\u6570\u3002    input_length\uff1a\u5f53\u8f93\u5165\u5e8f\u5217\u7684\u957f\u5ea6\u56fa\u5b9a\u65f6\uff0c\u8be5\u53c2\u6570\u4e3a\u8f93\u5165\u5e8f\u5217\u7684\u957f\u5ea6\u3002\u5f53\u9700\u8981\u5728\u8be5\u5c42\u540e\u8fde\u63a5 Flatten \u5c42\uff0c\u7136\u540e\u53c8\u8981\u8fde\u63a5 Dense \u5c42\u65f6\uff0c\u9700\u8981\u6307\u5b9a\u8be5\u53c2\u6570\uff0c\u5426\u5219\u5168\u8fde\u63a5\u7684\u8f93\u51fa\u65e0\u6cd5\u8ba1\u7b97\u51fa\u6765\u3002", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/layers/convolutional_layer/#shape_2", 
            "text": "\u5f62\u5982\uff08samples\uff0csteps\uff0cinput_dim\uff09\u76843D\u5f20\u91cf", 
            "title": "\u8f93\u5165shape"
        }, 
        {
            "location": "/layers/convolutional_layer/#shape_3", 
            "text": "\u5f62\u5982\uff08samples\uff0cnew_steps\uff0cnb_filter\uff09\u76843D\u5f20\u91cf\uff0c\u56e0\u4e3a\u6709\u5411\u91cf\u586b\u5145\u7684\u539f\u56e0\uff0c steps \u7684\u503c\u4f1a\u6539\u53d8", 
            "title": "\u8f93\u51fashape"
        }, 
        {
            "location": "/layers/convolutional_layer/#_5", 
            "text": "# apply an atrous convolution 1d with atrous rate 2 of length 3 to a sequence with 10 timesteps,\n# with 64 output filters\nmodel = Sequential()\nmodel.add(AtrousConvolution1D(64, 3, atrous_rate=2, border_mode='same', input_shape=(10, 32)))\n# now model.output_shape == (None, 10, 64)\n\n# add a new atrous conv1d on top\nmodel.add(AtrousConvolution1D(32, 3, atrous_rate=2, border_mode='same'))\n# now model.output_shape == (None, 10, 32)", 
            "title": "\u4f8b\u5b50"
        }, 
        {
            "location": "/layers/convolutional_layer/#convolution2d", 
            "text": "keras.layers.convolutional.Convolution2D(nb_filter, nb_row, nb_col, init='glorot_uniform', activation='linear', weights=None, border_mode='valid', subsample=(1, 1), dim_ordering='th', W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None, bias=True)  \u4e8c\u7ef4\u5377\u79ef\u5c42\u5bf9\u4e8c\u7ef4\u8f93\u5165\u8fdb\u884c\u6ed1\u52a8\u7a97\u5377\u79ef\uff0c\u5f53\u4f7f\u7528\u8be5\u5c42\u4f5c\u4e3a\u7b2c\u4e00\u5c42\u65f6\uff0c\u5e94\u63d0\u4f9b input_shape \u53c2\u6570\u3002\u4f8b\u5982 input_shape = (3,128,128) \u4ee3\u8868128*128\u7684\u5f69\u8272RGB\u56fe\u50cf", 
            "title": "Convolution2D\u5c42"
        }, 
        {
            "location": "/layers/convolutional_layer/#_6", 
            "text": "nb_filter\uff1a\u5377\u79ef\u6838\u7684\u6570\u76ee    nb_row\uff1a\u5377\u79ef\u6838\u7684\u884c\u6570    nb_col\uff1a\u5377\u79ef\u6838\u7684\u5217\u6570    init\uff1a\u521d\u59cb\u5316\u65b9\u6cd5\uff0c\u4e3a\u9884\u5b9a\u4e49\u521d\u59cb\u5316\u65b9\u6cd5\u540d\u7684\u5b57\u7b26\u4e32\uff0c\u6216\u7528\u4e8e\u521d\u59cb\u5316\u6743\u91cd\u7684Theano\u51fd\u6570\u3002\u8be5\u53c2\u6570\u4ec5\u5728\u4e0d\u4f20\u9012 weights \u53c2\u6570\u65f6\u6709\u610f\u4e49\u3002    activation\uff1a\u6fc0\u6d3b\u51fd\u6570\uff0c\u4e3a\u9884\u5b9a\u4e49\u7684\u6fc0\u6d3b\u51fd\u6570\u540d\uff08\u53c2\u8003 \u6fc0\u6d3b\u51fd\u6570 \uff09\uff0c\u6216\u9010\u5143\u7d20\uff08element-wise\uff09\u7684Theano\u51fd\u6570\u3002\u5982\u679c\u4e0d\u6307\u5b9a\u8be5\u53c2\u6570\uff0c\u5c06\u4e0d\u4f1a\u4f7f\u7528\u4efb\u4f55\u6fc0\u6d3b\u51fd\u6570\uff08\u5373\u4f7f\u7528\u7ebf\u6027\u6fc0\u6d3b\u51fd\u6570\uff1aa(x)=x\uff09    weights\uff1a\u6743\u503c\uff0c\u4e3anumpy array\u7684list\u3002\u8be5list\u5e94\u542b\u6709\u4e00\u4e2a\u5f62\u5982\uff08input_dim,output_dim\uff09\u7684\u6743\u91cd\u77e9\u9635\u548c\u4e00\u4e2a\u5f62\u5982(output_dim,)\u7684\u504f\u7f6e\u5411\u91cf\u3002    border_mode\uff1a\u8fb9\u754c\u6a21\u5f0f\uff0c\u4e3a\u201cvalid\u201d\uff0c\u201csame\u201d\u6216\u201cfull\u201d\uff0cfull\u9700\u8981\u4ee5theano\u4e3a\u540e\u7aef    subsample\uff1a\u957f\u4e3a2\u7684tuple\uff0c\u8f93\u51fa\u5bf9\u8f93\u5165\u7684\u4e0b\u91c7\u6837\u56e0\u5b50\uff0c\u66f4\u666e\u904d\u7684\u79f0\u547c\u662f\u201cstrides\u201d    W_regularizer\uff1a\u65bd\u52a0\u5728\u6743\u91cd\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a WeightRegularizer \u5bf9\u8c61    b_regularizer\uff1a\u65bd\u52a0\u5728\u504f\u7f6e\u5411\u91cf\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a WeightRegularizer \u5bf9\u8c61    activity_regularizer\uff1a\u65bd\u52a0\u5728\u8f93\u51fa\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a ActivityRegularizer \u5bf9\u8c61    W_constraints\uff1a\u65bd\u52a0\u5728\u6743\u91cd\u4e0a\u7684\u7ea6\u675f\u9879\uff0c\u4e3a Constraints \u5bf9\u8c61    b_constraints\uff1a\u65bd\u52a0\u5728\u504f\u7f6e\u4e0a\u7684\u7ea6\u675f\u9879\uff0c\u4e3a Constraints \u5bf9\u8c61    dim_ordering\uff1a\u2018th\u2019\u6216\u2018tf\u2019\u3002\u2018th\u2019\u6a21\u5f0f\u4e2d\u901a\u9053\u7ef4\uff08\u5982\u5f69\u8272\u56fe\u50cf\u76843\u901a\u9053\uff09\u4f4d\u4e8e\u7b2c1\u4e2a\u4f4d\u7f6e\uff08\u7ef4\u5ea6\u4ece0\u5f00\u59cb\u7b97\uff09\uff0c\u800c\u5728\u2018tf\u2019\u6a21\u5f0f\u4e2d\uff0c\u901a\u9053\u7ef4\u4f4d\u4e8e\u7b2c3\u4e2a\u4f4d\u7f6e\u3002\u4f8b\u5982128*128\u7684\u4e09\u901a\u9053\u5f69\u8272\u56fe\u7247\uff0c\u5728\u2018th\u2019\u6a21\u5f0f\u4e2d input_shape \u5e94\u5199\u4e3a\uff083\uff0c128\uff0c128\uff09\uff0c\u800c\u5728\u2018tf\u2019\u6a21\u5f0f\u4e2d\u5e94\u5199\u4e3a\uff08128\uff0c128\uff0c3\uff09\uff0c\u6ce8\u610f\u8fd9\u91cc3\u51fa\u73b0\u5728\u7b2c0\u4e2a\u4f4d\u7f6e\uff0c\u56e0\u4e3a input_shape \u4e0d\u5305\u542b\u6837\u672c\u6570\u7684\u7ef4\u5ea6\uff0c\u5728\u5176\u5185\u90e8\u5b9e\u73b0\u4e2d\uff0c\u5b9e\u9645\u4e0a\u662f\uff08None\uff0c3\uff0c128\uff0c128\uff09\u548c\uff08None\uff0c128\uff0c128\uff0c3\uff09\u3002\u9ed8\u8ba4\u662f image_dim_ordering \u6307\u5b9a\u7684\u6a21\u5f0f\uff0c\u53ef\u5728 ~/.keras/keras.json \u4e2d\u67e5\u770b\uff0c\u82e5\u6ca1\u6709\u8bbe\u7f6e\u8fc7\u5219\u4e3a'tf'\u3002    bias\uff1a\u5e03\u5c14\u503c\uff0c\u662f\u5426\u5305\u542b\u504f\u7f6e\u5411\u91cf\uff08\u5373\u5c42\u5bf9\u8f93\u5165\u505a\u7ebf\u6027\u53d8\u6362\u8fd8\u662f\u4eff\u5c04\u53d8\u6362\uff09", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/layers/convolutional_layer/#shape_4", 
            "text": "\u2018th\u2019\u6a21\u5f0f\u4e0b\uff0c\u8f93\u5165\u5f62\u5982\uff08samples,channels\uff0crows\uff0ccols\uff09\u76844D\u5f20\u91cf  \u2018tf\u2019\u6a21\u5f0f\u4e0b\uff0c\u8f93\u5165\u5f62\u5982\uff08samples\uff0crows\uff0ccols\uff0cchannels\uff09\u76844D\u5f20\u91cf  \u6ce8\u610f\u8fd9\u91cc\u7684\u8f93\u5165shape\u6307\u7684\u662f\u51fd\u6570\u5185\u90e8\u5b9e\u73b0\u7684\u8f93\u5165shape\uff0c\u800c\u975e\u51fd\u6570\u63a5\u53e3\u5e94\u6307\u5b9a\u7684 input_shape \uff0c\u8bf7\u53c2\u8003\u4e0b\u9762\u63d0\u4f9b\u7684\u4f8b\u5b50\u3002", 
            "title": "\u8f93\u5165shape"
        }, 
        {
            "location": "/layers/convolutional_layer/#shape_5", 
            "text": "\u2018th\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples\uff0cnb_filter, new_rows, new_cols\uff09\u76844D\u5f20\u91cf  \u2018tf\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples\uff0cnew_rows, new_cols\uff0cnb_filter\uff09\u76844D\u5f20\u91cf  \u8f93\u51fa\u7684\u884c\u5217\u6570\u53ef\u80fd\u4f1a\u56e0\u4e3a\u586b\u5145\u65b9\u6cd5\u800c\u6539\u53d8", 
            "title": "\u8f93\u51fashape"
        }, 
        {
            "location": "/layers/convolutional_layer/#_7", 
            "text": "# apply a 3x3 convolution with 64 output filters on a 256x256 image:\nmodel = Sequential()\nmodel.add(Convolution2D(64, 3, 3, border_mode='same', input_shape=(3, 256, 256)))\n# now model.output_shape == (None, 64, 256, 256)\n\n# add a 3x3 convolution on top, with 32 output filters:\nmodel.add(Convolution2D(32, 3, 3, border_mode='same'))\n# now model.output_shape == (None, 32, 256, 256)", 
            "title": "\u4f8b\u5b50"
        }, 
        {
            "location": "/layers/convolutional_layer/#atrousconvolution2d", 
            "text": "keras.layers.convolutional.AtrousConvolution2D(nb_filter, nb_row, nb_col, init='glorot_uniform', activation='linear', weights=None, border_mode='valid', subsample=(1, 1), atrous_rate=(1, 1), dim_ordering='th', W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None, bias=True)  \u8be5\u5c42\u5bf9\u4e8c\u7ef4\u8f93\u5165\u8fdb\u884cAtrous\u5377\u79ef\uff0c\u4e5f\u5373\u81a8\u80c0\u5377\u79ef\u6216\u5e26\u5b54\u6d1e\u7684\u5377\u79ef\u3002\u5f53\u4f7f\u7528\u8be5\u5c42\u4f5c\u4e3a\u7b2c\u4e00\u5c42\u65f6\uff0c\u5e94\u63d0\u4f9b input_shape \u53c2\u6570\u3002\u4f8b\u5982 input_shape = (3,128,128) \u4ee3\u8868128*128\u7684\u5f69\u8272RGB\u56fe\u50cf", 
            "title": "AtrousConvolution2D\u5c42"
        }, 
        {
            "location": "/layers/convolutional_layer/#_8", 
            "text": "nb_filter\uff1a\u5377\u79ef\u6838\u7684\u6570\u76ee    nb_row\uff1a\u5377\u79ef\u6838\u7684\u884c\u6570    nb_col\uff1a\u5377\u79ef\u6838\u7684\u5217\u6570    init\uff1a\u521d\u59cb\u5316\u65b9\u6cd5\uff0c\u4e3a\u9884\u5b9a\u4e49\u521d\u59cb\u5316\u65b9\u6cd5\u540d\u7684\u5b57\u7b26\u4e32\uff0c\u6216\u7528\u4e8e\u521d\u59cb\u5316\u6743\u91cd\u7684Theano\u51fd\u6570\u3002\u8be5\u53c2\u6570\u4ec5\u5728\u4e0d\u4f20\u9012 weights \u53c2\u6570\u65f6\u6709\u610f\u4e49\u3002    activation\uff1a\u6fc0\u6d3b\u51fd\u6570\uff0c\u4e3a\u9884\u5b9a\u4e49\u7684\u6fc0\u6d3b\u51fd\u6570\u540d\uff08\u53c2\u8003 \u6fc0\u6d3b\u51fd\u6570 \uff09\uff0c\u6216\u9010\u5143\u7d20\uff08element-wise\uff09\u7684Theano\u51fd\u6570\u3002\u5982\u679c\u4e0d\u6307\u5b9a\u8be5\u53c2\u6570\uff0c\u5c06\u4e0d\u4f1a\u4f7f\u7528\u4efb\u4f55\u6fc0\u6d3b\u51fd\u6570\uff08\u5373\u4f7f\u7528\u7ebf\u6027\u6fc0\u6d3b\u51fd\u6570\uff1aa(x)=x\uff09    weights\uff1a\u6743\u503c\uff0c\u4e3anumpy array\u7684list\u3002\u8be5list\u5e94\u542b\u6709\u4e00\u4e2a\u5f62\u5982\uff08input_dim,output_dim\uff09\u7684\u6743\u91cd\u77e9\u9635\u548c\u4e00\u4e2a\u5f62\u5982(output_dim,)\u7684\u504f\u7f6e\u5411\u91cf\u3002    border_mode\uff1a\u8fb9\u754c\u6a21\u5f0f\uff0c\u4e3a\u201cvalid\u201d\uff0c\u201csame\u201d\uff0c\u6216\u201cfull\u201d\uff0cfull\u9700\u8981\u4ee5theano\u4e3a\u540e\u7aef    subsample\uff1a\u957f\u4e3a2\u7684tuple\uff0c\u8f93\u51fa\u5bf9\u8f93\u5165\u7684\u4e0b\u91c7\u6837\u56e0\u5b50\uff0c\u66f4\u666e\u904d\u7684\u79f0\u547c\u662f\u201cstrides\u201d    atrous_rate\uff1a\u957f\u4e3a2\u7684tuple\uff0c\u4ee3\u8868\u5377\u79ef\u6838\u81a8\u80c0\u7684\u7cfb\u6570\uff0c\u5728\u5176\u4ed6\u5730\u65b9\u4e5f\u88ab\u79f0\u4e3a'filter_dilation'    W_regularizer\uff1a\u65bd\u52a0\u5728\u6743\u91cd\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a WeightRegularizer \u5bf9\u8c61    b_regularizer\uff1a\u65bd\u52a0\u5728\u504f\u7f6e\u5411\u91cf\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a WeightRegularizer \u5bf9\u8c61    activity_regularizer\uff1a\u65bd\u52a0\u5728\u8f93\u51fa\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a ActivityRegularizer \u5bf9\u8c61    W_constraints\uff1a\u65bd\u52a0\u5728\u6743\u91cd\u4e0a\u7684\u7ea6\u675f\u9879\uff0c\u4e3a Constraints \u5bf9\u8c61    b_constraints\uff1a\u65bd\u52a0\u5728\u504f\u7f6e\u4e0a\u7684\u7ea6\u675f\u9879\uff0c\u4e3a Constraints \u5bf9\u8c61    dim_ordering\uff1a\u2018th\u2019\u6216\u2018tf\u2019\u3002\u2018th\u2019\u6a21\u5f0f\u4e2d\u901a\u9053\u7ef4\uff08\u5982\u5f69\u8272\u56fe\u50cf\u76843\u901a\u9053\uff09\u4f4d\u4e8e\u7b2c1\u4e2a\u4f4d\u7f6e\uff08\u7ef4\u5ea6\u4ece0\u5f00\u59cb\u7b97\uff09\uff0c\u800c\u5728\u2018tf\u2019\u6a21\u5f0f\u4e2d\uff0c\u901a\u9053\u7ef4\u4f4d\u4e8e\u7b2c3\u4e2a\u4f4d\u7f6e\u3002\u4f8b\u5982128*128\u7684\u4e09\u901a\u9053\u5f69\u8272\u56fe\u7247\uff0c\u5728\u2018th\u2019\u6a21\u5f0f\u4e2d input_shape \u5e94\u5199\u4e3a\uff083\uff0c128\uff0c128\uff09\uff0c\u800c\u5728\u2018tf\u2019\u6a21\u5f0f\u4e2d\u5e94\u5199\u4e3a\uff08128\uff0c128\uff0c3\uff09\uff0c\u6ce8\u610f\u8fd9\u91cc3\u51fa\u73b0\u5728\u7b2c0\u4e2a\u4f4d\u7f6e\uff0c\u56e0\u4e3a input_shape \u4e0d\u5305\u542b\u6837\u672c\u6570\u7684\u7ef4\u5ea6\uff0c\u5728\u5176\u5185\u90e8\u5b9e\u73b0\u4e2d\uff0c\u5b9e\u9645\u4e0a\u662f\uff08None\uff0c3\uff0c128\uff0c128\uff09\u548c\uff08None\uff0c128\uff0c128\uff0c3\uff09\u3002\u9ed8\u8ba4\u662f image_dim_ordering \u6307\u5b9a\u7684\u6a21\u5f0f\uff0c\u53ef\u5728 ~/.keras/keras.json \u4e2d\u67e5\u770b\uff0c\u82e5\u6ca1\u6709\u8bbe\u7f6e\u8fc7\u5219\u4e3a'tf'\u3002    bias\uff1a\u5e03\u5c14\u503c\uff0c\u662f\u5426\u5305\u542b\u504f\u7f6e\u5411\u91cf\uff08\u5373\u5c42\u5bf9\u8f93\u5165\u505a\u7ebf\u6027\u53d8\u6362\u8fd8\u662f\u4eff\u5c04\u53d8\u6362\uff09", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/layers/convolutional_layer/#shape_6", 
            "text": "\u2018th\u2019\u6a21\u5f0f\u4e0b\uff0c\u8f93\u5165\u5f62\u5982\uff08samples,channels\uff0crows\uff0ccols\uff09\u76844D\u5f20\u91cf  \u2018tf\u2019\u6a21\u5f0f\u4e0b\uff0c\u8f93\u5165\u5f62\u5982\uff08samples\uff0crows\uff0ccols\uff0cchannels\uff09\u76844D\u5f20\u91cf  \u6ce8\u610f\u8fd9\u91cc\u7684\u8f93\u5165shape\u6307\u7684\u662f\u51fd\u6570\u5185\u90e8\u5b9e\u73b0\u7684\u8f93\u5165shape\uff0c\u800c\u975e\u51fd\u6570\u63a5\u53e3\u5e94\u6307\u5b9a\u7684 input_shape \uff0c\u8bf7\u53c2\u8003\u4e0b\u9762\u63d0\u4f9b\u7684\u4f8b\u5b50\u3002", 
            "title": "\u8f93\u5165shape"
        }, 
        {
            "location": "/layers/convolutional_layer/#shape_7", 
            "text": "\u2018th\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples\uff0cnb_filter, new_rows, new_cols\uff09\u76844D\u5f20\u91cf  \u2018tf\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples\uff0cnew_rows, new_cols\uff0cnb_filter\uff09\u76844D\u5f20\u91cf  \u8f93\u51fa\u7684\u884c\u5217\u6570\u53ef\u80fd\u4f1a\u56e0\u4e3a\u586b\u5145\u800c\u6539\u53d8", 
            "title": "\u8f93\u51fashape"
        }, 
        {
            "location": "/layers/convolutional_layer/#_9", 
            "text": "# apply a 3x3 convolution with atrous rate 2x2 and 64 output filters on a 256x256 image:\nmodel = Sequential()\nmodel.add(AtrousConvolution2D(64, 3, 3, atrous_rate=(2,2), border_mode='valid', input_shape=(3, 256, 256)))\n# now the actual kernel size is dilated from 3x3 to 5x5 (3+(3-1)*(2-1)=5)\n# thus model.output_shape == (None, 64, 252, 252)", 
            "title": "\u4f8b\u5b50"
        }, 
        {
            "location": "/layers/convolutional_layer/#_10", 
            "text": "Multi-Scale Context Aggregation by Dilated Convolutions", 
            "title": "\u53c2\u8003\u6587\u732e"
        }, 
        {
            "location": "/layers/convolutional_layer/#separableconvolution2d", 
            "text": "keras.layers.convolutional.SeparableConvolution2D(nb_filter, nb_row, nb_col, init='glorot_uniform', activation='linear', weights=None, border_mode='valid', subsample=(1, 1), depth_multiplier=1, dim_ordering='default', depthwise_regularizer=None, pointwise_regularizer=None, b_regularizer=None, activity_regularizer=None, depthwise_constraint=None, pointwise_constraint=None, b_constraint=None, bias=True)  \u8be5\u5c42\u662f\u5bf92D\u8f93\u5165\u7684\u53ef\u5206\u79bb\u5377\u79ef  \u53ef\u5206\u79bb\u5377\u79ef\u9996\u5148\u6309\u6df1\u5ea6\u65b9\u5411\u8fdb\u884c\u5377\u79ef\uff08\u5bf9\u6bcf\u4e2a\u8f93\u5165\u901a\u9053\u5206\u522b\u5377\u79ef\uff09\uff0c\u7136\u540e\u9010\u70b9\u8fdb\u884c\u5377\u79ef\uff0c\u5c06\u4e0a\u4e00\u6b65\u7684\u5377\u79ef\u7ed3\u679c\u6df7\u5408\u5230\u8f93\u51fa\u901a\u9053\u4e2d\u3002\u53c2\u6570 depth_multiplier \u63a7\u5236\u4e86\u5728depthwise\u5377\u79ef\uff08\u7b2c\u4e00\u6b65\uff09\u7684\u8fc7\u7a0b\u4e2d\uff0c\u6bcf\u4e2a\u8f93\u5165\u901a\u9053\u4fe1\u53f7\u4ea7\u751f\u591a\u5c11\u4e2a\u8f93\u51fa\u901a\u9053\u3002  \u76f4\u89c2\u6765\u8bf4\uff0c\u53ef\u5206\u79bb\u5377\u79ef\u53ef\u4ee5\u770b\u505a\u8bb2\u4e00\u4e2a\u5377\u79ef\u6838\u5206\u89e3\u4e3a\u4e24\u4e2a\u5c0f\u7684\u5377\u79ef\u6838\uff0c\u6216\u770b\u4f5cInception\u6a21\u5757\u7684\u4e00\u79cd\u6781\u7aef\u60c5\u51b5\u3002  \u5f53\u4f7f\u7528\u8be5\u5c42\u4f5c\u4e3a\u7b2c\u4e00\u5c42\u65f6\uff0c\u5e94\u63d0\u4f9b input_shape \u53c2\u6570\u3002\u4f8b\u5982 input_shape = (3,128,128) \u4ee3\u8868128*128\u7684\u5f69\u8272RGB\u56fe\u50cf", 
            "title": "SeparableConvolution2D\u5c42"
        }, 
        {
            "location": "/layers/convolutional_layer/#theano", 
            "text": "\u8be5\u5c42\u76ee\u524d\u53ea\u80fd\u5728Tensorflow\u540e\u7aef\u7684\u6761\u4ef6\u4e0b\u4f7f\u7528", 
            "title": "Theano\u8b66\u544a"
        }, 
        {
            "location": "/layers/convolutional_layer/#_11", 
            "text": "nb_filter\uff1a\u5377\u79ef\u6838\u7684\u6570\u76ee    nb_row\uff1a\u5377\u79ef\u6838\u7684\u884c\u6570    nb_col\uff1a\u5377\u79ef\u6838\u7684\u5217\u6570    init\uff1a\u521d\u59cb\u5316\u65b9\u6cd5\uff0c\u4e3a\u9884\u5b9a\u4e49\u521d\u59cb\u5316\u65b9\u6cd5\u540d\u7684\u5b57\u7b26\u4e32\uff0c\u6216\u7528\u4e8e\u521d\u59cb\u5316\u6743\u91cd\u7684Theano\u51fd\u6570\u3002\u8be5\u53c2\u6570\u4ec5\u5728\u4e0d\u4f20\u9012 weights \u53c2\u6570\u65f6\u6709\u610f\u4e49\u3002    activation\uff1a\u6fc0\u6d3b\u51fd\u6570\uff0c\u4e3a\u9884\u5b9a\u4e49\u7684\u6fc0\u6d3b\u51fd\u6570\u540d\uff08\u53c2\u8003 \u6fc0\u6d3b\u51fd\u6570 \uff09\uff0c\u6216\u9010\u5143\u7d20\uff08element-wise\uff09\u7684Theano\u51fd\u6570\u3002\u5982\u679c\u4e0d\u6307\u5b9a\u8be5\u53c2\u6570\uff0c\u5c06\u4e0d\u4f1a\u4f7f\u7528\u4efb\u4f55\u6fc0\u6d3b\u51fd\u6570\uff08\u5373\u4f7f\u7528\u7ebf\u6027\u6fc0\u6d3b\u51fd\u6570\uff1aa(x)=x\uff09    weights\uff1a\u6743\u503c\uff0c\u4e3anumpy array\u7684list\u3002\u8be5list\u5e94\u542b\u6709\u4e00\u4e2a\u5f62\u5982\uff08input_dim,output_dim\uff09\u7684\u6743\u91cd\u77e9\u9635\u548c\u4e00\u4e2a\u5f62\u5982(output_dim,)\u7684\u504f\u7f6e\u5411\u91cf\u3002    border_mode\uff1a\u8fb9\u754c\u6a21\u5f0f\uff0c\u4e3a\u201cvalid\u201d\uff0c\u201csame\u201d\uff0c\u6216\u201cfull\u201d\uff0cfull\u9700\u8981\u4ee5theano\u4e3a\u540e\u7aef    subsample\uff1a\u957f\u4e3a2\u7684tuple\uff0c\u8f93\u51fa\u5bf9\u8f93\u5165\u7684\u4e0b\u91c7\u6837\u56e0\u5b50\uff0c\u66f4\u666e\u904d\u7684\u79f0\u547c\u662f\u201cstrides\u201d    depth_multiplier\uff1a\u5728\u6309\u6df1\u5ea6\u5377\u79ef\u7684\u6b65\u9aa4\u4e2d\uff0c\u6bcf\u4e2a\u8f93\u5165\u901a\u9053\u4f7f\u7528\u591a\u5c11\u4e2a\u8f93\u51fa\u901a\u9053    depthwise_regularizer\uff1a\u65bd\u52a0\u5728\u6309\u6df1\u5ea6\u5377\u79ef\u7684\u6743\u91cd\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a WeightRegularizer \u5bf9\u8c61    pointwise_regularizer\uff1a\u65bd\u52a0\u5728\u6309\u70b9\u5377\u79ef\u7684\u6743\u91cd\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a WeightRegularizer \u5bf9\u8c61    b_regularizer\uff1a\u65bd\u52a0\u5728\u504f\u7f6e\u5411\u91cf\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a WeightRegularizer \u5bf9\u8c61    activity_regularizer\uff1a\u65bd\u52a0\u5728\u8f93\u51fa\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a ActivityRegularizer \u5bf9\u8c61    depthwise_constraint\uff1a\u65bd\u52a0\u5728\u6309\u6df1\u5ea6\u5377\u79ef\u6743\u91cd\u4e0a\u7684\u7ea6\u675f\u9879\uff0c\u4e3a Constraints \u5bf9\u8c61    pointwise_constraint\u65bd\u52a0\u5728\u6309\u70b9\u5377\u79ef\u6743\u91cd\u7684\u7ea6\u675f\u9879\uff0c\u4e3a Constraints \u5bf9\u8c61    b_constraints\uff1a\u65bd\u52a0\u5728\u504f\u7f6e\u4e0a\u7684\u7ea6\u675f\u9879\uff0c\u4e3a Constraints \u5bf9\u8c61    dim_ordering\uff1a\u2018th\u2019\u6216\u2018tf\u2019\u3002\u2018th\u2019\u6a21\u5f0f\u4e2d\u901a\u9053\u7ef4\uff08\u5982\u5f69\u8272\u56fe\u50cf\u76843\u901a\u9053\uff09\u4f4d\u4e8e\u7b2c1\u4e2a\u4f4d\u7f6e\uff08\u7ef4\u5ea6\u4ece0\u5f00\u59cb\u7b97\uff09\uff0c\u800c\u5728\u2018tf\u2019\u6a21\u5f0f\u4e2d\uff0c\u901a\u9053\u7ef4\u4f4d\u4e8e\u7b2c3\u4e2a\u4f4d\u7f6e\u3002\u4f8b\u5982128*128\u7684\u4e09\u901a\u9053\u5f69\u8272\u56fe\u7247\uff0c\u5728\u2018th\u2019\u6a21\u5f0f\u4e2d input_shape \u5e94\u5199\u4e3a\uff083\uff0c128\uff0c128\uff09\uff0c\u800c\u5728\u2018tf\u2019\u6a21\u5f0f\u4e2d\u5e94\u5199\u4e3a\uff08128\uff0c128\uff0c3\uff09\uff0c\u6ce8\u610f\u8fd9\u91cc3\u51fa\u73b0\u5728\u7b2c0\u4e2a\u4f4d\u7f6e\uff0c\u56e0\u4e3a input_shape \u4e0d\u5305\u542b\u6837\u672c\u6570\u7684\u7ef4\u5ea6\uff0c\u5728\u5176\u5185\u90e8\u5b9e\u73b0\u4e2d\uff0c\u5b9e\u9645\u4e0a\u662f\uff08None\uff0c3\uff0c128\uff0c128\uff09\u548c\uff08None\uff0c128\uff0c128\uff0c3\uff09\u3002\u9ed8\u8ba4\u662f image_dim_ordering \u6307\u5b9a\u7684\u6a21\u5f0f\uff0c\u53ef\u5728 ~/.keras/keras.json \u4e2d\u67e5\u770b\uff0c\u82e5\u6ca1\u6709\u8bbe\u7f6e\u8fc7\u5219\u4e3a'tf'\u3002    bias\uff1a\u5e03\u5c14\u503c\uff0c\u662f\u5426\u5305\u542b\u504f\u7f6e\u5411\u91cf\uff08\u5373\u5c42\u5bf9\u8f93\u5165\u505a\u7ebf\u6027\u53d8\u6362\u8fd8\u662f\u4eff\u5c04\u53d8\u6362\uff09", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/layers/convolutional_layer/#shape_8", 
            "text": "\u2018th\u2019\u6a21\u5f0f\u4e0b\uff0c\u8f93\u5165\u5f62\u5982\uff08samples,channels\uff0crows\uff0ccols\uff09\u76844D\u5f20\u91cf  \u2018tf\u2019\u6a21\u5f0f\u4e0b\uff0c\u8f93\u5165\u5f62\u5982\uff08samples\uff0crows\uff0ccols\uff0cchannels\uff09\u76844D\u5f20\u91cf  \u6ce8\u610f\u8fd9\u91cc\u7684\u8f93\u5165shape\u6307\u7684\u662f\u51fd\u6570\u5185\u90e8\u5b9e\u73b0\u7684\u8f93\u5165shape\uff0c\u800c\u975e\u51fd\u6570\u63a5\u53e3\u5e94\u6307\u5b9a\u7684 input_shape \uff0c\u8bf7\u53c2\u8003\u4e0b\u9762\u63d0\u4f9b\u7684\u4f8b\u5b50\u3002", 
            "title": "\u8f93\u5165shape"
        }, 
        {
            "location": "/layers/convolutional_layer/#shape_9", 
            "text": "\u2018th\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples\uff0cnb_filter, new_rows, new_cols\uff09\u76844D\u5f20\u91cf  \u2018tf\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples\uff0cnew_rows, new_cols\uff0cnb_filter\uff09\u76844D\u5f20\u91cf  \u8f93\u51fa\u7684\u884c\u5217\u6570\u53ef\u80fd\u4f1a\u56e0\u4e3a\u586b\u5145\u65b9\u6cd5\u800c\u6539\u53d8", 
            "title": "\u8f93\u51fashape"
        }, 
        {
            "location": "/layers/convolutional_layer/#deconvolution2d", 
            "text": "keras.layers.convolutional.Deconvolution2D(nb_filter, nb_row, nb_col, output_shape, init='glorot_uniform', activation='linear', weights=None, border_mode='valid', subsample=(1, 1), dim_ordering='tf', W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None, bias=True)  \u8be5\u5c42\u662f\u5377\u79ef\u64cd\u4f5c\u7684\u8f6c\u7f6e\uff08\u53cd\u5377\u79ef\uff09\u3002\u9700\u8981\u53cd\u5377\u79ef\u7684\u60c5\u51b5\u901a\u5e38\u53d1\u751f\u5728\u7528\u6237\u60f3\u8981\u5bf9\u4e00\u4e2a\u666e\u901a\u5377\u79ef\u7684\u7ed3\u679c\u505a\u53cd\u65b9\u5411\u7684\u53d8\u6362\u3002\u4f8b\u5982\uff0c\u5c06\u5177\u6709\u8be5\u5377\u79ef\u5c42\u8f93\u51fashape\u7684tensor\u8f6c\u6362\u4e3a\u5177\u6709\u8be5\u5377\u79ef\u5c42\u8f93\u5165shape\u7684tensor\u3002\uff0c\u540c\u65f6\u4fdd\u7559\u4e0e\u5377\u79ef\u5c42\u517c\u5bb9\u7684\u8fde\u63a5\u6a21\u5f0f\u3002  \u5f53\u4f7f\u7528\u8be5\u5c42\u4f5c\u4e3a\u7b2c\u4e00\u5c42\u65f6\uff0c\u5e94\u63d0\u4f9b input_shape \u53c2\u6570\u3002\u4f8b\u5982 input_shape = (3,128,128) \u4ee3\u8868128*128\u7684\u5f69\u8272RGB\u56fe\u50cf", 
            "title": "Deconvolution2D\u5c42"
        }, 
        {
            "location": "/layers/convolutional_layer/#_12", 
            "text": "nb_filter\uff1a\u5377\u79ef\u6838\u7684\u6570\u76ee    nb_row\uff1a\u5377\u79ef\u6838\u7684\u884c\u6570    nb_col\uff1a\u5377\u79ef\u6838\u7684\u5217\u6570    output_shape\uff1a\u53cd\u5377\u79ef\u7684\u8f93\u51fashape\uff0c\u4e3a\u6574\u6570\u7684tuple\uff0c\u5f62\u5982\uff08nb_samples,nb_filter,nb_output_rows,nb_output_cols\uff09\uff0c\u8ba1\u7b97output_shape\u7684\u516c\u5f0f\u662f\uff1ao = s (i - 1) + a + k - 2p,\u5176\u4e2da\u7684\u53d6\u503c\u8303\u56f4\u662f0~s-1\uff0c\u5176\u4e2d\uff1a   i:\u8f93\u5165\u7684size\uff08rows\u6216cols\uff09  k\uff1a\u5377\u79ef\u6838\u5927\u5c0f\uff08nb_filter\uff09  s: \u6b65\u957f\uff08subsample\uff09  a\uff1a\u7528\u6237\u6307\u5b9a\u7684\u7684\u7528\u4e8e\u533a\u522bs\u4e2a\u4e0d\u540c\u7684\u53ef\u80fdoutput size\u7684\u53c2\u6570     init\uff1a\u521d\u59cb\u5316\u65b9\u6cd5\uff0c\u4e3a\u9884\u5b9a\u4e49\u521d\u59cb\u5316\u65b9\u6cd5\u540d\u7684\u5b57\u7b26\u4e32\uff0c\u6216\u7528\u4e8e\u521d\u59cb\u5316\u6743\u91cd\u7684Theano\u51fd\u6570\u3002\u8be5\u53c2\u6570\u4ec5\u5728\u4e0d\u4f20\u9012 weights \u53c2\u6570\u65f6\u6709\u610f\u4e49\u3002    activation\uff1a\u6fc0\u6d3b\u51fd\u6570\uff0c\u4e3a\u9884\u5b9a\u4e49\u7684\u6fc0\u6d3b\u51fd\u6570\u540d\uff08\u53c2\u8003 \u6fc0\u6d3b\u51fd\u6570 \uff09\uff0c\u6216\u9010\u5143\u7d20\uff08element-wise\uff09\u7684Theano\u51fd\u6570\u3002\u5982\u679c\u4e0d\u6307\u5b9a\u8be5\u53c2\u6570\uff0c\u5c06\u4e0d\u4f1a\u4f7f\u7528\u4efb\u4f55\u6fc0\u6d3b\u51fd\u6570\uff08\u5373\u4f7f\u7528\u7ebf\u6027\u6fc0\u6d3b\u51fd\u6570\uff1aa(x)=x\uff09    weights\uff1a\u6743\u503c\uff0c\u4e3anumpy array\u7684list\u3002\u8be5list\u5e94\u542b\u6709\u4e00\u4e2a\u5f62\u5982\uff08input_dim,output_dim\uff09\u7684\u6743\u91cd\u77e9\u9635\u548c\u4e00\u4e2a\u5f62\u5982(output_dim,)\u7684\u504f\u7f6e\u5411\u91cf\u3002    border_mode\uff1a\u8fb9\u754c\u6a21\u5f0f\uff0c\u4e3a\u201cvalid\u201d\uff0c\u201csame\u201d\uff0c\u6216\u201cfull\u201d\uff0cfull\u9700\u8981\u4ee5theano\u4e3a\u540e\u7aef    subsample\uff1a\u957f\u4e3a2\u7684tuple\uff0c\u8f93\u51fa\u5bf9\u8f93\u5165\u7684\u4e0b\u91c7\u6837\u56e0\u5b50\uff0c\u66f4\u666e\u904d\u7684\u79f0\u547c\u662f\u201cstrides\u201d    W_regularizer\uff1a\u65bd\u52a0\u5728\u6743\u91cd\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a WeightRegularizer \u5bf9\u8c61    b_regularizer\uff1a\u65bd\u52a0\u5728\u504f\u7f6e\u5411\u91cf\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a WeightRegularizer \u5bf9\u8c61    activity_regularizer\uff1a\u65bd\u52a0\u5728\u8f93\u51fa\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a ActivityRegularizer \u5bf9\u8c61    W_constraints\uff1a\u65bd\u52a0\u5728\u6743\u91cd\u4e0a\u7684\u7ea6\u675f\u9879\uff0c\u4e3a Constraints \u5bf9\u8c61    b_constraints\uff1a\u65bd\u52a0\u5728\u504f\u7f6e\u4e0a\u7684\u7ea6\u675f\u9879\uff0c\u4e3a Constraints \u5bf9\u8c61    dim_ordering\uff1a\u2018th\u2019\u6216\u2018tf\u2019\u3002\u2018th\u2019\u6a21\u5f0f\u4e2d\u901a\u9053\u7ef4\uff08\u5982\u5f69\u8272\u56fe\u50cf\u76843\u901a\u9053\uff09\u4f4d\u4e8e\u7b2c1\u4e2a\u4f4d\u7f6e\uff08\u7ef4\u5ea6\u4ece0\u5f00\u59cb\u7b97\uff09\uff0c\u800c\u5728\u2018tf\u2019\u6a21\u5f0f\u4e2d\uff0c\u901a\u9053\u7ef4\u4f4d\u4e8e\u7b2c3\u4e2a\u4f4d\u7f6e\u3002\u4f8b\u5982128*128\u7684\u4e09\u901a\u9053\u5f69\u8272\u56fe\u7247\uff0c\u5728\u2018th\u2019\u6a21\u5f0f\u4e2d input_shape \u5e94\u5199\u4e3a\uff083\uff0c128\uff0c128\uff09\uff0c\u800c\u5728\u2018tf\u2019\u6a21\u5f0f\u4e2d\u5e94\u5199\u4e3a\uff08128\uff0c128\uff0c3\uff09\uff0c\u6ce8\u610f\u8fd9\u91cc3\u51fa\u73b0\u5728\u7b2c0\u4e2a\u4f4d\u7f6e\uff0c\u56e0\u4e3a input_shape \u4e0d\u5305\u542b\u6837\u672c\u6570\u7684\u7ef4\u5ea6\uff0c\u5728\u5176\u5185\u90e8\u5b9e\u73b0\u4e2d\uff0c\u5b9e\u9645\u4e0a\u662f\uff08None\uff0c3\uff0c128\uff0c128\uff09\u548c\uff08None\uff0c128\uff0c128\uff0c3\uff09\u3002\u9ed8\u8ba4\u662f image_dim_ordering \u6307\u5b9a\u7684\u6a21\u5f0f\uff0c\u53ef\u5728 ~/.keras/keras.json \u4e2d\u67e5\u770b\uff0c\u82e5\u6ca1\u6709\u8bbe\u7f6e\u8fc7\u5219\u4e3a'tf'\u3002    bias\uff1a\u5e03\u5c14\u503c\uff0c\u662f\u5426\u5305\u542b\u504f\u7f6e\u5411\u91cf\uff08\u5373\u5c42\u5bf9\u8f93\u5165\u505a\u7ebf\u6027\u53d8\u6362\u8fd8\u662f\u4eff\u5c04\u53d8\u6362\uff09", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/layers/convolutional_layer/#shape_10", 
            "text": "\u2018th\u2019\u6a21\u5f0f\u4e0b\uff0c\u8f93\u5165\u5f62\u5982\uff08samples,channels\uff0crows\uff0ccols\uff09\u76844D\u5f20\u91cf  \u2018tf\u2019\u6a21\u5f0f\u4e0b\uff0c\u8f93\u5165\u5f62\u5982\uff08samples\uff0crows\uff0ccols\uff0cchannels\uff09\u76844D\u5f20\u91cf  \u6ce8\u610f\u8fd9\u91cc\u7684\u8f93\u5165shape\u6307\u7684\u662f\u51fd\u6570\u5185\u90e8\u5b9e\u73b0\u7684\u8f93\u5165shape\uff0c\u800c\u975e\u51fd\u6570\u63a5\u53e3\u5e94\u6307\u5b9a\u7684 input_shape \uff0c\u8bf7\u53c2\u8003\u4e0b\u9762\u63d0\u4f9b\u7684\u4f8b\u5b50\u3002", 
            "title": "\u8f93\u5165shape"
        }, 
        {
            "location": "/layers/convolutional_layer/#shape_11", 
            "text": "\u2018th\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples\uff0cnb_filter, new_rows, new_cols\uff09\u76844D\u5f20\u91cf  \u2018tf\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples\uff0cnew_rows, new_cols\uff0cnb_filter\uff09\u76844D\u5f20\u91cf  \u8f93\u51fa\u7684\u884c\u5217\u6570\u53ef\u80fd\u4f1a\u56e0\u4e3a\u586b\u5145\u65b9\u6cd5\u800c\u6539\u53d8", 
            "title": "\u8f93\u51fashape"
        }, 
        {
            "location": "/layers/convolutional_layer/#_13", 
            "text": "# apply a 3x3 transposed convolution with stride 1x1 and 3 output filters on a 12x12 image:\nmodel = Sequential()\nmodel.add(Deconvolution2D(3, 3, 3, output_shape=(None, 3, 14, 14), border_mode='valid', input_shape=(3, 12, 12)))\n# output_shape will be (None, 3, 14, 14)\n\n# apply a 3x3 transposed convolution with stride 2x2 and 3 output filters on a 12x12 image:\nmodel = Sequential()\nmodel.add(Deconvolution2D(3, 3, 3, output_shape=(None, 3, 25, 25), subsample=(2, 2), border_mode='valid', input_shape=(3, 12, 12)))\nmodel.summary()\n# output_shape will be (None, 3, 25, 25)", 
            "title": "\u4f8b\u5b50"
        }, 
        {
            "location": "/layers/convolutional_layer/#_14", 
            "text": "A guide to convolution arithmetic for deep learning  Transposed convolution arithmetic   Deconvolutional Networks", 
            "title": "\u53c2\u8003\u6587\u732e"
        }, 
        {
            "location": "/layers/convolutional_layer/#convolution3d", 
            "text": "keras.layers.convolutional.Convolution3D(nb_filter, kernel_dim1, kernel_dim2, kernel_dim3, init='glorot_uniform', activation='linear', weights=None, border_mode='valid', subsample=(1, 1, 1), dim_ordering='th', W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None, bias=True)  \u4e09\u7ef4\u5377\u79ef\u5bf9\u4e09\u7ef4\u7684\u8f93\u5165\u8fdb\u884c\u6ed1\u52a8\u7a97\u5377\u79ef\uff0c\u5f53\u4f7f\u7528\u8be5\u5c42\u4f5c\u4e3a\u7b2c\u4e00\u5c42\u65f6\uff0c\u5e94\u63d0\u4f9b input_shape \u53c2\u6570\u3002\u4f8b\u5982 input_shape = (3,10,128,128) \u4ee3\u8868\u5bf910\u5e27128*128\u7684\u5f69\u8272RGB\u56fe\u50cf\u8fdb\u884c\u5377\u79ef", 
            "title": "Convolution3D\u5c42"
        }, 
        {
            "location": "/layers/convolutional_layer/#_15", 
            "text": "nb_filter\uff1a\u5377\u79ef\u6838\u7684\u6570\u76ee    kernel_dim1\uff1a\u5377\u79ef\u6838\u7b2c1\u7ef4\u5ea6\u7684\u957f    kernel_dim2\uff1a\u5377\u79ef\u6838\u7b2c2\u7ef4\u5ea6\u7684\u957f    kernel_dim3\uff1a\u5377\u79ef\u6838\u7b2c3\u7ef4\u5ea6\u7684\u957f    init\uff1a\u521d\u59cb\u5316\u65b9\u6cd5\uff0c\u4e3a\u9884\u5b9a\u4e49\u521d\u59cb\u5316\u65b9\u6cd5\u540d\u7684\u5b57\u7b26\u4e32\uff0c\u6216\u7528\u4e8e\u521d\u59cb\u5316\u6743\u91cd\u7684Theano\u51fd\u6570\u3002\u8be5\u53c2\u6570\u4ec5\u5728\u4e0d\u4f20\u9012 weights \u53c2\u6570\u65f6\u6709\u610f\u4e49\u3002    activation\uff1a\u6fc0\u6d3b\u51fd\u6570\uff0c\u4e3a\u9884\u5b9a\u4e49\u7684\u6fc0\u6d3b\u51fd\u6570\u540d\uff08\u53c2\u8003 \u6fc0\u6d3b\u51fd\u6570 \uff09\uff0c\u6216\u9010\u5143\u7d20\uff08element-wise\uff09\u7684Theano\u51fd\u6570\u3002\u5982\u679c\u4e0d\u6307\u5b9a\u8be5\u53c2\u6570\uff0c\u5c06\u4e0d\u4f1a\u4f7f\u7528\u4efb\u4f55\u6fc0\u6d3b\u51fd\u6570\uff08\u5373\u4f7f\u7528\u7ebf\u6027\u6fc0\u6d3b\u51fd\u6570\uff1aa(x)=x\uff09    weights\uff1a\u6743\u503c\uff0c\u4e3anumpy array\u7684list\u3002\u8be5list\u5e94\u542b\u6709\u4e00\u4e2a\u5f62\u5982\uff08input_dim,output_dim\uff09\u7684\u6743\u91cd\u77e9\u9635\u548c\u4e00\u4e2a\u5f62\u5982(output_dim,)\u7684\u504f\u7f6e\u5411\u91cf\u3002    border_mode\uff1a\u8fb9\u754c\u6a21\u5f0f\uff0c\u4e3a\u201cvalid\u201d\uff0c\u201csame\u201d\uff0c\u6216\u201cfull\u201d\uff0cfull\u9700\u8981\u4ee5theano\u4e3a\u540e\u7aef    subsample\uff1a\u957f\u4e3a3\u7684tuple\uff0c\u8f93\u51fa\u5bf9\u8f93\u5165\u7684\u4e0b\u91c7\u6837\u56e0\u5b50\uff0c\u66f4\u666e\u904d\u7684\u79f0\u547c\u662f\u201cstrides\u201d  *\u6ce8\u610f\uff0csubsample\u901a\u8fc7\u5bf93D\u5377\u79ef\u7684\u7ed3\u679c\u4ee5strides=\uff081\uff0c1\uff0c1\uff09\u5207\u7247\u5b9e\u73b0    W_regularizer\uff1a\u65bd\u52a0\u5728\u6743\u91cd\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a WeightRegularizer \u5bf9\u8c61    b_regularizer\uff1a\u65bd\u52a0\u5728\u504f\u7f6e\u5411\u91cf\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a WeightRegularizer \u5bf9\u8c61    activity_regularizer\uff1a\u65bd\u52a0\u5728\u8f93\u51fa\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a ActivityRegularizer \u5bf9\u8c61    W_constraints\uff1a\u65bd\u52a0\u5728\u6743\u91cd\u4e0a\u7684\u7ea6\u675f\u9879\uff0c\u4e3a Constraints \u5bf9\u8c61    b_constraints\uff1a\u65bd\u52a0\u5728\u504f\u7f6e\u4e0a\u7684\u7ea6\u675f\u9879\uff0c\u4e3a Constraints \u5bf9\u8c61    dim_ordering\uff1a\u2018th\u2019\u6216\u2018tf\u2019\u3002\u2018th\u2019\u6a21\u5f0f\u4e2d\u901a\u9053\u7ef4\uff08\u5982\u5f69\u8272\u56fe\u50cf\u76843\u901a\u9053\uff09\u4f4d\u4e8e\u7b2c1\u4e2a\u4f4d\u7f6e\uff08\u7ef4\u5ea6\u4ece0\u5f00\u59cb\u7b97\uff09\uff0c\u800c\u5728\u2018tf\u2019\u6a21\u5f0f\u4e2d\uff0c\u901a\u9053\u7ef4\u4f4d\u4e8e\u7b2c4\u4e2a\u4f4d\u7f6e\u3002\u9ed8\u8ba4\u662f image_dim_ordering \u6307\u5b9a\u7684\u6a21\u5f0f\uff0c\u53ef\u5728 ~/.keras/keras.json \u4e2d\u67e5\u770b\uff0c\u82e5\u6ca1\u6709\u8bbe\u7f6e\u8fc7\u5219\u4e3a'tf'\u3002    bias\uff1a\u5e03\u5c14\u503c\uff0c\u662f\u5426\u5305\u542b\u504f\u7f6e\u5411\u91cf\uff08\u5373\u5c42\u5bf9\u8f93\u5165\u505a\u7ebf\u6027\u53d8\u6362\u8fd8\u662f\u4eff\u5c04\u53d8\u6362\uff09", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/layers/convolutional_layer/#shape_12", 
            "text": "\u2018th\u2019\u6a21\u5f0f\u4e0b\uff0c\u8f93\u5165\u5e94\u4e3a\u5f62\u5982\uff08samples\uff0cchannels\uff0cinput_dim1\uff0cinput_dim2, input_dim3\uff09\u76845D\u5f20\u91cf  \u2018tf\u2019\u6a21\u5f0f\u4e0b\uff0c\u8f93\u5165\u5e94\u4e3a\u5f62\u5982\uff08samples\uff0cinput_dim1\uff0cinput_dim2, input_dim3\uff0cchannels\uff09\u76845D\u5f20\u91cf  \u8fd9\u91cc\u7684\u8f93\u5165shape\u6307\u7684\u662f\u51fd\u6570\u5185\u90e8\u5b9e\u73b0\u7684\u8f93\u5165shape\uff0c\u800c\u975e\u51fd\u6570\u63a5\u53e3\u5e94\u6307\u5b9a\u7684 input_shape \u3002", 
            "title": "\u8f93\u5165shape"
        }, 
        {
            "location": "/layers/convolutional_layer/#cropping1d", 
            "text": "keras.layers.convolutional.Cropping1D(cropping=(1, 1))  \u5728\u65f6\u95f4\u8f74\uff08axis1\uff09\u4e0a\u5bf91D\u8f93\u5165\uff08\u5373\u65f6\u95f4\u5e8f\u5217\uff09\u8fdb\u884c\u88c1\u526a", 
            "title": "Cropping1D\u5c42"
        }, 
        {
            "location": "/layers/convolutional_layer/#_16", 
            "text": "cropping\uff1a\u957f\u4e3a2\u7684tuple\uff0c\u6307\u5b9a\u5728\u5e8f\u5217\u7684\u9996\u5c3e\u8981\u88c1\u526a\u6389\u591a\u5c11\u4e2a\u5143\u7d20", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/layers/convolutional_layer/#shape_13", 
            "text": "\u5f62\u5982\uff08samples\uff0caxis_to_crop\uff0cfeatures\uff09\u76843D\u5f20\u91cf", 
            "title": "\u8f93\u5165shape"
        }, 
        {
            "location": "/layers/convolutional_layer/#shape_14", 
            "text": "\u5f62\u5982\uff08samples\uff0ccropped_axis\uff0cfeatures\uff09\u76843D\u5f20\u91cf", 
            "title": "\u8f93\u51fashape"
        }, 
        {
            "location": "/layers/convolutional_layer/#cropping2d", 
            "text": "keras.layers.convolutional.Cropping2D(cropping=((0, 0), (0, 0)), dim_ordering='default')  \u5bf92D\u8f93\u5165\uff08\u56fe\u50cf\uff09\u8fdb\u884c\u88c1\u526a\uff0c\u5c06\u5728\u7a7a\u57df\u7ef4\u5ea6\uff0c\u5373\u5bbd\u548c\u9ad8\u7684\u65b9\u5411\u4e0a\u88c1\u526a", 
            "title": "Cropping2D\u5c42"
        }, 
        {
            "location": "/layers/convolutional_layer/#_17", 
            "text": "cropping\uff1a\u957f\u4e3a2\u7684\u6574\u6570tuple\uff0c\u5206\u522b\u4e3a\u5bbd\u548c\u9ad8\u65b9\u5411\u4e0a\u5934\u90e8\u4e0e\u5c3e\u90e8\u9700\u8981\u88c1\u526a\u6389\u7684\u5143\u7d20\u6570    dim_ordering\uff1a\u2018th\u2019\u6216\u2018tf\u2019\u3002\u2018th\u2019\u6a21\u5f0f\u4e2d\u901a\u9053\u7ef4\uff08\u5982\u5f69\u8272\u56fe\u50cf\u76843\u901a\u9053\uff09\u4f4d\u4e8e\u7b2c1\u4e2a\u4f4d\u7f6e\uff08\u7ef4\u5ea6\u4ece0\u5f00\u59cb\u7b97\uff09\uff0c\u800c\u5728\u2018tf\u2019\u6a21\u5f0f\u4e2d\uff0c\u901a\u9053\u7ef4\u4f4d\u4e8e\u7b2c3\u4e2a\u4f4d\u7f6e\u3002\u4f8b\u5982128*128\u7684\u4e09\u901a\u9053\u5f69\u8272\u56fe\u7247\uff0c\u5728\u2018th\u2019\u6a21\u5f0f\u4e2d input_shape \u5e94\u5199\u4e3a\uff083\uff0c128\uff0c128\uff09\uff0c\u800c\u5728\u2018tf\u2019\u6a21\u5f0f\u4e2d\u5e94\u5199\u4e3a\uff08128\uff0c128\uff0c3\uff09\uff0c\u6ce8\u610f\u8fd9\u91cc3\u51fa\u73b0\u5728\u7b2c0\u4e2a\u4f4d\u7f6e\uff0c\u56e0\u4e3a input_shape \u4e0d\u5305\u542b\u6837\u672c\u6570\u7684\u7ef4\u5ea6\uff0c\u5728\u5176\u5185\u90e8\u5b9e\u73b0\u4e2d\uff0c\u5b9e\u9645\u4e0a\u662f\uff08None\uff0c3\uff0c128\uff0c128\uff09\u548c\uff08None\uff0c128\uff0c128\uff0c3\uff09\u3002\u9ed8\u8ba4\u662f image_dim_ordering \u6307\u5b9a\u7684\u6a21\u5f0f\uff0c\u53ef\u5728 ~/.keras/keras.json \u4e2d\u67e5\u770b\uff0c\u82e5\u6ca1\u6709\u8bbe\u7f6e\u8fc7\u5219\u4e3a'tf'\u3002", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/layers/convolutional_layer/#shape_15", 
            "text": "\u5f62\u5982\uff08samples\uff0cdepth, first_axis_to_crop, second_axis_to_crop\uff09", 
            "title": "\u8f93\u5165shape"
        }, 
        {
            "location": "/layers/convolutional_layer/#shape_16", 
            "text": "\u5f62\u5982(samples, depth, first_cropped_axis, second_cropped_axis)\u76844D\u5f20\u91cf", 
            "title": "\u8f93\u51fashape"
        }, 
        {
            "location": "/layers/convolutional_layer/#cropping3d", 
            "text": "keras.layers.convolutional.Cropping3D(cropping=((1, 1), (1, 1), (1, 1)), dim_ordering='default')  \u5bf92D\u8f93\u5165\uff08\u56fe\u50cf\uff09\u8fdb\u884c\u88c1\u526a", 
            "title": "Cropping3D\u5c42"
        }, 
        {
            "location": "/layers/convolutional_layer/#_18", 
            "text": "cropping\uff1a\u957f\u4e3a3\u7684\u6574\u6570tuple\uff0c\u5206\u522b\u4e3a\u4e09\u4e2a\u65b9\u5411\u4e0a\u5934\u90e8\u4e0e\u5c3e\u90e8\u9700\u8981\u88c1\u526a\u6389\u7684\u5143\u7d20\u6570    dim_ordering\uff1a\u2018th\u2019\u6216\u2018tf\u2019\u3002\u2018th\u2019\u6a21\u5f0f\u4e2d\u901a\u9053\u7ef4\uff08\u5982\u5f69\u8272\u56fe\u50cf\u76843\u901a\u9053\uff09\u4f4d\u4e8e\u7b2c1\u4e2a\u4f4d\u7f6e\uff08\u7ef4\u5ea6\u4ece0\u5f00\u59cb\u7b97\uff09\uff0c\u800c\u5728\u2018tf\u2019\u6a21\u5f0f\u4e2d\uff0c\u901a\u9053\u7ef4\u4f4d\u4e8e\u7b2c4\u4e2a\u4f4d\u7f6e\u3002\u9ed8\u8ba4\u662f image_dim_ordering \u6307\u5b9a\u7684\u6a21\u5f0f\uff0c\u53ef\u5728 ~/.keras/keras.json \u4e2d\u67e5\u770b\uff0c\u82e5\u6ca1\u6709\u8bbe\u7f6e\u8fc7\u5219\u4e3a'tf'\u3002", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/layers/convolutional_layer/#shape_17", 
            "text": "\u5f62\u5982 (samples, depth, first_axis_to_crop, second_axis_to_crop, third_axis_to_crop)\u76845D\u5f20\u91cf", 
            "title": "\u8f93\u5165shape"
        }, 
        {
            "location": "/layers/convolutional_layer/#shape_18", 
            "text": "\u5f62\u5982(samples, depth, first_cropped_axis, second_cropped_axis, third_cropped_axis)\u76845D\u5f20\u91cf", 
            "title": "\u8f93\u51fashape"
        }, 
        {
            "location": "/layers/convolutional_layer/#upsampling1d", 
            "text": "keras.layers.convolutional.UpSampling1D(length=2)  \u5728\u65f6\u95f4\u8f74\u4e0a\uff0c\u5c06\u6bcf\u4e2a\u65f6\u95f4\u6b65\u91cd\u590d length \u6b21", 
            "title": "UpSampling1D\u5c42"
        }, 
        {
            "location": "/layers/convolutional_layer/#_19", 
            "text": "length\uff1a\u4e0a\u91c7\u6837\u56e0\u5b50", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/layers/convolutional_layer/#shape_19", 
            "text": "\u5f62\u5982\uff08samples\uff0csteps\uff0cfeatures\uff09\u76843D\u5f20\u91cf", 
            "title": "\u8f93\u5165shape"
        }, 
        {
            "location": "/layers/convolutional_layer/#shape_20", 
            "text": "\u5f62\u5982\uff08samples\uff0cupsampled_steps\uff0cfeatures\uff09\u76843D\u5f20\u91cf", 
            "title": "\u8f93\u51fashape"
        }, 
        {
            "location": "/layers/convolutional_layer/#upsampling2d", 
            "text": "keras.layers.convolutional.UpSampling2D(size=(2, 2), dim_ordering='th')  \u5c06\u6570\u636e\u7684\u884c\u548c\u5217\u5206\u522b\u91cd\u590dsize[0]\u548csize[1]\u6b21", 
            "title": "UpSampling2D\u5c42"
        }, 
        {
            "location": "/layers/convolutional_layer/#_20", 
            "text": "size\uff1a\u6574\u6570tuple\uff0c\u5206\u522b\u4e3a\u884c\u548c\u5217\u4e0a\u91c7\u6837\u56e0\u5b50    dim_ordering\uff1a\u2018th\u2019\u6216\u2018tf\u2019\u3002\u2018th\u2019\u6a21\u5f0f\u4e2d\u901a\u9053\u7ef4\uff08\u5982\u5f69\u8272\u56fe\u50cf\u76843\u901a\u9053\uff09\u4f4d\u4e8e\u7b2c1\u4e2a\u4f4d\u7f6e\uff08\u7ef4\u5ea6\u4ece0\u5f00\u59cb\u7b97\uff09\uff0c\u800c\u5728\u2018tf\u2019\u6a21\u5f0f\u4e2d\uff0c\u901a\u9053\u7ef4\u4f4d\u4e8e\u7b2c3\u4e2a\u4f4d\u7f6e\u3002\u4f8b\u5982128*128\u7684\u4e09\u901a\u9053\u5f69\u8272\u56fe\u7247\uff0c\u5728\u2018th\u2019\u6a21\u5f0f\u4e2d input_shape \u5e94\u5199\u4e3a\uff083\uff0c128\uff0c128\uff09\uff0c\u800c\u5728\u2018tf\u2019\u6a21\u5f0f\u4e2d\u5e94\u5199\u4e3a\uff08128\uff0c128\uff0c3\uff09\uff0c\u6ce8\u610f\u8fd9\u91cc3\u51fa\u73b0\u5728\u7b2c0\u4e2a\u4f4d\u7f6e\uff0c\u56e0\u4e3a input_shape \u4e0d\u5305\u542b\u6837\u672c\u6570\u7684\u7ef4\u5ea6\uff0c\u5728\u5176\u5185\u90e8\u5b9e\u73b0\u4e2d\uff0c\u5b9e\u9645\u4e0a\u662f\uff08None\uff0c3\uff0c128\uff0c128\uff09\u548c\uff08None\uff0c128\uff0c128\uff0c3\uff09\u3002\u9ed8\u8ba4\u662f image_dim_ordering \u6307\u5b9a\u7684\u6a21\u5f0f\uff0c\u53ef\u5728 ~/.keras/keras.json \u4e2d\u67e5\u770b\uff0c\u82e5\u6ca1\u6709\u8bbe\u7f6e\u8fc7\u5219\u4e3a'tf'\u3002", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/layers/convolutional_layer/#shape_21", 
            "text": "\u2018th\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples\uff0cchannels, rows\uff0ccols\uff09\u76844D\u5f20\u91cf  \u2018tf\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples\uff0crows, cols\uff0cchannels\uff09\u76844D\u5f20\u91cf", 
            "title": "\u8f93\u5165shape"
        }, 
        {
            "location": "/layers/convolutional_layer/#shape_22", 
            "text": "\u2018th\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples\uff0cchannels, upsampled_rows, upsampled_cols\uff09\u76844D\u5f20\u91cf  \u2018tf\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples\uff0cupsampled_rows, upsampled_cols\uff0cchannels\uff09\u76844D\u5f20\u91cf", 
            "title": "\u8f93\u51fashape"
        }, 
        {
            "location": "/layers/convolutional_layer/#upsampling3d", 
            "text": "keras.layers.convolutional.UpSampling3D(size=(2, 2, 2), dim_ordering='th')  \u5c06\u6570\u636e\u7684\u4e09\u4e2a\u7ef4\u5ea6\u4e0a\u5206\u522b\u91cd\u590dsize[0]\u3001size[1]\u548cize[2]\u6b21  \u672c\u5c42\u76ee\u524d\u53ea\u80fd\u5728\u4f7f\u7528Theano\u4e3a\u540e\u7aef\u65f6\u53ef\u7528", 
            "title": "UpSampling3D\u5c42"
        }, 
        {
            "location": "/layers/convolutional_layer/#_21", 
            "text": "size\uff1a\u957f\u4e3a3\u7684\u6574\u6570tuple\uff0c\u4ee3\u8868\u5728\u4e09\u4e2a\u7ef4\u5ea6\u4e0a\u7684\u4e0a\u91c7\u6837\u56e0\u5b50    dim_ordering\uff1a\u2018th\u2019\u6216\u2018tf\u2019\u3002\u2018th\u2019\u6a21\u5f0f\u4e2d\u901a\u9053\u7ef4\uff08\u5982\u5f69\u8272\u56fe\u50cf\u76843\u901a\u9053\uff09\u4f4d\u4e8e\u7b2c1\u4e2a\u4f4d\u7f6e\uff08\u7ef4\u5ea6\u4ece0\u5f00\u59cb\u7b97\uff09\uff0c\u800c\u5728\u2018tf\u2019\u6a21\u5f0f\u4e2d\uff0c\u901a\u9053\u7ef4\u4f4d\u4e8e\u7b2c4\u4e2a\u4f4d\u7f6e\u3002\u9ed8\u8ba4\u662f image_dim_ordering \u6307\u5b9a\u7684\u6a21\u5f0f\uff0c\u53ef\u5728 ~/.keras/keras.json \u4e2d\u67e5\u770b\uff0c\u82e5\u6ca1\u6709\u8bbe\u7f6e\u8fc7\u5219\u4e3a'tf'\u3002", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/layers/convolutional_layer/#shape_23", 
            "text": "\u2018th\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples, channels, len_pool_dim1, len_pool_dim2, len_pool_dim3\uff09\u76845D\u5f20\u91cf  \u2018tf\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples, len_pool_dim1, len_pool_dim2, len_pool_dim3\uff0cchannels, \uff09\u76845D\u5f20\u91cf", 
            "title": "\u8f93\u5165shape"
        }, 
        {
            "location": "/layers/convolutional_layer/#shape_24", 
            "text": "\u2018th\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples, channels, dim1, dim2, dim3\uff09\u76845D\u5f20\u91cf  \u2018tf\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples, upsampled_dim1, upsampled_dim2, upsampled_dim3,channels,\uff09\u76845D\u5f20\u91cf", 
            "title": "\u8f93\u51fashape"
        }, 
        {
            "location": "/layers/convolutional_layer/#zeropadding1d", 
            "text": "keras.layers.convolutional.ZeroPadding1D(padding=1)  \u5bf91D\u8f93\u5165\u7684\u9996\u5c3e\u7aef\uff08\u5982\u65f6\u57df\u5e8f\u5217\uff09\u586b\u51450\uff0c\u4ee5\u63a7\u5236\u5377\u79ef\u4ee5\u540e\u5411\u91cf\u7684\u957f\u5ea6", 
            "title": "ZeroPadding1D\u5c42"
        }, 
        {
            "location": "/layers/convolutional_layer/#_22", 
            "text": "padding\uff1a\u6574\u6570\uff0c\u8868\u793a\u5728\u8981\u586b\u5145\u7684\u8f74\u7684\u8d77\u59cb\u548c\u7ed3\u675f\u5904\u586b\u51450\u7684\u6570\u76ee\uff0c\u8fd9\u91cc\u8981\u586b\u5145\u7684\u8f74\u662f\u8f741\uff08\u7b2c1\u7ef4\uff0c\u7b2c0\u7ef4\u662f\u6837\u672c\u6570\uff09", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/layers/convolutional_layer/#shape_25", 
            "text": "\u5f62\u5982\uff08samples\uff0caxis_to_pad\uff0cfeatures\uff09\u76843D\u5f20\u91cf", 
            "title": "\u8f93\u5165shape"
        }, 
        {
            "location": "/layers/convolutional_layer/#shape_26", 
            "text": "\u5f62\u5982\uff08samples\uff0cpaded_axis\uff0cfeatures\uff09\u76843D\u5f20\u91cf", 
            "title": "\u8f93\u51fashape"
        }, 
        {
            "location": "/layers/convolutional_layer/#zeropadding2d", 
            "text": "keras.layers.convolutional.ZeroPadding2D(padding=(1, 1), dim_ordering='th')  \u5bf92D\u8f93\u5165\uff08\u5982\u56fe\u7247\uff09\u7684\u8fb9\u754c\u586b\u51450\uff0c\u4ee5\u63a7\u5236\u5377\u79ef\u4ee5\u540e\u7279\u5f81\u56fe\u7684\u5927\u5c0f", 
            "title": "ZeroPadding2D\u5c42"
        }, 
        {
            "location": "/layers/convolutional_layer/#_23", 
            "text": "padding\uff1a\u6574\u6570tuple\uff0c\u8868\u793a\u5728\u8981\u586b\u5145\u7684\u8f74\u7684\u8d77\u59cb\u548c\u7ed3\u675f\u5904\u586b\u51450\u7684\u6570\u76ee\uff0c\u8fd9\u91cc\u8981\u586b\u5145\u7684\u8f74\u662f\u8f743\u548c\u8f744\uff08\u5373\u5728'th'\u6a21\u5f0f\u4e0b\u56fe\u50cf\u7684\u884c\u548c\u5217\uff0c\u5728\u2018tf\u2019\u6a21\u5f0f\u4e0b\u8981\u586b\u5145\u7684\u5219\u662f\u8f742\uff0c3\uff09   dim_ordering\uff1a\u2018th\u2019\u6216\u2018tf\u2019\u3002\u2018th\u2019\u6a21\u5f0f\u4e2d\u901a\u9053\u7ef4\uff08\u5982\u5f69\u8272\u56fe\u50cf\u76843\u901a\u9053\uff09\u4f4d\u4e8e\u7b2c1\u4e2a\u4f4d\u7f6e\uff08\u7ef4\u5ea6\u4ece0\u5f00\u59cb\u7b97\uff09\uff0c\u800c\u5728\u2018tf\u2019\u6a21\u5f0f\u4e2d\uff0c\u901a\u9053\u7ef4\u4f4d\u4e8e\u7b2c3\u4e2a\u4f4d\u7f6e\u3002\u4f8b\u5982128*128\u7684\u4e09\u901a\u9053\u5f69\u8272\u56fe\u7247\uff0c\u5728\u2018th\u2019\u6a21\u5f0f\u4e2d input_shape \u5e94\u5199\u4e3a\uff083\uff0c128\uff0c128\uff09\uff0c\u800c\u5728\u2018tf\u2019\u6a21\u5f0f\u4e2d\u5e94\u5199\u4e3a\uff08128\uff0c128\uff0c3\uff09\uff0c\u6ce8\u610f\u8fd9\u91cc3\u51fa\u73b0\u5728\u7b2c0\u4e2a\u4f4d\u7f6e\uff0c\u56e0\u4e3a input_shape \u4e0d\u5305\u542b\u6837\u672c\u6570\u7684\u7ef4\u5ea6\uff0c\u5728\u5176\u5185\u90e8\u5b9e\u73b0\u4e2d\uff0c\u5b9e\u9645\u4e0a\u662f\uff08None\uff0c3\uff0c128\uff0c128\uff09\u548c\uff08None\uff0c128\uff0c128\uff0c3\uff09\u3002\u9ed8\u8ba4\u662f image_dim_ordering \u6307\u5b9a\u7684\u6a21\u5f0f\uff0c\u53ef\u5728 ~/.keras/keras.json \u4e2d\u67e5\u770b\uff0c\u82e5\u6ca1\u6709\u8bbe\u7f6e\u8fc7\u5219\u4e3a'tf'\u3002", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/layers/convolutional_layer/#shape_27", 
            "text": "\u2018th\u2019\u6a21\u5f0f\u4e0b\uff0c\u5f62\u5982\uff08samples\uff0cchannels\uff0cfirst_axis_to_pad\uff0csecond_axis_to_pad\uff09\u76844D\u5f20\u91cf  \u2018tf\u2019\u6a21\u5f0f\u4e0b\uff0c\u5f62\u5982\uff08samples\uff0cfirst_axis_to_pad\uff0csecond_axis_to_pad, channels\uff09\u76844D\u5f20\u91cf", 
            "title": "\u8f93\u5165shape"
        }, 
        {
            "location": "/layers/convolutional_layer/#shape_28", 
            "text": "\u2018th\u2019\u6a21\u5f0f\u4e0b\uff0c\u5f62\u5982\uff08samples\uff0cchannels\uff0cfirst_paded_axis\uff0csecond_paded_axis\uff09\u76844D\u5f20\u91cf  \u2018tf\u2019\u6a21\u5f0f\u4e0b\uff0c\u5f62\u5982\uff08samples\uff0cfirst_paded_axis\uff0csecond_paded_axis, channels\uff09\u76844D\u5f20\u91cf", 
            "title": "\u8f93\u51fashape"
        }, 
        {
            "location": "/layers/convolutional_layer/#zeropadding3d", 
            "text": "keras.layers.convolutional.ZeroPadding3D(padding=(1, 1, 1), dim_ordering='th')  \u5c06\u6570\u636e\u7684\u4e09\u4e2a\u7ef4\u5ea6\u4e0a\u586b\u51450  \u672c\u5c42\u76ee\u524d\u53ea\u80fd\u5728\u4f7f\u7528Theano\u4e3a\u540e\u7aef\u65f6\u53ef\u7528", 
            "title": "ZeroPadding3D\u5c42"
        }, 
        {
            "location": "/layers/convolutional_layer/#_24", 
            "text": "padding\uff1a\u6574\u6570tuple\uff0c\u8868\u793a\u5728\u8981\u586b\u5145\u7684\u8f74\u7684\u8d77\u59cb\u548c\u7ed3\u675f\u5904\u586b\u51450\u7684\u6570\u76ee\uff0c\u8fd9\u91cc\u8981\u586b\u5145\u7684\u8f74\u662f\u8f743\uff0c\u8f744\u548c\u8f745\uff0c\u2018tf\u2019\u6a21\u5f0f\u4e0b\u5219\u662f\u8f742\uff0c3\u548c4   dim_ordering\uff1a\u2018th\u2019\u6216\u2018tf\u2019\u3002\u2018th\u2019\u6a21\u5f0f\u4e2d\u901a\u9053\u7ef4\uff08\u5982\u5f69\u8272\u56fe\u50cf\u76843\u901a\u9053\uff09\u4f4d\u4e8e\u7b2c1\u4e2a\u4f4d\u7f6e\uff08\u7ef4\u5ea6\u4ece0\u5f00\u59cb\u7b97\uff09\uff0c\u800c\u5728\u2018tf\u2019\u6a21\u5f0f\u4e2d\uff0c\u901a\u9053\u7ef4\u4f4d\u4e8e\u7b2c4\u4e2a\u4f4d\u7f6e\u3002\u9ed8\u8ba4\u662f image_dim_ordering \u6307\u5b9a\u7684\u6a21\u5f0f\uff0c\u53ef\u5728 ~/.keras/keras.json \u4e2d\u67e5\u770b\uff0c\u82e5\u6ca1\u6709\u8bbe\u7f6e\u8fc7\u5219\u4e3a'tf'\u3002", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/layers/convolutional_layer/#shape_29", 
            "text": "\u2018th\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples, channels, first_axis_to_pad\uff0cfirst_axis_to_pad, first_axis_to_pad,\uff09\u76845D\u5f20\u91cf  \u2018tf\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples, first_axis_to_pad\uff0cfirst_axis_to_pad, first_axis_to_pad, channels\uff09\u76845D\u5f20\u91cf", 
            "title": "\u8f93\u5165shape"
        }, 
        {
            "location": "/layers/convolutional_layer/#shape_30", 
            "text": "\u2018th\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples, channels, first_paded_axis\uff0csecond_paded_axis, third_paded_axis,\uff09\u76845D\u5f20\u91cf  \u2018tf\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples, len_pool_dim1, len_pool_dim2, len_pool_dim3\uff0cchannels, \uff09\u76845D\u5f20\u91cf", 
            "title": "\u8f93\u51fashape"
        }, 
        {
            "location": "/layers/pooling_layer/", 
            "text": "\u6c60\u5316\u5c42\n\n\nMaxPooling1D\u5c42\n\n\nkeras.layers.convolutional.MaxPooling1D(pool_length=2, stride=None, border_mode='valid')\n\n\n\n\n\u5bf9\u65f6\u57df1D\u4fe1\u53f7\u8fdb\u884c\u6700\u5927\u503c\u6c60\u5316\n\n\n\u53c2\u6570\n\n\n\n\n\n\npool_length\uff1a\u4e0b\u91c7\u6837\u56e0\u5b50\uff0c\u5982\u53d62\u5219\u5c06\u8f93\u5165\u4e0b\u91c7\u6837\u5230\u4e00\u534a\u957f\u5ea6\n\n\n\n\n\n\nstride\uff1a\u6574\u6570\u6216None\uff0c\u6b65\u957f\u503c\n\n\n\n\n\n\nborder_mode\uff1a\u2018valid\u2019\u6216\u8005\u2018same\u2019\n\n\n\n\n\n\n\u8f93\u5165shape\n\n\n\n\n\u5f62\u5982\uff08samples\uff0csteps\uff0cfeatures\uff09\u76843D\u5f20\u91cf\n\n\n\n\n\u8f93\u51fashape\n\n\n\n\n\u5f62\u5982\uff08samples\uff0cdownsampled_steps\uff0cfeatures\uff09\u76843D\u5f20\u91cf\n\n\n\n\n\n\nMaxPooling2D\u5c42\n\n\nkeras.layers.convolutional.MaxPooling2D(pool_size=(2, 2), strides=None, border_mode='valid', dim_ordering='th')\n\n\n\n\n\u4e3a\u7a7a\u57df\u4fe1\u53f7\u65bd\u52a0\u6700\u5927\u503c\u6c60\u5316\n\n\n\u53c2\u6570\n\n\n\n\n\n\npool_size\uff1a\u957f\u4e3a2\u7684\u6574\u6570tuple\uff0c\u4ee3\u8868\u5728\u4e24\u4e2a\u65b9\u5411\uff08\u7ad6\u76f4\uff0c\u6c34\u5e73\uff09\u4e0a\u7684\u4e0b\u91c7\u6837\u56e0\u5b50\uff0c\u5982\u53d6\uff082\uff0c2\uff09\u5c06\u4f7f\u56fe\u7247\u5728\u4e24\u4e2a\u7ef4\u5ea6\u4e0a\u5747\u53d8\u4e3a\u539f\u957f\u7684\u4e00\u534a\n\n\n\n\n\n\nstrides\uff1a\u957f\u4e3a2\u7684\u6574\u6570tuple\uff0c\u6216\u8005None\uff0c\u6b65\u957f\u503c\u3002\n\n\n\n\n\n\nborder_mode\uff1a\u2018valid\u2019\u6216\u8005\u2018same\u2019\n\n\n\n\n\n\ndim_ordering\uff1a\u2018th\u2019\u6216\u2018tf\u2019\u3002\u2018th\u2019\u6a21\u5f0f\u4e2d\u901a\u9053\u7ef4\uff08\u5982\u5f69\u8272\u56fe\u50cf\u76843\u901a\u9053\uff09\u4f4d\u4e8e\u7b2c1\u4e2a\u4f4d\u7f6e\uff08\u7ef4\u5ea6\u4ece0\u5f00\u59cb\u7b97\uff09\uff0c\u800c\u5728\u2018tf\u2019\u6a21\u5f0f\u4e2d\uff0c\u901a\u9053\u7ef4\u4f4d\u4e8e\u7b2c3\u4e2a\u4f4d\u7f6e\u3002\u4f8b\u5982128*128\u7684\u4e09\u901a\u9053\u5f69\u8272\u56fe\u7247\uff0c\u5728\u2018th\u2019\u6a21\u5f0f\u4e2d\ninput_shape\n\u5e94\u5199\u4e3a\uff083\uff0c128\uff0c128\uff09\uff0c\u800c\u5728\u2018tf\u2019\u6a21\u5f0f\u4e2d\u5e94\u5199\u4e3a\uff08128\uff0c128\uff0c3\uff09\uff0c\u6ce8\u610f\u8fd9\u91cc3\u51fa\u73b0\u5728\u7b2c0\u4e2a\u4f4d\u7f6e\uff0c\u56e0\u4e3a\ninput_shape\n\u4e0d\u5305\u542b\u6837\u672c\u6570\u7684\u7ef4\u5ea6\uff0c\u5728\u5176\u5185\u90e8\u5b9e\u73b0\u4e2d\uff0c\u5b9e\u9645\u4e0a\u662f\uff08None\uff0c3\uff0c128\uff0c128\uff09\u548c\uff08None\uff0c128\uff0c128\uff0c3\uff09\u3002\u9ed8\u8ba4\u662f\nimage_dim_ordering\n\u6307\u5b9a\u7684\u6a21\u5f0f\uff0c\u53ef\u5728\n~/.keras/keras.json\n\u4e2d\u67e5\u770b\uff0c\u82e5\u6ca1\u6709\u8bbe\u7f6e\u8fc7\u5219\u4e3a'tf'\u3002\n\n\n\n\n\n\n\u8f93\u5165shape\n\n\n\u2018th\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples\uff0cchannels, rows\uff0ccols\uff09\u76844D\u5f20\u91cf\n\n\n\u2018tf\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples\uff0crows, cols\uff0cchannels\uff09\u76844D\u5f20\u91cf\n\n\n\u8f93\u51fashape\n\n\n\u2018th\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples\uff0cchannels, pooled_rows, pooled_cols\uff09\u76844D\u5f20\u91cf\n\n\n\u2018tf\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples\uff0cpooled_rows, pooled_cols\uff0cchannels\uff09\u76844D\u5f20\u91cf\n\n\n\n\nMaxPooling3D\u5c42\n\n\nkeras.layers.convolutional.MaxPooling3D(pool_size=(2, 2, 2), strides=None, border_mode='valid', dim_ordering='th')\n\n\n\n\n\u4e3a3D\u4fe1\u53f7\uff08\u7a7a\u57df\u6216\u65f6\u7a7a\u57df\uff09\u65bd\u52a0\u6700\u5927\u503c\u6c60\u5316\n\n\n\u672c\u5c42\u76ee\u524d\u53ea\u80fd\u5728\u4f7f\u7528Theano\u4e3a\u540e\u7aef\u65f6\u53ef\u7528\n\n\n\u53c2\u6570\n\n\n\n\n\n\npool_size\uff1a\u957f\u4e3a3\u7684\u6574\u6570tuple\uff0c\u4ee3\u8868\u5728\u4e09\u4e2a\u7ef4\u5ea6\u4e0a\u7684\u4e0b\u91c7\u6837\u56e0\u5b50\uff0c\u5982\u53d6\uff082\uff0c2\uff0c2\uff09\u5c06\u4f7f\u4fe1\u53f7\u5728\u6bcf\u4e2a\u7ef4\u5ea6\u90fd\u53d8\u4e3a\u539f\u6765\u7684\u4e00\u534a\u957f\u3002\n\n\n\n\n\n\nstrides\uff1a\u957f\u4e3a3\u7684\u6574\u6570tuple\uff0c\u6216\u8005None\uff0c\u6b65\u957f\u503c\u3002\n\n\n\n\n\n\nborder_mode\uff1a\u2018valid\u2019\u6216\u8005\u2018same\u2019\n\n\n\n\n\n\ndim_ordering\uff1a\u2018th\u2019\u6216\u2018tf\u2019\u3002\u2018th\u2019\u6a21\u5f0f\u4e2d\u901a\u9053\u7ef4\uff08\u5982\u5f69\u8272\u56fe\u50cf\u76843\u901a\u9053\uff09\u4f4d\u4e8e\u7b2c1\u4e2a\u4f4d\u7f6e\uff08\u7ef4\u5ea6\u4ece0\u5f00\u59cb\u7b97\uff09\uff0c\u800c\u5728\u2018tf\u2019\u6a21\u5f0f\u4e2d\uff0c\u901a\u9053\u7ef4\u4f4d\u4e8e\u7b2c4\u4e2a\u4f4d\u7f6e\u3002\u9ed8\u8ba4\u662f\nimage_dim_ordering\n\u6307\u5b9a\u7684\u6a21\u5f0f\uff0c\u53ef\u5728\n~/.keras/keras.json\n\u4e2d\u67e5\u770b\uff0c\u82e5\u6ca1\u6709\u8bbe\u7f6e\u8fc7\u5219\u4e3a'tf'\u3002\n\n\n\n\n\n\n\u8f93\u5165shape\n\n\n\u2018th\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples, channels, len_pool_dim1, len_pool_dim2, len_pool_dim3\uff09\u76845D\u5f20\u91cf\n\n\n\u2018tf\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples, len_pool_dim1, len_pool_dim2, len_pool_dim3\uff0cchannels, \uff09\u76845D\u5f20\u91cf\n\n\n\u8f93\u51fashape\n\n\n\u2018th\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples, channels, pooled_dim1, pooled_dim2, pooled_dim3\uff09\u76845D\u5f20\u91cf\n\n\n\u2018tf\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples, pooled_dim1, pooled_dim2, pooled_dim3,channels,\uff09\u76845D\u5f20\u91cf\n\n\n\n\nAveragePooling1D\u5c42\n\n\nkeras.layers.convolutional.AveragePooling1D(pool_length=2, stride=None, border_mode='valid')\n\n\n\n\n\u5bf9\u65f6\u57df1D\u4fe1\u53f7\u8fdb\u884c\u5e73\u5747\u503c\u6c60\u5316\n\n\n\u53c2\u6570\n\n\n\n\n\n\npool_length\uff1a\u4e0b\u91c7\u6837\u56e0\u5b50\uff0c\u5982\u53d62\u5219\u5c06\u8f93\u5165\u4e0b\u91c7\u6837\u5230\u4e00\u534a\u957f\u5ea6\n\n\n\n\n\n\nstride\uff1a\u6574\u6570\u6216None\uff0c\u6b65\u957f\u503c\n\n\n\n\n\n\nborder_mode\uff1a\u2018valid\u2019\u6216\u8005\u2018same\u2019\n\n\n\n\n\u6ce8\u610f\uff0c\u76ee\u524d\u2018same\u2019\u6a21\u5f0f\u53ea\u80fd\u5728TensorFlow\u4f5c\u4e3a\u540e\u7aef\u65f6\u4f7f\u7528\n\n\n\n\n\n\n\n\n\u8f93\u5165shape\n\n\n\n\n\u5f62\u5982\uff08samples\uff0csteps\uff0cfeatures\uff09\u76843D\u5f20\u91cf\n\n\n\n\n\u8f93\u51fashape\n\n\n\n\n\u5f62\u5982\uff08samples\uff0cdownsampled_steps\uff0cfeatures\uff09\u76843D\u5f20\u91cf\n\n\n\n\n\n\nAveragePooling2D\u5c42\n\n\nkeras.layers.convolutional.AveragePooling2D(pool_size=(2, 2), strides=None, border_mode='valid', dim_ordering='th')\n\n\n\n\n\u4e3a\u7a7a\u57df\u4fe1\u53f7\u65bd\u52a0\u5e73\u5747\u503c\u6c60\u5316\n\n\n\u53c2\u6570\n\n\n\n\n\n\npool_size\uff1a\u957f\u4e3a2\u7684\u6574\u6570tuple\uff0c\u4ee3\u8868\u5728\u4e24\u4e2a\u65b9\u5411\uff08\u7ad6\u76f4\uff0c\u6c34\u5e73\uff09\u4e0a\u7684\u4e0b\u91c7\u6837\u56e0\u5b50\uff0c\u5982\u53d6\uff082\uff0c2\uff09\u5c06\u4f7f\u56fe\u7247\u5728\u4e24\u4e2a\u7ef4\u5ea6\u4e0a\u5747\u53d8\u4e3a\u539f\u957f\u7684\u4e00\u534a\n\n\n\n\n\n\nstrides\uff1a\u957f\u4e3a2\u7684\u6574\u6570tuple\uff0c\u6216\u8005None\uff0c\u6b65\u957f\u503c\u3002\n\n\n\n\n\n\nborder_mode\uff1a\u2018valid\u2019\u6216\u8005\u2018same\u2019\n\n\n\n\n\n\ndim_ordering\uff1a\u2018th\u2019\u6216\u2018tf\u2019\u3002\u2018th\u2019\u6a21\u5f0f\u4e2d\u901a\u9053\u7ef4\uff08\u5982\u5f69\u8272\u56fe\u50cf\u76843\u901a\u9053\uff09\u4f4d\u4e8e\u7b2c1\u4e2a\u4f4d\u7f6e\uff08\u7ef4\u5ea6\u4ece0\u5f00\u59cb\u7b97\uff09\uff0c\u800c\u5728\u2018tf\u2019\u6a21\u5f0f\u4e2d\uff0c\u901a\u9053\u7ef4\u4f4d\u4e8e\u7b2c3\u4e2a\u4f4d\u7f6e\u3002\u4f8b\u5982128*128\u7684\u4e09\u901a\u9053\u5f69\u8272\u56fe\u7247\uff0c\u5728\u2018th\u2019\u6a21\u5f0f\u4e2d\ninput_shape\n\u5e94\u5199\u4e3a\uff083\uff0c128\uff0c128\uff09\uff0c\u800c\u5728\u2018tf\u2019\u6a21\u5f0f\u4e2d\u5e94\u5199\u4e3a\uff08128\uff0c128\uff0c3\uff09\uff0c\u6ce8\u610f\u8fd9\u91cc3\u51fa\u73b0\u5728\u7b2c0\u4e2a\u4f4d\u7f6e\uff0c\u56e0\u4e3a\ninput_shape\n\u4e0d\u5305\u542b\u6837\u672c\u6570\u7684\u7ef4\u5ea6\uff0c\u5728\u5176\u5185\u90e8\u5b9e\u73b0\u4e2d\uff0c\u5b9e\u9645\u4e0a\u662f\uff08None\uff0c3\uff0c128\uff0c128\uff09\u548c\uff08None\uff0c128\uff0c128\uff0c3\uff09\u3002\u9ed8\u8ba4\u662f\nimage_dim_ordering\n\u6307\u5b9a\u7684\u6a21\u5f0f\uff0c\u53ef\u5728\n~/.keras/keras.json\n\u4e2d\u67e5\u770b\uff0c\u82e5\u6ca1\u6709\u8bbe\u7f6e\u8fc7\u5219\u4e3a'tf'\u3002\n\n\n\u8f93\u5165shape\n\n\n\u2018th\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples\uff0cchannels, rows\uff0ccols\uff09\u76844D\u5f20\u91cf\n\n\n\u2018tf\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples\uff0crows, cols\uff0cchannels\uff09\u76844D\u5f20\u91cf\n\n\n\u8f93\u51fashape\n\n\n\u2018th\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples\uff0cchannels, pooled_rows, pooled_cols\uff09\u76844D\u5f20\u91cf\n\n\n\u2018tf\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples\uff0cpooled_rows, pooled_cols\uff0cchannels\uff09\u76844D\u5f20\u91cf\n\n\n\n\nAveragePooling3D\u5c42\n\n\nkeras.layers.convolutional.AveragePooling3D(pool_size=(2, 2, 2), strides=None, border_mode='valid', dim_ordering='th')\n\n\n\n\n\u4e3a3D\u4fe1\u53f7\uff08\u7a7a\u57df\u6216\u65f6\u7a7a\u57df\uff09\u65bd\u52a0\u5e73\u5747\u503c\u6c60\u5316\n\n\n\u672c\u5c42\u76ee\u524d\u53ea\u80fd\u5728\u4f7f\u7528Theano\u4e3a\u540e\u7aef\u65f6\u53ef\u7528\n\n\n\u53c2\u6570\n\n\n\n\n\n\npool_size\uff1a\u957f\u4e3a3\u7684\u6574\u6570tuple\uff0c\u4ee3\u8868\u5728\u4e09\u4e2a\u7ef4\u5ea6\u4e0a\u7684\u4e0b\u91c7\u6837\u56e0\u5b50\uff0c\u5982\u53d6\uff082\uff0c2\uff0c2\uff09\u5c06\u4f7f\u4fe1\u53f7\u5728\u6bcf\u4e2a\u7ef4\u5ea6\u90fd\u53d8\u4e3a\u539f\u6765\u7684\u4e00\u534a\u957f\u3002\n\n\n\n\n\n\nstrides\uff1a\u957f\u4e3a3\u7684\u6574\u6570tuple\uff0c\u6216\u8005None\uff0c\u6b65\u957f\u503c\u3002\n\n\n\n\n\n\nborder_mode\uff1a\u2018valid\u2019\u6216\u8005\u2018same\u2019\n\n\n\n\n\n\ndim_ordering\uff1adim_ordering\uff1a\u2018th\u2019\u6216\u2018tf\u2019\u3002\u2018th\u2019\u6a21\u5f0f\u4e2d\u901a\u9053\u7ef4\uff08\u5982\u5f69\u8272\u56fe\u50cf\u76843\u901a\u9053\uff09\u4f4d\u4e8e\u7b2c1\u4e2a\u4f4d\u7f6e\uff08\u7ef4\u5ea6\u4ece0\u5f00\u59cb\u7b97\uff09\uff0c\u800c\u5728\u2018tf\u2019\u6a21\u5f0f\u4e2d\uff0c\u901a\u9053\u7ef4\u4f4d\u4e8e\u7b2c4\u4e2a\u4f4d\u7f6e\u3002\u9ed8\u8ba4\u662f\nimage_dim_ordering\n\u6307\u5b9a\u7684\u6a21\u5f0f\uff0c\u53ef\u5728\n~/.keras/keras.json\n\u4e2d\u67e5\u770b\uff0c\u82e5\u6ca1\u6709\u8bbe\u7f6e\u8fc7\u5219\u4e3a'tf'\u3002\n\n\n\n\n\n\n\u8f93\u5165shape\n\n\n\u2018th\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples, channels, len_pool_dim1, len_pool_dim2, len_pool_dim3\uff09\u76845D\u5f20\u91cf\n\n\n\u2018tf\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples, len_pool_dim1, len_pool_dim2, len_pool_dim3\uff0cchannels, \uff09\u76845D\u5f20\u91cf\n\n\n\u8f93\u51fashape\n\n\n\u2018th\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples, channels, pooled_dim1, pooled_dim2, pooled_dim3\uff09\u76845D\u5f20\u91cf\n\n\n\u2018tf\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples, pooled_dim1, pooled_dim2, pooled_dim3,channels,\uff09\u76845D\u5f20\u91cf\n\n\n\n\nGlobalMaxPooling1D\u5c42\n\n\nkeras.layers.pooling.GlobalMaxPooling1D()\n\n\n\n\n\u5bf9\u4e8e\u65f6\u95f4\u4fe1\u53f7\u7684\u5168\u5c40\u6700\u5927\u6c60\u5316\n\n\n\u8f93\u5165shape\n\n\n\n\n\u5f62\u5982\uff08samples\uff0csteps\uff0cfeatures\uff09\u76843D\u5f20\u91cf\n\n\n\n\n\u8f93\u51fashape\n\n\n\n\n\u5f62\u5982(samples, features)\u76842D\u5f20\u91cf\n\n\n\n\n\n\nGlobalAveragePooling1D\u5c42\n\n\nkeras.layers.pooling.GlobalAveragePooling1D()\n\n\n\n\n\u4e3a\u65f6\u57df\u4fe1\u53f7\u65bd\u52a0\u5168\u5c40\u5e73\u5747\u503c\u6c60\u5316\n\n\n\u8f93\u5165shape\n\n\n\n\n\u5f62\u5982\uff08samples\uff0csteps\uff0cfeatures\uff09\u76843D\u5f20\u91cf\n\n\n\n\n\u8f93\u51fashape\n\n\n\n\n\u5f62\u5982(samples, features)\u76842D\u5f20\u91cf\n\n\n\n\n\n\nGlobalMaxPooling2D\u5c42\n\n\nkeras.layers.pooling.GlobalMaxPooling2D(dim_ordering='default')\n\n\n\n\n\u4e3a\u7a7a\u57df\u4fe1\u53f7\u65bd\u52a0\u5168\u5c40\u6700\u5927\u503c\u6c60\u5316\n\n\n\u53c2\u6570\n\n\n\n\ndim_ordering\uff1a\u2018th\u2019\u6216\u2018tf\u2019\u3002\u2018th\u2019\u6a21\u5f0f\u4e2d\u901a\u9053\u7ef4\uff08\u5982\u5f69\u8272\u56fe\u50cf\u76843\u901a\u9053\uff09\u4f4d\u4e8e\u7b2c1\u4e2a\u4f4d\u7f6e\uff08\u7ef4\u5ea6\u4ece0\u5f00\u59cb\u7b97\uff09\uff0c\u800c\u5728\u2018tf\u2019\u6a21\u5f0f\u4e2d\uff0c\u901a\u9053\u7ef4\u4f4d\u4e8e\u7b2c3\u4e2a\u4f4d\u7f6e\u3002\u4f8b\u5982128*128\u7684\u4e09\u901a\u9053\u5f69\u8272\u56fe\u7247\uff0c\u5728\u2018th\u2019\u6a21\u5f0f\u4e2d\ninput_shape\n\u5e94\u5199\u4e3a\uff083\uff0c128\uff0c128\uff09\uff0c\u800c\u5728\u2018tf\u2019\u6a21\u5f0f\u4e2d\u5e94\u5199\u4e3a\uff08128\uff0c128\uff0c3\uff09\uff0c\u6ce8\u610f\u8fd9\u91cc3\u51fa\u73b0\u5728\u7b2c0\u4e2a\u4f4d\u7f6e\uff0c\u56e0\u4e3a\ninput_shape\n\u4e0d\u5305\u542b\u6837\u672c\u6570\u7684\u7ef4\u5ea6\uff0c\u5728\u5176\u5185\u90e8\u5b9e\u73b0\u4e2d\uff0c\u5b9e\u9645\u4e0a\u662f\uff08None\uff0c3\uff0c128\uff0c128\uff09\u548c\uff08None\uff0c128\uff0c128\uff0c3\uff09\u3002\u9ed8\u8ba4\u662f\nimage_dim_ordering\n\u6307\u5b9a\u7684\u6a21\u5f0f\uff0c\u53ef\u5728\n~/.keras/keras.json\n\u4e2d\u67e5\u770b\uff0c\u82e5\u6ca1\u6709\u8bbe\u7f6e\u8fc7\u5219\u4e3a'tf'\u3002\n\n\n\n\n\u8f93\u5165shape\n\n\n\u2018th\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples\uff0cchannels, rows\uff0ccols\uff09\u76844D\u5f20\u91cf\n\n\n\u2018tf\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples\uff0crows, cols\uff0cchannels\uff09\u76844D\u5f20\u91cf\n\n\n\u8f93\u51fashape\n\n\n\u5f62\u5982(nb_samples, channels)\u76842D\u5f20\u91cf\n\n\n\n\nGlobalAveragePooling2D\u5c42\n\n\nkeras.layers.pooling.GlobalAveragePooling2D(dim_ordering='default')\n\n\n\n\n\u4e3a\u7a7a\u57df\u4fe1\u53f7\u65bd\u52a0\u5168\u5c40\u5e73\u5747\u503c\u6c60\u5316\n\n\n\u53c2\u6570\n\n\n\n\ndim_ordering\uff1a\u2018th\u2019\u6216\u2018tf\u2019\u3002\u2018th\u2019\u6a21\u5f0f\u4e2d\u901a\u9053\u7ef4\uff08\u5982\u5f69\u8272\u56fe\u50cf\u76843\u901a\u9053\uff09\u4f4d\u4e8e\u7b2c1\u4e2a\u4f4d\u7f6e\uff08\u7ef4\u5ea6\u4ece0\u5f00\u59cb\u7b97\uff09\uff0c\u800c\u5728\u2018tf\u2019\u6a21\u5f0f\u4e2d\uff0c\u901a\u9053\u7ef4\u4f4d\u4e8e\u7b2c3\u4e2a\u4f4d\u7f6e\u3002\u4f8b\u5982128*128\u7684\u4e09\u901a\u9053\u5f69\u8272\u56fe\u7247\uff0c\u5728\u2018th\u2019\u6a21\u5f0f\u4e2d\ninput_shape\n\u5e94\u5199\u4e3a\uff083\uff0c128\uff0c128\uff09\uff0c\u800c\u5728\u2018tf\u2019\u6a21\u5f0f\u4e2d\u5e94\u5199\u4e3a\uff08128\uff0c128\uff0c3\uff09\uff0c\u6ce8\u610f\u8fd9\u91cc3\u51fa\u73b0\u5728\u7b2c0\u4e2a\u4f4d\u7f6e\uff0c\u56e0\u4e3a\ninput_shape\n\u4e0d\u5305\u542b\u6837\u672c\u6570\u7684\u7ef4\u5ea6\uff0c\u5728\u5176\u5185\u90e8\u5b9e\u73b0\u4e2d\uff0c\u5b9e\u9645\u4e0a\u662f\uff08None\uff0c3\uff0c128\uff0c128\uff09\u548c\uff08None\uff0c128\uff0c128\uff0c3\uff09\u3002\u9ed8\u8ba4\u662f\nimage_dim_ordering\n\u6307\u5b9a\u7684\u6a21\u5f0f\uff0c\u53ef\u5728\n~/.keras/keras.json\n\u4e2d\u67e5\u770b\uff0c\u82e5\u6ca1\u6709\u8bbe\u7f6e\u8fc7\u5219\u4e3a'tf'\u3002\n\n\n\n\n\u8f93\u5165shape\n\n\n\u2018th\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples\uff0cchannels, rows\uff0ccols\uff09\u76844D\u5f20\u91cf\n\n\n\u2018tf\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples\uff0crows, cols\uff0cchannels\uff09\u76844D\u5f20\u91cf\n\n\n\u8f93\u51fashape\n\n\n\u5f62\u5982(nb_samples, channels)\u76842D\u5f20\u91cf", 
            "title": "\u6c60\u5316\u5c42Pooling"
        }, 
        {
            "location": "/layers/pooling_layer/#_1", 
            "text": "", 
            "title": "\u6c60\u5316\u5c42"
        }, 
        {
            "location": "/layers/pooling_layer/#maxpooling1d", 
            "text": "keras.layers.convolutional.MaxPooling1D(pool_length=2, stride=None, border_mode='valid')  \u5bf9\u65f6\u57df1D\u4fe1\u53f7\u8fdb\u884c\u6700\u5927\u503c\u6c60\u5316", 
            "title": "MaxPooling1D\u5c42"
        }, 
        {
            "location": "/layers/pooling_layer/#_2", 
            "text": "pool_length\uff1a\u4e0b\u91c7\u6837\u56e0\u5b50\uff0c\u5982\u53d62\u5219\u5c06\u8f93\u5165\u4e0b\u91c7\u6837\u5230\u4e00\u534a\u957f\u5ea6    stride\uff1a\u6574\u6570\u6216None\uff0c\u6b65\u957f\u503c    border_mode\uff1a\u2018valid\u2019\u6216\u8005\u2018same\u2019", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/layers/pooling_layer/#shape", 
            "text": "\u5f62\u5982\uff08samples\uff0csteps\uff0cfeatures\uff09\u76843D\u5f20\u91cf", 
            "title": "\u8f93\u5165shape"
        }, 
        {
            "location": "/layers/pooling_layer/#shape_1", 
            "text": "\u5f62\u5982\uff08samples\uff0cdownsampled_steps\uff0cfeatures\uff09\u76843D\u5f20\u91cf", 
            "title": "\u8f93\u51fashape"
        }, 
        {
            "location": "/layers/pooling_layer/#maxpooling2d", 
            "text": "keras.layers.convolutional.MaxPooling2D(pool_size=(2, 2), strides=None, border_mode='valid', dim_ordering='th')  \u4e3a\u7a7a\u57df\u4fe1\u53f7\u65bd\u52a0\u6700\u5927\u503c\u6c60\u5316", 
            "title": "MaxPooling2D\u5c42"
        }, 
        {
            "location": "/layers/pooling_layer/#_3", 
            "text": "pool_size\uff1a\u957f\u4e3a2\u7684\u6574\u6570tuple\uff0c\u4ee3\u8868\u5728\u4e24\u4e2a\u65b9\u5411\uff08\u7ad6\u76f4\uff0c\u6c34\u5e73\uff09\u4e0a\u7684\u4e0b\u91c7\u6837\u56e0\u5b50\uff0c\u5982\u53d6\uff082\uff0c2\uff09\u5c06\u4f7f\u56fe\u7247\u5728\u4e24\u4e2a\u7ef4\u5ea6\u4e0a\u5747\u53d8\u4e3a\u539f\u957f\u7684\u4e00\u534a    strides\uff1a\u957f\u4e3a2\u7684\u6574\u6570tuple\uff0c\u6216\u8005None\uff0c\u6b65\u957f\u503c\u3002    border_mode\uff1a\u2018valid\u2019\u6216\u8005\u2018same\u2019    dim_ordering\uff1a\u2018th\u2019\u6216\u2018tf\u2019\u3002\u2018th\u2019\u6a21\u5f0f\u4e2d\u901a\u9053\u7ef4\uff08\u5982\u5f69\u8272\u56fe\u50cf\u76843\u901a\u9053\uff09\u4f4d\u4e8e\u7b2c1\u4e2a\u4f4d\u7f6e\uff08\u7ef4\u5ea6\u4ece0\u5f00\u59cb\u7b97\uff09\uff0c\u800c\u5728\u2018tf\u2019\u6a21\u5f0f\u4e2d\uff0c\u901a\u9053\u7ef4\u4f4d\u4e8e\u7b2c3\u4e2a\u4f4d\u7f6e\u3002\u4f8b\u5982128*128\u7684\u4e09\u901a\u9053\u5f69\u8272\u56fe\u7247\uff0c\u5728\u2018th\u2019\u6a21\u5f0f\u4e2d input_shape \u5e94\u5199\u4e3a\uff083\uff0c128\uff0c128\uff09\uff0c\u800c\u5728\u2018tf\u2019\u6a21\u5f0f\u4e2d\u5e94\u5199\u4e3a\uff08128\uff0c128\uff0c3\uff09\uff0c\u6ce8\u610f\u8fd9\u91cc3\u51fa\u73b0\u5728\u7b2c0\u4e2a\u4f4d\u7f6e\uff0c\u56e0\u4e3a input_shape \u4e0d\u5305\u542b\u6837\u672c\u6570\u7684\u7ef4\u5ea6\uff0c\u5728\u5176\u5185\u90e8\u5b9e\u73b0\u4e2d\uff0c\u5b9e\u9645\u4e0a\u662f\uff08None\uff0c3\uff0c128\uff0c128\uff09\u548c\uff08None\uff0c128\uff0c128\uff0c3\uff09\u3002\u9ed8\u8ba4\u662f image_dim_ordering \u6307\u5b9a\u7684\u6a21\u5f0f\uff0c\u53ef\u5728 ~/.keras/keras.json \u4e2d\u67e5\u770b\uff0c\u82e5\u6ca1\u6709\u8bbe\u7f6e\u8fc7\u5219\u4e3a'tf'\u3002", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/layers/pooling_layer/#shape_2", 
            "text": "\u2018th\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples\uff0cchannels, rows\uff0ccols\uff09\u76844D\u5f20\u91cf  \u2018tf\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples\uff0crows, cols\uff0cchannels\uff09\u76844D\u5f20\u91cf", 
            "title": "\u8f93\u5165shape"
        }, 
        {
            "location": "/layers/pooling_layer/#shape_3", 
            "text": "\u2018th\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples\uff0cchannels, pooled_rows, pooled_cols\uff09\u76844D\u5f20\u91cf  \u2018tf\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples\uff0cpooled_rows, pooled_cols\uff0cchannels\uff09\u76844D\u5f20\u91cf", 
            "title": "\u8f93\u51fashape"
        }, 
        {
            "location": "/layers/pooling_layer/#maxpooling3d", 
            "text": "keras.layers.convolutional.MaxPooling3D(pool_size=(2, 2, 2), strides=None, border_mode='valid', dim_ordering='th')  \u4e3a3D\u4fe1\u53f7\uff08\u7a7a\u57df\u6216\u65f6\u7a7a\u57df\uff09\u65bd\u52a0\u6700\u5927\u503c\u6c60\u5316  \u672c\u5c42\u76ee\u524d\u53ea\u80fd\u5728\u4f7f\u7528Theano\u4e3a\u540e\u7aef\u65f6\u53ef\u7528", 
            "title": "MaxPooling3D\u5c42"
        }, 
        {
            "location": "/layers/pooling_layer/#_4", 
            "text": "pool_size\uff1a\u957f\u4e3a3\u7684\u6574\u6570tuple\uff0c\u4ee3\u8868\u5728\u4e09\u4e2a\u7ef4\u5ea6\u4e0a\u7684\u4e0b\u91c7\u6837\u56e0\u5b50\uff0c\u5982\u53d6\uff082\uff0c2\uff0c2\uff09\u5c06\u4f7f\u4fe1\u53f7\u5728\u6bcf\u4e2a\u7ef4\u5ea6\u90fd\u53d8\u4e3a\u539f\u6765\u7684\u4e00\u534a\u957f\u3002    strides\uff1a\u957f\u4e3a3\u7684\u6574\u6570tuple\uff0c\u6216\u8005None\uff0c\u6b65\u957f\u503c\u3002    border_mode\uff1a\u2018valid\u2019\u6216\u8005\u2018same\u2019    dim_ordering\uff1a\u2018th\u2019\u6216\u2018tf\u2019\u3002\u2018th\u2019\u6a21\u5f0f\u4e2d\u901a\u9053\u7ef4\uff08\u5982\u5f69\u8272\u56fe\u50cf\u76843\u901a\u9053\uff09\u4f4d\u4e8e\u7b2c1\u4e2a\u4f4d\u7f6e\uff08\u7ef4\u5ea6\u4ece0\u5f00\u59cb\u7b97\uff09\uff0c\u800c\u5728\u2018tf\u2019\u6a21\u5f0f\u4e2d\uff0c\u901a\u9053\u7ef4\u4f4d\u4e8e\u7b2c4\u4e2a\u4f4d\u7f6e\u3002\u9ed8\u8ba4\u662f image_dim_ordering \u6307\u5b9a\u7684\u6a21\u5f0f\uff0c\u53ef\u5728 ~/.keras/keras.json \u4e2d\u67e5\u770b\uff0c\u82e5\u6ca1\u6709\u8bbe\u7f6e\u8fc7\u5219\u4e3a'tf'\u3002", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/layers/pooling_layer/#shape_4", 
            "text": "\u2018th\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples, channels, len_pool_dim1, len_pool_dim2, len_pool_dim3\uff09\u76845D\u5f20\u91cf  \u2018tf\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples, len_pool_dim1, len_pool_dim2, len_pool_dim3\uff0cchannels, \uff09\u76845D\u5f20\u91cf", 
            "title": "\u8f93\u5165shape"
        }, 
        {
            "location": "/layers/pooling_layer/#shape_5", 
            "text": "\u2018th\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples, channels, pooled_dim1, pooled_dim2, pooled_dim3\uff09\u76845D\u5f20\u91cf  \u2018tf\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples, pooled_dim1, pooled_dim2, pooled_dim3,channels,\uff09\u76845D\u5f20\u91cf", 
            "title": "\u8f93\u51fashape"
        }, 
        {
            "location": "/layers/pooling_layer/#averagepooling1d", 
            "text": "keras.layers.convolutional.AveragePooling1D(pool_length=2, stride=None, border_mode='valid')  \u5bf9\u65f6\u57df1D\u4fe1\u53f7\u8fdb\u884c\u5e73\u5747\u503c\u6c60\u5316", 
            "title": "AveragePooling1D\u5c42"
        }, 
        {
            "location": "/layers/pooling_layer/#_5", 
            "text": "pool_length\uff1a\u4e0b\u91c7\u6837\u56e0\u5b50\uff0c\u5982\u53d62\u5219\u5c06\u8f93\u5165\u4e0b\u91c7\u6837\u5230\u4e00\u534a\u957f\u5ea6    stride\uff1a\u6574\u6570\u6216None\uff0c\u6b65\u957f\u503c    border_mode\uff1a\u2018valid\u2019\u6216\u8005\u2018same\u2019   \u6ce8\u610f\uff0c\u76ee\u524d\u2018same\u2019\u6a21\u5f0f\u53ea\u80fd\u5728TensorFlow\u4f5c\u4e3a\u540e\u7aef\u65f6\u4f7f\u7528", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/layers/pooling_layer/#shape_6", 
            "text": "\u5f62\u5982\uff08samples\uff0csteps\uff0cfeatures\uff09\u76843D\u5f20\u91cf", 
            "title": "\u8f93\u5165shape"
        }, 
        {
            "location": "/layers/pooling_layer/#shape_7", 
            "text": "\u5f62\u5982\uff08samples\uff0cdownsampled_steps\uff0cfeatures\uff09\u76843D\u5f20\u91cf", 
            "title": "\u8f93\u51fashape"
        }, 
        {
            "location": "/layers/pooling_layer/#averagepooling2d", 
            "text": "keras.layers.convolutional.AveragePooling2D(pool_size=(2, 2), strides=None, border_mode='valid', dim_ordering='th')  \u4e3a\u7a7a\u57df\u4fe1\u53f7\u65bd\u52a0\u5e73\u5747\u503c\u6c60\u5316", 
            "title": "AveragePooling2D\u5c42"
        }, 
        {
            "location": "/layers/pooling_layer/#_6", 
            "text": "pool_size\uff1a\u957f\u4e3a2\u7684\u6574\u6570tuple\uff0c\u4ee3\u8868\u5728\u4e24\u4e2a\u65b9\u5411\uff08\u7ad6\u76f4\uff0c\u6c34\u5e73\uff09\u4e0a\u7684\u4e0b\u91c7\u6837\u56e0\u5b50\uff0c\u5982\u53d6\uff082\uff0c2\uff09\u5c06\u4f7f\u56fe\u7247\u5728\u4e24\u4e2a\u7ef4\u5ea6\u4e0a\u5747\u53d8\u4e3a\u539f\u957f\u7684\u4e00\u534a    strides\uff1a\u957f\u4e3a2\u7684\u6574\u6570tuple\uff0c\u6216\u8005None\uff0c\u6b65\u957f\u503c\u3002    border_mode\uff1a\u2018valid\u2019\u6216\u8005\u2018same\u2019    dim_ordering\uff1a\u2018th\u2019\u6216\u2018tf\u2019\u3002\u2018th\u2019\u6a21\u5f0f\u4e2d\u901a\u9053\u7ef4\uff08\u5982\u5f69\u8272\u56fe\u50cf\u76843\u901a\u9053\uff09\u4f4d\u4e8e\u7b2c1\u4e2a\u4f4d\u7f6e\uff08\u7ef4\u5ea6\u4ece0\u5f00\u59cb\u7b97\uff09\uff0c\u800c\u5728\u2018tf\u2019\u6a21\u5f0f\u4e2d\uff0c\u901a\u9053\u7ef4\u4f4d\u4e8e\u7b2c3\u4e2a\u4f4d\u7f6e\u3002\u4f8b\u5982128*128\u7684\u4e09\u901a\u9053\u5f69\u8272\u56fe\u7247\uff0c\u5728\u2018th\u2019\u6a21\u5f0f\u4e2d input_shape \u5e94\u5199\u4e3a\uff083\uff0c128\uff0c128\uff09\uff0c\u800c\u5728\u2018tf\u2019\u6a21\u5f0f\u4e2d\u5e94\u5199\u4e3a\uff08128\uff0c128\uff0c3\uff09\uff0c\u6ce8\u610f\u8fd9\u91cc3\u51fa\u73b0\u5728\u7b2c0\u4e2a\u4f4d\u7f6e\uff0c\u56e0\u4e3a input_shape \u4e0d\u5305\u542b\u6837\u672c\u6570\u7684\u7ef4\u5ea6\uff0c\u5728\u5176\u5185\u90e8\u5b9e\u73b0\u4e2d\uff0c\u5b9e\u9645\u4e0a\u662f\uff08None\uff0c3\uff0c128\uff0c128\uff09\u548c\uff08None\uff0c128\uff0c128\uff0c3\uff09\u3002\u9ed8\u8ba4\u662f image_dim_ordering \u6307\u5b9a\u7684\u6a21\u5f0f\uff0c\u53ef\u5728 ~/.keras/keras.json \u4e2d\u67e5\u770b\uff0c\u82e5\u6ca1\u6709\u8bbe\u7f6e\u8fc7\u5219\u4e3a'tf'\u3002", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/layers/pooling_layer/#shape_8", 
            "text": "\u2018th\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples\uff0cchannels, rows\uff0ccols\uff09\u76844D\u5f20\u91cf  \u2018tf\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples\uff0crows, cols\uff0cchannels\uff09\u76844D\u5f20\u91cf", 
            "title": "\u8f93\u5165shape"
        }, 
        {
            "location": "/layers/pooling_layer/#shape_9", 
            "text": "\u2018th\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples\uff0cchannels, pooled_rows, pooled_cols\uff09\u76844D\u5f20\u91cf  \u2018tf\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples\uff0cpooled_rows, pooled_cols\uff0cchannels\uff09\u76844D\u5f20\u91cf", 
            "title": "\u8f93\u51fashape"
        }, 
        {
            "location": "/layers/pooling_layer/#averagepooling3d", 
            "text": "keras.layers.convolutional.AveragePooling3D(pool_size=(2, 2, 2), strides=None, border_mode='valid', dim_ordering='th')  \u4e3a3D\u4fe1\u53f7\uff08\u7a7a\u57df\u6216\u65f6\u7a7a\u57df\uff09\u65bd\u52a0\u5e73\u5747\u503c\u6c60\u5316  \u672c\u5c42\u76ee\u524d\u53ea\u80fd\u5728\u4f7f\u7528Theano\u4e3a\u540e\u7aef\u65f6\u53ef\u7528", 
            "title": "AveragePooling3D\u5c42"
        }, 
        {
            "location": "/layers/pooling_layer/#_7", 
            "text": "pool_size\uff1a\u957f\u4e3a3\u7684\u6574\u6570tuple\uff0c\u4ee3\u8868\u5728\u4e09\u4e2a\u7ef4\u5ea6\u4e0a\u7684\u4e0b\u91c7\u6837\u56e0\u5b50\uff0c\u5982\u53d6\uff082\uff0c2\uff0c2\uff09\u5c06\u4f7f\u4fe1\u53f7\u5728\u6bcf\u4e2a\u7ef4\u5ea6\u90fd\u53d8\u4e3a\u539f\u6765\u7684\u4e00\u534a\u957f\u3002    strides\uff1a\u957f\u4e3a3\u7684\u6574\u6570tuple\uff0c\u6216\u8005None\uff0c\u6b65\u957f\u503c\u3002    border_mode\uff1a\u2018valid\u2019\u6216\u8005\u2018same\u2019    dim_ordering\uff1adim_ordering\uff1a\u2018th\u2019\u6216\u2018tf\u2019\u3002\u2018th\u2019\u6a21\u5f0f\u4e2d\u901a\u9053\u7ef4\uff08\u5982\u5f69\u8272\u56fe\u50cf\u76843\u901a\u9053\uff09\u4f4d\u4e8e\u7b2c1\u4e2a\u4f4d\u7f6e\uff08\u7ef4\u5ea6\u4ece0\u5f00\u59cb\u7b97\uff09\uff0c\u800c\u5728\u2018tf\u2019\u6a21\u5f0f\u4e2d\uff0c\u901a\u9053\u7ef4\u4f4d\u4e8e\u7b2c4\u4e2a\u4f4d\u7f6e\u3002\u9ed8\u8ba4\u662f image_dim_ordering \u6307\u5b9a\u7684\u6a21\u5f0f\uff0c\u53ef\u5728 ~/.keras/keras.json \u4e2d\u67e5\u770b\uff0c\u82e5\u6ca1\u6709\u8bbe\u7f6e\u8fc7\u5219\u4e3a'tf'\u3002", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/layers/pooling_layer/#shape_10", 
            "text": "\u2018th\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples, channels, len_pool_dim1, len_pool_dim2, len_pool_dim3\uff09\u76845D\u5f20\u91cf  \u2018tf\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples, len_pool_dim1, len_pool_dim2, len_pool_dim3\uff0cchannels, \uff09\u76845D\u5f20\u91cf", 
            "title": "\u8f93\u5165shape"
        }, 
        {
            "location": "/layers/pooling_layer/#shape_11", 
            "text": "\u2018th\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples, channels, pooled_dim1, pooled_dim2, pooled_dim3\uff09\u76845D\u5f20\u91cf  \u2018tf\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples, pooled_dim1, pooled_dim2, pooled_dim3,channels,\uff09\u76845D\u5f20\u91cf", 
            "title": "\u8f93\u51fashape"
        }, 
        {
            "location": "/layers/pooling_layer/#globalmaxpooling1d", 
            "text": "keras.layers.pooling.GlobalMaxPooling1D()  \u5bf9\u4e8e\u65f6\u95f4\u4fe1\u53f7\u7684\u5168\u5c40\u6700\u5927\u6c60\u5316", 
            "title": "GlobalMaxPooling1D\u5c42"
        }, 
        {
            "location": "/layers/pooling_layer/#shape_12", 
            "text": "\u5f62\u5982\uff08samples\uff0csteps\uff0cfeatures\uff09\u76843D\u5f20\u91cf", 
            "title": "\u8f93\u5165shape"
        }, 
        {
            "location": "/layers/pooling_layer/#shape_13", 
            "text": "\u5f62\u5982(samples, features)\u76842D\u5f20\u91cf", 
            "title": "\u8f93\u51fashape"
        }, 
        {
            "location": "/layers/pooling_layer/#globalaveragepooling1d", 
            "text": "keras.layers.pooling.GlobalAveragePooling1D()  \u4e3a\u65f6\u57df\u4fe1\u53f7\u65bd\u52a0\u5168\u5c40\u5e73\u5747\u503c\u6c60\u5316", 
            "title": "GlobalAveragePooling1D\u5c42"
        }, 
        {
            "location": "/layers/pooling_layer/#shape_14", 
            "text": "\u5f62\u5982\uff08samples\uff0csteps\uff0cfeatures\uff09\u76843D\u5f20\u91cf", 
            "title": "\u8f93\u5165shape"
        }, 
        {
            "location": "/layers/pooling_layer/#shape_15", 
            "text": "\u5f62\u5982(samples, features)\u76842D\u5f20\u91cf", 
            "title": "\u8f93\u51fashape"
        }, 
        {
            "location": "/layers/pooling_layer/#globalmaxpooling2d", 
            "text": "keras.layers.pooling.GlobalMaxPooling2D(dim_ordering='default')  \u4e3a\u7a7a\u57df\u4fe1\u53f7\u65bd\u52a0\u5168\u5c40\u6700\u5927\u503c\u6c60\u5316", 
            "title": "GlobalMaxPooling2D\u5c42"
        }, 
        {
            "location": "/layers/pooling_layer/#_8", 
            "text": "dim_ordering\uff1a\u2018th\u2019\u6216\u2018tf\u2019\u3002\u2018th\u2019\u6a21\u5f0f\u4e2d\u901a\u9053\u7ef4\uff08\u5982\u5f69\u8272\u56fe\u50cf\u76843\u901a\u9053\uff09\u4f4d\u4e8e\u7b2c1\u4e2a\u4f4d\u7f6e\uff08\u7ef4\u5ea6\u4ece0\u5f00\u59cb\u7b97\uff09\uff0c\u800c\u5728\u2018tf\u2019\u6a21\u5f0f\u4e2d\uff0c\u901a\u9053\u7ef4\u4f4d\u4e8e\u7b2c3\u4e2a\u4f4d\u7f6e\u3002\u4f8b\u5982128*128\u7684\u4e09\u901a\u9053\u5f69\u8272\u56fe\u7247\uff0c\u5728\u2018th\u2019\u6a21\u5f0f\u4e2d input_shape \u5e94\u5199\u4e3a\uff083\uff0c128\uff0c128\uff09\uff0c\u800c\u5728\u2018tf\u2019\u6a21\u5f0f\u4e2d\u5e94\u5199\u4e3a\uff08128\uff0c128\uff0c3\uff09\uff0c\u6ce8\u610f\u8fd9\u91cc3\u51fa\u73b0\u5728\u7b2c0\u4e2a\u4f4d\u7f6e\uff0c\u56e0\u4e3a input_shape \u4e0d\u5305\u542b\u6837\u672c\u6570\u7684\u7ef4\u5ea6\uff0c\u5728\u5176\u5185\u90e8\u5b9e\u73b0\u4e2d\uff0c\u5b9e\u9645\u4e0a\u662f\uff08None\uff0c3\uff0c128\uff0c128\uff09\u548c\uff08None\uff0c128\uff0c128\uff0c3\uff09\u3002\u9ed8\u8ba4\u662f image_dim_ordering \u6307\u5b9a\u7684\u6a21\u5f0f\uff0c\u53ef\u5728 ~/.keras/keras.json \u4e2d\u67e5\u770b\uff0c\u82e5\u6ca1\u6709\u8bbe\u7f6e\u8fc7\u5219\u4e3a'tf'\u3002", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/layers/pooling_layer/#shape_16", 
            "text": "\u2018th\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples\uff0cchannels, rows\uff0ccols\uff09\u76844D\u5f20\u91cf  \u2018tf\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples\uff0crows, cols\uff0cchannels\uff09\u76844D\u5f20\u91cf", 
            "title": "\u8f93\u5165shape"
        }, 
        {
            "location": "/layers/pooling_layer/#shape_17", 
            "text": "\u5f62\u5982(nb_samples, channels)\u76842D\u5f20\u91cf", 
            "title": "\u8f93\u51fashape"
        }, 
        {
            "location": "/layers/pooling_layer/#globalaveragepooling2d", 
            "text": "keras.layers.pooling.GlobalAveragePooling2D(dim_ordering='default')  \u4e3a\u7a7a\u57df\u4fe1\u53f7\u65bd\u52a0\u5168\u5c40\u5e73\u5747\u503c\u6c60\u5316", 
            "title": "GlobalAveragePooling2D\u5c42"
        }, 
        {
            "location": "/layers/pooling_layer/#_9", 
            "text": "dim_ordering\uff1a\u2018th\u2019\u6216\u2018tf\u2019\u3002\u2018th\u2019\u6a21\u5f0f\u4e2d\u901a\u9053\u7ef4\uff08\u5982\u5f69\u8272\u56fe\u50cf\u76843\u901a\u9053\uff09\u4f4d\u4e8e\u7b2c1\u4e2a\u4f4d\u7f6e\uff08\u7ef4\u5ea6\u4ece0\u5f00\u59cb\u7b97\uff09\uff0c\u800c\u5728\u2018tf\u2019\u6a21\u5f0f\u4e2d\uff0c\u901a\u9053\u7ef4\u4f4d\u4e8e\u7b2c3\u4e2a\u4f4d\u7f6e\u3002\u4f8b\u5982128*128\u7684\u4e09\u901a\u9053\u5f69\u8272\u56fe\u7247\uff0c\u5728\u2018th\u2019\u6a21\u5f0f\u4e2d input_shape \u5e94\u5199\u4e3a\uff083\uff0c128\uff0c128\uff09\uff0c\u800c\u5728\u2018tf\u2019\u6a21\u5f0f\u4e2d\u5e94\u5199\u4e3a\uff08128\uff0c128\uff0c3\uff09\uff0c\u6ce8\u610f\u8fd9\u91cc3\u51fa\u73b0\u5728\u7b2c0\u4e2a\u4f4d\u7f6e\uff0c\u56e0\u4e3a input_shape \u4e0d\u5305\u542b\u6837\u672c\u6570\u7684\u7ef4\u5ea6\uff0c\u5728\u5176\u5185\u90e8\u5b9e\u73b0\u4e2d\uff0c\u5b9e\u9645\u4e0a\u662f\uff08None\uff0c3\uff0c128\uff0c128\uff09\u548c\uff08None\uff0c128\uff0c128\uff0c3\uff09\u3002\u9ed8\u8ba4\u662f image_dim_ordering \u6307\u5b9a\u7684\u6a21\u5f0f\uff0c\u53ef\u5728 ~/.keras/keras.json \u4e2d\u67e5\u770b\uff0c\u82e5\u6ca1\u6709\u8bbe\u7f6e\u8fc7\u5219\u4e3a'tf'\u3002", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/layers/pooling_layer/#shape_18", 
            "text": "\u2018th\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples\uff0cchannels, rows\uff0ccols\uff09\u76844D\u5f20\u91cf  \u2018tf\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples\uff0crows, cols\uff0cchannels\uff09\u76844D\u5f20\u91cf", 
            "title": "\u8f93\u5165shape"
        }, 
        {
            "location": "/layers/pooling_layer/#shape_19", 
            "text": "\u5f62\u5982(nb_samples, channels)\u76842D\u5f20\u91cf", 
            "title": "\u8f93\u51fashape"
        }, 
        {
            "location": "/layers/locally_connected_layer/", 
            "text": "\u5c40\u90e8\u8fde\u63a5\u5c42LocallyConnceted\n\n\nLocallyConnected1D\u5c42\n\n\nkeras.layers.local.LocallyConnected1D(nb_filter, filter_length, init='uniform', activation='linear', weights=None, border_mode='valid', subsample_length=1, W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None, bias=True, input_dim=None, input_length=None)\n\n\n\n\nLocallyConnected1D\n\u5c42\u4e0e\nConvolution1D\n\u5de5\u4f5c\u65b9\u5f0f\u7c7b\u4f3c\uff0c\u552f\u4e00\u7684\u533a\u522b\u662f\u4e0d\u8fdb\u884c\u6743\u503c\u5171\u4eab\u3002\u5373\u65bd\u52a0\u5728\u4e0d\u540c\u8f93\u5165patch\u7684\u6ee4\u6ce2\u5668\u662f\u4e0d\u4e00\u6837\u7684\uff0c\u5f53\u4f7f\u7528\u8be5\u5c42\u4f5c\u4e3a\u6a21\u578b\u9996\u5c42\u65f6\uff0c\u9700\u8981\u63d0\u4f9b\u53c2\u6570\ninput_dim\n\u6216\ninput_shape\n\u53c2\u6570\u3002\u53c2\u6570\u542b\u4e49\u53c2\u8003\nConvolution1D\n\u3002\u6ce8\u610f\u8be5\u5c42\u7684\ninput_shape\n\u5fc5\u987b\u5b8c\u5168\u6307\u5b9a\uff0c\u4e0d\u652f\u6301\nNone\n\n\n\u53c2\u6570\n\n\n\n\n\n\nnb_filter\uff1a\u5377\u79ef\u6838\u7684\u6570\u76ee\uff08\u5373\u8f93\u51fa\u7684\u7ef4\u5ea6\uff09\n\n\n\n\n\n\nfilter_length\uff1a\u5377\u79ef\u6838\u7684\u7a7a\u57df\u6216\u65f6\u57df\u957f\u5ea6\n\n\n\n\n\n\ninit\uff1a\u521d\u59cb\u5316\u65b9\u6cd5\uff0c\u4e3a\u9884\u5b9a\u4e49\u521d\u59cb\u5316\u65b9\u6cd5\u540d\u7684\u5b57\u7b26\u4e32\uff0c\u6216\u7528\u4e8e\u521d\u59cb\u5316\u6743\u91cd\u7684Theano\u51fd\u6570\u3002\u8be5\u53c2\u6570\u4ec5\u5728\u4e0d\u4f20\u9012\nweights\n\u53c2\u6570\u65f6\u6709\u610f\u4e49\u3002\n\n\n\n\n\n\nactivation\uff1a\u6fc0\u6d3b\u51fd\u6570\uff0c\u4e3a\u9884\u5b9a\u4e49\u7684\u6fc0\u6d3b\u51fd\u6570\u540d\uff08\u53c2\u8003\n\u6fc0\u6d3b\u51fd\u6570\n\uff09\uff0c\u6216\u9010\u5143\u7d20\uff08element-wise\uff09\u7684Theano\u51fd\u6570\u3002\u5982\u679c\u4e0d\u6307\u5b9a\u8be5\u53c2\u6570\uff0c\u5c06\u4e0d\u4f1a\u4f7f\u7528\u4efb\u4f55\u6fc0\u6d3b\u51fd\u6570\uff08\u5373\u4f7f\u7528\u7ebf\u6027\u6fc0\u6d3b\u51fd\u6570\uff1aa(x)=x\uff09\n\n\n\n\n\n\nweights\uff1a\u6743\u503c\uff0c\u4e3anumpy array\u7684list\u3002\u8be5list\u5e94\u542b\u6709\u4e00\u4e2a\u5f62\u5982\uff08input_dim,output_dim\uff09\u7684\u6743\u91cd\u77e9\u9635\u548c\u4e00\u4e2a\u5f62\u5982(output_dim,)\u7684\u504f\u7f6e\u5411\u91cf\u3002\n\n\n\n\n\n\nborder_mode\uff1a\u8fb9\u754c\u6a21\u5f0f\uff0c\u4e3a\u201cvalid\u201d\u6216\u201csame\u201d\n\n\n\n\n\n\nsubsample_length\uff1a\u8f93\u51fa\u5bf9\u8f93\u5165\u7684\u4e0b\u91c7\u6837\u56e0\u5b50\n\n\n\n\n\n\nW_regularizer\uff1a\u65bd\u52a0\u5728\u6743\u91cd\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a\nWeightRegularizer\n\u5bf9\u8c61\n\n\n\n\n\n\nb_regularizer\uff1a\u65bd\u52a0\u5728\u504f\u7f6e\u5411\u91cf\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a\nWeightRegularizer\n\u5bf9\u8c61\n\n\n\n\n\n\nactivity_regularizer\uff1a\u65bd\u52a0\u5728\u8f93\u51fa\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a\nActivityRegularizer\n\u5bf9\u8c61\n\n\n\n\n\n\nW_constraints\uff1a\u65bd\u52a0\u5728\u6743\u91cd\u4e0a\u7684\u7ea6\u675f\u9879\uff0c\u4e3a\nConstraints\n\u5bf9\u8c61\n\n\n\n\n\n\nb_constraints\uff1a\u65bd\u52a0\u5728\u504f\u7f6e\u4e0a\u7684\u7ea6\u675f\u9879\uff0c\u4e3a\nConstraints\n\u5bf9\u8c61\n\n\n\n\n\n\nbias\uff1a\u5e03\u5c14\u503c\uff0c\u662f\u5426\u5305\u542b\u504f\u7f6e\u5411\u91cf\uff08\u5373\u5c42\u5bf9\u8f93\u5165\u505a\u7ebf\u6027\u53d8\u6362\u8fd8\u662f\u4eff\u5c04\u53d8\u6362\uff09\n\n\n\n\n\n\ninput_dim\uff1a\u6574\u6570\uff0c\u8f93\u5165\u6570\u636e\u7684\u7ef4\u5ea6\u3002\u5f53\u8be5\u5c42\u4f5c\u4e3a\u7f51\u7edc\u7684\u7b2c\u4e00\u5c42\u65f6\uff0c\u5fc5\u987b\u6307\u5b9a\u8be5\u53c2\u6570\u6216\ninput_shape\n\u53c2\u6570\u3002\n\n\n\n\n\n\ninput_length\uff1a\u5f53\u8f93\u5165\u5e8f\u5217\u7684\u957f\u5ea6\u56fa\u5b9a\u65f6\uff0c\u8be5\u53c2\u6570\u4e3a\u8f93\u5165\u5e8f\u5217\u7684\u957f\u5ea6\u3002\u5f53\u9700\u8981\u5728\u8be5\u5c42\u540e\u8fde\u63a5\nFlatten\n\u5c42\uff0c\u7136\u540e\u53c8\u8981\u8fde\u63a5\nDense\n\u5c42\u65f6\uff0c\u9700\u8981\u6307\u5b9a\u8be5\u53c2\u6570\uff0c\u5426\u5219\u5168\u8fde\u63a5\u7684\u8f93\u51fa\u65e0\u6cd5\u8ba1\u7b97\u51fa\u6765\u3002\n\n\n\n\n\n\n\u8f93\u5165shape\n\n\n\u5f62\u5982\uff08samples\uff0csteps\uff0cinput_dim\uff09\u76843D\u5f20\u91cf\n\n\n\u8f93\u51fashape\n\n\n\u5f62\u5982\uff08samples\uff0cnew_steps\uff0cnb_filter\uff09\u76843D\u5f20\u91cf\uff0c\u56e0\u4e3a\u6709\u5411\u91cf\u586b\u5145\u7684\u539f\u56e0\uff0c\nsteps\n\u7684\u503c\u4f1a\u6539\u53d8\n\n\n\u4f8b\u5b50\n\n\n# apply a unshared weight convolution 1d of length 3 to a sequence with\n# 10 timesteps, with 64 output filters\nmodel = Sequential()\nmodel.add(LocallyConnected1D(64, 3, input_shape=(10, 32)))\n# now model.output_shape == (None, 8, 64)\n# add a new conv1d on top\nmodel.add(LocallyConnected1D(32, 3))\n# now model.output_shape == (None, 6, 32)\n\n\n\n\n\n\nLocallyConnected2D\u5c42\n\n\nkeras.layers.local.LocallyConnected2D(nb_filter, nb_row, nb_col, init='glorot_uniform', activation='linear', weights=None, border_mode='valid', subsample=(1, 1), dim_ordering='default', W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None, bias=True)\n\n\n\n\nLocallyConnected2D\n\u5c42\u4e0e\nConvolution2D\n\u5de5\u4f5c\u65b9\u5f0f\u7c7b\u4f3c\uff0c\u552f\u4e00\u7684\u533a\u522b\u662f\u4e0d\u8fdb\u884c\u6743\u503c\u5171\u4eab\u3002\u5373\u65bd\u52a0\u5728\u4e0d\u540c\u8f93\u5165patch\u7684\u6ee4\u6ce2\u5668\u662f\u4e0d\u4e00\u6837\u7684\uff0c\u5f53\u4f7f\u7528\u8be5\u5c42\u4f5c\u4e3a\u6a21\u578b\u9996\u5c42\u65f6\uff0c\u9700\u8981\u63d0\u4f9b\u53c2\u6570\ninput_dim\n\u6216\ninput_shape\n\u53c2\u6570\u3002\u53c2\u6570\u542b\u4e49\u53c2\u8003\nConvolution2D\n\u3002\u6ce8\u610f\u8be5\u5c42\u7684\ninput_shape\n\u5fc5\u987b\u5b8c\u5168\u6307\u5b9a\uff0c\u4e0d\u652f\u6301\nNone\n\n\n\u53c2\u6570\n\n\n\n\n\n\nnb_filter\uff1a\u5377\u79ef\u6838\u7684\u6570\u76ee\n\n\n\n\n\n\nnb_row\uff1a\u5377\u79ef\u6838\u7684\u884c\u6570\n\n\n\n\n\n\nnb_col\uff1a\u5377\u79ef\u6838\u7684\u5217\u6570\n\n\n\n\n\n\ninit\uff1a\u521d\u59cb\u5316\u65b9\u6cd5\uff0c\u4e3a\u9884\u5b9a\u4e49\u521d\u59cb\u5316\u65b9\u6cd5\u540d\u7684\u5b57\u7b26\u4e32\uff0c\u6216\u7528\u4e8e\u521d\u59cb\u5316\u6743\u91cd\u7684Theano\u51fd\u6570\u3002\u8be5\u53c2\u6570\u4ec5\u5728\u4e0d\u4f20\u9012\nweights\n\u53c2\u6570\u65f6\u6709\u610f\u4e49\u3002\n\n\n\n\n\n\nactivation\uff1a\u6fc0\u6d3b\u51fd\u6570\uff0c\u4e3a\u9884\u5b9a\u4e49\u7684\u6fc0\u6d3b\u51fd\u6570\u540d\uff08\u53c2\u8003\n\u6fc0\u6d3b\u51fd\u6570\n\uff09\uff0c\u6216\u9010\u5143\u7d20\uff08element-wise\uff09\u7684Theano\u51fd\u6570\u3002\u5982\u679c\u4e0d\u6307\u5b9a\u8be5\u53c2\u6570\uff0c\u5c06\u4e0d\u4f1a\u4f7f\u7528\u4efb\u4f55\u6fc0\u6d3b\u51fd\u6570\uff08\u5373\u4f7f\u7528\u7ebf\u6027\u6fc0\u6d3b\u51fd\u6570\uff1aa(x)=x\uff09\n\n\n\n\n\n\nweights\uff1a\u6743\u503c\uff0c\u4e3anumpy array\u7684list\u3002\u8be5list\u5e94\u542b\u6709\u4e00\u4e2a\u5f62\u5982\uff08input_dim,output_dim\uff09\u7684\u6743\u91cd\u77e9\u9635\u548c\u4e00\u4e2a\u5f62\u5982(output_dim,)\u7684\u504f\u7f6e\u5411\u91cf\u3002\n\n\n\n\n\n\nborder_mode\uff1a\u8fb9\u754c\u6a21\u5f0f\uff0c\u4e3a\u201cvalid\u201d\u6216\u201csame\u201d\n\n\n\n\n\n\nsubsample\uff1a\u957f\u4e3a2\u7684tuple\uff0c\u8f93\u51fa\u5bf9\u8f93\u5165\u7684\u4e0b\u91c7\u6837\u56e0\u5b50\uff0c\u66f4\u666e\u904d\u7684\u79f0\u547c\u662f\u201cstrides\u201d\n\n\n\n\n\n\nW_regularizer\uff1a\u65bd\u52a0\u5728\u6743\u91cd\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a\nWeightRegularizer\n\u5bf9\u8c61\n\n\n\n\n\n\nb_regularizer\uff1a\u65bd\u52a0\u5728\u504f\u7f6e\u5411\u91cf\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a\nWeightRegularizer\n\u5bf9\u8c61\n\n\n\n\n\n\nactivity_regularizer\uff1a\u65bd\u52a0\u5728\u8f93\u51fa\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a\nActivityRegularizer\n\u5bf9\u8c61\n\n\n\n\n\n\nW_constraints\uff1a\u65bd\u52a0\u5728\u6743\u91cd\u4e0a\u7684\u7ea6\u675f\u9879\uff0c\u4e3a\nConstraints\n\u5bf9\u8c61\n\n\n\n\n\n\nb_constraints\uff1a\u65bd\u52a0\u5728\u504f\u7f6e\u4e0a\u7684\u7ea6\u675f\u9879\uff0c\u4e3a\nConstraints\n\u5bf9\u8c61\n\n\n\n\n\n\ndim_ordering\uff1a\u2018th\u2019\u6216\u2018tf\u2019\u3002\u2018th\u2019\u6a21\u5f0f\u4e2d\u901a\u9053\u7ef4\uff08\u5982\u5f69\u8272\u56fe\u50cf\u76843\u901a\u9053\uff09\u4f4d\u4e8e\u7b2c1\u4e2a\u4f4d\u7f6e\uff08\u7ef4\u5ea6\u4ece0\u5f00\u59cb\u7b97\uff09\uff0c\u800c\u5728\u2018tf\u2019\u6a21\u5f0f\u4e2d\uff0c\u901a\u9053\u7ef4\u4f4d\u4e8e\u7b2c3\u4e2a\u4f4d\u7f6e\u3002\u4f8b\u5982128*128\u7684\u4e09\u901a\u9053\u5f69\u8272\u56fe\u7247\uff0c\u5728\u2018th\u2019\u6a21\u5f0f\u4e2d\ninput_shape\n\u5e94\u5199\u4e3a\uff083\uff0c128\uff0c128\uff09\uff0c\u800c\u5728\u2018tf\u2019\u6a21\u5f0f\u4e2d\u5e94\u5199\u4e3a\uff08128\uff0c128\uff0c3\uff09\uff0c\u6ce8\u610f\u8fd9\u91cc3\u51fa\u73b0\u5728\u7b2c0\u4e2a\u4f4d\u7f6e\uff0c\u56e0\u4e3a\ninput_shape\n\u4e0d\u5305\u542b\u6837\u672c\u6570\u7684\u7ef4\u5ea6\uff0c\u5728\u5176\u5185\u90e8\u5b9e\u73b0\u4e2d\uff0c\u5b9e\u9645\u4e0a\u662f\uff08None\uff0c3\uff0c128\uff0c128\uff09\u548c\uff08None\uff0c128\uff0c128\uff0c3\uff09\u3002\u9ed8\u8ba4\u662f\nimage_dim_ordering\n\u6307\u5b9a\u7684\u6a21\u5f0f\uff0c\u53ef\u5728\n~/.keras/keras.json\n\u4e2d\u67e5\u770b\uff0c\u82e5\u6ca1\u6709\u8bbe\u7f6e\u8fc7\u5219\u4e3a'tf'\u3002\n\n\n\n\n\n\nbias\uff1a\u5e03\u5c14\u503c\uff0c\u662f\u5426\u5305\u542b\u504f\u7f6e\u5411\u91cf\uff08\u5373\u5c42\u5bf9\u8f93\u5165\u505a\u7ebf\u6027\u53d8\u6362\u8fd8\u662f\u4eff\u5c04\u53d8\u6362\uff09\n\n\n\n\n\n\n\u8f93\u5165shape\n\n\n\u2018th\u2019\u6a21\u5f0f\u4e0b\uff0c\u8f93\u5165\u5f62\u5982\uff08samples,channels\uff0crows\uff0ccols\uff09\u76844D\u5f20\u91cf\n\n\n\u2018tf\u2019\u6a21\u5f0f\u4e0b\uff0c\u8f93\u5165\u5f62\u5982\uff08samples\uff0crows\uff0ccols\uff0cchannels\uff09\u76844D\u5f20\u91cf\n\n\n\u6ce8\u610f\u8fd9\u91cc\u7684\u8f93\u5165shape\u6307\u7684\u662f\u51fd\u6570\u5185\u90e8\u5b9e\u73b0\u7684\u8f93\u5165shape\uff0c\u800c\u975e\u51fd\u6570\u63a5\u53e3\u5e94\u6307\u5b9a\u7684\ninput_shape\n\uff0c\u8bf7\u53c2\u8003\u4e0b\u9762\u63d0\u4f9b\u7684\u4f8b\u5b50\u3002\n\n\n\u8f93\u51fashape\n\n\n\u2018th\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples\uff0cnb_filter, new_rows, new_cols\uff09\u76844D\u5f20\u91cf\n\n\n\u2018tf\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples\uff0cnew_rows, new_cols\uff0cnb_filter\uff09\u76844D\u5f20\u91cf\n\n\n\u8f93\u51fa\u7684\u884c\u5217\u6570\u53ef\u80fd\u4f1a\u56e0\u4e3a\u586b\u5145\u65b9\u6cd5\u800c\u6539\u53d8\n\n\n\u4f8b\u5b50\n\n\n# apply a 3x3 unshared weights convolution with 64 output filters on a 32x32 image:\nmodel = Sequential()\nmodel.add(LocallyConnected2D(64, 3, 3, input_shape=(3, 32, 32)))\n# now model.output_shape == (None, 64, 30, 30)\n# notice that this layer will consume (30*30)*(3*3*3*64) + (30*30)*64 parameters\n\n# add a 3x3 unshared weights convolution on top, with 32 output filters:\nmodel.add(LocallyConnected2D(32, 3, 3))\n# now model.output_shape == (None, 32, 28, 28)", 
            "title": "\u5c40\u90e8\u8fde\u63a5\u5c42Locally-connented"
        }, 
        {
            "location": "/layers/locally_connected_layer/#locallyconnceted", 
            "text": "", 
            "title": "\u5c40\u90e8\u8fde\u63a5\u5c42LocallyConnceted"
        }, 
        {
            "location": "/layers/locally_connected_layer/#locallyconnected1d", 
            "text": "keras.layers.local.LocallyConnected1D(nb_filter, filter_length, init='uniform', activation='linear', weights=None, border_mode='valid', subsample_length=1, W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None, bias=True, input_dim=None, input_length=None)  LocallyConnected1D \u5c42\u4e0e Convolution1D \u5de5\u4f5c\u65b9\u5f0f\u7c7b\u4f3c\uff0c\u552f\u4e00\u7684\u533a\u522b\u662f\u4e0d\u8fdb\u884c\u6743\u503c\u5171\u4eab\u3002\u5373\u65bd\u52a0\u5728\u4e0d\u540c\u8f93\u5165patch\u7684\u6ee4\u6ce2\u5668\u662f\u4e0d\u4e00\u6837\u7684\uff0c\u5f53\u4f7f\u7528\u8be5\u5c42\u4f5c\u4e3a\u6a21\u578b\u9996\u5c42\u65f6\uff0c\u9700\u8981\u63d0\u4f9b\u53c2\u6570 input_dim \u6216 input_shape \u53c2\u6570\u3002\u53c2\u6570\u542b\u4e49\u53c2\u8003 Convolution1D \u3002\u6ce8\u610f\u8be5\u5c42\u7684 input_shape \u5fc5\u987b\u5b8c\u5168\u6307\u5b9a\uff0c\u4e0d\u652f\u6301 None", 
            "title": "LocallyConnected1D\u5c42"
        }, 
        {
            "location": "/layers/locally_connected_layer/#_1", 
            "text": "nb_filter\uff1a\u5377\u79ef\u6838\u7684\u6570\u76ee\uff08\u5373\u8f93\u51fa\u7684\u7ef4\u5ea6\uff09    filter_length\uff1a\u5377\u79ef\u6838\u7684\u7a7a\u57df\u6216\u65f6\u57df\u957f\u5ea6    init\uff1a\u521d\u59cb\u5316\u65b9\u6cd5\uff0c\u4e3a\u9884\u5b9a\u4e49\u521d\u59cb\u5316\u65b9\u6cd5\u540d\u7684\u5b57\u7b26\u4e32\uff0c\u6216\u7528\u4e8e\u521d\u59cb\u5316\u6743\u91cd\u7684Theano\u51fd\u6570\u3002\u8be5\u53c2\u6570\u4ec5\u5728\u4e0d\u4f20\u9012 weights \u53c2\u6570\u65f6\u6709\u610f\u4e49\u3002    activation\uff1a\u6fc0\u6d3b\u51fd\u6570\uff0c\u4e3a\u9884\u5b9a\u4e49\u7684\u6fc0\u6d3b\u51fd\u6570\u540d\uff08\u53c2\u8003 \u6fc0\u6d3b\u51fd\u6570 \uff09\uff0c\u6216\u9010\u5143\u7d20\uff08element-wise\uff09\u7684Theano\u51fd\u6570\u3002\u5982\u679c\u4e0d\u6307\u5b9a\u8be5\u53c2\u6570\uff0c\u5c06\u4e0d\u4f1a\u4f7f\u7528\u4efb\u4f55\u6fc0\u6d3b\u51fd\u6570\uff08\u5373\u4f7f\u7528\u7ebf\u6027\u6fc0\u6d3b\u51fd\u6570\uff1aa(x)=x\uff09    weights\uff1a\u6743\u503c\uff0c\u4e3anumpy array\u7684list\u3002\u8be5list\u5e94\u542b\u6709\u4e00\u4e2a\u5f62\u5982\uff08input_dim,output_dim\uff09\u7684\u6743\u91cd\u77e9\u9635\u548c\u4e00\u4e2a\u5f62\u5982(output_dim,)\u7684\u504f\u7f6e\u5411\u91cf\u3002    border_mode\uff1a\u8fb9\u754c\u6a21\u5f0f\uff0c\u4e3a\u201cvalid\u201d\u6216\u201csame\u201d    subsample_length\uff1a\u8f93\u51fa\u5bf9\u8f93\u5165\u7684\u4e0b\u91c7\u6837\u56e0\u5b50    W_regularizer\uff1a\u65bd\u52a0\u5728\u6743\u91cd\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a WeightRegularizer \u5bf9\u8c61    b_regularizer\uff1a\u65bd\u52a0\u5728\u504f\u7f6e\u5411\u91cf\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a WeightRegularizer \u5bf9\u8c61    activity_regularizer\uff1a\u65bd\u52a0\u5728\u8f93\u51fa\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a ActivityRegularizer \u5bf9\u8c61    W_constraints\uff1a\u65bd\u52a0\u5728\u6743\u91cd\u4e0a\u7684\u7ea6\u675f\u9879\uff0c\u4e3a Constraints \u5bf9\u8c61    b_constraints\uff1a\u65bd\u52a0\u5728\u504f\u7f6e\u4e0a\u7684\u7ea6\u675f\u9879\uff0c\u4e3a Constraints \u5bf9\u8c61    bias\uff1a\u5e03\u5c14\u503c\uff0c\u662f\u5426\u5305\u542b\u504f\u7f6e\u5411\u91cf\uff08\u5373\u5c42\u5bf9\u8f93\u5165\u505a\u7ebf\u6027\u53d8\u6362\u8fd8\u662f\u4eff\u5c04\u53d8\u6362\uff09    input_dim\uff1a\u6574\u6570\uff0c\u8f93\u5165\u6570\u636e\u7684\u7ef4\u5ea6\u3002\u5f53\u8be5\u5c42\u4f5c\u4e3a\u7f51\u7edc\u7684\u7b2c\u4e00\u5c42\u65f6\uff0c\u5fc5\u987b\u6307\u5b9a\u8be5\u53c2\u6570\u6216 input_shape \u53c2\u6570\u3002    input_length\uff1a\u5f53\u8f93\u5165\u5e8f\u5217\u7684\u957f\u5ea6\u56fa\u5b9a\u65f6\uff0c\u8be5\u53c2\u6570\u4e3a\u8f93\u5165\u5e8f\u5217\u7684\u957f\u5ea6\u3002\u5f53\u9700\u8981\u5728\u8be5\u5c42\u540e\u8fde\u63a5 Flatten \u5c42\uff0c\u7136\u540e\u53c8\u8981\u8fde\u63a5 Dense \u5c42\u65f6\uff0c\u9700\u8981\u6307\u5b9a\u8be5\u53c2\u6570\uff0c\u5426\u5219\u5168\u8fde\u63a5\u7684\u8f93\u51fa\u65e0\u6cd5\u8ba1\u7b97\u51fa\u6765\u3002", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/layers/locally_connected_layer/#shape", 
            "text": "\u5f62\u5982\uff08samples\uff0csteps\uff0cinput_dim\uff09\u76843D\u5f20\u91cf", 
            "title": "\u8f93\u5165shape"
        }, 
        {
            "location": "/layers/locally_connected_layer/#shape_1", 
            "text": "\u5f62\u5982\uff08samples\uff0cnew_steps\uff0cnb_filter\uff09\u76843D\u5f20\u91cf\uff0c\u56e0\u4e3a\u6709\u5411\u91cf\u586b\u5145\u7684\u539f\u56e0\uff0c steps \u7684\u503c\u4f1a\u6539\u53d8", 
            "title": "\u8f93\u51fashape"
        }, 
        {
            "location": "/layers/locally_connected_layer/#_2", 
            "text": "# apply a unshared weight convolution 1d of length 3 to a sequence with\n# 10 timesteps, with 64 output filters\nmodel = Sequential()\nmodel.add(LocallyConnected1D(64, 3, input_shape=(10, 32)))\n# now model.output_shape == (None, 8, 64)\n# add a new conv1d on top\nmodel.add(LocallyConnected1D(32, 3))\n# now model.output_shape == (None, 6, 32)", 
            "title": "\u4f8b\u5b50"
        }, 
        {
            "location": "/layers/locally_connected_layer/#locallyconnected2d", 
            "text": "keras.layers.local.LocallyConnected2D(nb_filter, nb_row, nb_col, init='glorot_uniform', activation='linear', weights=None, border_mode='valid', subsample=(1, 1), dim_ordering='default', W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None, bias=True)  LocallyConnected2D \u5c42\u4e0e Convolution2D \u5de5\u4f5c\u65b9\u5f0f\u7c7b\u4f3c\uff0c\u552f\u4e00\u7684\u533a\u522b\u662f\u4e0d\u8fdb\u884c\u6743\u503c\u5171\u4eab\u3002\u5373\u65bd\u52a0\u5728\u4e0d\u540c\u8f93\u5165patch\u7684\u6ee4\u6ce2\u5668\u662f\u4e0d\u4e00\u6837\u7684\uff0c\u5f53\u4f7f\u7528\u8be5\u5c42\u4f5c\u4e3a\u6a21\u578b\u9996\u5c42\u65f6\uff0c\u9700\u8981\u63d0\u4f9b\u53c2\u6570 input_dim \u6216 input_shape \u53c2\u6570\u3002\u53c2\u6570\u542b\u4e49\u53c2\u8003 Convolution2D \u3002\u6ce8\u610f\u8be5\u5c42\u7684 input_shape \u5fc5\u987b\u5b8c\u5168\u6307\u5b9a\uff0c\u4e0d\u652f\u6301 None", 
            "title": "LocallyConnected2D\u5c42"
        }, 
        {
            "location": "/layers/locally_connected_layer/#_3", 
            "text": "nb_filter\uff1a\u5377\u79ef\u6838\u7684\u6570\u76ee    nb_row\uff1a\u5377\u79ef\u6838\u7684\u884c\u6570    nb_col\uff1a\u5377\u79ef\u6838\u7684\u5217\u6570    init\uff1a\u521d\u59cb\u5316\u65b9\u6cd5\uff0c\u4e3a\u9884\u5b9a\u4e49\u521d\u59cb\u5316\u65b9\u6cd5\u540d\u7684\u5b57\u7b26\u4e32\uff0c\u6216\u7528\u4e8e\u521d\u59cb\u5316\u6743\u91cd\u7684Theano\u51fd\u6570\u3002\u8be5\u53c2\u6570\u4ec5\u5728\u4e0d\u4f20\u9012 weights \u53c2\u6570\u65f6\u6709\u610f\u4e49\u3002    activation\uff1a\u6fc0\u6d3b\u51fd\u6570\uff0c\u4e3a\u9884\u5b9a\u4e49\u7684\u6fc0\u6d3b\u51fd\u6570\u540d\uff08\u53c2\u8003 \u6fc0\u6d3b\u51fd\u6570 \uff09\uff0c\u6216\u9010\u5143\u7d20\uff08element-wise\uff09\u7684Theano\u51fd\u6570\u3002\u5982\u679c\u4e0d\u6307\u5b9a\u8be5\u53c2\u6570\uff0c\u5c06\u4e0d\u4f1a\u4f7f\u7528\u4efb\u4f55\u6fc0\u6d3b\u51fd\u6570\uff08\u5373\u4f7f\u7528\u7ebf\u6027\u6fc0\u6d3b\u51fd\u6570\uff1aa(x)=x\uff09    weights\uff1a\u6743\u503c\uff0c\u4e3anumpy array\u7684list\u3002\u8be5list\u5e94\u542b\u6709\u4e00\u4e2a\u5f62\u5982\uff08input_dim,output_dim\uff09\u7684\u6743\u91cd\u77e9\u9635\u548c\u4e00\u4e2a\u5f62\u5982(output_dim,)\u7684\u504f\u7f6e\u5411\u91cf\u3002    border_mode\uff1a\u8fb9\u754c\u6a21\u5f0f\uff0c\u4e3a\u201cvalid\u201d\u6216\u201csame\u201d    subsample\uff1a\u957f\u4e3a2\u7684tuple\uff0c\u8f93\u51fa\u5bf9\u8f93\u5165\u7684\u4e0b\u91c7\u6837\u56e0\u5b50\uff0c\u66f4\u666e\u904d\u7684\u79f0\u547c\u662f\u201cstrides\u201d    W_regularizer\uff1a\u65bd\u52a0\u5728\u6743\u91cd\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a WeightRegularizer \u5bf9\u8c61    b_regularizer\uff1a\u65bd\u52a0\u5728\u504f\u7f6e\u5411\u91cf\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a WeightRegularizer \u5bf9\u8c61    activity_regularizer\uff1a\u65bd\u52a0\u5728\u8f93\u51fa\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a ActivityRegularizer \u5bf9\u8c61    W_constraints\uff1a\u65bd\u52a0\u5728\u6743\u91cd\u4e0a\u7684\u7ea6\u675f\u9879\uff0c\u4e3a Constraints \u5bf9\u8c61    b_constraints\uff1a\u65bd\u52a0\u5728\u504f\u7f6e\u4e0a\u7684\u7ea6\u675f\u9879\uff0c\u4e3a Constraints \u5bf9\u8c61    dim_ordering\uff1a\u2018th\u2019\u6216\u2018tf\u2019\u3002\u2018th\u2019\u6a21\u5f0f\u4e2d\u901a\u9053\u7ef4\uff08\u5982\u5f69\u8272\u56fe\u50cf\u76843\u901a\u9053\uff09\u4f4d\u4e8e\u7b2c1\u4e2a\u4f4d\u7f6e\uff08\u7ef4\u5ea6\u4ece0\u5f00\u59cb\u7b97\uff09\uff0c\u800c\u5728\u2018tf\u2019\u6a21\u5f0f\u4e2d\uff0c\u901a\u9053\u7ef4\u4f4d\u4e8e\u7b2c3\u4e2a\u4f4d\u7f6e\u3002\u4f8b\u5982128*128\u7684\u4e09\u901a\u9053\u5f69\u8272\u56fe\u7247\uff0c\u5728\u2018th\u2019\u6a21\u5f0f\u4e2d input_shape \u5e94\u5199\u4e3a\uff083\uff0c128\uff0c128\uff09\uff0c\u800c\u5728\u2018tf\u2019\u6a21\u5f0f\u4e2d\u5e94\u5199\u4e3a\uff08128\uff0c128\uff0c3\uff09\uff0c\u6ce8\u610f\u8fd9\u91cc3\u51fa\u73b0\u5728\u7b2c0\u4e2a\u4f4d\u7f6e\uff0c\u56e0\u4e3a input_shape \u4e0d\u5305\u542b\u6837\u672c\u6570\u7684\u7ef4\u5ea6\uff0c\u5728\u5176\u5185\u90e8\u5b9e\u73b0\u4e2d\uff0c\u5b9e\u9645\u4e0a\u662f\uff08None\uff0c3\uff0c128\uff0c128\uff09\u548c\uff08None\uff0c128\uff0c128\uff0c3\uff09\u3002\u9ed8\u8ba4\u662f image_dim_ordering \u6307\u5b9a\u7684\u6a21\u5f0f\uff0c\u53ef\u5728 ~/.keras/keras.json \u4e2d\u67e5\u770b\uff0c\u82e5\u6ca1\u6709\u8bbe\u7f6e\u8fc7\u5219\u4e3a'tf'\u3002    bias\uff1a\u5e03\u5c14\u503c\uff0c\u662f\u5426\u5305\u542b\u504f\u7f6e\u5411\u91cf\uff08\u5373\u5c42\u5bf9\u8f93\u5165\u505a\u7ebf\u6027\u53d8\u6362\u8fd8\u662f\u4eff\u5c04\u53d8\u6362\uff09", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/layers/locally_connected_layer/#shape_2", 
            "text": "\u2018th\u2019\u6a21\u5f0f\u4e0b\uff0c\u8f93\u5165\u5f62\u5982\uff08samples,channels\uff0crows\uff0ccols\uff09\u76844D\u5f20\u91cf  \u2018tf\u2019\u6a21\u5f0f\u4e0b\uff0c\u8f93\u5165\u5f62\u5982\uff08samples\uff0crows\uff0ccols\uff0cchannels\uff09\u76844D\u5f20\u91cf  \u6ce8\u610f\u8fd9\u91cc\u7684\u8f93\u5165shape\u6307\u7684\u662f\u51fd\u6570\u5185\u90e8\u5b9e\u73b0\u7684\u8f93\u5165shape\uff0c\u800c\u975e\u51fd\u6570\u63a5\u53e3\u5e94\u6307\u5b9a\u7684 input_shape \uff0c\u8bf7\u53c2\u8003\u4e0b\u9762\u63d0\u4f9b\u7684\u4f8b\u5b50\u3002", 
            "title": "\u8f93\u5165shape"
        }, 
        {
            "location": "/layers/locally_connected_layer/#shape_3", 
            "text": "\u2018th\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples\uff0cnb_filter, new_rows, new_cols\uff09\u76844D\u5f20\u91cf  \u2018tf\u2019\u6a21\u5f0f\u4e0b\uff0c\u4e3a\u5f62\u5982\uff08samples\uff0cnew_rows, new_cols\uff0cnb_filter\uff09\u76844D\u5f20\u91cf  \u8f93\u51fa\u7684\u884c\u5217\u6570\u53ef\u80fd\u4f1a\u56e0\u4e3a\u586b\u5145\u65b9\u6cd5\u800c\u6539\u53d8", 
            "title": "\u8f93\u51fashape"
        }, 
        {
            "location": "/layers/locally_connected_layer/#_4", 
            "text": "# apply a 3x3 unshared weights convolution with 64 output filters on a 32x32 image:\nmodel = Sequential()\nmodel.add(LocallyConnected2D(64, 3, 3, input_shape=(3, 32, 32)))\n# now model.output_shape == (None, 64, 30, 30)\n# notice that this layer will consume (30*30)*(3*3*3*64) + (30*30)*64 parameters\n\n# add a 3x3 unshared weights convolution on top, with 32 output filters:\nmodel.add(LocallyConnected2D(32, 3, 3))\n# now model.output_shape == (None, 32, 28, 28)", 
            "title": "\u4f8b\u5b50"
        }, 
        {
            "location": "/layers/recurrent_layer/", 
            "text": "\u9012\u5f52\u5c42Recurrent\n\n\nRecurrent\u5c42\n\n\nkeras.layers.recurrent.Recurrent(weights=None, return_sequences=False, go_backwards=False, stateful=False, unroll=False, consume_less='cpu', input_dim=None, input_length=None)\n\n\n\n\n\u8fd9\u662f\u9012\u5f52\u5c42\u7684\u62bd\u8c61\u7c7b\uff0c\u8bf7\u4e0d\u8981\u5728\u6a21\u578b\u4e2d\u76f4\u63a5\u5e94\u7528\u8be5\u5c42\uff08\u56e0\u4e3a\u5b83\u662f\u62bd\u8c61\u7c7b\uff0c\u65e0\u6cd5\u5b9e\u4f8b\u5316\u4efb\u4f55\u5bf9\u8c61\uff09\u3002\u8bf7\u4f7f\u7528\u5b83\u7684\u5b50\u7c7b\nLSTM\n\u6216\nSimpleRNN\n\u3002\n\n\n\u6240\u6709\u7684\u9012\u5f52\u5c42\uff08\nLSTM\n,\nGRU\n,\nSimpleRNN\n\uff09\u90fd\u670d\u4ece\u672c\u5c42\u7684\u6027\u8d28\uff0c\u5e76\u63a5\u53d7\u672c\u5c42\u6307\u5b9a\u7684\u6240\u6709\u5173\u952e\u5b57\u53c2\u6570\u3002\n\n\n\u53c2\u6570\n\n\n\n\n\n\nweights\uff1anumpy array\u7684list\uff0c\u7528\u4ee5\u521d\u59cb\u5316\u6743\u91cd\u3002\u8be5list\u5f62\u5982\n[(input_dim, output_dim),(output_dim, output_dim),(output_dim,)]\n\n\n\n\n\n\nreturn_sequences\uff1a\u5e03\u5c14\u503c\uff0c\u9ed8\u8ba4\nFalse\n\uff0c\u63a7\u5236\u8fd4\u56de\u7c7b\u578b\u3002\u82e5\u4e3a\nTrue\n\u5219\u8fd4\u56de\u6574\u4e2a\u5e8f\u5217\uff0c\u5426\u5219\u4ec5\u8fd4\u56de\u8f93\u51fa\u5e8f\u5217\u7684\u6700\u540e\u4e00\u4e2a\u8f93\u51fa\n\n\n\n\n\n\ngo_backwards\uff1a\u5e03\u5c14\u503c\uff0c\u9ed8\u8ba4\u4e3a\nFalse\n\uff0c\u82e5\u4e3a\nTrue\n\uff0c\u5219\u9006\u5411\u5904\u7406\u8f93\u5165\u5e8f\u5217\n\n\n\n\n\n\nstateful\uff1a\u5e03\u5c14\u503c\uff0c\u9ed8\u8ba4\u4e3a\nFalse\n\uff0c\u82e5\u4e3a\nTrue\n\uff0c\u5219\u4e00\u4e2abatch\u4e2d\u4e0b\u6807\u4e3ai\u7684\u6837\u672c\u7684\u6700\u7ec8\u72b6\u6001\u5c06\u4f1a\u7528\u4f5c\u4e0b\u4e00\u4e2abatch\u540c\u6837\u4e0b\u6807\u7684\u6837\u672c\u7684\u521d\u59cb\u72b6\u6001\u3002\n\n\n\n\n\n\nunroll\uff1a\u5e03\u5c14\u503c\uff0c\u9ed8\u8ba4\u4e3a\nFalse\n\uff0c\u82e5\u4e3a\nTrue\n\uff0c\u5219\u9012\u5f52\u5c42\u5c06\u88ab\u5c55\u5f00\uff0c\u5426\u5219\u5c31\u4f7f\u7528\u7b26\u53f7\u5316\u7684\u5faa\u73af\u3002\u5f53\u4f7f\u7528TensorFlow\u4e3a\u540e\u7aef\u65f6\uff0c\u9012\u5f52\u7f51\u7edc\u672c\u6765\u5c31\u662f\u5c55\u5f00\u7684\uff0c\u56e0\u6b64\u8be5\u5c42\u4e0d\u505a\u4efb\u4f55\u4e8b\u60c5\u3002\u5c42\u5c55\u5f00\u4f1a\u5360\u7528\u66f4\u591a\u7684\u5185\u5b58\uff0c\u4f46\u4f1a\u52a0\u901fRNN\u7684\u8fd0\u7b97\u3002\u5c42\u5c55\u5f00\u53ea\u9002\u7528\u4e8e\u77ed\u5e8f\u5217\u3002\n\n\n\n\n\n\nconsume_less\uff1a\u2018cpu\u2019\u6216\u2018mem\u2019\u4e4b\u4e00\u3002\u82e5\u8bbe\u4e3a\u2018cpu\u2019\uff0c\u5219RNN\u5c06\u4f7f\u7528\u8f83\u5c11\u3001\u8f83\u5927\u7684\u77e9\u9635\u4e58\u6cd5\u6765\u5b9e\u73b0\uff0c\u4ece\u800c\u5728CPU\u4e0a\u4f1a\u8fd0\u884c\u66f4\u5feb\uff0c\u4f46\u4f1a\u66f4\u6d88\u8017\u5185\u5b58\u3002\u5982\u679c\u8bbe\u4e3a\u2018mem\u2019\uff0c\u5219RNN\u5c06\u4f1a\u8f83\u591a\u7684\u5c0f\u77e9\u9635\u4e58\u6cd5\u6765\u5b9e\u73b0\uff0c\u4ece\u800c\u5728GPU\u5e76\u884c\u8ba1\u7b97\u65f6\u4f1a\u8fd0\u884c\u66f4\u5feb\uff08\u4f46\u5728CPU\u4e0a\u6162\uff09\uff0c\u5e76\u5360\u7528\u8f83\u5c11\u5185\u5b58\u3002\n\n\n\n\n\n\ninput_dim\uff1a\u8f93\u5165\u7ef4\u5ea6\uff0c\u5f53\u4f7f\u7528\u8be5\u5c42\u4e3a\u6a21\u578b\u9996\u5c42\u65f6\uff0c\u5e94\u6307\u5b9a\u8be5\u503c\uff08\u6216\u7b49\u4ef7\u7684\u6307\u5b9ainput_shape)\n\n\n\n\n\n\ninput_length\uff1a\u5f53\u8f93\u5165\u5e8f\u5217\u7684\u957f\u5ea6\u56fa\u5b9a\u65f6\uff0c\u8be5\u53c2\u6570\u4e3a\u8f93\u5165\u5e8f\u5217\u7684\u957f\u5ea6\u3002\u5f53\u9700\u8981\u5728\u8be5\u5c42\u540e\u8fde\u63a5\nFlatten\n\u5c42\uff0c\u7136\u540e\u53c8\u8981\u8fde\u63a5\nDense\n\u5c42\u65f6\uff0c\u9700\u8981\u6307\u5b9a\u8be5\u53c2\u6570\uff0c\u5426\u5219\u5168\u8fde\u63a5\u7684\u8f93\u51fa\u65e0\u6cd5\u8ba1\u7b97\u51fa\u6765\u3002\u6ce8\u610f\uff0c\u5982\u679c\u9012\u5f52\u5c42\u4e0d\u662f\u7f51\u7edc\u7684\u7b2c\u4e00\u5c42\uff0c\u4f60\u9700\u8981\u5728\u7f51\u7edc\u7684\u7b2c\u4e00\u5c42\u4e2d\u6307\u5b9a\u5e8f\u5217\u7684\u957f\u5ea6\uff0c\u5982\u901a\u8fc7\ninput_shape\n\u6307\u5b9a\u3002\n\n\n\n\n\n\n\u8f93\u5165shape\n\n\n\u5f62\u5982\uff08samples\uff0ctimesteps\uff0cinput_dim\uff09\u76843D\u5f20\u91cf\n\n\n\u8f93\u51fashape\n\n\n\u5982\u679c\nreturn_sequences=True\n\uff1a\u8fd4\u56de\u5f62\u5982\uff08samples\uff0ctimesteps\uff0coutput_dim\uff09\u76843D\u5f20\u91cf\n\n\n\u5426\u5219\uff0c\u8fd4\u56de\u5f62\u5982\uff08samples\uff0coutput_dim\uff09\u76842D\u5f20\u91cf\n\n\n\u4f8b\u5b50\n\n\n# as the first layer in a Sequential model\nmodel = Sequential()\nmodel.add(LSTM(32, input_shape=(10, 64)))\n# now model.output_shape == (None, 10, 32)\n# note: `None` is the batch dimension.\n\n# the following is identical:\nmodel = Sequential()\nmodel.add(LSTM(32, input_dim=64, input_length=10))\n\n# for subsequent layers, not need to specify the input size:\nmodel.add(LSTM(16))\n\n\n\n\n\u5c4f\u853d\u8f93\u5165\u6570\u636e\uff08Masking\uff09\n\n\n\u9012\u5f52\u5c42\u652f\u6301\u901a\u8fc7\u65f6\u95f4\u6b65\u53d8\u91cf\u5bf9\u8f93\u5165\u6570\u636e\u8fdb\u884cMasking\uff0c\u5982\u679c\u60f3\u5c06\u8f93\u5165\u6570\u636e\u7684\u4e00\u90e8\u5206\u5c4f\u853d\u6389\uff0c\u8bf7\u4f7f\u7528\nEmbedding\n\u5c42\u5e76\u5c06\u53c2\u6570\nmask_zero\n\u8bbe\u4e3a\nTrue\n\u3002\n\n\nTensorFlow\u8b66\u544a\n\n\n\u76ee\u524d\u4e3a\u6b62\uff0c\u5f53\u4f7f\u7528TensorFlow\u4f5c\u4e3a\u540e\u7aef\u65f6\uff0c\u5e8f\u5217\u7684\u65f6\u95f4\u6b65\u6570\u76ee\u5fc5\u987b\u5728\u7f51\u7edc\u4e2d\u6307\u5b9a\u3002\u901a\u8fc7\ninput_length\n\uff08\u5982\u679c\u7f51\u7edc\u9996\u5c42\u662f\u9012\u5f52\u5c42\uff09\u6216\u5b8c\u6574\u7684\ninput_shape\n\u6765\u6307\u5b9a\u8be5\u503c\u3002\n\n\n\u4f7f\u7528\u72b6\u6001RNN\u7684\u6ce8\u610f\u4e8b\u9879\n\n\n\u53ef\u4ee5\u5c06RNN\u8bbe\u7f6e\u4e3a\u2018stateful\u2019\uff0c\u610f\u5473\u7740\u8bad\u7ec3\u65f6\u6bcf\u4e2abatch\u7684\u72b6\u6001\u90fd\u4f1a\u88ab\u91cd\u7528\u4e8e\u521d\u59cb\u5316\u4e0b\u4e00\u4e2abatch\u7684\u521d\u59cb\u72b6\u6001\u3002\u72b6\u6001RNN\u5047\u8bbe\u8fde\u7eed\u7684\u4e24\u4e2abatch\u4e4b\u4e2d\uff0c\u76f8\u540c\u4e0b\u6807\u7684\u5143\u7d20\u6709\u4e00\u4e00\u6620\u5c04\u5173\u7cfb\u3002\n\n\n\u8981\u542f\u7528\u72b6\u6001RNN\uff0c\u8bf7\u5728\u5b9e\u4f8b\u5316\u5c42\u5bf9\u8c61\u65f6\u6307\u5b9a\u53c2\u6570\nstateful=True\n\uff0c\u5e76\u6307\u5b9a\u6a21\u578b\u4f7f\u7528\u56fa\u5b9a\u5927\u5c0f\u7684batch\uff1a\u901a\u8fc7\u5728\u6a21\u578b\u7684\u7b2c\u4e00\u5c42\u4f20\u5165\nbatch_input_shape=(...)\n\u6765\u5b9e\u73b0\u3002\u8be5\u53c2\u6570\u5e94\u4e3a\u5305\u542bbatch\u5927\u5c0f\u7684\u5143\u7ec4\uff0c\u4f8b\u5982\uff0832\uff0c10\uff0c100\uff09\u4ee3\u8868\u6bcf\u4e2abatch\u7684\u5927\u5c0f\u662f32.\n\n\n\u5982\u679c\u8981\u5c06\u9012\u5f52\u5c42\u7684\u72b6\u6001\u91cd\u7f6e\uff0c\u8bf7\u8c03\u7528\n.reset_states()\n\uff0c\u5bf9\u6a21\u578b\u8c03\u7528\u5c06\u91cd\u7f6e\u6a21\u578b\u4e2d\u6240\u6709\u72b6\u6001RNN\u7684\u72b6\u6001\u3002\u5bf9\u5355\u4e2a\u5c42\u8c03\u7528\u5219\u53ea\u91cd\u7f6e\u8be5\u5c42\u7684\u72b6\u6001\u3002\n\n\n\u4ee5TensorFlow\u4f5c\u4e3a\u540e\u7aef\u65f6\u4f7f\u7528dropout\u7684\u6ce8\u610f\u4e8b\u9879\n\n\n\u5f53\u4f7f\u7528TensorFlow\u4f5c\u4e3a\u540e\u7aef\u65f6\uff0c\u5982\u679c\u8981\u5728\u9012\u5f52\u5c42\u4f7f\u7528dropout\uff0c\u9700\u8981\u540c\u4e0a\u9762\u6240\u8ff0\u7684\u4e00\u6837\u6307\u5b9a\u597d\u56fa\u5b9a\u7684batch\u5927\u5c0f\n\n\n\n\nSimpleRNN\u5c42\n\n\nkeras.layers.recurrent.SimpleRNN(output_dim, init='glorot_uniform', inner_init='orthogonal', activation='tanh', W_regularizer=None, U_regularizer=None, b_regularizer=None, dropout_W=0.0, dropout_U=0.0)\n\n\n\n\n\u5168\u8fde\u63a5RNN\u7f51\u7edc\uff0cRNN\u7684\u8f93\u51fa\u4f1a\u88ab\u56de\u9988\u5230\u8f93\u5165\n\n\n\u53c2\u6570\n\n\n\n\n\n\noutput_dim\uff1a\u5185\u90e8\u6295\u5f71\u548c\u8f93\u51fa\u7684\u7ef4\u5ea6\n\n\n\n\n\n\ninit\uff1a\u521d\u59cb\u5316\u65b9\u6cd5\uff0c\u4e3a\u9884\u5b9a\u4e49\u521d\u59cb\u5316\u65b9\u6cd5\u540d\u7684\u5b57\u7b26\u4e32\uff0c\u6216\u7528\u4e8e\u521d\u59cb\u5316\u6743\u91cd\u7684Theano\u51fd\u6570\u3002\n\n\n\n\n\n\ninner_init\uff1a\u5185\u90e8\u5355\u5143\u7684\u521d\u59cb\u5316\u65b9\u6cd5\n\n\n\n\n\n\nactivation\uff1a\u6fc0\u6d3b\u51fd\u6570\uff0c\u4e3a\u9884\u5b9a\u4e49\u7684\u6fc0\u6d3b\u51fd\u6570\u540d\uff08\u53c2\u8003\n\u6fc0\u6d3b\u51fd\u6570\n\uff09\n\n\n\n\n\n\nW_regularizer\uff1a\u65bd\u52a0\u5728\u6743\u91cd\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a\nWeightRegularizer\n\u5bf9\u8c61\n\n\n\n\n\n\nU_regularizer\uff1a\u65bd\u52a0\u5728\u9012\u5f52\u6743\u91cd\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a\nWeightRegularizer\n\u5bf9\u8c61\n\n\n\n\n\n\nb_regularizer\uff1a\u65bd\u52a0\u5728\u504f\u7f6e\u5411\u91cf\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a\nWeightRegularizer\n\u5bf9\u8c61\n\n\n\n\n\n\ndropout_W\uff1a0~1\u4e4b\u95f4\u7684\u6d6e\u70b9\u6570\uff0c\u63a7\u5236\u8f93\u5165\u5355\u5143\u5230\u8f93\u5165\u95e8\u7684\u8fde\u63a5\u65ad\u5f00\u6bd4\u4f8b\n\n\n\n\n\n\ndropout_U\uff1a0~1\u4e4b\u95f4\u7684\u6d6e\u70b9\u6570\uff0c\u63a7\u5236\u8f93\u5165\u5355\u5143\u5230\u9012\u5f52\u8fde\u63a5\u7684\u65ad\u5f00\u6bd4\u4f8b\n\n\n\n\n\n\n\u53c2\u8003\u6587\u732e\n\n\n\n\nA Theoretically Grounded Application of Dropout in Recurrent Neural Networks\n\n\n\n\n\n\nGRU\u5c42\n\n\nkeras.layers.recurrent.GRU(output_dim, init='glorot_uniform', inner_init='orthogonal', activation='tanh', inner_activation='hard_sigmoid', W_regularizer=None, U_regularizer=None, b_regularizer=None, dropout_W=0.0, dropout_U=0.0)\n\n\n\n\n\u95e8\u9650\u9012\u5f52\u5355\u5143\uff08\u8be6\u89c1\u53c2\u8003\u6587\u732e\uff09\n\n\n\u53c2\u6570\n\n\n\n\n\n\noutput_dim\uff1a\u5185\u90e8\u6295\u5f71\u548c\u8f93\u51fa\u7684\u7ef4\u5ea6\n\n\n\n\n\n\ninit\uff1a\u521d\u59cb\u5316\u65b9\u6cd5\uff0c\u4e3a\u9884\u5b9a\u4e49\u521d\u59cb\u5316\u65b9\u6cd5\u540d\u7684\u5b57\u7b26\u4e32\uff0c\u6216\u7528\u4e8e\u521d\u59cb\u5316\u6743\u91cd\u7684Theano\u51fd\u6570\u3002\n\n\n\n\n\n\ninner_init\uff1a\u5185\u90e8\u5355\u5143\u7684\u521d\u59cb\u5316\u65b9\u6cd5\n\n\n\n\n\n\nactivation\uff1a\u6fc0\u6d3b\u51fd\u6570\uff0c\u4e3a\u9884\u5b9a\u4e49\u7684\u6fc0\u6d3b\u51fd\u6570\u540d\uff08\u53c2\u8003\n\u6fc0\u6d3b\u51fd\u6570\n\uff09\n\n\n\n\n\n\ninner_activation\uff1a\u5185\u90e8\u5355\u5143\u6fc0\u6d3b\u51fd\u6570\n\n\n\n\n\n\nW_regularizer\uff1a\u65bd\u52a0\u5728\u6743\u91cd\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a\nWeightRegularizer\n\u5bf9\u8c61\n\n\n\n\n\n\nU_regularizer\uff1a\u65bd\u52a0\u5728\u9012\u5f52\u6743\u91cd\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a\nWeightRegularizer\n\u5bf9\u8c61\n\n\n\n\n\n\nb_regularizer\uff1a\u65bd\u52a0\u5728\u504f\u7f6e\u5411\u91cf\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a\nWeightRegularizer\n\u5bf9\u8c61\n\n\n\n\n\n\ndropout_W\uff1a0~1\u4e4b\u95f4\u7684\u6d6e\u70b9\u6570\uff0c\u63a7\u5236\u8f93\u5165\u5355\u5143\u5230\u8f93\u5165\u95e8\u7684\u8fde\u63a5\u65ad\u5f00\u6bd4\u4f8b\n\n\n\n\n\n\ndropout_U\uff1a0~1\u4e4b\u95f4\u7684\u6d6e\u70b9\u6570\uff0c\u63a7\u5236\u8f93\u5165\u5355\u5143\u5230\u9012\u5f52\u8fde\u63a5\u7684\u65ad\u5f00\u6bd4\u4f8b\n\n\n\n\n\n\n\u53c2\u8003\u6587\u732e\n\n\n\n\n\n\nOn the Properties of Neural Machine Translation: Encoder\u2013Decoder Approaches\n\n\n\n\n\n\nEmpirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling\n\n\n\n\n\n\nA Theoretically Grounded Application of Dropout in Recurrent Neural Networks\n\n\n\n\n\n\n\n\nLSTM\u5c42\n\n\nkeras.layers.recurrent.LSTM(output_dim, init='glorot_uniform', inner_init='orthogonal', forget_bias_init='one', activation='tanh', inner_activation='hard_sigmoid', W_regularizer=None, U_regularizer=None, b_regularizer=None, dropout_W=0.0, dropout_U=0.0)\n\n\n\n\nKeras\u957f\u77ed\u671f\u8bb0\u5fc6\u6a21\u578b\uff0c\u5173\u4e8e\u6b64\u7b97\u6cd5\u7684\u8be6\u60c5\uff0c\u8bf7\u53c2\u8003\n\u672c\u6559\u7a0b\n\n\n\u53c2\u6570\n\n\n\n\n\n\noutput_dim\uff1a\u5185\u90e8\u6295\u5f71\u548c\u8f93\u51fa\u7684\u7ef4\u5ea6\n\n\n\n\n\n\ninit\uff1a\u521d\u59cb\u5316\u65b9\u6cd5\uff0c\u4e3a\u9884\u5b9a\u4e49\u521d\u59cb\u5316\u65b9\u6cd5\u540d\u7684\u5b57\u7b26\u4e32\uff0c\u6216\u7528\u4e8e\u521d\u59cb\u5316\u6743\u91cd\u7684Theano\u51fd\u6570\u3002\n\n\n\n\n\n\ninner_init\uff1a\u5185\u90e8\u5355\u5143\u7684\u521d\u59cb\u5316\u65b9\u6cd5\n\n\n\n\n\n\nforget_bias_init\uff1a\u9057\u5fd8\u95e8\u504f\u7f6e\u7684\u521d\u59cb\u5316\u51fd\u6570\uff0c\nJozefowicz et al.\n\u5efa\u8bae\u521d\u59cb\u5316\u4e3a\u51681\u5143\u7d20\n\n\n\n\n\n\nactivation\uff1a\u6fc0\u6d3b\u51fd\u6570\uff0c\u4e3a\u9884\u5b9a\u4e49\u7684\u6fc0\u6d3b\u51fd\u6570\u540d\uff08\u53c2\u8003\n\u6fc0\u6d3b\u51fd\u6570\n\uff09\n\n\n\n\n\n\ninner_activation\uff1a\u5185\u90e8\u5355\u5143\u6fc0\u6d3b\u51fd\u6570\n\n\n\n\n\n\nW_regularizer\uff1a\u65bd\u52a0\u5728\u6743\u91cd\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a\nWeightRegularizer\n\u5bf9\u8c61\n\n\n\n\n\n\nU_regularizer\uff1a\u65bd\u52a0\u5728\u9012\u5f52\u6743\u91cd\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a\nWeightRegularizer\n\u5bf9\u8c61\n\n\n\n\n\n\nb_regularizer\uff1a\u65bd\u52a0\u5728\u504f\u7f6e\u5411\u91cf\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a\nWeightRegularizer\n\u5bf9\u8c61\n\n\n\n\n\n\ndropout_W\uff1a0~1\u4e4b\u95f4\u7684\u6d6e\u70b9\u6570\uff0c\u63a7\u5236\u8f93\u5165\u5355\u5143\u5230\u8f93\u5165\u95e8\u7684\u8fde\u63a5\u65ad\u5f00\u6bd4\u4f8b\n\n\n\n\n\n\ndropout_U\uff1a0~1\u4e4b\u95f4\u7684\u6d6e\u70b9\u6570\uff0c\u63a7\u5236\u8f93\u5165\u5355\u5143\u5230\u9012\u5f52\u8fde\u63a5\u7684\u65ad\u5f00\u6bd4\u4f8b\n\n\n\n\n\n\n\u53c2\u8003\u6587\u732e\n\n\n\n\n\n\nLong short-term memory \n\uff08original 1997 paper\uff09\n\n\n\n\n\n\nLearning to forget: Continual prediction with LSTM\n\n\n\n\n\n\nSupervised sequence labelling with recurrent neural networks\n\n\n\n\n\n\nA Theoretically Grounded Application of Dropout in Recurrent Neural Networks", 
            "title": "\u9012\u5f52\u5c42Recurrent"
        }, 
        {
            "location": "/layers/recurrent_layer/#recurrent", 
            "text": "", 
            "title": "\u9012\u5f52\u5c42Recurrent"
        }, 
        {
            "location": "/layers/recurrent_layer/#recurrent_1", 
            "text": "keras.layers.recurrent.Recurrent(weights=None, return_sequences=False, go_backwards=False, stateful=False, unroll=False, consume_less='cpu', input_dim=None, input_length=None)  \u8fd9\u662f\u9012\u5f52\u5c42\u7684\u62bd\u8c61\u7c7b\uff0c\u8bf7\u4e0d\u8981\u5728\u6a21\u578b\u4e2d\u76f4\u63a5\u5e94\u7528\u8be5\u5c42\uff08\u56e0\u4e3a\u5b83\u662f\u62bd\u8c61\u7c7b\uff0c\u65e0\u6cd5\u5b9e\u4f8b\u5316\u4efb\u4f55\u5bf9\u8c61\uff09\u3002\u8bf7\u4f7f\u7528\u5b83\u7684\u5b50\u7c7b LSTM \u6216 SimpleRNN \u3002  \u6240\u6709\u7684\u9012\u5f52\u5c42\uff08 LSTM , GRU , SimpleRNN \uff09\u90fd\u670d\u4ece\u672c\u5c42\u7684\u6027\u8d28\uff0c\u5e76\u63a5\u53d7\u672c\u5c42\u6307\u5b9a\u7684\u6240\u6709\u5173\u952e\u5b57\u53c2\u6570\u3002", 
            "title": "Recurrent\u5c42"
        }, 
        {
            "location": "/layers/recurrent_layer/#_1", 
            "text": "weights\uff1anumpy array\u7684list\uff0c\u7528\u4ee5\u521d\u59cb\u5316\u6743\u91cd\u3002\u8be5list\u5f62\u5982 [(input_dim, output_dim),(output_dim, output_dim),(output_dim,)]    return_sequences\uff1a\u5e03\u5c14\u503c\uff0c\u9ed8\u8ba4 False \uff0c\u63a7\u5236\u8fd4\u56de\u7c7b\u578b\u3002\u82e5\u4e3a True \u5219\u8fd4\u56de\u6574\u4e2a\u5e8f\u5217\uff0c\u5426\u5219\u4ec5\u8fd4\u56de\u8f93\u51fa\u5e8f\u5217\u7684\u6700\u540e\u4e00\u4e2a\u8f93\u51fa    go_backwards\uff1a\u5e03\u5c14\u503c\uff0c\u9ed8\u8ba4\u4e3a False \uff0c\u82e5\u4e3a True \uff0c\u5219\u9006\u5411\u5904\u7406\u8f93\u5165\u5e8f\u5217    stateful\uff1a\u5e03\u5c14\u503c\uff0c\u9ed8\u8ba4\u4e3a False \uff0c\u82e5\u4e3a True \uff0c\u5219\u4e00\u4e2abatch\u4e2d\u4e0b\u6807\u4e3ai\u7684\u6837\u672c\u7684\u6700\u7ec8\u72b6\u6001\u5c06\u4f1a\u7528\u4f5c\u4e0b\u4e00\u4e2abatch\u540c\u6837\u4e0b\u6807\u7684\u6837\u672c\u7684\u521d\u59cb\u72b6\u6001\u3002    unroll\uff1a\u5e03\u5c14\u503c\uff0c\u9ed8\u8ba4\u4e3a False \uff0c\u82e5\u4e3a True \uff0c\u5219\u9012\u5f52\u5c42\u5c06\u88ab\u5c55\u5f00\uff0c\u5426\u5219\u5c31\u4f7f\u7528\u7b26\u53f7\u5316\u7684\u5faa\u73af\u3002\u5f53\u4f7f\u7528TensorFlow\u4e3a\u540e\u7aef\u65f6\uff0c\u9012\u5f52\u7f51\u7edc\u672c\u6765\u5c31\u662f\u5c55\u5f00\u7684\uff0c\u56e0\u6b64\u8be5\u5c42\u4e0d\u505a\u4efb\u4f55\u4e8b\u60c5\u3002\u5c42\u5c55\u5f00\u4f1a\u5360\u7528\u66f4\u591a\u7684\u5185\u5b58\uff0c\u4f46\u4f1a\u52a0\u901fRNN\u7684\u8fd0\u7b97\u3002\u5c42\u5c55\u5f00\u53ea\u9002\u7528\u4e8e\u77ed\u5e8f\u5217\u3002    consume_less\uff1a\u2018cpu\u2019\u6216\u2018mem\u2019\u4e4b\u4e00\u3002\u82e5\u8bbe\u4e3a\u2018cpu\u2019\uff0c\u5219RNN\u5c06\u4f7f\u7528\u8f83\u5c11\u3001\u8f83\u5927\u7684\u77e9\u9635\u4e58\u6cd5\u6765\u5b9e\u73b0\uff0c\u4ece\u800c\u5728CPU\u4e0a\u4f1a\u8fd0\u884c\u66f4\u5feb\uff0c\u4f46\u4f1a\u66f4\u6d88\u8017\u5185\u5b58\u3002\u5982\u679c\u8bbe\u4e3a\u2018mem\u2019\uff0c\u5219RNN\u5c06\u4f1a\u8f83\u591a\u7684\u5c0f\u77e9\u9635\u4e58\u6cd5\u6765\u5b9e\u73b0\uff0c\u4ece\u800c\u5728GPU\u5e76\u884c\u8ba1\u7b97\u65f6\u4f1a\u8fd0\u884c\u66f4\u5feb\uff08\u4f46\u5728CPU\u4e0a\u6162\uff09\uff0c\u5e76\u5360\u7528\u8f83\u5c11\u5185\u5b58\u3002    input_dim\uff1a\u8f93\u5165\u7ef4\u5ea6\uff0c\u5f53\u4f7f\u7528\u8be5\u5c42\u4e3a\u6a21\u578b\u9996\u5c42\u65f6\uff0c\u5e94\u6307\u5b9a\u8be5\u503c\uff08\u6216\u7b49\u4ef7\u7684\u6307\u5b9ainput_shape)    input_length\uff1a\u5f53\u8f93\u5165\u5e8f\u5217\u7684\u957f\u5ea6\u56fa\u5b9a\u65f6\uff0c\u8be5\u53c2\u6570\u4e3a\u8f93\u5165\u5e8f\u5217\u7684\u957f\u5ea6\u3002\u5f53\u9700\u8981\u5728\u8be5\u5c42\u540e\u8fde\u63a5 Flatten \u5c42\uff0c\u7136\u540e\u53c8\u8981\u8fde\u63a5 Dense \u5c42\u65f6\uff0c\u9700\u8981\u6307\u5b9a\u8be5\u53c2\u6570\uff0c\u5426\u5219\u5168\u8fde\u63a5\u7684\u8f93\u51fa\u65e0\u6cd5\u8ba1\u7b97\u51fa\u6765\u3002\u6ce8\u610f\uff0c\u5982\u679c\u9012\u5f52\u5c42\u4e0d\u662f\u7f51\u7edc\u7684\u7b2c\u4e00\u5c42\uff0c\u4f60\u9700\u8981\u5728\u7f51\u7edc\u7684\u7b2c\u4e00\u5c42\u4e2d\u6307\u5b9a\u5e8f\u5217\u7684\u957f\u5ea6\uff0c\u5982\u901a\u8fc7 input_shape \u6307\u5b9a\u3002", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/layers/recurrent_layer/#shape", 
            "text": "\u5f62\u5982\uff08samples\uff0ctimesteps\uff0cinput_dim\uff09\u76843D\u5f20\u91cf", 
            "title": "\u8f93\u5165shape"
        }, 
        {
            "location": "/layers/recurrent_layer/#shape_1", 
            "text": "\u5982\u679c return_sequences=True \uff1a\u8fd4\u56de\u5f62\u5982\uff08samples\uff0ctimesteps\uff0coutput_dim\uff09\u76843D\u5f20\u91cf  \u5426\u5219\uff0c\u8fd4\u56de\u5f62\u5982\uff08samples\uff0coutput_dim\uff09\u76842D\u5f20\u91cf", 
            "title": "\u8f93\u51fashape"
        }, 
        {
            "location": "/layers/recurrent_layer/#_2", 
            "text": "# as the first layer in a Sequential model\nmodel = Sequential()\nmodel.add(LSTM(32, input_shape=(10, 64)))\n# now model.output_shape == (None, 10, 32)\n# note: `None` is the batch dimension.\n\n# the following is identical:\nmodel = Sequential()\nmodel.add(LSTM(32, input_dim=64, input_length=10))\n\n# for subsequent layers, not need to specify the input size:\nmodel.add(LSTM(16))", 
            "title": "\u4f8b\u5b50"
        }, 
        {
            "location": "/layers/recurrent_layer/#masking", 
            "text": "\u9012\u5f52\u5c42\u652f\u6301\u901a\u8fc7\u65f6\u95f4\u6b65\u53d8\u91cf\u5bf9\u8f93\u5165\u6570\u636e\u8fdb\u884cMasking\uff0c\u5982\u679c\u60f3\u5c06\u8f93\u5165\u6570\u636e\u7684\u4e00\u90e8\u5206\u5c4f\u853d\u6389\uff0c\u8bf7\u4f7f\u7528 Embedding \u5c42\u5e76\u5c06\u53c2\u6570 mask_zero \u8bbe\u4e3a True \u3002", 
            "title": "\u5c4f\u853d\u8f93\u5165\u6570\u636e\uff08Masking\uff09"
        }, 
        {
            "location": "/layers/recurrent_layer/#tensorflow", 
            "text": "\u76ee\u524d\u4e3a\u6b62\uff0c\u5f53\u4f7f\u7528TensorFlow\u4f5c\u4e3a\u540e\u7aef\u65f6\uff0c\u5e8f\u5217\u7684\u65f6\u95f4\u6b65\u6570\u76ee\u5fc5\u987b\u5728\u7f51\u7edc\u4e2d\u6307\u5b9a\u3002\u901a\u8fc7 input_length \uff08\u5982\u679c\u7f51\u7edc\u9996\u5c42\u662f\u9012\u5f52\u5c42\uff09\u6216\u5b8c\u6574\u7684 input_shape \u6765\u6307\u5b9a\u8be5\u503c\u3002", 
            "title": "TensorFlow\u8b66\u544a"
        }, 
        {
            "location": "/layers/recurrent_layer/#rnn", 
            "text": "\u53ef\u4ee5\u5c06RNN\u8bbe\u7f6e\u4e3a\u2018stateful\u2019\uff0c\u610f\u5473\u7740\u8bad\u7ec3\u65f6\u6bcf\u4e2abatch\u7684\u72b6\u6001\u90fd\u4f1a\u88ab\u91cd\u7528\u4e8e\u521d\u59cb\u5316\u4e0b\u4e00\u4e2abatch\u7684\u521d\u59cb\u72b6\u6001\u3002\u72b6\u6001RNN\u5047\u8bbe\u8fde\u7eed\u7684\u4e24\u4e2abatch\u4e4b\u4e2d\uff0c\u76f8\u540c\u4e0b\u6807\u7684\u5143\u7d20\u6709\u4e00\u4e00\u6620\u5c04\u5173\u7cfb\u3002  \u8981\u542f\u7528\u72b6\u6001RNN\uff0c\u8bf7\u5728\u5b9e\u4f8b\u5316\u5c42\u5bf9\u8c61\u65f6\u6307\u5b9a\u53c2\u6570 stateful=True \uff0c\u5e76\u6307\u5b9a\u6a21\u578b\u4f7f\u7528\u56fa\u5b9a\u5927\u5c0f\u7684batch\uff1a\u901a\u8fc7\u5728\u6a21\u578b\u7684\u7b2c\u4e00\u5c42\u4f20\u5165 batch_input_shape=(...) \u6765\u5b9e\u73b0\u3002\u8be5\u53c2\u6570\u5e94\u4e3a\u5305\u542bbatch\u5927\u5c0f\u7684\u5143\u7ec4\uff0c\u4f8b\u5982\uff0832\uff0c10\uff0c100\uff09\u4ee3\u8868\u6bcf\u4e2abatch\u7684\u5927\u5c0f\u662f32.  \u5982\u679c\u8981\u5c06\u9012\u5f52\u5c42\u7684\u72b6\u6001\u91cd\u7f6e\uff0c\u8bf7\u8c03\u7528 .reset_states() \uff0c\u5bf9\u6a21\u578b\u8c03\u7528\u5c06\u91cd\u7f6e\u6a21\u578b\u4e2d\u6240\u6709\u72b6\u6001RNN\u7684\u72b6\u6001\u3002\u5bf9\u5355\u4e2a\u5c42\u8c03\u7528\u5219\u53ea\u91cd\u7f6e\u8be5\u5c42\u7684\u72b6\u6001\u3002", 
            "title": "\u4f7f\u7528\u72b6\u6001RNN\u7684\u6ce8\u610f\u4e8b\u9879"
        }, 
        {
            "location": "/layers/recurrent_layer/#tensorflowdropout", 
            "text": "\u5f53\u4f7f\u7528TensorFlow\u4f5c\u4e3a\u540e\u7aef\u65f6\uff0c\u5982\u679c\u8981\u5728\u9012\u5f52\u5c42\u4f7f\u7528dropout\uff0c\u9700\u8981\u540c\u4e0a\u9762\u6240\u8ff0\u7684\u4e00\u6837\u6307\u5b9a\u597d\u56fa\u5b9a\u7684batch\u5927\u5c0f", 
            "title": "\u4ee5TensorFlow\u4f5c\u4e3a\u540e\u7aef\u65f6\u4f7f\u7528dropout\u7684\u6ce8\u610f\u4e8b\u9879"
        }, 
        {
            "location": "/layers/recurrent_layer/#simplernn", 
            "text": "keras.layers.recurrent.SimpleRNN(output_dim, init='glorot_uniform', inner_init='orthogonal', activation='tanh', W_regularizer=None, U_regularizer=None, b_regularizer=None, dropout_W=0.0, dropout_U=0.0)  \u5168\u8fde\u63a5RNN\u7f51\u7edc\uff0cRNN\u7684\u8f93\u51fa\u4f1a\u88ab\u56de\u9988\u5230\u8f93\u5165", 
            "title": "SimpleRNN\u5c42"
        }, 
        {
            "location": "/layers/recurrent_layer/#_3", 
            "text": "output_dim\uff1a\u5185\u90e8\u6295\u5f71\u548c\u8f93\u51fa\u7684\u7ef4\u5ea6    init\uff1a\u521d\u59cb\u5316\u65b9\u6cd5\uff0c\u4e3a\u9884\u5b9a\u4e49\u521d\u59cb\u5316\u65b9\u6cd5\u540d\u7684\u5b57\u7b26\u4e32\uff0c\u6216\u7528\u4e8e\u521d\u59cb\u5316\u6743\u91cd\u7684Theano\u51fd\u6570\u3002    inner_init\uff1a\u5185\u90e8\u5355\u5143\u7684\u521d\u59cb\u5316\u65b9\u6cd5    activation\uff1a\u6fc0\u6d3b\u51fd\u6570\uff0c\u4e3a\u9884\u5b9a\u4e49\u7684\u6fc0\u6d3b\u51fd\u6570\u540d\uff08\u53c2\u8003 \u6fc0\u6d3b\u51fd\u6570 \uff09    W_regularizer\uff1a\u65bd\u52a0\u5728\u6743\u91cd\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a WeightRegularizer \u5bf9\u8c61    U_regularizer\uff1a\u65bd\u52a0\u5728\u9012\u5f52\u6743\u91cd\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a WeightRegularizer \u5bf9\u8c61    b_regularizer\uff1a\u65bd\u52a0\u5728\u504f\u7f6e\u5411\u91cf\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a WeightRegularizer \u5bf9\u8c61    dropout_W\uff1a0~1\u4e4b\u95f4\u7684\u6d6e\u70b9\u6570\uff0c\u63a7\u5236\u8f93\u5165\u5355\u5143\u5230\u8f93\u5165\u95e8\u7684\u8fde\u63a5\u65ad\u5f00\u6bd4\u4f8b    dropout_U\uff1a0~1\u4e4b\u95f4\u7684\u6d6e\u70b9\u6570\uff0c\u63a7\u5236\u8f93\u5165\u5355\u5143\u5230\u9012\u5f52\u8fde\u63a5\u7684\u65ad\u5f00\u6bd4\u4f8b", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/layers/recurrent_layer/#_4", 
            "text": "A Theoretically Grounded Application of Dropout in Recurrent Neural Networks", 
            "title": "\u53c2\u8003\u6587\u732e"
        }, 
        {
            "location": "/layers/recurrent_layer/#gru", 
            "text": "keras.layers.recurrent.GRU(output_dim, init='glorot_uniform', inner_init='orthogonal', activation='tanh', inner_activation='hard_sigmoid', W_regularizer=None, U_regularizer=None, b_regularizer=None, dropout_W=0.0, dropout_U=0.0)  \u95e8\u9650\u9012\u5f52\u5355\u5143\uff08\u8be6\u89c1\u53c2\u8003\u6587\u732e\uff09", 
            "title": "GRU\u5c42"
        }, 
        {
            "location": "/layers/recurrent_layer/#_5", 
            "text": "output_dim\uff1a\u5185\u90e8\u6295\u5f71\u548c\u8f93\u51fa\u7684\u7ef4\u5ea6    init\uff1a\u521d\u59cb\u5316\u65b9\u6cd5\uff0c\u4e3a\u9884\u5b9a\u4e49\u521d\u59cb\u5316\u65b9\u6cd5\u540d\u7684\u5b57\u7b26\u4e32\uff0c\u6216\u7528\u4e8e\u521d\u59cb\u5316\u6743\u91cd\u7684Theano\u51fd\u6570\u3002    inner_init\uff1a\u5185\u90e8\u5355\u5143\u7684\u521d\u59cb\u5316\u65b9\u6cd5    activation\uff1a\u6fc0\u6d3b\u51fd\u6570\uff0c\u4e3a\u9884\u5b9a\u4e49\u7684\u6fc0\u6d3b\u51fd\u6570\u540d\uff08\u53c2\u8003 \u6fc0\u6d3b\u51fd\u6570 \uff09    inner_activation\uff1a\u5185\u90e8\u5355\u5143\u6fc0\u6d3b\u51fd\u6570    W_regularizer\uff1a\u65bd\u52a0\u5728\u6743\u91cd\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a WeightRegularizer \u5bf9\u8c61    U_regularizer\uff1a\u65bd\u52a0\u5728\u9012\u5f52\u6743\u91cd\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a WeightRegularizer \u5bf9\u8c61    b_regularizer\uff1a\u65bd\u52a0\u5728\u504f\u7f6e\u5411\u91cf\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a WeightRegularizer \u5bf9\u8c61    dropout_W\uff1a0~1\u4e4b\u95f4\u7684\u6d6e\u70b9\u6570\uff0c\u63a7\u5236\u8f93\u5165\u5355\u5143\u5230\u8f93\u5165\u95e8\u7684\u8fde\u63a5\u65ad\u5f00\u6bd4\u4f8b    dropout_U\uff1a0~1\u4e4b\u95f4\u7684\u6d6e\u70b9\u6570\uff0c\u63a7\u5236\u8f93\u5165\u5355\u5143\u5230\u9012\u5f52\u8fde\u63a5\u7684\u65ad\u5f00\u6bd4\u4f8b", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/layers/recurrent_layer/#_6", 
            "text": "On the Properties of Neural Machine Translation: Encoder\u2013Decoder Approaches    Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling    A Theoretically Grounded Application of Dropout in Recurrent Neural Networks", 
            "title": "\u53c2\u8003\u6587\u732e"
        }, 
        {
            "location": "/layers/recurrent_layer/#lstm", 
            "text": "keras.layers.recurrent.LSTM(output_dim, init='glorot_uniform', inner_init='orthogonal', forget_bias_init='one', activation='tanh', inner_activation='hard_sigmoid', W_regularizer=None, U_regularizer=None, b_regularizer=None, dropout_W=0.0, dropout_U=0.0)  Keras\u957f\u77ed\u671f\u8bb0\u5fc6\u6a21\u578b\uff0c\u5173\u4e8e\u6b64\u7b97\u6cd5\u7684\u8be6\u60c5\uff0c\u8bf7\u53c2\u8003 \u672c\u6559\u7a0b", 
            "title": "LSTM\u5c42"
        }, 
        {
            "location": "/layers/recurrent_layer/#_7", 
            "text": "output_dim\uff1a\u5185\u90e8\u6295\u5f71\u548c\u8f93\u51fa\u7684\u7ef4\u5ea6    init\uff1a\u521d\u59cb\u5316\u65b9\u6cd5\uff0c\u4e3a\u9884\u5b9a\u4e49\u521d\u59cb\u5316\u65b9\u6cd5\u540d\u7684\u5b57\u7b26\u4e32\uff0c\u6216\u7528\u4e8e\u521d\u59cb\u5316\u6743\u91cd\u7684Theano\u51fd\u6570\u3002    inner_init\uff1a\u5185\u90e8\u5355\u5143\u7684\u521d\u59cb\u5316\u65b9\u6cd5    forget_bias_init\uff1a\u9057\u5fd8\u95e8\u504f\u7f6e\u7684\u521d\u59cb\u5316\u51fd\u6570\uff0c Jozefowicz et al. \u5efa\u8bae\u521d\u59cb\u5316\u4e3a\u51681\u5143\u7d20    activation\uff1a\u6fc0\u6d3b\u51fd\u6570\uff0c\u4e3a\u9884\u5b9a\u4e49\u7684\u6fc0\u6d3b\u51fd\u6570\u540d\uff08\u53c2\u8003 \u6fc0\u6d3b\u51fd\u6570 \uff09    inner_activation\uff1a\u5185\u90e8\u5355\u5143\u6fc0\u6d3b\u51fd\u6570    W_regularizer\uff1a\u65bd\u52a0\u5728\u6743\u91cd\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a WeightRegularizer \u5bf9\u8c61    U_regularizer\uff1a\u65bd\u52a0\u5728\u9012\u5f52\u6743\u91cd\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a WeightRegularizer \u5bf9\u8c61    b_regularizer\uff1a\u65bd\u52a0\u5728\u504f\u7f6e\u5411\u91cf\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a WeightRegularizer \u5bf9\u8c61    dropout_W\uff1a0~1\u4e4b\u95f4\u7684\u6d6e\u70b9\u6570\uff0c\u63a7\u5236\u8f93\u5165\u5355\u5143\u5230\u8f93\u5165\u95e8\u7684\u8fde\u63a5\u65ad\u5f00\u6bd4\u4f8b    dropout_U\uff1a0~1\u4e4b\u95f4\u7684\u6d6e\u70b9\u6570\uff0c\u63a7\u5236\u8f93\u5165\u5355\u5143\u5230\u9012\u5f52\u8fde\u63a5\u7684\u65ad\u5f00\u6bd4\u4f8b", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/layers/recurrent_layer/#_8", 
            "text": "Long short-term memory  \uff08original 1997 paper\uff09    Learning to forget: Continual prediction with LSTM    Supervised sequence labelling with recurrent neural networks    A Theoretically Grounded Application of Dropout in Recurrent Neural Networks", 
            "title": "\u53c2\u8003\u6587\u732e"
        }, 
        {
            "location": "/layers/embedding_layer/", 
            "text": "\u5d4c\u5165\u5c42 Embedding\n\n\nEmbedding\u5c42\n\n\nkeras.layers.embeddings.Embedding(input_dim, output_dim, init='uniform', input_length=None, W_regularizer=None, activity_regularizer=None, W_constraint=None, mask_zero=False, weights=None, dropout=0.0)\n\n\n\n\n\u5d4c\u5165\u5c42\u5c06\u6b63\u6574\u6570\uff08\u4e0b\u6807\uff09\u8f6c\u6362\u4e3a\u5177\u6709\u56fa\u5b9a\u5927\u5c0f\u7684\u5411\u91cf\uff0c\u5982[[4],[20]]-\n[[0.25,0.1],[0.6,-0.2]]\n\n\nEmbedding\u5c42\u53ea\u80fd\u4f5c\u4e3a\u6a21\u578b\u7684\u7b2c\u4e00\u5c42\n\n\n\u53c2\u6570\n\n\n\n\n\n\ninput_dim\uff1a\u5927\u6216\u7b49\u4e8e0\u7684\u6574\u6570\uff0c\u5b57\u5178\u957f\u5ea6\uff0c\u5373\u8f93\u5165\u6570\u636e\u6700\u5927\u4e0b\u6807+1\n\n\n\n\n\n\noutput_dim\uff1a\u5927\u4e8e0\u7684\u6574\u6570\uff0c\u4ee3\u8868\u5168\u8fde\u63a5\u5d4c\u5165\u7684\u7ef4\u5ea6\n\n\n\n\n\n\ninit\uff1a\u521d\u59cb\u5316\u65b9\u6cd5\uff0c\u4e3a\u9884\u5b9a\u4e49\u521d\u59cb\u5316\u65b9\u6cd5\u540d\u7684\u5b57\u7b26\u4e32\uff0c\u6216\u7528\u4e8e\u521d\u59cb\u5316\u6743\u91cd\u7684Theano\u51fd\u6570\u3002\u8be5\u53c2\u6570\u4ec5\u5728\u4e0d\u4f20\u9012\nweights\n\u53c2\u6570\u65f6\u6709\u610f\u4e49\u3002\n\n\n\n\n\n\nweights\uff1a\u6743\u503c\uff0c\u4e3anumpy array\u7684list\u3002\u8be5list\u5e94\u4ec5\u542b\u6709\u4e00\u4e2a\u5982\uff08input_dim,output_dim\uff09\u7684\u6743\u91cd\u77e9\u9635\n\n\n\n\n\n\nW_regularizer\uff1a\u65bd\u52a0\u5728\u6743\u91cd\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a\nWeightRegularizer\n\u5bf9\u8c61\n\n\n\n\n\n\nW_constraints\uff1a\u65bd\u52a0\u5728\u6743\u91cd\u4e0a\u7684\u7ea6\u675f\u9879\uff0c\u4e3a\nConstraints\n\u5bf9\u8c61\n\n\n\n\n\n\nmask_zero\uff1a\u5e03\u5c14\u503c\uff0c\u786e\u5b9a\u662f\u5426\u5c06\u8f93\u5165\u4e2d\u7684\u20180\u2019\u770b\u4f5c\u662f\u5e94\u8be5\u88ab\u5ffd\u7565\u7684\u2018\u586b\u5145\u2019\uff08padding\uff09\u503c\uff0c\u8be5\u53c2\u6570\u5728\u4f7f\u7528\n\u9012\u5f52\u5c42\n\u5904\u7406\u53d8\u957f\u8f93\u5165\u65f6\u6709\u7528\u3002\u8bbe\u7f6e\u4e3a\nTrue\n\u7684\u8bdd\uff0c\u6a21\u578b\u4e2d\u540e\u7eed\u7684\u5c42\u5fc5\u987b\u90fd\u652f\u6301masking\uff0c\u5426\u5219\u4f1a\u629b\u51fa\u5f02\u5e38\n\n\n\n\n\n\ninput_length\uff1a\u5f53\u8f93\u5165\u5e8f\u5217\u7684\u957f\u5ea6\u56fa\u5b9a\u65f6\uff0c\u8be5\u503c\u4e3a\u5176\u957f\u5ea6\u3002\u5982\u679c\u8981\u5728\u8be5\u5c42\u540e\u63a5\nFlatten\n\u5c42\uff0c\u7136\u540e\u63a5\nDense\n\u5c42\uff0c\u5219\u5fc5\u987b\u6307\u5b9a\u8be5\u53c2\u6570\uff0c\u5426\u5219\nDense\n\u5c42\u7684\u8f93\u51fa\u7ef4\u5ea6\u65e0\u6cd5\u81ea\u52a8\u63a8\u65ad\u3002\n\n\n\n\n\n\ndropout\uff1a0~1\u7684\u6d6e\u70b9\u6570\uff0c\u4ee3\u8868\u8981\u65ad\u5f00\u7684\u5d4c\u5165\u6bd4\u4f8b\uff0c\n\n\n\n\n\n\n\u8f93\u5165shape\n\n\n\u5f62\u5982\uff08samples\uff0csequence_length\uff09\u76842D\u5f20\u91cf\n\n\n\u8f93\u51fashape\n\n\n\u5f62\u5982(samples, sequence_length, output_dim)\u76843D\u5f20\u91cf\n\n\n\u53c2\u8003\u6587\u732e\n\n\n\n\nA Theoretically Grounded Application of Dropout in Recurrent Neural Networks", 
            "title": "\u5d4c\u5165\u5c42Embedding"
        }, 
        {
            "location": "/layers/embedding_layer/#embedding", 
            "text": "", 
            "title": "\u5d4c\u5165\u5c42 Embedding"
        }, 
        {
            "location": "/layers/embedding_layer/#embedding_1", 
            "text": "keras.layers.embeddings.Embedding(input_dim, output_dim, init='uniform', input_length=None, W_regularizer=None, activity_regularizer=None, W_constraint=None, mask_zero=False, weights=None, dropout=0.0)  \u5d4c\u5165\u5c42\u5c06\u6b63\u6574\u6570\uff08\u4e0b\u6807\uff09\u8f6c\u6362\u4e3a\u5177\u6709\u56fa\u5b9a\u5927\u5c0f\u7684\u5411\u91cf\uff0c\u5982[[4],[20]]- [[0.25,0.1],[0.6,-0.2]]  Embedding\u5c42\u53ea\u80fd\u4f5c\u4e3a\u6a21\u578b\u7684\u7b2c\u4e00\u5c42", 
            "title": "Embedding\u5c42"
        }, 
        {
            "location": "/layers/embedding_layer/#_1", 
            "text": "input_dim\uff1a\u5927\u6216\u7b49\u4e8e0\u7684\u6574\u6570\uff0c\u5b57\u5178\u957f\u5ea6\uff0c\u5373\u8f93\u5165\u6570\u636e\u6700\u5927\u4e0b\u6807+1    output_dim\uff1a\u5927\u4e8e0\u7684\u6574\u6570\uff0c\u4ee3\u8868\u5168\u8fde\u63a5\u5d4c\u5165\u7684\u7ef4\u5ea6    init\uff1a\u521d\u59cb\u5316\u65b9\u6cd5\uff0c\u4e3a\u9884\u5b9a\u4e49\u521d\u59cb\u5316\u65b9\u6cd5\u540d\u7684\u5b57\u7b26\u4e32\uff0c\u6216\u7528\u4e8e\u521d\u59cb\u5316\u6743\u91cd\u7684Theano\u51fd\u6570\u3002\u8be5\u53c2\u6570\u4ec5\u5728\u4e0d\u4f20\u9012 weights \u53c2\u6570\u65f6\u6709\u610f\u4e49\u3002    weights\uff1a\u6743\u503c\uff0c\u4e3anumpy array\u7684list\u3002\u8be5list\u5e94\u4ec5\u542b\u6709\u4e00\u4e2a\u5982\uff08input_dim,output_dim\uff09\u7684\u6743\u91cd\u77e9\u9635    W_regularizer\uff1a\u65bd\u52a0\u5728\u6743\u91cd\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a WeightRegularizer \u5bf9\u8c61    W_constraints\uff1a\u65bd\u52a0\u5728\u6743\u91cd\u4e0a\u7684\u7ea6\u675f\u9879\uff0c\u4e3a Constraints \u5bf9\u8c61    mask_zero\uff1a\u5e03\u5c14\u503c\uff0c\u786e\u5b9a\u662f\u5426\u5c06\u8f93\u5165\u4e2d\u7684\u20180\u2019\u770b\u4f5c\u662f\u5e94\u8be5\u88ab\u5ffd\u7565\u7684\u2018\u586b\u5145\u2019\uff08padding\uff09\u503c\uff0c\u8be5\u53c2\u6570\u5728\u4f7f\u7528 \u9012\u5f52\u5c42 \u5904\u7406\u53d8\u957f\u8f93\u5165\u65f6\u6709\u7528\u3002\u8bbe\u7f6e\u4e3a True \u7684\u8bdd\uff0c\u6a21\u578b\u4e2d\u540e\u7eed\u7684\u5c42\u5fc5\u987b\u90fd\u652f\u6301masking\uff0c\u5426\u5219\u4f1a\u629b\u51fa\u5f02\u5e38    input_length\uff1a\u5f53\u8f93\u5165\u5e8f\u5217\u7684\u957f\u5ea6\u56fa\u5b9a\u65f6\uff0c\u8be5\u503c\u4e3a\u5176\u957f\u5ea6\u3002\u5982\u679c\u8981\u5728\u8be5\u5c42\u540e\u63a5 Flatten \u5c42\uff0c\u7136\u540e\u63a5 Dense \u5c42\uff0c\u5219\u5fc5\u987b\u6307\u5b9a\u8be5\u53c2\u6570\uff0c\u5426\u5219 Dense \u5c42\u7684\u8f93\u51fa\u7ef4\u5ea6\u65e0\u6cd5\u81ea\u52a8\u63a8\u65ad\u3002    dropout\uff1a0~1\u7684\u6d6e\u70b9\u6570\uff0c\u4ee3\u8868\u8981\u65ad\u5f00\u7684\u5d4c\u5165\u6bd4\u4f8b\uff0c", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/layers/embedding_layer/#shape", 
            "text": "\u5f62\u5982\uff08samples\uff0csequence_length\uff09\u76842D\u5f20\u91cf", 
            "title": "\u8f93\u5165shape"
        }, 
        {
            "location": "/layers/embedding_layer/#shape_1", 
            "text": "\u5f62\u5982(samples, sequence_length, output_dim)\u76843D\u5f20\u91cf", 
            "title": "\u8f93\u51fashape"
        }, 
        {
            "location": "/layers/embedding_layer/#_2", 
            "text": "A Theoretically Grounded Application of Dropout in Recurrent Neural Networks", 
            "title": "\u53c2\u8003\u6587\u732e"
        }, 
        {
            "location": "/layers/advanced_activation_layer/", 
            "text": "\u9ad8\u7ea7\u6fc0\u6d3b\u5c42Advanced Activation\n\n\nLeakyReLU\u5c42\n\n\nkeras.layers.advanced_activations.LeakyReLU(alpha=0.3)\n\n\n\n\nLeakyRelU\u662f\u4fee\u6b63\u7ebf\u6027\u5355\u5143\uff08Rectified Linear Unit\uff0cReLU\uff09\u7684\u7279\u6b8a\u7248\u672c\uff0c\u5f53\u4e0d\u6fc0\u6d3b\u65f6\uff0cLeakyReLU\u4ecd\u7136\u4f1a\u6709\u975e\u96f6\u8f93\u51fa\u503c\uff0c\u4ece\u800c\u83b7\u5f97\u4e00\u4e2a\u5c0f\u68af\u5ea6\uff0c\u907f\u514dReLU\u53ef\u80fd\u51fa\u73b0\u7684\u795e\u7ecf\u5143\u201c\u6b7b\u4ea1\u201d\u73b0\u8c61\u3002\u5373\uff0c\nf(x)=alpha * x for x \n 0\n, \nf(x) = x for x\n=0\n\n\n\u53c2\u6570\n\n\n\n\nalpha\uff1a\u5927\u4e8e0\u7684\u6d6e\u70b9\u6570\uff0c\u4ee3\u8868\u6fc0\u6d3b\u51fd\u6570\u56fe\u50cf\u4e2d\u7b2c\u4e09\u8c61\u9650\u7ebf\u6bb5\u7684\u659c\u7387\n\n\n\n\n\u8f93\u5165shape\n\n\n\u4efb\u610f\uff0c\u5f53\u4f7f\u7528\u8be5\u5c42\u4e3a\u6a21\u578b\u9996\u5c42\u65f6\u9700\u6307\u5b9a\ninput_shape\n\u53c2\u6570\n\n\n\u8f93\u51fashape\n\n\n\u4e0e\u8f93\u5165\u76f8\u540c\n\n\n\n\nPReLU\u5c42\n\n\nkeras.layers.advanced_activations.PReLU(init='zero', weights=None, shared_axes=None)\n\n\n\n\n\u8be5\u5c42\u4e3a\u53c2\u6570\u5316\u7684ReLU\uff08Parametric ReLU\uff09\uff0c\u8868\u8fbe\u5f0f\u662f\uff1a\nf(x) = alpha * x for x \n 0\n, \nf(x) = x for x\n=0\n\uff0c\u6b64\u5904\u7684\nalpha\n\u4e3a\u4e00\u4e2a\u4e0exshape\u76f8\u540c\u7684\u53ef\u5b66\u4e60\u7684\u53c2\u6570\u5411\u91cf\u3002\n\n\n\u53c2\u6570\n\n\n\n\n\n\ninit\uff1aalpha\u7684\u521d\u59cb\u5316\u51fd\u6570\n\n\n\n\n\n\nweights\uff1aalpha\u7684\u521d\u59cb\u5316\u503c\uff0c\u4e3a\u5177\u6709\u5355\u4e2anumpy array\u7684list\n\n\n\n\n\n\nshared_axes\uff1a\u8be5\u53c2\u6570\u6307\u5b9a\u7684\u8f74\u5c06\u5171\u4eab\u540c\u4e00\u7ec4\u79d1\u5b66\u7cfb\u53c2\u6570\uff0c\u4f8b\u5982\u5047\u5982\u8f93\u5165\u7279\u5f81\u56fe\u662f\u4ece2D\u5377\u79ef\u8fc7\u6765\u7684\uff0c\u5177\u6709\u5f62\u5982\n(batch, height, width, channels)\n\u8fd9\u6837\u7684shape\uff0c\u5219\u6216\u8bb8\u4f60\u4f1a\u5e0c\u671b\u5728\u7a7a\u57df\u5171\u4eab\u53c2\u6570\uff0c\u8fd9\u6837\u6bcf\u4e2afilter\u5c31\u53ea\u6709\u4e00\u7ec4\u53c2\u6570\uff0c\u8bbe\u5b9a\nshared_axes=[1,2]\n\u53ef\u5b8c\u6210\u8be5\u76ee\u6807\n\n\n\n\n\n\n\u8f93\u5165shape\n\n\n\u4efb\u610f\uff0c\u5f53\u4f7f\u7528\u8be5\u5c42\u4e3a\u6a21\u578b\u9996\u5c42\u65f6\u9700\u6307\u5b9a\ninput_shape\n\u53c2\u6570\n\n\n\u8f93\u51fashape\n\n\n\u4e0e\u8f93\u5165\u76f8\u540c\n\n\n\u53c2\u8003\u6587\u732e\n\n\n\n\nDelving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification\n\n\n\n\n\n\nELU\u5c42\n\n\nkeras.layers.advanced_activations.ELU(alpha=1.0)\n\n\n\n\nELU\u5c42\u662f\u6307\u6570\u7ebf\u6027\u5355\u5143\uff08Exponential Linera Unit\uff09\uff0c\u8868\u8fbe\u5f0f\u4e3a\uff1a\n\u8be5\u5c42\u4e3a\u53c2\u6570\u5316\u7684ReLU\uff08Parametric ReLU\uff09\uff0c\u8868\u8fbe\u5f0f\u662f\uff1a\nf(x) = alpha * (exp(x) - 1.) for x \n 0\n, \nf(x) = x for x\n=0\n\n\n\u53c2\u6570\n\n\n\n\nalpha\uff1a\u63a7\u5236\u8d1f\u56e0\u5b50\u7684\u53c2\u6570\n\n\n\n\n\u8f93\u5165shape\n\n\n\u4efb\u610f\uff0c\u5f53\u4f7f\u7528\u8be5\u5c42\u4e3a\u6a21\u578b\u9996\u5c42\u65f6\u9700\u6307\u5b9a\ninput_shape\n\u53c2\u6570\n\n\n\u8f93\u51fashape\n\n\n\u4e0e\u8f93\u5165\u76f8\u540c\n\n\n\u53c2\u8003\u6587\u732e\n\n\n\n\nFast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)\n\n\n\n\n\n\nParametricSoftplus\u5c42\n\n\nkeras.layers.advanced_activations.ParametricSoftplus(alpha_init=0.2, beta_init=5.0, weights=None, shared_axes=None)\n\n\n\n\n\u8be5\u5c42\u662f\u53c2\u6570\u5316\u7684Softplus\uff0c\u8868\u8fbe\u5f0f\u662f\uff1a\nf(x) = alpha * log(1 + exp(beta * x))\n\n\n\u53c2\u6570\n\n\n\n\n\n\nalpha_init\uff1a\u6d6e\u70b9\u6570\uff0calpha\u7684\u521d\u59cb\u503c\n\n\n\n\n\n\nbeta_init\uff1a\u6d6e\u70b9\u6570\uff0cbeta\u7684\u521d\u59cb\u503c\n\n\n\n\n\n\nweights\uff1a\u521d\u59cb\u5316\u6743\u91cd\uff0c\u4e3a\u542b\u6709\u4e24\u4e2anumpy array\u7684list\n\n\n\n\n\n\nshared_axes\uff1a\u8be5\u53c2\u6570\u6307\u5b9a\u7684\u8f74\u5c06\u5171\u4eab\u540c\u4e00\u7ec4\u79d1\u5b66\u7cfb\u53c2\u6570\uff0c\u4f8b\u5982\u5047\u5982\u8f93\u5165\u7279\u5f81\u56fe\u662f\u4ece2D\u5377\u79ef\u8fc7\u6765\u7684\uff0c\u5177\u6709\u5f62\u5982\n(batch, height, width, channels)\n\u8fd9\u6837\u7684shape\uff0c\u5219\u6216\u8bb8\u4f60\u4f1a\u5e0c\u671b\u5728\u7a7a\u57df\u5171\u4eab\u53c2\u6570\uff0c\u8fd9\u6837\u6bcf\u4e2afilter\u5c31\u53ea\u6709\u4e00\u7ec4\u53c2\u6570\uff0c\u8bbe\u5b9a\nshared_axes=[1,2]\n\u53ef\u5b8c\u6210\u8be5\u76ee\u6807\n\n\n\n\n\n\n\u8f93\u5165shape\n\n\n\u4efb\u610f\uff0c\u5f53\u4f7f\u7528\u8be5\u5c42\u4e3a\u6a21\u578b\u9996\u5c42\u65f6\u9700\u6307\u5b9a\ninput_shape\n\u53c2\u6570\n\n\n\u8f93\u51fashape\n\n\n\u4e0e\u8f93\u5165\u76f8\u540c\n\n\n\u53c2\u8003\u6587\u732e\n\n\n\n\nInferring Nonlinear Neuronal Computation Based on Physiologically Plausible Inputs\n\n\n\n\n\n\nThresholdedReLU\u5c42\n\n\nkeras.layers.advanced_activations.ThresholdedReLU(theta=1.0)\n\n\n\n\n\u8be5\u5c42\u662f\u5e26\u6709\u95e8\u9650\u7684ReLU\uff0c\u8868\u8fbe\u5f0f\u662f\uff1a\nf(x) = x for x \n theta\n,\nf(x) = 0 otherwise\n\n\n\u53c2\u6570\n\n\n\n\ntheata\uff1a\u5927\u6216\u7b49\u4e8e0\u7684\u6d6e\u70b9\u6570\uff0c\u6fc0\u6d3b\u95e8\u9650\u4f4d\u7f6e\n\n\n\n\n\u8f93\u5165shape\n\n\n\u4efb\u610f\uff0c\u5f53\u4f7f\u7528\u8be5\u5c42\u4e3a\u6a21\u578b\u9996\u5c42\u65f6\u9700\u6307\u5b9a\ninput_shape\n\u53c2\u6570\n\n\n\u8f93\u51fashape\n\n\n\u4e0e\u8f93\u5165\u76f8\u540c\n\n\n\u53c2\u8003\u6587\u732e\n\n\n\n\nZero-Bias Autoencoders and the Benefits of Co-Adapting Features\n\n\n\n\n\n\n\n\nSReLU\u5c42\n\n\nkeras.layers.advanced_activations.SReLU(t_left_init='zero', a_left_init='glorot_uniform', t_right_init='glorot_uniform', a_right_init='one', shared_axes=None)\n\n\n\n\n\u8be5\u5c42\u662fS\u5f62\u7684ReLU\n\n\n\u53c2\u6570\n\n\n\n\n\n\nt_left_init\uff1a\u5de6\u4fa7\u622a\u65ad\u521d\u59cb\u5316\u51fd\u6570\n\n\n\n\n\n\na_left_init\uff1a\u5de6\u4fa7\u659c\u7387\u521d\u59cb\u5316\u51fd\u6570\n\n\n\n\n\n\nt_right_init\uff1a\u53f3\u4fa7\u622a\u65ad\u521d\u59cb\u5316\u51fd\u6570\n\n\n\n\n\n\na_right_init\uff1a\u53f3\u4fa7\u659c\u7387\u521d\u59cb\u5316\u51fd\u6570\n\n\n\n\n\n\nshared_axes\uff1a\u8be5\u53c2\u6570\u6307\u5b9a\u7684\u8f74\u5c06\u5171\u4eab\u540c\u4e00\u7ec4\u79d1\u5b66\u7cfb\u53c2\u6570\uff0c\u4f8b\u5982\u5047\u5982\u8f93\u5165\u7279\u5f81\u56fe\u662f\u4ece2D\u5377\u79ef\u8fc7\u6765\u7684\uff0c\u5177\u6709\u5f62\u5982\n(batch, height, width, channels)\n\u8fd9\u6837\u7684shape\uff0c\u5219\u6216\u8bb8\u4f60\u4f1a\u5e0c\u671b\u5728\u7a7a\u57df\u5171\u4eab\u53c2\u6570\uff0c\u8fd9\u6837\u6bcf\u4e2afilter\u5c31\u53ea\u6709\u4e00\u7ec4\u53c2\u6570\uff0c\u8bbe\u5b9a\nshared_axes=[1,2]\n\u53ef\u5b8c\u6210\u8be5\u76ee\u6807\n\n\n\n\n\n\n\u8f93\u5165shape\n\n\n\u4efb\u610f\uff0c\u5f53\u4f7f\u7528\u8be5\u5c42\u4e3a\u6a21\u578b\u9996\u5c42\u65f6\u9700\u6307\u5b9a\ninput_shape\n\u53c2\u6570\n\n\n\u8f93\u51fashape\n\n\n\u4e0e\u8f93\u5165\u76f8\u540c\n\n\n\u53c2\u8003\u6587\u732e\n\n\n\n\nDeep Learning with S-shaped Rectified Linear Activation Units", 
            "title": "\u9ad8\u7ea7\u6fc0\u6d3b\u5c42Advanced Activation"
        }, 
        {
            "location": "/layers/advanced_activation_layer/#advanced-activation", 
            "text": "", 
            "title": "\u9ad8\u7ea7\u6fc0\u6d3b\u5c42Advanced Activation"
        }, 
        {
            "location": "/layers/advanced_activation_layer/#leakyrelu", 
            "text": "keras.layers.advanced_activations.LeakyReLU(alpha=0.3)  LeakyRelU\u662f\u4fee\u6b63\u7ebf\u6027\u5355\u5143\uff08Rectified Linear Unit\uff0cReLU\uff09\u7684\u7279\u6b8a\u7248\u672c\uff0c\u5f53\u4e0d\u6fc0\u6d3b\u65f6\uff0cLeakyReLU\u4ecd\u7136\u4f1a\u6709\u975e\u96f6\u8f93\u51fa\u503c\uff0c\u4ece\u800c\u83b7\u5f97\u4e00\u4e2a\u5c0f\u68af\u5ea6\uff0c\u907f\u514dReLU\u53ef\u80fd\u51fa\u73b0\u7684\u795e\u7ecf\u5143\u201c\u6b7b\u4ea1\u201d\u73b0\u8c61\u3002\u5373\uff0c f(x)=alpha * x for x   0 ,  f(x) = x for x =0", 
            "title": "LeakyReLU\u5c42"
        }, 
        {
            "location": "/layers/advanced_activation_layer/#_1", 
            "text": "alpha\uff1a\u5927\u4e8e0\u7684\u6d6e\u70b9\u6570\uff0c\u4ee3\u8868\u6fc0\u6d3b\u51fd\u6570\u56fe\u50cf\u4e2d\u7b2c\u4e09\u8c61\u9650\u7ebf\u6bb5\u7684\u659c\u7387", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/layers/advanced_activation_layer/#shape", 
            "text": "\u4efb\u610f\uff0c\u5f53\u4f7f\u7528\u8be5\u5c42\u4e3a\u6a21\u578b\u9996\u5c42\u65f6\u9700\u6307\u5b9a input_shape \u53c2\u6570", 
            "title": "\u8f93\u5165shape"
        }, 
        {
            "location": "/layers/advanced_activation_layer/#shape_1", 
            "text": "\u4e0e\u8f93\u5165\u76f8\u540c", 
            "title": "\u8f93\u51fashape"
        }, 
        {
            "location": "/layers/advanced_activation_layer/#prelu", 
            "text": "keras.layers.advanced_activations.PReLU(init='zero', weights=None, shared_axes=None)  \u8be5\u5c42\u4e3a\u53c2\u6570\u5316\u7684ReLU\uff08Parametric ReLU\uff09\uff0c\u8868\u8fbe\u5f0f\u662f\uff1a f(x) = alpha * x for x   0 ,  f(x) = x for x =0 \uff0c\u6b64\u5904\u7684 alpha \u4e3a\u4e00\u4e2a\u4e0exshape\u76f8\u540c\u7684\u53ef\u5b66\u4e60\u7684\u53c2\u6570\u5411\u91cf\u3002", 
            "title": "PReLU\u5c42"
        }, 
        {
            "location": "/layers/advanced_activation_layer/#_2", 
            "text": "init\uff1aalpha\u7684\u521d\u59cb\u5316\u51fd\u6570    weights\uff1aalpha\u7684\u521d\u59cb\u5316\u503c\uff0c\u4e3a\u5177\u6709\u5355\u4e2anumpy array\u7684list    shared_axes\uff1a\u8be5\u53c2\u6570\u6307\u5b9a\u7684\u8f74\u5c06\u5171\u4eab\u540c\u4e00\u7ec4\u79d1\u5b66\u7cfb\u53c2\u6570\uff0c\u4f8b\u5982\u5047\u5982\u8f93\u5165\u7279\u5f81\u56fe\u662f\u4ece2D\u5377\u79ef\u8fc7\u6765\u7684\uff0c\u5177\u6709\u5f62\u5982 (batch, height, width, channels) \u8fd9\u6837\u7684shape\uff0c\u5219\u6216\u8bb8\u4f60\u4f1a\u5e0c\u671b\u5728\u7a7a\u57df\u5171\u4eab\u53c2\u6570\uff0c\u8fd9\u6837\u6bcf\u4e2afilter\u5c31\u53ea\u6709\u4e00\u7ec4\u53c2\u6570\uff0c\u8bbe\u5b9a shared_axes=[1,2] \u53ef\u5b8c\u6210\u8be5\u76ee\u6807", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/layers/advanced_activation_layer/#shape_2", 
            "text": "\u4efb\u610f\uff0c\u5f53\u4f7f\u7528\u8be5\u5c42\u4e3a\u6a21\u578b\u9996\u5c42\u65f6\u9700\u6307\u5b9a input_shape \u53c2\u6570", 
            "title": "\u8f93\u5165shape"
        }, 
        {
            "location": "/layers/advanced_activation_layer/#shape_3", 
            "text": "\u4e0e\u8f93\u5165\u76f8\u540c", 
            "title": "\u8f93\u51fashape"
        }, 
        {
            "location": "/layers/advanced_activation_layer/#_3", 
            "text": "Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification", 
            "title": "\u53c2\u8003\u6587\u732e"
        }, 
        {
            "location": "/layers/advanced_activation_layer/#elu", 
            "text": "keras.layers.advanced_activations.ELU(alpha=1.0)  ELU\u5c42\u662f\u6307\u6570\u7ebf\u6027\u5355\u5143\uff08Exponential Linera Unit\uff09\uff0c\u8868\u8fbe\u5f0f\u4e3a\uff1a\n\u8be5\u5c42\u4e3a\u53c2\u6570\u5316\u7684ReLU\uff08Parametric ReLU\uff09\uff0c\u8868\u8fbe\u5f0f\u662f\uff1a f(x) = alpha * (exp(x) - 1.) for x   0 ,  f(x) = x for x =0", 
            "title": "ELU\u5c42"
        }, 
        {
            "location": "/layers/advanced_activation_layer/#_4", 
            "text": "alpha\uff1a\u63a7\u5236\u8d1f\u56e0\u5b50\u7684\u53c2\u6570", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/layers/advanced_activation_layer/#shape_4", 
            "text": "\u4efb\u610f\uff0c\u5f53\u4f7f\u7528\u8be5\u5c42\u4e3a\u6a21\u578b\u9996\u5c42\u65f6\u9700\u6307\u5b9a input_shape \u53c2\u6570", 
            "title": "\u8f93\u5165shape"
        }, 
        {
            "location": "/layers/advanced_activation_layer/#shape_5", 
            "text": "\u4e0e\u8f93\u5165\u76f8\u540c", 
            "title": "\u8f93\u51fashape"
        }, 
        {
            "location": "/layers/advanced_activation_layer/#_5", 
            "text": "Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)", 
            "title": "\u53c2\u8003\u6587\u732e"
        }, 
        {
            "location": "/layers/advanced_activation_layer/#parametricsoftplus", 
            "text": "keras.layers.advanced_activations.ParametricSoftplus(alpha_init=0.2, beta_init=5.0, weights=None, shared_axes=None)  \u8be5\u5c42\u662f\u53c2\u6570\u5316\u7684Softplus\uff0c\u8868\u8fbe\u5f0f\u662f\uff1a f(x) = alpha * log(1 + exp(beta * x))", 
            "title": "ParametricSoftplus\u5c42"
        }, 
        {
            "location": "/layers/advanced_activation_layer/#_6", 
            "text": "alpha_init\uff1a\u6d6e\u70b9\u6570\uff0calpha\u7684\u521d\u59cb\u503c    beta_init\uff1a\u6d6e\u70b9\u6570\uff0cbeta\u7684\u521d\u59cb\u503c    weights\uff1a\u521d\u59cb\u5316\u6743\u91cd\uff0c\u4e3a\u542b\u6709\u4e24\u4e2anumpy array\u7684list    shared_axes\uff1a\u8be5\u53c2\u6570\u6307\u5b9a\u7684\u8f74\u5c06\u5171\u4eab\u540c\u4e00\u7ec4\u79d1\u5b66\u7cfb\u53c2\u6570\uff0c\u4f8b\u5982\u5047\u5982\u8f93\u5165\u7279\u5f81\u56fe\u662f\u4ece2D\u5377\u79ef\u8fc7\u6765\u7684\uff0c\u5177\u6709\u5f62\u5982 (batch, height, width, channels) \u8fd9\u6837\u7684shape\uff0c\u5219\u6216\u8bb8\u4f60\u4f1a\u5e0c\u671b\u5728\u7a7a\u57df\u5171\u4eab\u53c2\u6570\uff0c\u8fd9\u6837\u6bcf\u4e2afilter\u5c31\u53ea\u6709\u4e00\u7ec4\u53c2\u6570\uff0c\u8bbe\u5b9a shared_axes=[1,2] \u53ef\u5b8c\u6210\u8be5\u76ee\u6807", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/layers/advanced_activation_layer/#shape_6", 
            "text": "\u4efb\u610f\uff0c\u5f53\u4f7f\u7528\u8be5\u5c42\u4e3a\u6a21\u578b\u9996\u5c42\u65f6\u9700\u6307\u5b9a input_shape \u53c2\u6570", 
            "title": "\u8f93\u5165shape"
        }, 
        {
            "location": "/layers/advanced_activation_layer/#shape_7", 
            "text": "\u4e0e\u8f93\u5165\u76f8\u540c", 
            "title": "\u8f93\u51fashape"
        }, 
        {
            "location": "/layers/advanced_activation_layer/#_7", 
            "text": "Inferring Nonlinear Neuronal Computation Based on Physiologically Plausible Inputs", 
            "title": "\u53c2\u8003\u6587\u732e"
        }, 
        {
            "location": "/layers/advanced_activation_layer/#thresholdedrelu", 
            "text": "keras.layers.advanced_activations.ThresholdedReLU(theta=1.0)  \u8be5\u5c42\u662f\u5e26\u6709\u95e8\u9650\u7684ReLU\uff0c\u8868\u8fbe\u5f0f\u662f\uff1a f(x) = x for x   theta , f(x) = 0 otherwise", 
            "title": "ThresholdedReLU\u5c42"
        }, 
        {
            "location": "/layers/advanced_activation_layer/#_8", 
            "text": "theata\uff1a\u5927\u6216\u7b49\u4e8e0\u7684\u6d6e\u70b9\u6570\uff0c\u6fc0\u6d3b\u95e8\u9650\u4f4d\u7f6e", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/layers/advanced_activation_layer/#shape_8", 
            "text": "\u4efb\u610f\uff0c\u5f53\u4f7f\u7528\u8be5\u5c42\u4e3a\u6a21\u578b\u9996\u5c42\u65f6\u9700\u6307\u5b9a input_shape \u53c2\u6570", 
            "title": "\u8f93\u5165shape"
        }, 
        {
            "location": "/layers/advanced_activation_layer/#shape_9", 
            "text": "\u4e0e\u8f93\u5165\u76f8\u540c", 
            "title": "\u8f93\u51fashape"
        }, 
        {
            "location": "/layers/advanced_activation_layer/#_9", 
            "text": "Zero-Bias Autoencoders and the Benefits of Co-Adapting Features", 
            "title": "\u53c2\u8003\u6587\u732e"
        }, 
        {
            "location": "/layers/advanced_activation_layer/#srelu", 
            "text": "keras.layers.advanced_activations.SReLU(t_left_init='zero', a_left_init='glorot_uniform', t_right_init='glorot_uniform', a_right_init='one', shared_axes=None)  \u8be5\u5c42\u662fS\u5f62\u7684ReLU", 
            "title": "SReLU\u5c42"
        }, 
        {
            "location": "/layers/advanced_activation_layer/#_10", 
            "text": "t_left_init\uff1a\u5de6\u4fa7\u622a\u65ad\u521d\u59cb\u5316\u51fd\u6570    a_left_init\uff1a\u5de6\u4fa7\u659c\u7387\u521d\u59cb\u5316\u51fd\u6570    t_right_init\uff1a\u53f3\u4fa7\u622a\u65ad\u521d\u59cb\u5316\u51fd\u6570    a_right_init\uff1a\u53f3\u4fa7\u659c\u7387\u521d\u59cb\u5316\u51fd\u6570    shared_axes\uff1a\u8be5\u53c2\u6570\u6307\u5b9a\u7684\u8f74\u5c06\u5171\u4eab\u540c\u4e00\u7ec4\u79d1\u5b66\u7cfb\u53c2\u6570\uff0c\u4f8b\u5982\u5047\u5982\u8f93\u5165\u7279\u5f81\u56fe\u662f\u4ece2D\u5377\u79ef\u8fc7\u6765\u7684\uff0c\u5177\u6709\u5f62\u5982 (batch, height, width, channels) \u8fd9\u6837\u7684shape\uff0c\u5219\u6216\u8bb8\u4f60\u4f1a\u5e0c\u671b\u5728\u7a7a\u57df\u5171\u4eab\u53c2\u6570\uff0c\u8fd9\u6837\u6bcf\u4e2afilter\u5c31\u53ea\u6709\u4e00\u7ec4\u53c2\u6570\uff0c\u8bbe\u5b9a shared_axes=[1,2] \u53ef\u5b8c\u6210\u8be5\u76ee\u6807", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/layers/advanced_activation_layer/#shape_10", 
            "text": "\u4efb\u610f\uff0c\u5f53\u4f7f\u7528\u8be5\u5c42\u4e3a\u6a21\u578b\u9996\u5c42\u65f6\u9700\u6307\u5b9a input_shape \u53c2\u6570", 
            "title": "\u8f93\u5165shape"
        }, 
        {
            "location": "/layers/advanced_activation_layer/#shape_11", 
            "text": "\u4e0e\u8f93\u5165\u76f8\u540c", 
            "title": "\u8f93\u51fashape"
        }, 
        {
            "location": "/layers/advanced_activation_layer/#_11", 
            "text": "Deep Learning with S-shaped Rectified Linear Activation Units", 
            "title": "\u53c2\u8003\u6587\u732e"
        }, 
        {
            "location": "/layers/normalization_layer/", 
            "text": "\uff08\u6279\uff09\u89c4\u8303\u5316BatchNormalization\n\n\nBatchNormalization\u5c42\n\n\nkeras.layers.normalization.BatchNormalization(epsilon=1e-06, mode=0, axis=-1, momentum=0.9, weights=None, beta_init='zero', gamma_init='one')\n\n\n\n\n\u8be5\u5c42\u5728\u6bcf\u4e2abatch\u4e0a\u5c06\u524d\u4e00\u5c42\u7684\u6fc0\u6d3b\u503c\u91cd\u65b0\u89c4\u8303\u5316\uff0c\u5373\u4f7f\u5f97\u5176\u8f93\u51fa\u6570\u636e\u7684\u5747\u503c\u63a5\u8fd10\uff0c\u5176\u6807\u51c6\u5dee\u63a5\u8fd11\n\n\n\u53c2\u6570\n\n\n\n\n\n\nepsilon\uff1a\u5927\u4e8e0\u7684\u5c0f\u6d6e\u70b9\u6570\uff0c\u7528\u4e8e\u9632\u6b62\u96640\u9519\u8bef\n\n\n\n\n\n\nmode\uff1a\u6574\u6570\uff0c\u6307\u5b9a\u89c4\u8303\u5316\u7684\u6a21\u5f0f\uff0c\u53d60\u62161\n\n\n\n\n0\uff1a\u6309\u7279\u5f81\u89c4\u8303\u5316\uff0c\u8f93\u5165\u7684\u5404\u4e2a\u7279\u5f81\u56fe\u5c06\u72ec\u7acb\u88ab\u89c4\u8303\u5316\u3002\u89c4\u8303\u5316\u7684\u8f74\u7531\u53c2\u6570\naxis\n\u6307\u5b9a\u3002\u6ce8\u610f\uff0c\u5982\u679c\u8f93\u5165\u662f\u2018th\u2019\u683c\u5f0f\u5f62\u72b6\u7684\uff08samples\uff0cchannels\uff0crows\uff0ccols\uff09\u76844D\u56fe\u50cf\u5f20\u91cf\uff0c\u5219\u5e94\u8bbe\u7f6e\u89c4\u8303\u5316\u7684\u8f74\u4e3a1\uff0c\u5373\u6cbf\u7740\u901a\u9053\u8f74\u89c4\u8303\u5316\u3002\u5728\u8bad\u7ec3\u9636\u6bb5\uff0c\u6211\u4eec\u4f7f\u7528\u6bcf\u4e2abatch\u6570\u636e\u7684\u7edf\u8ba1\u4fe1\u606f\uff08\u5982\uff1a\u5747\u503c\u3001\u6807\u51c6\u5dee\u7b49\uff09\u6765\u5bf9\u8bad\u7ec3\u6570\u636e\u8fdb\u884c\u89c4\u8303\u5316\uff0c\u800c\u5728\u6d4b\u8bd5\u9636\u6bb5\uff0c\u6211\u4eec\u4f7f\u7528\u8bad\u7ec3\u65f6\u5f97\u5230\u7684\u7edf\u8ba1\u4fe1\u606f\u7684\u6ed1\u52a8\u5e73\u5747\u6765\u5bf9\u6d4b\u8bd5\u6570\u636e\u8fdb\u884c\u89c4\u8303\u5316\u3002    \n\n\n1\uff1a\u6309\u6837\u672c\u89c4\u8303\u5316\uff0c\u8be5\u6a21\u5f0f\u9ed8\u8ba4\u8f93\u5165\u4e3a2D\n\n\n2: \u6309\u7279\u5f81\u89c4\u8303\u5316, \u4e0e\u6a21\u5f0f0\u76f8\u4f3c, \u4f46\u4e0d\u540c\u4e4b\u5904\u5728\u4e8e\uff1a\u5728\u8bad\u7ec3\u548c\u6d4b\u8bd5\u8fc7\u7a0b\u4e2d\uff0c\u5747\u4f7f\u7528\u6bcf\u4e2abatch\u6570\u636e\u7684\u7edf\u8ba1\u4fe1\u606f\u800c\u5206\u522b\u5bf9\u8bad\u7ec3\u6570\u636e\u548c\u6d4b\u8bd5\u6570\u636e\u8fdb\u884c\u89c4\u8303\u5316\u3002\n\n\naxis\uff1a\u6574\u6570\uff0c\u6307\u5b9a\u5f53\nmode=0\n\u65f6\u89c4\u8303\u5316\u7684\u8f74\u3002\u4f8b\u5982\u8f93\u5165\u662f\u5f62\u5982\uff08samples\uff0cchannels\uff0crows\uff0ccols\uff09\u76844D\u56fe\u50cf\u5f20\u91cf\uff0c\u5219\u5e94\u8bbe\u7f6e\u89c4\u8303\u5316\u7684\u8f74\u4e3a1\uff0c\u610f\u5473\u7740\u5bf9\u6bcf\u4e2a\u7279\u5f81\u56fe\u8fdb\u884c\u89c4\u8303\u5316\n\n\n\n\n\n\n\n\nmomentum\uff1a\u5728\u6309\u7279\u5f81\u89c4\u8303\u5316\u65f6\uff0c\u8ba1\u7b97\u6570\u636e\u7684\u6307\u6570\u5e73\u5747\u6570\u548c\u6807\u51c6\u5dee\u65f6\u7684\u52a8\u91cf\n\n\n\n\n\n\nweights\uff1a\u521d\u59cb\u5316\u6743\u91cd\uff0c\u4e3a\u5305\u542b2\u4e2anumpy array\u7684list\uff0c\u5176shape\u4e3a\n[(input_shape,),(input_shape)]\n\n\n\n\n\n\nbeta_init\uff1abeta\u7684\u521d\u59cb\u5316\u65b9\u6cd5\uff0c\u4e3a\u9884\u5b9a\u4e49\u521d\u59cb\u5316\u65b9\u6cd5\u540d\u7684\u5b57\u7b26\u4e32\uff0c\u6216\u7528\u4e8e\u521d\u59cb\u5316\u6743\u91cd\u7684Theano\u51fd\u6570\u3002\u8be5\u53c2\u6570\u4ec5\u5728\u4e0d\u4f20\u9012\nweights\n\u53c2\u6570\u65f6\u6709\u610f\u4e49\u3002\n\n\n\n\n\n\ngamma_init\uff1agamma\u7684\u521d\u59cb\u5316\u65b9\u6cd5\uff0c\u4e3a\u9884\u5b9a\u4e49\u521d\u59cb\u5316\u65b9\u6cd5\u540d\u7684\u5b57\u7b26\u4e32\uff0c\u6216\u7528\u4e8e\u521d\u59cb\u5316\u6743\u91cd\u7684Theano\u51fd\u6570\u3002\u8be5\u53c2\u6570\u4ec5\u5728\u4e0d\u4f20\u9012\nweights\n\u53c2\u6570\u65f6\u6709\u610f\u4e49\u3002\n\n\n\n\n\n\ngamma_regularizer\uff1aWeightRegularizer(\u5982L1\u6216L2\u6b63\u5219\u5316)\u7684\u5b9e\u4f8b\uff0c\u4f5c\u7528\u5728gamma\u5411\u91cf\u4e0a\u3002\n\n\n\n\n\n\nbeta_regularizer\uff1aWeightRegularizer\u7684\u5b9e\u4f8b\uff0c\u4f5c\u7528\u5728beta\u5411\u91cf\u4e0a\u3002\n\n\n\n\n\n\n\u8f93\u5165shape\n\n\n\u4efb\u610f\uff0c\u5f53\u4f7f\u7528\u672c\u5c42\u4e3a\u6a21\u578b\u9996\u5c42\u65f6\uff0c\u6307\u5b9a\ninput_shape\n\u53c2\u6570\u65f6\u6709\u610f\u4e49\u3002\n\n\n\u8f93\u51fashape\n\n\n\u4e0e\u8f93\u5165shape\u76f8\u540c\n\n\n\u53c2\u8003\u6587\u732e\n\n\n\n\nBatch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift\n\n\n\n\n\u3010Tips\u3011\u7edf\u8ba1\u5b66\u4e60\u7684\u4e00\u4e2a\u91cd\u8981\u5047\u8bbe\u662f\u6e90\u7a7a\u95f4\u4e0e\u76ee\u6807\u7a7a\u95f4\u7684\u6570\u636e\u5206\u5e03\u662f\u4e00\u81f4\u7684\uff0c\u800c\u795e\u7ecf\u7f51\u7edc\u5404\u5c42\u8f93\u51fa\u7684\u5206\u5e03\u4e0d\u4e00\u5b9a\u4e0e\u8f93\u5165\u4e00\u81f4\uff0c\u5c24\u5176\u5f53\u7f51\u7edc\u8d8a\u6df1\uff0c\u8fd9\u79cd\u4e0d\u4e00\u81f4\u8d8a\u660e\u663e\u3002BatchNormalization\u628a\u5206\u5e03\u4e00\u81f4\u5f31\u5316\u4e3a\u5747\u503c\u4e0e\u65b9\u5dee\u4e00\u81f4\uff0c\u7136\u800c\u5373\u4f7f\u662f\u8fd9\u79cd\u5f31\u5316\u7684\u7248\u672c\u4e5f\u5bf9\u5b66\u4e60\u8fc7\u7a0b\u8d77\u5230\u4e86\u91cd\u8981\u6548\u679c\u3002\u53e6\u4e00\u65b9\u9762\uff0cBN\u7684\u66f4\u91cd\u8981\u4f5c\u7528\u662f\u9632\u6b62\u68af\u5ea6\u5f25\u6563\uff0c\u5b83\u901a\u8fc7\u5c06\u6fc0\u6d3b\u503c\u89c4\u8303\u4e3a\u7edf\u4e00\u7684\u5747\u503c\u548c\u65b9\u5dee\uff0c\u5c06\u539f\u672c\u4f1a\u51cf\u5c0f\u7684\u6fc0\u6d3b\u503c\u5f97\u5230\u653e\u5927\u3002\u3010@Bigmoyan\u3011", 
            "title": "\u89c4\u8303\u5c42BatchNormalization"
        }, 
        {
            "location": "/layers/normalization_layer/#batchnormalization", 
            "text": "", 
            "title": "\uff08\u6279\uff09\u89c4\u8303\u5316BatchNormalization"
        }, 
        {
            "location": "/layers/normalization_layer/#batchnormalization_1", 
            "text": "keras.layers.normalization.BatchNormalization(epsilon=1e-06, mode=0, axis=-1, momentum=0.9, weights=None, beta_init='zero', gamma_init='one')  \u8be5\u5c42\u5728\u6bcf\u4e2abatch\u4e0a\u5c06\u524d\u4e00\u5c42\u7684\u6fc0\u6d3b\u503c\u91cd\u65b0\u89c4\u8303\u5316\uff0c\u5373\u4f7f\u5f97\u5176\u8f93\u51fa\u6570\u636e\u7684\u5747\u503c\u63a5\u8fd10\uff0c\u5176\u6807\u51c6\u5dee\u63a5\u8fd11", 
            "title": "BatchNormalization\u5c42"
        }, 
        {
            "location": "/layers/normalization_layer/#_1", 
            "text": "epsilon\uff1a\u5927\u4e8e0\u7684\u5c0f\u6d6e\u70b9\u6570\uff0c\u7528\u4e8e\u9632\u6b62\u96640\u9519\u8bef    mode\uff1a\u6574\u6570\uff0c\u6307\u5b9a\u89c4\u8303\u5316\u7684\u6a21\u5f0f\uff0c\u53d60\u62161   0\uff1a\u6309\u7279\u5f81\u89c4\u8303\u5316\uff0c\u8f93\u5165\u7684\u5404\u4e2a\u7279\u5f81\u56fe\u5c06\u72ec\u7acb\u88ab\u89c4\u8303\u5316\u3002\u89c4\u8303\u5316\u7684\u8f74\u7531\u53c2\u6570 axis \u6307\u5b9a\u3002\u6ce8\u610f\uff0c\u5982\u679c\u8f93\u5165\u662f\u2018th\u2019\u683c\u5f0f\u5f62\u72b6\u7684\uff08samples\uff0cchannels\uff0crows\uff0ccols\uff09\u76844D\u56fe\u50cf\u5f20\u91cf\uff0c\u5219\u5e94\u8bbe\u7f6e\u89c4\u8303\u5316\u7684\u8f74\u4e3a1\uff0c\u5373\u6cbf\u7740\u901a\u9053\u8f74\u89c4\u8303\u5316\u3002\u5728\u8bad\u7ec3\u9636\u6bb5\uff0c\u6211\u4eec\u4f7f\u7528\u6bcf\u4e2abatch\u6570\u636e\u7684\u7edf\u8ba1\u4fe1\u606f\uff08\u5982\uff1a\u5747\u503c\u3001\u6807\u51c6\u5dee\u7b49\uff09\u6765\u5bf9\u8bad\u7ec3\u6570\u636e\u8fdb\u884c\u89c4\u8303\u5316\uff0c\u800c\u5728\u6d4b\u8bd5\u9636\u6bb5\uff0c\u6211\u4eec\u4f7f\u7528\u8bad\u7ec3\u65f6\u5f97\u5230\u7684\u7edf\u8ba1\u4fe1\u606f\u7684\u6ed1\u52a8\u5e73\u5747\u6765\u5bf9\u6d4b\u8bd5\u6570\u636e\u8fdb\u884c\u89c4\u8303\u5316\u3002      1\uff1a\u6309\u6837\u672c\u89c4\u8303\u5316\uff0c\u8be5\u6a21\u5f0f\u9ed8\u8ba4\u8f93\u5165\u4e3a2D  2: \u6309\u7279\u5f81\u89c4\u8303\u5316, \u4e0e\u6a21\u5f0f0\u76f8\u4f3c, \u4f46\u4e0d\u540c\u4e4b\u5904\u5728\u4e8e\uff1a\u5728\u8bad\u7ec3\u548c\u6d4b\u8bd5\u8fc7\u7a0b\u4e2d\uff0c\u5747\u4f7f\u7528\u6bcf\u4e2abatch\u6570\u636e\u7684\u7edf\u8ba1\u4fe1\u606f\u800c\u5206\u522b\u5bf9\u8bad\u7ec3\u6570\u636e\u548c\u6d4b\u8bd5\u6570\u636e\u8fdb\u884c\u89c4\u8303\u5316\u3002  axis\uff1a\u6574\u6570\uff0c\u6307\u5b9a\u5f53 mode=0 \u65f6\u89c4\u8303\u5316\u7684\u8f74\u3002\u4f8b\u5982\u8f93\u5165\u662f\u5f62\u5982\uff08samples\uff0cchannels\uff0crows\uff0ccols\uff09\u76844D\u56fe\u50cf\u5f20\u91cf\uff0c\u5219\u5e94\u8bbe\u7f6e\u89c4\u8303\u5316\u7684\u8f74\u4e3a1\uff0c\u610f\u5473\u7740\u5bf9\u6bcf\u4e2a\u7279\u5f81\u56fe\u8fdb\u884c\u89c4\u8303\u5316     momentum\uff1a\u5728\u6309\u7279\u5f81\u89c4\u8303\u5316\u65f6\uff0c\u8ba1\u7b97\u6570\u636e\u7684\u6307\u6570\u5e73\u5747\u6570\u548c\u6807\u51c6\u5dee\u65f6\u7684\u52a8\u91cf    weights\uff1a\u521d\u59cb\u5316\u6743\u91cd\uff0c\u4e3a\u5305\u542b2\u4e2anumpy array\u7684list\uff0c\u5176shape\u4e3a [(input_shape,),(input_shape)]    beta_init\uff1abeta\u7684\u521d\u59cb\u5316\u65b9\u6cd5\uff0c\u4e3a\u9884\u5b9a\u4e49\u521d\u59cb\u5316\u65b9\u6cd5\u540d\u7684\u5b57\u7b26\u4e32\uff0c\u6216\u7528\u4e8e\u521d\u59cb\u5316\u6743\u91cd\u7684Theano\u51fd\u6570\u3002\u8be5\u53c2\u6570\u4ec5\u5728\u4e0d\u4f20\u9012 weights \u53c2\u6570\u65f6\u6709\u610f\u4e49\u3002    gamma_init\uff1agamma\u7684\u521d\u59cb\u5316\u65b9\u6cd5\uff0c\u4e3a\u9884\u5b9a\u4e49\u521d\u59cb\u5316\u65b9\u6cd5\u540d\u7684\u5b57\u7b26\u4e32\uff0c\u6216\u7528\u4e8e\u521d\u59cb\u5316\u6743\u91cd\u7684Theano\u51fd\u6570\u3002\u8be5\u53c2\u6570\u4ec5\u5728\u4e0d\u4f20\u9012 weights \u53c2\u6570\u65f6\u6709\u610f\u4e49\u3002    gamma_regularizer\uff1aWeightRegularizer(\u5982L1\u6216L2\u6b63\u5219\u5316)\u7684\u5b9e\u4f8b\uff0c\u4f5c\u7528\u5728gamma\u5411\u91cf\u4e0a\u3002    beta_regularizer\uff1aWeightRegularizer\u7684\u5b9e\u4f8b\uff0c\u4f5c\u7528\u5728beta\u5411\u91cf\u4e0a\u3002", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/layers/normalization_layer/#shape", 
            "text": "\u4efb\u610f\uff0c\u5f53\u4f7f\u7528\u672c\u5c42\u4e3a\u6a21\u578b\u9996\u5c42\u65f6\uff0c\u6307\u5b9a input_shape \u53c2\u6570\u65f6\u6709\u610f\u4e49\u3002", 
            "title": "\u8f93\u5165shape"
        }, 
        {
            "location": "/layers/normalization_layer/#shape_1", 
            "text": "\u4e0e\u8f93\u5165shape\u76f8\u540c", 
            "title": "\u8f93\u51fashape"
        }, 
        {
            "location": "/layers/normalization_layer/#_2", 
            "text": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift   \u3010Tips\u3011\u7edf\u8ba1\u5b66\u4e60\u7684\u4e00\u4e2a\u91cd\u8981\u5047\u8bbe\u662f\u6e90\u7a7a\u95f4\u4e0e\u76ee\u6807\u7a7a\u95f4\u7684\u6570\u636e\u5206\u5e03\u662f\u4e00\u81f4\u7684\uff0c\u800c\u795e\u7ecf\u7f51\u7edc\u5404\u5c42\u8f93\u51fa\u7684\u5206\u5e03\u4e0d\u4e00\u5b9a\u4e0e\u8f93\u5165\u4e00\u81f4\uff0c\u5c24\u5176\u5f53\u7f51\u7edc\u8d8a\u6df1\uff0c\u8fd9\u79cd\u4e0d\u4e00\u81f4\u8d8a\u660e\u663e\u3002BatchNormalization\u628a\u5206\u5e03\u4e00\u81f4\u5f31\u5316\u4e3a\u5747\u503c\u4e0e\u65b9\u5dee\u4e00\u81f4\uff0c\u7136\u800c\u5373\u4f7f\u662f\u8fd9\u79cd\u5f31\u5316\u7684\u7248\u672c\u4e5f\u5bf9\u5b66\u4e60\u8fc7\u7a0b\u8d77\u5230\u4e86\u91cd\u8981\u6548\u679c\u3002\u53e6\u4e00\u65b9\u9762\uff0cBN\u7684\u66f4\u91cd\u8981\u4f5c\u7528\u662f\u9632\u6b62\u68af\u5ea6\u5f25\u6563\uff0c\u5b83\u901a\u8fc7\u5c06\u6fc0\u6d3b\u503c\u89c4\u8303\u4e3a\u7edf\u4e00\u7684\u5747\u503c\u548c\u65b9\u5dee\uff0c\u5c06\u539f\u672c\u4f1a\u51cf\u5c0f\u7684\u6fc0\u6d3b\u503c\u5f97\u5230\u653e\u5927\u3002\u3010@Bigmoyan\u3011", 
            "title": "\u53c2\u8003\u6587\u732e"
        }, 
        {
            "location": "/layers/noise_layer/", 
            "text": "\u566a\u58f0\u5c42Noise\n\n\nGaussianNoise\u5c42\n\n\nkeras.layers.noise.GaussianNoise(sigma)\n\n\n\n\n\u4e3a\u5c42\u7684\u8f93\u5165\u65bd\u52a00\u5747\u503c\uff0c\u6807\u51c6\u5dee\u4e3a\nsigma\n\u7684\u52a0\u6027\u9ad8\u65af\u566a\u58f0\u3002\u8be5\u5c42\u5728\u514b\u670d\u8fc7\u62df\u5408\u65f6\u6bd4\u8f83\u6709\u7528\uff0c\u4f60\u53ef\u4ee5\u5c06\u5b83\u770b\u4f5c\u662f\u968f\u673a\u7684\u6570\u636e\u63d0\u5347\u3002\u9ad8\u65af\u566a\u58f0\u662f\u9700\u8981\u5bf9\u8f93\u5165\u6570\u636e\u8fdb\u884c\u7834\u574f\u65f6\u7684\u81ea\u7136\u9009\u62e9\u3002\n\n\n\u4e00\u4e2a\u4f7f\u7528\u566a\u58f0\u5c42\u7684\u5178\u578b\u6848\u4f8b\u662f\u6784\u5efa\u53bb\u566a\u81ea\u52a8\u7f16\u7801\u5668\uff0c\u5373Denoising AutoEncoder\uff08DAE\uff09\u3002\u8be5\u7f16\u7801\u5668\u8bd5\u56fe\u4ece\u52a0\u566a\u7684\u8f93\u5165\u4e2d\u91cd\u6784\u65e0\u566a\u4fe1\u53f7\uff0c\u4ee5\u5b66\u4e60\u5230\u539f\u59cb\u4fe1\u53f7\u7684\u9c81\u68d2\u6027\u8868\u793a\u3002\n\n\n\u56e0\u4e3a\u8fd9\u662f\u4e00\u4e2a\u8d77\u6b63\u5219\u5316\u4f5c\u7528\u7684\u5c42\uff0c\u8be5\u5c42\u53ea\u5728\u8bad\u7ec3\u65f6\u624d\u6709\u6548\u3002\n\n\n\u53c2\u6570\n\n\n\n\nsigma\uff1a\u6d6e\u70b9\u6570\uff0c\u4ee3\u8868\u8981\u4ea7\u751f\u7684\u9ad8\u65af\u566a\u58f0\u6807\u51c6\u5dee\n\n\n\n\n\u8f93\u5165shape\n\n\n\u4efb\u610f\uff0c\u5f53\u4f7f\u7528\u8be5\u5c42\u4e3a\u6a21\u578b\u9996\u5c42\u65f6\u9700\u6307\u5b9a\ninput_shape\n\u53c2\u6570\n\n\n\u8f93\u51fashape\n\n\n\u4e0e\u8f93\u5165\u76f8\u540c\n\n\n\n\nGaussianDropout\u5c42\n\n\nkeras.layers.noise.GaussianDropout(p)\n\n\n\n\n\u4e3a\u5c42\u7684\u8f93\u5165\u65bd\u52a0\u4ee51\u4e3a\u5747\u503c\uff0c\u6807\u51c6\u5dee\u4e3a\nsqrt(p/(1-p)\n\u7684\u4e58\u6027\u9ad8\u65af\u566a\u58f0\n\n\n\u56e0\u4e3a\u8fd9\u662f\u4e00\u4e2a\u8d77\u6b63\u5219\u5316\u4f5c\u7528\u7684\u5c42\uff0c\u8be5\u5c42\u53ea\u5728\u8bad\u7ec3\u65f6\u624d\u6709\u6548\u3002\n\n\n\u53c2\u6570\n\n\n\n\np\uff1a\u6d6e\u70b9\u6570\uff0c\u65ad\u8fde\u6982\u7387\uff0c\u4e0e\nDropout\u5c42\n\u76f8\u540c\n\n\n\n\n\u8f93\u5165shape\n\n\n\u4efb\u610f\uff0c\u5f53\u4f7f\u7528\u8be5\u5c42\u4e3a\u6a21\u578b\u9996\u5c42\u65f6\u9700\u6307\u5b9a\ninput_shape\n\u53c2\u6570\n\n\n\u8f93\u51fashape\n\n\n\u4e0e\u8f93\u5165\u76f8\u540c\n\n\n\u53c2\u8003\u6587\u732e\n\n\n\n\nDropout: A Simple Way to Prevent Neural Networks from Overfitting", 
            "title": "\u566a\u58f0\u5c42Noise"
        }, 
        {
            "location": "/layers/noise_layer/#noise", 
            "text": "", 
            "title": "\u566a\u58f0\u5c42Noise"
        }, 
        {
            "location": "/layers/noise_layer/#gaussiannoise", 
            "text": "keras.layers.noise.GaussianNoise(sigma)  \u4e3a\u5c42\u7684\u8f93\u5165\u65bd\u52a00\u5747\u503c\uff0c\u6807\u51c6\u5dee\u4e3a sigma \u7684\u52a0\u6027\u9ad8\u65af\u566a\u58f0\u3002\u8be5\u5c42\u5728\u514b\u670d\u8fc7\u62df\u5408\u65f6\u6bd4\u8f83\u6709\u7528\uff0c\u4f60\u53ef\u4ee5\u5c06\u5b83\u770b\u4f5c\u662f\u968f\u673a\u7684\u6570\u636e\u63d0\u5347\u3002\u9ad8\u65af\u566a\u58f0\u662f\u9700\u8981\u5bf9\u8f93\u5165\u6570\u636e\u8fdb\u884c\u7834\u574f\u65f6\u7684\u81ea\u7136\u9009\u62e9\u3002  \u4e00\u4e2a\u4f7f\u7528\u566a\u58f0\u5c42\u7684\u5178\u578b\u6848\u4f8b\u662f\u6784\u5efa\u53bb\u566a\u81ea\u52a8\u7f16\u7801\u5668\uff0c\u5373Denoising AutoEncoder\uff08DAE\uff09\u3002\u8be5\u7f16\u7801\u5668\u8bd5\u56fe\u4ece\u52a0\u566a\u7684\u8f93\u5165\u4e2d\u91cd\u6784\u65e0\u566a\u4fe1\u53f7\uff0c\u4ee5\u5b66\u4e60\u5230\u539f\u59cb\u4fe1\u53f7\u7684\u9c81\u68d2\u6027\u8868\u793a\u3002  \u56e0\u4e3a\u8fd9\u662f\u4e00\u4e2a\u8d77\u6b63\u5219\u5316\u4f5c\u7528\u7684\u5c42\uff0c\u8be5\u5c42\u53ea\u5728\u8bad\u7ec3\u65f6\u624d\u6709\u6548\u3002", 
            "title": "GaussianNoise\u5c42"
        }, 
        {
            "location": "/layers/noise_layer/#_1", 
            "text": "sigma\uff1a\u6d6e\u70b9\u6570\uff0c\u4ee3\u8868\u8981\u4ea7\u751f\u7684\u9ad8\u65af\u566a\u58f0\u6807\u51c6\u5dee", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/layers/noise_layer/#shape", 
            "text": "\u4efb\u610f\uff0c\u5f53\u4f7f\u7528\u8be5\u5c42\u4e3a\u6a21\u578b\u9996\u5c42\u65f6\u9700\u6307\u5b9a input_shape \u53c2\u6570", 
            "title": "\u8f93\u5165shape"
        }, 
        {
            "location": "/layers/noise_layer/#shape_1", 
            "text": "\u4e0e\u8f93\u5165\u76f8\u540c", 
            "title": "\u8f93\u51fashape"
        }, 
        {
            "location": "/layers/noise_layer/#gaussiandropout", 
            "text": "keras.layers.noise.GaussianDropout(p)  \u4e3a\u5c42\u7684\u8f93\u5165\u65bd\u52a0\u4ee51\u4e3a\u5747\u503c\uff0c\u6807\u51c6\u5dee\u4e3a sqrt(p/(1-p) \u7684\u4e58\u6027\u9ad8\u65af\u566a\u58f0  \u56e0\u4e3a\u8fd9\u662f\u4e00\u4e2a\u8d77\u6b63\u5219\u5316\u4f5c\u7528\u7684\u5c42\uff0c\u8be5\u5c42\u53ea\u5728\u8bad\u7ec3\u65f6\u624d\u6709\u6548\u3002", 
            "title": "GaussianDropout\u5c42"
        }, 
        {
            "location": "/layers/noise_layer/#_2", 
            "text": "p\uff1a\u6d6e\u70b9\u6570\uff0c\u65ad\u8fde\u6982\u7387\uff0c\u4e0e Dropout\u5c42 \u76f8\u540c", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/layers/noise_layer/#shape_2", 
            "text": "\u4efb\u610f\uff0c\u5f53\u4f7f\u7528\u8be5\u5c42\u4e3a\u6a21\u578b\u9996\u5c42\u65f6\u9700\u6307\u5b9a input_shape \u53c2\u6570", 
            "title": "\u8f93\u5165shape"
        }, 
        {
            "location": "/layers/noise_layer/#shape_3", 
            "text": "\u4e0e\u8f93\u5165\u76f8\u540c", 
            "title": "\u8f93\u51fashape"
        }, 
        {
            "location": "/layers/noise_layer/#_3", 
            "text": "Dropout: A Simple Way to Prevent Neural Networks from Overfitting", 
            "title": "\u53c2\u8003\u6587\u732e"
        }, 
        {
            "location": "/layers/wrapper/", 
            "text": "\u5305\u88c5\u5668Wrapper\n\n\nTimeDistributed\u5305\u88c5\u5668\n\n\nkeras.layers.wrappers.TimeDistributed(layer)\n\n\n\n\n\u8be5\u5305\u88c5\u5668\u53ef\u4ee5\u628a\u4e00\u4e2a\u5c42\u5e94\u7528\u5230\u8f93\u5165\u7684\u6bcf\u4e00\u4e2a\u65f6\u95f4\u6b65\u4e0a\n\n\n\u53c2\u6570\n\n\n\n\nlayer\uff1aKeras\u5c42\u5bf9\u8c61\n\n\n\n\n\u8f93\u5165\u81f3\u5c11\u4e3a3D\u5f20\u91cf\uff0c\u4e0b\u6807\u4e3a1\u7684\u7ef4\u5ea6\u5c06\u88ab\u8ba4\u4e3a\u662f\u65f6\u95f4\u7ef4\n\n\n\u4f8b\u5982\uff0c\u8003\u8651\u4e00\u4e2a\u542b\u670932\u4e2a\u6837\u672c\u7684batch\uff0c\u6bcf\u4e2a\u6837\u672c\u90fd\u662f10\u4e2a\u5411\u91cf\u7ec4\u6210\u7684\u5e8f\u5217\uff0c\u6bcf\u4e2a\u5411\u91cf\u957f\u4e3a16\uff0c\u5219\u5176\u8f93\u5165\u7ef4\u5ea6\u4e3a\n(32,10,16)\n\uff0c\u5176\u4e0d\u5305\u542bbatch\u5927\u5c0f\u7684\ninput_shape\n\u4e3a\n(10,16)\n\n\n\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u5305\u88c5\u5668\nTimeDistributed\n\u5305\u88c5\nDense\n\uff0c\u4ee5\u4ea7\u751f\u9488\u5bf9\u5404\u4e2a\u65f6\u95f4\u6b65\u4fe1\u53f7\u7684\u72ec\u7acb\u5168\u8fde\u63a5\uff1a\n\n\n# as the first layer in a model\nmodel = Sequential()\nmodel.add(TimeDistributed(Dense(8), input_shape=(10, 16)))\n# now model.output_shape == (None, 10, 8)\n\n# subsequent layers: no need for input_shape\nmodel.add(TimeDistributed(Dense(32)))\n# now model.output_shape == (None, 10, 32)\n\n\n\n\n\u7a0b\u5e8f\u7684\u8f93\u51fa\u6570\u636eshape\u4e3a\n(32,10,8)\n\n\n\u4f7f\u7528\nTimeDistributed\n\u5305\u88c5\nDense\n\u4e25\u683c\u7b49\u4ef7\u4e8e\nlayers.TimeDistribuedDense\n\u3002\u4e0d\u540c\u7684\u662f\u5305\u88c5\u5668\nTimeDistribued\n\u8fd8\u53ef\u4ee5\u5bf9\u522b\u7684\u5c42\u8fdb\u884c\u5305\u88c5\uff0c\u5982\u8fd9\u91cc\u5bf9\nConvolution2D\n\u5305\u88c5\uff1a\n\n\nmodel = Sequential()\nmodel.add(TimeDistributed(Convolution2D(64, 3, 3), input_shape=(10, 3, 299, 299)))\n\n\n\n\nBidirectional\u5305\u88c5\u5668\n\n\nkeras.layers.wrappers.Bidirectional(layer, merge_mode='concat', weights=None)\n\n\n\n\n\u53cc\u5411RNN\u5305\u88c5\u5668\n\n\n\u53c2\u6570\n\n\n\n\nlayer\uff1a\nRecurrent\n\u5bf9\u8c61\n\n\nmerge_mode\uff1a\u524d\u5411\u548c\u540e\u5411RNN\u8f93\u51fa\u7684\u7ed3\u5408\u65b9\u5f0f\uff0c\u4e3a\nsum\n,\nmul\n,\nconcat\n,\nave\n\u548c\nNone\n\u4e4b\u4e00\uff0c\u82e5\u8bbe\u4e3aNone\uff0c\u5219\u8fd4\u56de\u503c\u4e0d\u7ed3\u5408\uff0c\u800c\u662f\u4ee5\u5217\u8868\u7684\u5f62\u5f0f\u8fd4\u56de\n\n\n\n\n\u4f8b\u5b50\n\n\nmodel = Sequential()\nmodel.add(Bidirectional(LSTM(10, return_sequences=True), input_shape=(5, 10)))\nmodel.add(Bidirectional(LSTM(10)))\nmodel.add(Dense(5))\nmodel.add(Activation('softmax'))\nmodel.compile(loss='categorical_crossentropy', optimizer='rmsprop')", 
            "title": "\u5305\u88c5\u5668Wrapper"
        }, 
        {
            "location": "/layers/wrapper/#wrapper", 
            "text": "", 
            "title": "\u5305\u88c5\u5668Wrapper"
        }, 
        {
            "location": "/layers/wrapper/#timedistributed", 
            "text": "keras.layers.wrappers.TimeDistributed(layer)  \u8be5\u5305\u88c5\u5668\u53ef\u4ee5\u628a\u4e00\u4e2a\u5c42\u5e94\u7528\u5230\u8f93\u5165\u7684\u6bcf\u4e00\u4e2a\u65f6\u95f4\u6b65\u4e0a", 
            "title": "TimeDistributed\u5305\u88c5\u5668"
        }, 
        {
            "location": "/layers/wrapper/#_1", 
            "text": "layer\uff1aKeras\u5c42\u5bf9\u8c61   \u8f93\u5165\u81f3\u5c11\u4e3a3D\u5f20\u91cf\uff0c\u4e0b\u6807\u4e3a1\u7684\u7ef4\u5ea6\u5c06\u88ab\u8ba4\u4e3a\u662f\u65f6\u95f4\u7ef4  \u4f8b\u5982\uff0c\u8003\u8651\u4e00\u4e2a\u542b\u670932\u4e2a\u6837\u672c\u7684batch\uff0c\u6bcf\u4e2a\u6837\u672c\u90fd\u662f10\u4e2a\u5411\u91cf\u7ec4\u6210\u7684\u5e8f\u5217\uff0c\u6bcf\u4e2a\u5411\u91cf\u957f\u4e3a16\uff0c\u5219\u5176\u8f93\u5165\u7ef4\u5ea6\u4e3a (32,10,16) \uff0c\u5176\u4e0d\u5305\u542bbatch\u5927\u5c0f\u7684 input_shape \u4e3a (10,16)  \u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u5305\u88c5\u5668 TimeDistributed \u5305\u88c5 Dense \uff0c\u4ee5\u4ea7\u751f\u9488\u5bf9\u5404\u4e2a\u65f6\u95f4\u6b65\u4fe1\u53f7\u7684\u72ec\u7acb\u5168\u8fde\u63a5\uff1a  # as the first layer in a model\nmodel = Sequential()\nmodel.add(TimeDistributed(Dense(8), input_shape=(10, 16)))\n# now model.output_shape == (None, 10, 8)\n\n# subsequent layers: no need for input_shape\nmodel.add(TimeDistributed(Dense(32)))\n# now model.output_shape == (None, 10, 32)  \u7a0b\u5e8f\u7684\u8f93\u51fa\u6570\u636eshape\u4e3a (32,10,8)  \u4f7f\u7528 TimeDistributed \u5305\u88c5 Dense \u4e25\u683c\u7b49\u4ef7\u4e8e layers.TimeDistribuedDense \u3002\u4e0d\u540c\u7684\u662f\u5305\u88c5\u5668 TimeDistribued \u8fd8\u53ef\u4ee5\u5bf9\u522b\u7684\u5c42\u8fdb\u884c\u5305\u88c5\uff0c\u5982\u8fd9\u91cc\u5bf9 Convolution2D \u5305\u88c5\uff1a  model = Sequential()\nmodel.add(TimeDistributed(Convolution2D(64, 3, 3), input_shape=(10, 3, 299, 299)))", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/layers/wrapper/#bidirectional", 
            "text": "keras.layers.wrappers.Bidirectional(layer, merge_mode='concat', weights=None)  \u53cc\u5411RNN\u5305\u88c5\u5668", 
            "title": "Bidirectional\u5305\u88c5\u5668"
        }, 
        {
            "location": "/layers/wrapper/#_2", 
            "text": "layer\uff1a Recurrent \u5bf9\u8c61  merge_mode\uff1a\u524d\u5411\u548c\u540e\u5411RNN\u8f93\u51fa\u7684\u7ed3\u5408\u65b9\u5f0f\uff0c\u4e3a sum , mul , concat , ave \u548c None \u4e4b\u4e00\uff0c\u82e5\u8bbe\u4e3aNone\uff0c\u5219\u8fd4\u56de\u503c\u4e0d\u7ed3\u5408\uff0c\u800c\u662f\u4ee5\u5217\u8868\u7684\u5f62\u5f0f\u8fd4\u56de", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/layers/wrapper/#_3", 
            "text": "model = Sequential()\nmodel.add(Bidirectional(LSTM(10, return_sequences=True), input_shape=(5, 10)))\nmodel.add(Bidirectional(LSTM(10)))\nmodel.add(Dense(5))\nmodel.add(Activation('softmax'))\nmodel.compile(loss='categorical_crossentropy', optimizer='rmsprop')", 
            "title": "\u4f8b\u5b50"
        }, 
        {
            "location": "/layers/writting_layer/", 
            "text": "\u7f16\u5199\u81ea\u5df1\u7684\u5c42\n\n\n\u5bf9\u4e8e\u7b80\u5355\u7684\u5b9a\u5236\u64cd\u4f5c\uff0c\u6211\u4eec\u6216\u8bb8\u53ef\u4ee5\u901a\u8fc7\u4f7f\u7528\nlayers.core.Lambda\n\u5c42\u6765\u5b8c\u6210\u3002\u4f46\u5bf9\u4e8e\u4efb\u4f55\u5177\u6709\u53ef\u8bad\u7ec3\u6743\u91cd\u7684\u5b9a\u5236\u5c42\uff0c\u4f60\u5e94\u8be5\u81ea\u5df1\u6765\u5b9e\u73b0\u3002\n\n\n\u8fd9\u91cc\u662f\u4e00\u4e2aKeras\u5c42\u5e94\u8be5\u5177\u6709\u7684\u6846\u67b6\u7ed3\u6784(1.1.3\u4ee5\u540e\u7684\u7248\u672c\uff0c\u5982\u679c\u4f60\u7684\u7248\u672c\u66f4\u65e7\u8bf7\u5347\u7ea7)\uff0c\u8981\u5b9a\u5236\u81ea\u5df1\u7684\u5c42\uff0c\u4f60\u9700\u8981\u5b9e\u73b0\u4e0b\u9762\u4e09\u4e2a\u65b9\u6cd5\n\n\n\n\n\n\nbuild(input_shape)\n\uff1a\u8fd9\u662f\u5b9a\u4e49\u6743\u91cd\u7684\u65b9\u6cd5\uff0c\u53ef\u8bad\u7ec3\u7684\u6743\u5e94\u8be5\u5728\u8fd9\u91cc\u88ab\u52a0\u5165\u5217\u8868\n`self.trainable_weights\n\u4e2d\u3002\u5176\u4ed6\u7684\u5c5e\u6027\u8fd8\u5305\u62ec\nself.non_trainabe_weights\n\uff08\u5217\u8868\uff09\u548c\nself.updates\n\uff08\u9700\u8981\u66f4\u65b0\u7684\u5f62\u5982\uff08tensor, new_tensor\uff09\u7684tuple\u7684\u5217\u8868\uff09\u3002\u4f60\u53ef\u4ee5\u53c2\u8003\nBatchNormalization\n\u5c42\u7684\u5b9e\u73b0\u6765\u5b66\u4e60\u5982\u4f55\u4f7f\u7528\u4e0a\u9762\u4e24\u4e2a\u5c5e\u6027\u3002\u8fd9\u4e2a\u65b9\u6cd5\u5fc5\u987b\u8bbe\u7f6e\nself.built = True\n\uff0c\u53ef\u901a\u8fc7\u8c03\u7528\nsuper([layer],self).build()\n\u5b9e\u73b0\n\n\n\n\n\n\ncall(x)\n\uff1a\u8fd9\u662f\u5b9a\u4e49\u5c42\u529f\u80fd\u7684\u65b9\u6cd5\uff0c\u9664\u975e\u4f60\u5e0c\u671b\u4f60\u5199\u7684\u5c42\u652f\u6301masking\uff0c\u5426\u5219\u4f60\u53ea\u9700\u8981\u5173\u5fc3\ncall\n\u7684\u7b2c\u4e00\u4e2a\u53c2\u6570\uff1a\u8f93\u5165\u5f20\u91cf\n\n\n\n\n\n\nget_output_shape_for(input_shape)\n\uff1a\u5982\u679c\u4f60\u7684\u5c42\u4fee\u6539\u4e86\u8f93\u5165\u6570\u636e\u7684shape\uff0c\u4f60\u5e94\u8be5\u5728\u8fd9\u91cc\u6307\u5b9ashape\u53d8\u5316\u7684\u65b9\u6cd5\uff0c\u8fd9\u4e2a\u51fd\u6570\u4f7f\u5f97Keras\u53ef\u4ee5\u505a\u81ea\u52a8shape\u63a8\u65ad\n\n\n\n\n\n\nfrom keras import backend as K\nfrom keras.engine.topology import Layer\n\nclass MyLayer(Layer):\n    def __init__(self, output_dim, **kwargs):\n        self.output_dim = output_dim\n        super(MyLayer, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        self.W = self.add_weight(shape=(input_shape[1], self.output_dim),\n                                initializer='random_uniform',\n                                trainable=True)\n        super(MyLayer, self).build()  # be sure you call this somewhere! \n\n    def call(self, x, mask=None):\n        return K.dot(x, self.W)\n\n    def get_output_shape_for(self, input_shape):\n        return (input_shape[0] + self.output_dim)\n\n\n\n\n\n\n\n\n\u8c03\u6574\u65e7\u7248Keras\u7f16\u5199\u7684\u5c42\u4ee5\u9002\u5e94Keras1.0\n\n\n\n\n\n\n\u4ee5\u4e0b\u5185\u5bb9\u662f\u4f60\u5728\u5c06\u65e7\u7248Keras\u5b9e\u73b0\u7684\u5c42\u8c03\u6574\u4e3a\u65b0\u7248Keras\u5e94\u6ce8\u610f\u7684\u5185\u5bb9\uff0c\u8fd9\u4e9b\u5185\u5bb9\u5bf9\u4f60\u5728Keras1.0\u4e2d\u7f16\u5199\u81ea\u5df1\u7684\u5c42\u4e5f\u6709\u6240\u5e2e\u52a9\u3002\n\n\n\n\n\n\n\u4f60\u7684Layer\u5e94\u8be5\u7ee7\u627f\u81ea\nkeras.engine.topology.Layer\n\uff0c\u800c\u4e0d\u662f\u4e4b\u524d\u7684\nkeras.layers.core.Layer\n\u3002\u53e6\u5916\uff0c\nMaskedLayer\n\u5df2\u7ecf\u88ab\u79fb\u9664\u3002\n\n\n\n\n\n\nbuild\n\u65b9\u6cd5\u73b0\u5728\u63a5\u53d7\ninput_shape\n\u53c2\u6570\uff0c\u800c\u4e0d\u662f\u50cf\u4ee5\u524d\u4e00\u6837\u901a\u8fc7\nself.input_shape\n\u6765\u83b7\u5f97\u8be5\u503c\uff0c\u6240\u4ee5\u8bf7\u628a\nbuild(self)\n\u8f6c\u4e3a\nbuild(self, input_shape)\n\n\n\n\n\n\n\u8bf7\u6b63\u786e\u5c06\noutput_shape\n\u5c5e\u6027\u8f6c\u6362\u4e3a\u65b9\u6cd5\nget_output_shape_for(self, train=False)\n\uff0c\u5e76\u5220\u53bb\u539f\u6765\u7684\noutput_shape\n\n\n\n\n\n\n\u65b0\u5c42\u7684\u8ba1\u7b97\u903b\u8f91\u73b0\u5728\u5e94\u5b9e\u73b0\u5728\ncall\n\u65b9\u6cd5\u4e2d\uff0c\u800c\u4e0d\u662f\u4e4b\u524d\u7684\nget_output\n\u3002\u6ce8\u610f\u4e0d\u8981\u6539\u52a8\n__call__\n\u65b9\u6cd5\u3002\u5c06\nget_output(self,train=False)\n\u8f6c\u6362\u4e3a\ncall(self,x,mask=None)\n\u540e\u8bf7\u5220\u9664\u539f\u6765\u7684\nget_output\n\u65b9\u6cd5\u3002\n\n\n\n\n\n\nKeras1.0\u4e0d\u518d\u4f7f\u7528\u5e03\u5c14\u503c\ntrain\n\u6765\u63a7\u5236\u8bad\u7ec3\u72b6\u6001\u548c\u6d4b\u8bd5\u72b6\u6001\uff0c\u5982\u679c\u4f60\u7684\u5c42\u5728\u6d4b\u8bd5\u548c\u8bad\u7ec3\u4e24\u79cd\u60c5\u5f62\u4e0b\u8868\u73b0\u4e0d\u540c\uff0c\u8bf7\u5728\ncall\n\u4e2d\u4f7f\u7528\u6307\u5b9a\u72b6\u6001\u7684\u51fd\u6570\u3002\u5982\uff0c\nx=K.in_train_phase(train_x, test_y)\n\u3002\u4f8b\u5982\uff0c\u5728Dropout\u7684\ncall\n\u65b9\u6cd5\u4e2d\u4f60\u53ef\u4ee5\u770b\u5230\uff1a\n\n\n\n\n\n\nreturn K.in_train_phase(K.dropout(x, level=self.p), x)\n\n\n\n\n\n\n\n\nget_config\n\u8fd4\u56de\u7684\u914d\u7f6e\u4fe1\u606f\u53ef\u80fd\u4f1a\u5305\u62ec\u7c7b\u540d\uff0c\u8bf7\u4ece\u8be5\u51fd\u6570\u4e2d\u5c06\u5176\u53bb\u6389\u3002\u5982\u679c\u4f60\u7684\u5c42\u5728\u5b9e\u4f8b\u5316\u65f6\u9700\u8981\u66f4\u591a\u4fe1\u606f\uff08\u5373\u4f7f\u5c06\nconfig\n\u4f5c\u4e3akwargs\u4f20\u5165\u4e5f\u4e0d\u80fd\u63d0\u4f9b\u8db3\u591f\u4fe1\u606f\uff09\uff0c\u8bf7\u91cd\u65b0\u5b9e\u73b0\nfrom_config\n\u3002\u8bf7\u53c2\u8003\nLambda\n\u6216\nMerge\n\u5c42\u770b\u770b\u590d\u6742\u7684\nfrom_config\n\u662f\u5982\u4f55\u5b9e\u73b0\u7684\u3002\n\n\n\n\n\n\n\u5982\u679c\u4f60\u5728\u4f7f\u7528Masking\uff0c\u8bf7\u5b9e\u73b0\ncompute_mas(input_tensor, input_mask)\n\uff0c\u8be5\u51fd\u6570\u5c06\u8fd4\u56de\noutput_mask\n\u3002\u8bf7\u786e\u4fdd\u5728\n__init__()\n\u4e2d\u8bbe\u7f6e\nself.supports_masking = True\n\n\n\n\n\n\n\u5982\u679c\u4f60\u5e0c\u671bKeras\u5728\u4f60\u7f16\u5199\u7684\u5c42\u4e0eKeras\u5185\u7f6e\u5c42\u76f8\u8fde\u65f6\u8fdb\u884c\u8f93\u5165\u517c\u5bb9\u6027\u68c0\u67e5\uff0c\u8bf7\u5728\n__init__\n\u8bbe\u7f6e\nself.input_specs\n\u6216\u5b9e\u73b0\ninput_specs()\n\u5e76\u5305\u88c5\u4e3a\u5c5e\u6027\uff08@property\uff09\u3002\u8be5\u5c5e\u6027\u5e94\u4e3a\nengine.InputSpec\n\u7684\u5bf9\u8c61\u5217\u8868\u3002\u5728\u4f60\u5e0c\u671b\u5728\ncall\n\u4e2d\u83b7\u53d6\u8f93\u5165shape\u65f6\uff0c\u8be5\u5c5e\u6027\u4e5f\u6bd4\u8f83\u6709\u7528\u3002\n\n\n\n\n\n\n\u4e0b\u9762\u7684\u65b9\u6cd5\u548c\u5c5e\u6027\u662f\u5185\u7f6e\u7684\uff0c\u8bf7\u4e0d\u8981\u8986\u76d6\u5b83\u4eec\n\n\n\n\n\n\n__call__\n\n\n\n\n\n\nadd_input\n\n\n\n\n\n\nassert_input_compatibility\n\n\n\n\n\n\nset_input\n\n\n\n\n\n\ninput\n\n\n\n\n\n\noutput\n\n\n\n\n\n\ninput_shape\n\n\n\n\n\n\noutput_shape\n\n\n\n\n\n\ninput_mask\n\n\n\n\n\n\noutput_mask\n\n\n\n\n\n\nget_input_at\n\n\n\n\n\n\nget_output_at\n\n\n\n\n\n\nget_input_shape_at\n\n\n\n\n\n\nget_output_shape_at\n\n\n\n\n\n\nget_input_mask_at\n\n\n\n\n\n\nget_output_mask_at\n\n\n\n\n\n\n\n\n\n\n\u73b0\u5b58\u7684Keras\u5c42\u4ee3\u7801\u53ef\u4ee5\u4e3a\u4f60\u7684\u5b9e\u73b0\u63d0\u4f9b\u826f\u597d\u53c2\u8003\uff0c\u9605\u8bfb\u6e90\u4ee3\u7801\u5427\uff01", 
            "title": "\u7f16\u5199\u81ea\u5df1\u7684\u5c42"
        }, 
        {
            "location": "/layers/writting_layer/#_1", 
            "text": "\u5bf9\u4e8e\u7b80\u5355\u7684\u5b9a\u5236\u64cd\u4f5c\uff0c\u6211\u4eec\u6216\u8bb8\u53ef\u4ee5\u901a\u8fc7\u4f7f\u7528 layers.core.Lambda \u5c42\u6765\u5b8c\u6210\u3002\u4f46\u5bf9\u4e8e\u4efb\u4f55\u5177\u6709\u53ef\u8bad\u7ec3\u6743\u91cd\u7684\u5b9a\u5236\u5c42\uff0c\u4f60\u5e94\u8be5\u81ea\u5df1\u6765\u5b9e\u73b0\u3002  \u8fd9\u91cc\u662f\u4e00\u4e2aKeras\u5c42\u5e94\u8be5\u5177\u6709\u7684\u6846\u67b6\u7ed3\u6784(1.1.3\u4ee5\u540e\u7684\u7248\u672c\uff0c\u5982\u679c\u4f60\u7684\u7248\u672c\u66f4\u65e7\u8bf7\u5347\u7ea7)\uff0c\u8981\u5b9a\u5236\u81ea\u5df1\u7684\u5c42\uff0c\u4f60\u9700\u8981\u5b9e\u73b0\u4e0b\u9762\u4e09\u4e2a\u65b9\u6cd5    build(input_shape) \uff1a\u8fd9\u662f\u5b9a\u4e49\u6743\u91cd\u7684\u65b9\u6cd5\uff0c\u53ef\u8bad\u7ec3\u7684\u6743\u5e94\u8be5\u5728\u8fd9\u91cc\u88ab\u52a0\u5165\u5217\u8868 `self.trainable_weights \u4e2d\u3002\u5176\u4ed6\u7684\u5c5e\u6027\u8fd8\u5305\u62ec self.non_trainabe_weights \uff08\u5217\u8868\uff09\u548c self.updates \uff08\u9700\u8981\u66f4\u65b0\u7684\u5f62\u5982\uff08tensor, new_tensor\uff09\u7684tuple\u7684\u5217\u8868\uff09\u3002\u4f60\u53ef\u4ee5\u53c2\u8003 BatchNormalization \u5c42\u7684\u5b9e\u73b0\u6765\u5b66\u4e60\u5982\u4f55\u4f7f\u7528\u4e0a\u9762\u4e24\u4e2a\u5c5e\u6027\u3002\u8fd9\u4e2a\u65b9\u6cd5\u5fc5\u987b\u8bbe\u7f6e self.built = True \uff0c\u53ef\u901a\u8fc7\u8c03\u7528 super([layer],self).build() \u5b9e\u73b0    call(x) \uff1a\u8fd9\u662f\u5b9a\u4e49\u5c42\u529f\u80fd\u7684\u65b9\u6cd5\uff0c\u9664\u975e\u4f60\u5e0c\u671b\u4f60\u5199\u7684\u5c42\u652f\u6301masking\uff0c\u5426\u5219\u4f60\u53ea\u9700\u8981\u5173\u5fc3 call \u7684\u7b2c\u4e00\u4e2a\u53c2\u6570\uff1a\u8f93\u5165\u5f20\u91cf    get_output_shape_for(input_shape) \uff1a\u5982\u679c\u4f60\u7684\u5c42\u4fee\u6539\u4e86\u8f93\u5165\u6570\u636e\u7684shape\uff0c\u4f60\u5e94\u8be5\u5728\u8fd9\u91cc\u6307\u5b9ashape\u53d8\u5316\u7684\u65b9\u6cd5\uff0c\u8fd9\u4e2a\u51fd\u6570\u4f7f\u5f97Keras\u53ef\u4ee5\u505a\u81ea\u52a8shape\u63a8\u65ad    from keras import backend as K\nfrom keras.engine.topology import Layer\n\nclass MyLayer(Layer):\n    def __init__(self, output_dim, **kwargs):\n        self.output_dim = output_dim\n        super(MyLayer, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        self.W = self.add_weight(shape=(input_shape[1], self.output_dim),\n                                initializer='random_uniform',\n                                trainable=True)\n        super(MyLayer, self).build()  # be sure you call this somewhere! \n\n    def call(self, x, mask=None):\n        return K.dot(x, self.W)\n\n    def get_output_shape_for(self, input_shape):\n        return (input_shape[0] + self.output_dim)", 
            "title": "\u7f16\u5199\u81ea\u5df1\u7684\u5c42"
        }, 
        {
            "location": "/layers/writting_layer/#keraskeras10", 
            "text": "\u4ee5\u4e0b\u5185\u5bb9\u662f\u4f60\u5728\u5c06\u65e7\u7248Keras\u5b9e\u73b0\u7684\u5c42\u8c03\u6574\u4e3a\u65b0\u7248Keras\u5e94\u6ce8\u610f\u7684\u5185\u5bb9\uff0c\u8fd9\u4e9b\u5185\u5bb9\u5bf9\u4f60\u5728Keras1.0\u4e2d\u7f16\u5199\u81ea\u5df1\u7684\u5c42\u4e5f\u6709\u6240\u5e2e\u52a9\u3002    \u4f60\u7684Layer\u5e94\u8be5\u7ee7\u627f\u81ea keras.engine.topology.Layer \uff0c\u800c\u4e0d\u662f\u4e4b\u524d\u7684 keras.layers.core.Layer \u3002\u53e6\u5916\uff0c MaskedLayer \u5df2\u7ecf\u88ab\u79fb\u9664\u3002    build \u65b9\u6cd5\u73b0\u5728\u63a5\u53d7 input_shape \u53c2\u6570\uff0c\u800c\u4e0d\u662f\u50cf\u4ee5\u524d\u4e00\u6837\u901a\u8fc7 self.input_shape \u6765\u83b7\u5f97\u8be5\u503c\uff0c\u6240\u4ee5\u8bf7\u628a build(self) \u8f6c\u4e3a build(self, input_shape)    \u8bf7\u6b63\u786e\u5c06 output_shape \u5c5e\u6027\u8f6c\u6362\u4e3a\u65b9\u6cd5 get_output_shape_for(self, train=False) \uff0c\u5e76\u5220\u53bb\u539f\u6765\u7684 output_shape    \u65b0\u5c42\u7684\u8ba1\u7b97\u903b\u8f91\u73b0\u5728\u5e94\u5b9e\u73b0\u5728 call \u65b9\u6cd5\u4e2d\uff0c\u800c\u4e0d\u662f\u4e4b\u524d\u7684 get_output \u3002\u6ce8\u610f\u4e0d\u8981\u6539\u52a8 __call__ \u65b9\u6cd5\u3002\u5c06 get_output(self,train=False) \u8f6c\u6362\u4e3a call(self,x,mask=None) \u540e\u8bf7\u5220\u9664\u539f\u6765\u7684 get_output \u65b9\u6cd5\u3002    Keras1.0\u4e0d\u518d\u4f7f\u7528\u5e03\u5c14\u503c train \u6765\u63a7\u5236\u8bad\u7ec3\u72b6\u6001\u548c\u6d4b\u8bd5\u72b6\u6001\uff0c\u5982\u679c\u4f60\u7684\u5c42\u5728\u6d4b\u8bd5\u548c\u8bad\u7ec3\u4e24\u79cd\u60c5\u5f62\u4e0b\u8868\u73b0\u4e0d\u540c\uff0c\u8bf7\u5728 call \u4e2d\u4f7f\u7528\u6307\u5b9a\u72b6\u6001\u7684\u51fd\u6570\u3002\u5982\uff0c x=K.in_train_phase(train_x, test_y) \u3002\u4f8b\u5982\uff0c\u5728Dropout\u7684 call \u65b9\u6cd5\u4e2d\u4f60\u53ef\u4ee5\u770b\u5230\uff1a    return K.in_train_phase(K.dropout(x, level=self.p), x)    get_config \u8fd4\u56de\u7684\u914d\u7f6e\u4fe1\u606f\u53ef\u80fd\u4f1a\u5305\u62ec\u7c7b\u540d\uff0c\u8bf7\u4ece\u8be5\u51fd\u6570\u4e2d\u5c06\u5176\u53bb\u6389\u3002\u5982\u679c\u4f60\u7684\u5c42\u5728\u5b9e\u4f8b\u5316\u65f6\u9700\u8981\u66f4\u591a\u4fe1\u606f\uff08\u5373\u4f7f\u5c06 config \u4f5c\u4e3akwargs\u4f20\u5165\u4e5f\u4e0d\u80fd\u63d0\u4f9b\u8db3\u591f\u4fe1\u606f\uff09\uff0c\u8bf7\u91cd\u65b0\u5b9e\u73b0 from_config \u3002\u8bf7\u53c2\u8003 Lambda \u6216 Merge \u5c42\u770b\u770b\u590d\u6742\u7684 from_config \u662f\u5982\u4f55\u5b9e\u73b0\u7684\u3002    \u5982\u679c\u4f60\u5728\u4f7f\u7528Masking\uff0c\u8bf7\u5b9e\u73b0 compute_mas(input_tensor, input_mask) \uff0c\u8be5\u51fd\u6570\u5c06\u8fd4\u56de output_mask \u3002\u8bf7\u786e\u4fdd\u5728 __init__() \u4e2d\u8bbe\u7f6e self.supports_masking = True    \u5982\u679c\u4f60\u5e0c\u671bKeras\u5728\u4f60\u7f16\u5199\u7684\u5c42\u4e0eKeras\u5185\u7f6e\u5c42\u76f8\u8fde\u65f6\u8fdb\u884c\u8f93\u5165\u517c\u5bb9\u6027\u68c0\u67e5\uff0c\u8bf7\u5728 __init__ \u8bbe\u7f6e self.input_specs \u6216\u5b9e\u73b0 input_specs() \u5e76\u5305\u88c5\u4e3a\u5c5e\u6027\uff08@property\uff09\u3002\u8be5\u5c5e\u6027\u5e94\u4e3a engine.InputSpec \u7684\u5bf9\u8c61\u5217\u8868\u3002\u5728\u4f60\u5e0c\u671b\u5728 call \u4e2d\u83b7\u53d6\u8f93\u5165shape\u65f6\uff0c\u8be5\u5c5e\u6027\u4e5f\u6bd4\u8f83\u6709\u7528\u3002    \u4e0b\u9762\u7684\u65b9\u6cd5\u548c\u5c5e\u6027\u662f\u5185\u7f6e\u7684\uff0c\u8bf7\u4e0d\u8981\u8986\u76d6\u5b83\u4eec    __call__    add_input    assert_input_compatibility    set_input    input    output    input_shape    output_shape    input_mask    output_mask    get_input_at    get_output_at    get_input_shape_at    get_output_shape_at    get_input_mask_at    get_output_mask_at      \u73b0\u5b58\u7684Keras\u5c42\u4ee3\u7801\u53ef\u4ee5\u4e3a\u4f60\u7684\u5b9e\u73b0\u63d0\u4f9b\u826f\u597d\u53c2\u8003\uff0c\u9605\u8bfb\u6e90\u4ee3\u7801\u5427\uff01", 
            "title": "\u8c03\u6574\u65e7\u7248Keras\u7f16\u5199\u7684\u5c42\u4ee5\u9002\u5e94Keras1.0"
        }, 
        {
            "location": "/preprocessing/sequence/", 
            "text": "\u5e8f\u5217\u9884\u5904\u7406\n\n\n\u586b\u5145\u5e8f\u5217pad_sequences\n\n\nkeras.preprocessing.sequence.pad_sequences(sequences, maxlen=None, dtype='int32'\uff0cpadding='pre', truncating='pre', value=0)\n\n\n\n\n\u5c06\u957f\u4e3a\nnb_samples\n\u7684\u5e8f\u5217\uff08\u6807\u91cf\u5e8f\u5217\uff09\u8f6c\u5316\u4e3a\u5f62\u5982\n(nb_samples,nb_timesteps)\n2D numpy array\u3002\u5982\u679c\u63d0\u4f9b\u4e86\u53c2\u6570\nmaxlen\n\uff0c\nnb_timesteps=maxlen\n\uff0c\u5426\u5219\u5176\u503c\u4e3a\u6700\u957f\u5e8f\u5217\u7684\u957f\u5ea6\u3002\u5176\u4ed6\u77ed\u4e8e\u8be5\u957f\u5ea6\u7684\u5e8f\u5217\u90fd\u4f1a\u5728\u540e\u90e8\u586b\u51450\u4ee5\u8fbe\u5230\u8be5\u957f\u5ea6\u3002\u957f\u4e8e\nnb_timesteps\n\u7684\u5e8f\u5217\u5c06\u4f1a\u88ab\u622a\u65ad\uff0c\u4ee5\u4f7f\u5176\u5339\u914d\u76ee\u6807\u957f\u5ea6\u3002padding\u548c\u622a\u65ad\u53d1\u751f\u7684\u4f4d\u7f6e\u5206\u522b\u53d6\u51b3\u4e8e\npadding\n\u548c\ntruncating\n.\n\n\n\u53c2\u6570\n\n\n\n\n\n\nsequences\uff1a\u6d6e\u70b9\u6570\u6216\u6574\u6570\u6784\u6210\u7684\u4e24\u5c42\u5d4c\u5957\u5217\u8868\n\n\n\n\n\n\nmaxlen\uff1aNone\u6216\u6574\u6570\uff0c\u4e3a\u5e8f\u5217\u7684\u6700\u5927\u957f\u5ea6\u3002\u5927\u4e8e\u6b64\u957f\u5ea6\u7684\u5e8f\u5217\u5c06\u88ab\u622a\u77ed\uff0c\u5c0f\u4e8e\u6b64\u957f\u5ea6\u7684\u5e8f\u5217\u5c06\u5728\u540e\u90e8\u586b0.\n\n\n\n\n\n\ndtype\uff1a\u8fd4\u56de\u7684numpy array\u7684\u6570\u636e\u7c7b\u578b\n\n\n\n\n\n\npadding\uff1a\u2018pre\u2019\u6216\u2018post\u2019\uff0c\u786e\u5b9a\u5f53\u9700\u8981\u88650\u65f6\uff0c\u5728\u5e8f\u5217\u7684\u8d77\u59cb\u8fd8\u662f\u7ed3\u5c3e\u8865\n\n\n\n\n\n\ntruncating\uff1a\u2018pre\u2019\u6216\u2018post\u2019\uff0c\u786e\u5b9a\u5f53\u9700\u8981\u622a\u65ad\u5e8f\u5217\u65f6\uff0c\u4ece\u8d77\u59cb\u8fd8\u662f\u7ed3\u5c3e\u622a\u65ad\n\n\n\n\n\n\nvalue\uff1a\u6d6e\u70b9\u6570\uff0c\u6b64\u503c\u5c06\u5728\u586b\u5145\u65f6\u4ee3\u66ff\u9ed8\u8ba4\u7684\u586b\u5145\u503c0\n\n\n\n\n\n\n\u8fd4\u56de\u503c\n\n\n\u8fd4\u56de\u5f62\u5982\n(nb_samples,nb_timesteps)\n\u76842D\u5f20\u91cf\n\n\n\n\n\u8df3\u5b57skipgrams\n\n\nkeras.preprocessing.sequence.skipgrams(sequence, vocabulary_size, \n    window_size=4, negative_samples=1., shuffle=True, \n    categorical=False, sampling_table=None)\n\n\n\n\nskipgrams\u5c06\u4e00\u4e2a\u8bcd\u5411\u91cf\u4e0b\u6807\u7684\u5e8f\u5217\u8f6c\u5316\u4e3a\u4e0b\u9762\u7684\u4e00\u5bf9tuple\uff1a\n\n\n\n\n\n\n\u5bf9\u4e8e\u6b63\u6837\u672c\uff0c\u8f6c\u5316\u4e3a\uff08word\uff0cword in the same window\uff09\n\n\n\n\n\n\n\u5bf9\u4e8e\u8d1f\u6837\u672c\uff0c\u8f6c\u5316\u4e3a\uff08word\uff0crandom word from the vocabulary\uff09\n\n\n\n\n\n\n\u3010Tips\u3011\u6839\u636e\u7ef4\u57fa\u767e\u79d1\uff0cn-gram\u4ee3\u8868\u5728\u7ed9\u5b9a\u5e8f\u5217\u4e2d\u4ea7\u751f\u8fde\u7eed\u7684n\u9879\uff0c\u5f53\u5e8f\u5217\u53e5\u5b50\u65f6\uff0c\u6bcf\u9879\u5c31\u662f\u5355\u8bcd\uff0c\u6b64\u65f6n-gram\u4e5f\u79f0\u4e3ashingles\u3002\u800cskip-gram\u7684\u63a8\u5e7f\uff0cskip-gram\u4ea7\u751f\u7684n\u9879\u5b50\u5e8f\u5217\u4e2d\uff0c\u5404\u4e2a\u9879\u5728\u539f\u5e8f\u5217\u4e2d\u4e0d\u8fde\u7eed\uff0c\u800c\u662f\u8df3\u4e86k\u4e2a\u5b57\u3002\u4f8b\u5982\uff0c\u5bf9\u4e8e\u53e5\u5b50\uff1a\n\n\n\u201cthe rain in Spain falls mainly on the plain\u201d\n\n\n\u5176 2-grams\u4e3a\u5b50\u5e8f\u5217\u96c6\u5408\uff1a\n\n\nthe rain\uff0crain in\uff0cin Spain\uff0cSpain falls\uff0cfalls mainly\uff0cmainly on\uff0con the\uff0cthe plain\n\n\n\u5176 1-skip-2-grams\u4e3a\u5b50\u5e8f\u5217\u96c6\u5408\uff1a\n\n\nthe in, rain Spain, in falls, Spain mainly, falls on, mainly the, on plain.\n\n\n\u66f4\u591a\u8be6\u60c5\u8bf7\u53c2\u8003\nEfficient Estimation of Word Representations in Vector Space\n\u3010@BigMoyan\u3011\n\n\n\u53c2\u6570\n\n\n\n\n\n\nsequence\uff1a\u4e0b\u6807\u7684\u5217\u8868\uff0c\u5982\u679c\u4f7f\u7528sampling_tabel\uff0c\u5219\u67d0\u4e2a\u8bcd\u7684\u4e0b\u6807\u5e94\u8be5\u4e3a\u5b83\u5728\u6570\u636e\u5e93\u4e2d\u7684\u987a\u5e8f\u3002\uff08\u4ece1\u5f00\u59cb\uff09\n\n\n\n\n\n\nvocabulary_size\uff1a\u6574\u6570\uff0c\u5b57\u5178\u5927\u5c0f\n\n\n\n\n\n\nwindow_size\uff1a\u6574\u6570\uff0c\u6b63\u6837\u672c\u5bf9\u4e4b\u95f4\u7684\u6700\u5927\u8ddd\u79bb\n\n\n\n\n\n\nnegative_samples\uff1a\u5927\u4e8e0\u7684\u6d6e\u70b9\u6570\uff0c\u7b49\u4e8e0\u4ee3\u8868\u6ca1\u6709\u8d1f\u6837\u672c\uff0c\u7b49\u4e8e1\u4ee3\u8868\u8d1f\u6837\u672c\u4e0e\u6b63\u6837\u672c\u6570\u76ee\u76f8\u540c\uff0c\u4ee5\u6b64\u7c7b\u63a8\uff08\u5373\u8d1f\u6837\u672c\u7684\u6570\u76ee\u662f\u6b63\u6837\u672c\u7684\nnegative_samples\n\u500d\uff09\n\n\n\n\n\n\nshuffle\uff1a\u5e03\u5c14\u503c\uff0c\u786e\u5b9a\u662f\u5426\u968f\u673a\u6253\u4e71\u6837\u672c\n\n\n\n\n\n\ncategorical\uff1a\u5e03\u5c14\u503c\uff0c\u786e\u5b9a\u662f\u5426\u8981\u4f7f\u5f97\u8fd4\u56de\u7684\u6807\u7b7e\u5177\u6709\u786e\u5b9a\u7c7b\u522b\n\n\n\n\n\n\nsampling_table\uff1a\u5f62\u5982\n(vocabulary_size,)\n\u7684numpy array\uff0c\u5176\u4e2d\nsampling_table[i]\n\u4ee3\u8868\u6ca1\u6709\u8d1f\u6837\u672c\u6216\u968f\u673a\u8d1f\u6837\u672c\u3002\u7b49\u4e8e1\u4e3a\u4e0e\u6b63\u6837\u672c\u7684\u6570\u76ee\u76f8\u540c\n\u91c7\u6837\u5230\u8be5\u4e0b\u6807\u4e3ai\u7684\u5355\u8bcd\u7684\u6982\u7387\uff08\u5047\u5b9a\u8be5\u5355\u8bcd\u662f\u6570\u636e\u5e93\u4e2d\u7b2ci\u5e38\u89c1\u7684\u5355\u8bcd\uff09\n\n\n\n\n\n\n\u8f93\u51fa\n\n\n\u51fd\u6570\u7684\u8f93\u51fa\u662f\u4e00\u4e2a\n(couples,labels)\n\u7684\u5143\u7ec4\uff0c\u5176\u4e2d\uff1a\n\n\n\n\n\n\ncouples\n\u662f\u4e00\u4e2a\u957f\u4e3a2\u7684\u6574\u6570\u5217\u8868\uff1a\n[word_index,other_word_index]\n\n\n\n\n\n\nlabels\n\u662f\u4e00\u4e2a\u4ec5\u75310\u548c1\u6784\u6210\u7684\u5217\u8868\uff0c1\u4ee3\u8868\nother_word_index\n\u5728\nword_index\n\u7684\u7a97\u53e3\uff0c0\u4ee3\u8868\nother_word_index\n\u662f\u8bcd\u5178\u91cc\u7684\u968f\u673a\u5355\u8bcd\u3002\n\n\n\n\n\n\n\u5982\u679c\u8bbe\u7f6e\ncategorical\n\u4e3a\nTrue\n\uff0c\u5219\u6807\u7b7e\u5c06\u4ee5one-hot\u7684\u65b9\u5f0f\u7ed9\u51fa\uff0c\u53731\u53d8\u4e3a[0,1]\uff0c0\u53d8\u4e3a[1,0]\n\n\n\n\n\n\n\n\n\u83b7\u53d6\u91c7\u6837\u8868make_sampling_table\n\n\nkeras.preprocessing.sequence.make_sampling_table(size, sampling_factor=1e-5)\n\n\n\n\n\u8be5\u51fd\u6570\u7528\u4ee5\u4ea7\u751f\nskipgrams\n\u4e2d\u6240\u9700\u8981\u7684\u53c2\u6570\nsampling_table\n\u3002\u8fd9\u662f\u4e00\u4e2a\u957f\u4e3a\nsize\n\u7684\u5411\u91cf\uff0c\nsampling_table[i]\n\u4ee3\u8868\u91c7\u6837\u5230\u6570\u636e\u96c6\u4e2d\u7b2ci\u5e38\u89c1\u7684\u8bcd\u7684\u6982\u7387\uff08\u4e3a\u5e73\u8861\u671f\u8d77\u89c1\uff0c\u5bf9\u4e8e\u8d8a\u7ecf\u5e38\u51fa\u73b0\u7684\u8bcd\uff0c\u8981\u4ee5\u8d8a\u4f4e\u7684\u6982\u7387\u91c7\u5230\u5b83\uff09\n\n\n\u53c2\u6570\n\n\n\n\n\n\nsize\uff1a\u8bcd\u5178\u7684\u5927\u5c0f\n\n\n\n\n\n\nsampling_factor\uff1a\u6b64\u503c\u8d8a\u4f4e\uff0c\u5219\u4ee3\u8868\u91c7\u6837\u65f6\u66f4\u7f13\u6162\u7684\u6982\u7387\u8870\u51cf\uff08\u5373\u5e38\u7528\u7684\u8bcd\u4f1a\u88ab\u4ee5\u66f4\u4f4e\u7684\u6982\u7387\u88ab\u91c7\u5230\uff09\uff0c\u5982\u679c\u8bbe\u7f6e\u4e3a1\uff0c\u5219\u4ee3\u8868\u4e0d\u8fdb\u884c\u4e0b\u91c7\u6837\uff0c\u5373\u6240\u6709\u6837\u672c\u88ab\u91c7\u6837\u5230\u7684\u6982\u7387\u90fd\u662f1\u3002", 
            "title": "\u5e8f\u5217\u9884\u5904\u7406"
        }, 
        {
            "location": "/preprocessing/sequence/#_1", 
            "text": "", 
            "title": "\u5e8f\u5217\u9884\u5904\u7406"
        }, 
        {
            "location": "/preprocessing/sequence/#pad_sequences", 
            "text": "keras.preprocessing.sequence.pad_sequences(sequences, maxlen=None, dtype='int32'\uff0cpadding='pre', truncating='pre', value=0)  \u5c06\u957f\u4e3a nb_samples \u7684\u5e8f\u5217\uff08\u6807\u91cf\u5e8f\u5217\uff09\u8f6c\u5316\u4e3a\u5f62\u5982 (nb_samples,nb_timesteps) 2D numpy array\u3002\u5982\u679c\u63d0\u4f9b\u4e86\u53c2\u6570 maxlen \uff0c nb_timesteps=maxlen \uff0c\u5426\u5219\u5176\u503c\u4e3a\u6700\u957f\u5e8f\u5217\u7684\u957f\u5ea6\u3002\u5176\u4ed6\u77ed\u4e8e\u8be5\u957f\u5ea6\u7684\u5e8f\u5217\u90fd\u4f1a\u5728\u540e\u90e8\u586b\u51450\u4ee5\u8fbe\u5230\u8be5\u957f\u5ea6\u3002\u957f\u4e8e nb_timesteps \u7684\u5e8f\u5217\u5c06\u4f1a\u88ab\u622a\u65ad\uff0c\u4ee5\u4f7f\u5176\u5339\u914d\u76ee\u6807\u957f\u5ea6\u3002padding\u548c\u622a\u65ad\u53d1\u751f\u7684\u4f4d\u7f6e\u5206\u522b\u53d6\u51b3\u4e8e padding \u548c truncating .", 
            "title": "\u586b\u5145\u5e8f\u5217pad_sequences"
        }, 
        {
            "location": "/preprocessing/sequence/#_2", 
            "text": "sequences\uff1a\u6d6e\u70b9\u6570\u6216\u6574\u6570\u6784\u6210\u7684\u4e24\u5c42\u5d4c\u5957\u5217\u8868    maxlen\uff1aNone\u6216\u6574\u6570\uff0c\u4e3a\u5e8f\u5217\u7684\u6700\u5927\u957f\u5ea6\u3002\u5927\u4e8e\u6b64\u957f\u5ea6\u7684\u5e8f\u5217\u5c06\u88ab\u622a\u77ed\uff0c\u5c0f\u4e8e\u6b64\u957f\u5ea6\u7684\u5e8f\u5217\u5c06\u5728\u540e\u90e8\u586b0.    dtype\uff1a\u8fd4\u56de\u7684numpy array\u7684\u6570\u636e\u7c7b\u578b    padding\uff1a\u2018pre\u2019\u6216\u2018post\u2019\uff0c\u786e\u5b9a\u5f53\u9700\u8981\u88650\u65f6\uff0c\u5728\u5e8f\u5217\u7684\u8d77\u59cb\u8fd8\u662f\u7ed3\u5c3e\u8865    truncating\uff1a\u2018pre\u2019\u6216\u2018post\u2019\uff0c\u786e\u5b9a\u5f53\u9700\u8981\u622a\u65ad\u5e8f\u5217\u65f6\uff0c\u4ece\u8d77\u59cb\u8fd8\u662f\u7ed3\u5c3e\u622a\u65ad    value\uff1a\u6d6e\u70b9\u6570\uff0c\u6b64\u503c\u5c06\u5728\u586b\u5145\u65f6\u4ee3\u66ff\u9ed8\u8ba4\u7684\u586b\u5145\u503c0", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/preprocessing/sequence/#_3", 
            "text": "\u8fd4\u56de\u5f62\u5982 (nb_samples,nb_timesteps) \u76842D\u5f20\u91cf", 
            "title": "\u8fd4\u56de\u503c"
        }, 
        {
            "location": "/preprocessing/sequence/#skipgrams", 
            "text": "keras.preprocessing.sequence.skipgrams(sequence, vocabulary_size, \n    window_size=4, negative_samples=1., shuffle=True, \n    categorical=False, sampling_table=None)  skipgrams\u5c06\u4e00\u4e2a\u8bcd\u5411\u91cf\u4e0b\u6807\u7684\u5e8f\u5217\u8f6c\u5316\u4e3a\u4e0b\u9762\u7684\u4e00\u5bf9tuple\uff1a    \u5bf9\u4e8e\u6b63\u6837\u672c\uff0c\u8f6c\u5316\u4e3a\uff08word\uff0cword in the same window\uff09    \u5bf9\u4e8e\u8d1f\u6837\u672c\uff0c\u8f6c\u5316\u4e3a\uff08word\uff0crandom word from the vocabulary\uff09    \u3010Tips\u3011\u6839\u636e\u7ef4\u57fa\u767e\u79d1\uff0cn-gram\u4ee3\u8868\u5728\u7ed9\u5b9a\u5e8f\u5217\u4e2d\u4ea7\u751f\u8fde\u7eed\u7684n\u9879\uff0c\u5f53\u5e8f\u5217\u53e5\u5b50\u65f6\uff0c\u6bcf\u9879\u5c31\u662f\u5355\u8bcd\uff0c\u6b64\u65f6n-gram\u4e5f\u79f0\u4e3ashingles\u3002\u800cskip-gram\u7684\u63a8\u5e7f\uff0cskip-gram\u4ea7\u751f\u7684n\u9879\u5b50\u5e8f\u5217\u4e2d\uff0c\u5404\u4e2a\u9879\u5728\u539f\u5e8f\u5217\u4e2d\u4e0d\u8fde\u7eed\uff0c\u800c\u662f\u8df3\u4e86k\u4e2a\u5b57\u3002\u4f8b\u5982\uff0c\u5bf9\u4e8e\u53e5\u5b50\uff1a  \u201cthe rain in Spain falls mainly on the plain\u201d  \u5176 2-grams\u4e3a\u5b50\u5e8f\u5217\u96c6\u5408\uff1a  the rain\uff0crain in\uff0cin Spain\uff0cSpain falls\uff0cfalls mainly\uff0cmainly on\uff0con the\uff0cthe plain  \u5176 1-skip-2-grams\u4e3a\u5b50\u5e8f\u5217\u96c6\u5408\uff1a  the in, rain Spain, in falls, Spain mainly, falls on, mainly the, on plain.  \u66f4\u591a\u8be6\u60c5\u8bf7\u53c2\u8003 Efficient Estimation of Word Representations in Vector Space \u3010@BigMoyan\u3011", 
            "title": "\u8df3\u5b57skipgrams"
        }, 
        {
            "location": "/preprocessing/sequence/#_4", 
            "text": "sequence\uff1a\u4e0b\u6807\u7684\u5217\u8868\uff0c\u5982\u679c\u4f7f\u7528sampling_tabel\uff0c\u5219\u67d0\u4e2a\u8bcd\u7684\u4e0b\u6807\u5e94\u8be5\u4e3a\u5b83\u5728\u6570\u636e\u5e93\u4e2d\u7684\u987a\u5e8f\u3002\uff08\u4ece1\u5f00\u59cb\uff09    vocabulary_size\uff1a\u6574\u6570\uff0c\u5b57\u5178\u5927\u5c0f    window_size\uff1a\u6574\u6570\uff0c\u6b63\u6837\u672c\u5bf9\u4e4b\u95f4\u7684\u6700\u5927\u8ddd\u79bb    negative_samples\uff1a\u5927\u4e8e0\u7684\u6d6e\u70b9\u6570\uff0c\u7b49\u4e8e0\u4ee3\u8868\u6ca1\u6709\u8d1f\u6837\u672c\uff0c\u7b49\u4e8e1\u4ee3\u8868\u8d1f\u6837\u672c\u4e0e\u6b63\u6837\u672c\u6570\u76ee\u76f8\u540c\uff0c\u4ee5\u6b64\u7c7b\u63a8\uff08\u5373\u8d1f\u6837\u672c\u7684\u6570\u76ee\u662f\u6b63\u6837\u672c\u7684 negative_samples \u500d\uff09    shuffle\uff1a\u5e03\u5c14\u503c\uff0c\u786e\u5b9a\u662f\u5426\u968f\u673a\u6253\u4e71\u6837\u672c    categorical\uff1a\u5e03\u5c14\u503c\uff0c\u786e\u5b9a\u662f\u5426\u8981\u4f7f\u5f97\u8fd4\u56de\u7684\u6807\u7b7e\u5177\u6709\u786e\u5b9a\u7c7b\u522b    sampling_table\uff1a\u5f62\u5982 (vocabulary_size,) \u7684numpy array\uff0c\u5176\u4e2d sampling_table[i] \u4ee3\u8868\u6ca1\u6709\u8d1f\u6837\u672c\u6216\u968f\u673a\u8d1f\u6837\u672c\u3002\u7b49\u4e8e1\u4e3a\u4e0e\u6b63\u6837\u672c\u7684\u6570\u76ee\u76f8\u540c\n\u91c7\u6837\u5230\u8be5\u4e0b\u6807\u4e3ai\u7684\u5355\u8bcd\u7684\u6982\u7387\uff08\u5047\u5b9a\u8be5\u5355\u8bcd\u662f\u6570\u636e\u5e93\u4e2d\u7b2ci\u5e38\u89c1\u7684\u5355\u8bcd\uff09", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/preprocessing/sequence/#_5", 
            "text": "\u51fd\u6570\u7684\u8f93\u51fa\u662f\u4e00\u4e2a (couples,labels) \u7684\u5143\u7ec4\uff0c\u5176\u4e2d\uff1a    couples \u662f\u4e00\u4e2a\u957f\u4e3a2\u7684\u6574\u6570\u5217\u8868\uff1a [word_index,other_word_index]    labels \u662f\u4e00\u4e2a\u4ec5\u75310\u548c1\u6784\u6210\u7684\u5217\u8868\uff0c1\u4ee3\u8868 other_word_index \u5728 word_index \u7684\u7a97\u53e3\uff0c0\u4ee3\u8868 other_word_index \u662f\u8bcd\u5178\u91cc\u7684\u968f\u673a\u5355\u8bcd\u3002    \u5982\u679c\u8bbe\u7f6e categorical \u4e3a True \uff0c\u5219\u6807\u7b7e\u5c06\u4ee5one-hot\u7684\u65b9\u5f0f\u7ed9\u51fa\uff0c\u53731\u53d8\u4e3a[0,1]\uff0c0\u53d8\u4e3a[1,0]", 
            "title": "\u8f93\u51fa"
        }, 
        {
            "location": "/preprocessing/sequence/#make_sampling_table", 
            "text": "keras.preprocessing.sequence.make_sampling_table(size, sampling_factor=1e-5)  \u8be5\u51fd\u6570\u7528\u4ee5\u4ea7\u751f skipgrams \u4e2d\u6240\u9700\u8981\u7684\u53c2\u6570 sampling_table \u3002\u8fd9\u662f\u4e00\u4e2a\u957f\u4e3a size \u7684\u5411\u91cf\uff0c sampling_table[i] \u4ee3\u8868\u91c7\u6837\u5230\u6570\u636e\u96c6\u4e2d\u7b2ci\u5e38\u89c1\u7684\u8bcd\u7684\u6982\u7387\uff08\u4e3a\u5e73\u8861\u671f\u8d77\u89c1\uff0c\u5bf9\u4e8e\u8d8a\u7ecf\u5e38\u51fa\u73b0\u7684\u8bcd\uff0c\u8981\u4ee5\u8d8a\u4f4e\u7684\u6982\u7387\u91c7\u5230\u5b83\uff09", 
            "title": "\u83b7\u53d6\u91c7\u6837\u8868make_sampling_table"
        }, 
        {
            "location": "/preprocessing/sequence/#_6", 
            "text": "size\uff1a\u8bcd\u5178\u7684\u5927\u5c0f    sampling_factor\uff1a\u6b64\u503c\u8d8a\u4f4e\uff0c\u5219\u4ee3\u8868\u91c7\u6837\u65f6\u66f4\u7f13\u6162\u7684\u6982\u7387\u8870\u51cf\uff08\u5373\u5e38\u7528\u7684\u8bcd\u4f1a\u88ab\u4ee5\u66f4\u4f4e\u7684\u6982\u7387\u88ab\u91c7\u5230\uff09\uff0c\u5982\u679c\u8bbe\u7f6e\u4e3a1\uff0c\u5219\u4ee3\u8868\u4e0d\u8fdb\u884c\u4e0b\u91c7\u6837\uff0c\u5373\u6240\u6709\u6837\u672c\u88ab\u91c7\u6837\u5230\u7684\u6982\u7387\u90fd\u662f1\u3002", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/preprocessing/text/", 
            "text": "\u6587\u672c\u9884\u5904\u7406\n\n\n\u53e5\u5b50\u5206\u5272text_to_word_sequence\n\n\nkeras.preprocessing.text.text_to_word_sequence(text, \n    filters=base_filter(), lower=True, split=\n \n)\n\n\n\n\n\u672c\u51fd\u6570\u5c06\u4e00\u4e2a\u53e5\u5b50\u62c6\u5206\u6210\u5355\u8bcd\u6784\u6210\u7684\u5217\u8868\n\n\n\u53c2\u6570\n\n\n\n\n\n\ntext\uff1a\u5b57\u7b26\u4e32\uff0c\u5f85\u5904\u7406\u7684\u6587\u672c\n\n\n\n\n\n\nfilters\uff1a\u9700\u8981\u6ee4\u9664\u7684\u5b57\u7b26\u7684\u5217\u8868\u6216\u8fde\u63a5\u5f62\u6210\u7684\u5b57\u7b26\u4e32\uff0c\u4f8b\u5982\u6807\u70b9\u7b26\u53f7\u3002\u9ed8\u8ba4\u503c\u4e3a\nbase_filter()\n\uff0c\u5305\u542b\u6807\u70b9\u7b26\u53f7\uff0c\u5236\u8868\u7b26\u548c\u6362\u884c\u7b26\u7b49\n\n\n\n\n\n\nlower\uff1a\u5e03\u5c14\u503c\uff0c\u662f\u5426\u5c06\u5e8f\u5217\u8bbe\u4e3a\u5c0f\u5199\u5f62\u5f0f\n\n\n\n\n\n\nsplit\uff1a\u5b57\u7b26\u4e32\uff0c\u5355\u8bcd\u7684\u5206\u9694\u7b26\uff0c\u5982\u7a7a\u683c\n\n\n\n\n\n\n\u8fd4\u56de\u503c\n\n\n\u5b57\u7b26\u4e32\u5217\u8868\n\n\n\n\none-hot\u7f16\u7801\n\n\nkeras.preprocessing.text.one_hot(text, n,\n    filters=base_filter(), lower=True, split=\n \n)\n\n\n\n\n\u672c\u51fd\u6570\u5c06\u4e00\u6bb5\u6587\u672c\u7f16\u7801\u4e3aone-hot\u5f62\u5f0f\u7684\u7801\uff0c\u5373\u4ec5\u8bb0\u5f55\u8bcd\u5728\u8bcd\u5178\u4e2d\u7684\u4e0b\u6807\u3002\n\n\n\u3010Tips\u3011\n\u4ece\u5b9a\u4e49\u4e0a\uff0c\u5f53\u5b57\u5178\u957f\u4e3an\u65f6\uff0c\u6bcf\u4e2a\u5355\u8bcd\u5e94\u5f62\u6210\u4e00\u4e2a\u957f\u4e3an\u7684\u5411\u91cf\uff0c\u5176\u4e2d\u4ec5\u6709\u5355\u8bcd\u672c\u8eab\u5728\u5b57\u5178\u4e2d\u4e0b\u6807\u7684\u4f4d\u7f6e\u4e3a1\uff0c\u5176\u4f59\u5747\u4e3a0\uff0c\u8fd9\u79f0\u4e3aone-hot\u3002\u3010@Bigmoyan\u3011\n\n\n\u4e3a\u4e86\u65b9\u4fbf\u8d77\u89c1\uff0c\u51fd\u6570\u5728\u8fd9\u91cc\u4ec5\u628a\u201c1\u201d\u7684\u4f4d\u7f6e\uff0c\u5373\u5b57\u5178\u4e2d\u8bcd\u7684\u4e0b\u6807\u8bb0\u5f55\u4e0b\u6765\u3002\n\n\n\u53c2\u6570\n\n\n\n\nn\uff1a\u6574\u6570\uff0c\u5b57\u5178\u957f\u5ea6\n\n\n\n\n\u8fd4\u56de\u503c\n\n\n\u6574\u6570\u5217\u8868\uff0c\u6bcf\u4e2a\u6574\u6570\u662f[1,n]\u4e4b\u95f4\u7684\u503c\uff0c\u4ee3\u8868\u4e00\u4e2a\u5355\u8bcd\uff08\u4e0d\u4fdd\u8bc1\u552f\u4e00\u6027\uff0c\u5373\u5982\u679c\u8bcd\u5178\u957f\u5ea6\u4e0d\u591f\uff0c\u4e0d\u540c\u7684\u5355\u8bcd\u53ef\u80fd\u4f1a\u88ab\u7f16\u4e3a\u540c\u4e00\u4e2a\u7801\uff09\u3002\n\n\n\n\n\u5206\u8bcd\u5668Tokenizer\n\n\nkeras.preprocessing.text.Tokenizer(nb_words=None, filters=base_filter(), \n    lower=True, split=\n \n)\n\n\n\n\nTokenizer\u662f\u4e00\u4e2a\u7528\u4e8e\u5411\u91cf\u5316\u6587\u672c\uff0c\u6216\u5c06\u6587\u672c\u8f6c\u6362\u4e3a\u5e8f\u5217\uff08\u5373\u5355\u8bcd\u5728\u5b57\u5178\u4e2d\u7684\u4e0b\u6807\u6784\u6210\u7684\u5217\u8868\uff0c\u4ece1\u7b97\u8d77\uff09\u7684\u7c7b\u3002\n\n\n\u6784\u9020\u53c2\u6570\n\n\n\n\n\n\n\u4e0e\ntext_to_word_sequence\n\u540c\u540d\u53c2\u6570\u542b\u4e49\u76f8\u540c\n\n\n\n\n\n\nnb_words\uff1aNone\u6216\u6574\u6570\uff0c\u5904\u7406\u7684\u6700\u5927\u5355\u8bcd\u6570\u91cf\u3002\u82e5\u88ab\u8bbe\u7f6e\u4e3a\u6574\u6570\uff0c\u5219\u5206\u8bcd\u5668\u5c06\u88ab\u9650\u5236\u4e3a\u5904\u7406\u6570\u636e\u96c6\u4e2d\u6700\u5e38\u89c1\u7684\nnb_words\n\u4e2a\u5355\u8bcd\n\n\n\n\n\n\n\u7c7b\u65b9\u6cd5\n\n\n\n\n\n\nfit_on_texts(texts)\n\n\n\n\ntexts\uff1a\u8981\u7528\u4ee5\u8bad\u7ec3\u7684\u6587\u672c\u5217\u8868\n\n\n\n\n\n\n\n\ntexts_to_sequences(texts)\n\n\n\n\n\n\ntexts\uff1a\u5f85\u8f6c\u4e3a\u5e8f\u5217\u7684\u6587\u672c\u5217\u8868\n\n\n\n\n\n\n\u8fd4\u56de\u503c\uff1a\u5e8f\u5217\u7684\u5217\u8868\uff0c\u5217\u8868\u4e2d\u6bcf\u4e2a\u5e8f\u5217\u5bf9\u5e94\u4e8e\u4e00\u6bb5\u8f93\u5165\u6587\u672c\n\n\n\n\n\n\n\n\n\n\ntexts_to_sequences_generator(texts)\n\n\n\n\n\n\n\u672c\u51fd\u6570\u662f\ntexts_to_sequences\n\u7684\u751f\u6210\u5668\u51fd\u6570\u7248\n\n\n\n\n\n\ntexts\uff1a\u5f85\u8f6c\u4e3a\u5e8f\u5217\u7684\u6587\u672c\u5217\u8868\n\n\n\n\n\n\n\u8fd4\u56de\u503c\uff1a\u6bcf\u6b21\u8c03\u7528\u8fd4\u56de\u5bf9\u5e94\u4e8e\u4e00\u6bb5\u8f93\u5165\u6587\u672c\u7684\u5e8f\u5217\n\n\n\n\n\n\n\n\n\n\ntexts_to_matrix(texts, mode)\uff1a\n\n\n\n\n\n\ntexts\uff1a\u5f85\u5411\u91cf\u5316\u7684\u6587\u672c\u5217\u8868\n\n\n\n\n\n\nmode\uff1a\u2018binary\u2019\uff0c\u2018count\u2019\uff0c\u2018tfidf\u2019\uff0c\u2018freq\u2019\u4e4b\u4e00\uff0c\u9ed8\u8ba4\u4e3a\u2018binary\u2019\n\n\n\n\n\n\n\u8fd4\u56de\u503c\uff1a\u5f62\u5982\n(len(texts), nb_words)\n\u7684numpy array\n\n\n\n\n\n\n\n\n\n\nfit_on_sequences(sequences):\n\n\n\n\nsequences\uff1a\u8981\u7528\u4ee5\u8bad\u7ec3\u7684\u5e8f\u5217\u5217\u8868\n\n\n\n\n\n\n\n\nsequences_to_matrix(sequences):\n\n\n\n\n\n\nsequences\uff1a\u5f85\u5411\u91cf\u5316\u7684\u5e8f\u5217\u5217\u8868\n\n\n\n\n\n\nmode\uff1a\u2018binary\u2019\uff0c\u2018count\u2019\uff0c\u2018tfidf\u2019\uff0c\u2018freq\u2019\u4e4b\u4e00\uff0c\u9ed8\u8ba4\u4e3a\u2018binary\u2019\n\n\n\n\n\n\n\u8fd4\u56de\u503c\uff1a\u5f62\u5982\n(len(sequences), nb_words)\n\u7684numpy array\n\n\n\n\n\n\n\n\n\n\n\u5c5e\u6027\n\n\n\n\nword_counts:\u5b57\u5178\uff0c\u5c06\u5355\u8bcd\uff08\u5b57\u7b26\u4e32\uff09\u6620\u5c04\u4e3a\u5b83\u4eec\u5728\u8bad\u7ec3\u671f\u95f4\u51fa\u73b0\u7684\u6b21\u6570\u3002\u4ec5\u5728\u8c03\u7528fit_on_texts\u4e4b\u540e\u8bbe\u7f6e\u3002\n\n\nword_docs: \u5b57\u5178\uff0c\u5c06\u5355\u8bcd\uff08\u5b57\u7b26\u4e32\uff09\u6620\u5c04\u4e3a\u5b83\u4eec\u5728\u8bad\u7ec3\u671f\u95f4\u6240\u51fa\u73b0\u7684\u6587\u6863\u6216\u6587\u672c\u7684\u6570\u91cf\u3002\u4ec5\u5728\u8c03\u7528fit_on_texts\u4e4b\u540e\u8bbe\u7f6e\u3002\n\n\nword_index: \u5b57\u5178\uff0c\u5c06\u5355\u8bcd\uff08\u5b57\u7b26\u4e32\uff09\u6620\u5c04\u4e3a\u5b83\u4eec\u7684\u6392\u540d\u6216\u8005\u7d22\u5f15\u3002\u4ec5\u5728\u8c03\u7528fit_on_texts\u4e4b\u540e\u8bbe\u7f6e\u3002\n\n\ndocument_count: \u6574\u6570\u3002\u5206\u8bcd\u5668\u88ab\u8bad\u7ec3\u7684\u6587\u6863\uff08\u6587\u672c\u6216\u8005\u5e8f\u5217\uff09\u6570\u91cf\u3002\u4ec5\u5728\u8c03\u7528fit_on_texts\u6216fit_on_sequences\u4e4b\u540e\u8bbe\u7f6e\u3002", 
            "title": "\u6587\u672c\u9884\u5904\u7406"
        }, 
        {
            "location": "/preprocessing/text/#_1", 
            "text": "", 
            "title": "\u6587\u672c\u9884\u5904\u7406"
        }, 
        {
            "location": "/preprocessing/text/#text_to_word_sequence", 
            "text": "keras.preprocessing.text.text_to_word_sequence(text, \n    filters=base_filter(), lower=True, split=   )  \u672c\u51fd\u6570\u5c06\u4e00\u4e2a\u53e5\u5b50\u62c6\u5206\u6210\u5355\u8bcd\u6784\u6210\u7684\u5217\u8868", 
            "title": "\u53e5\u5b50\u5206\u5272text_to_word_sequence"
        }, 
        {
            "location": "/preprocessing/text/#_2", 
            "text": "text\uff1a\u5b57\u7b26\u4e32\uff0c\u5f85\u5904\u7406\u7684\u6587\u672c    filters\uff1a\u9700\u8981\u6ee4\u9664\u7684\u5b57\u7b26\u7684\u5217\u8868\u6216\u8fde\u63a5\u5f62\u6210\u7684\u5b57\u7b26\u4e32\uff0c\u4f8b\u5982\u6807\u70b9\u7b26\u53f7\u3002\u9ed8\u8ba4\u503c\u4e3a base_filter() \uff0c\u5305\u542b\u6807\u70b9\u7b26\u53f7\uff0c\u5236\u8868\u7b26\u548c\u6362\u884c\u7b26\u7b49    lower\uff1a\u5e03\u5c14\u503c\uff0c\u662f\u5426\u5c06\u5e8f\u5217\u8bbe\u4e3a\u5c0f\u5199\u5f62\u5f0f    split\uff1a\u5b57\u7b26\u4e32\uff0c\u5355\u8bcd\u7684\u5206\u9694\u7b26\uff0c\u5982\u7a7a\u683c", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/preprocessing/text/#_3", 
            "text": "\u5b57\u7b26\u4e32\u5217\u8868", 
            "title": "\u8fd4\u56de\u503c"
        }, 
        {
            "location": "/preprocessing/text/#one-hot", 
            "text": "keras.preprocessing.text.one_hot(text, n,\n    filters=base_filter(), lower=True, split=   )  \u672c\u51fd\u6570\u5c06\u4e00\u6bb5\u6587\u672c\u7f16\u7801\u4e3aone-hot\u5f62\u5f0f\u7684\u7801\uff0c\u5373\u4ec5\u8bb0\u5f55\u8bcd\u5728\u8bcd\u5178\u4e2d\u7684\u4e0b\u6807\u3002  \u3010Tips\u3011\n\u4ece\u5b9a\u4e49\u4e0a\uff0c\u5f53\u5b57\u5178\u957f\u4e3an\u65f6\uff0c\u6bcf\u4e2a\u5355\u8bcd\u5e94\u5f62\u6210\u4e00\u4e2a\u957f\u4e3an\u7684\u5411\u91cf\uff0c\u5176\u4e2d\u4ec5\u6709\u5355\u8bcd\u672c\u8eab\u5728\u5b57\u5178\u4e2d\u4e0b\u6807\u7684\u4f4d\u7f6e\u4e3a1\uff0c\u5176\u4f59\u5747\u4e3a0\uff0c\u8fd9\u79f0\u4e3aone-hot\u3002\u3010@Bigmoyan\u3011  \u4e3a\u4e86\u65b9\u4fbf\u8d77\u89c1\uff0c\u51fd\u6570\u5728\u8fd9\u91cc\u4ec5\u628a\u201c1\u201d\u7684\u4f4d\u7f6e\uff0c\u5373\u5b57\u5178\u4e2d\u8bcd\u7684\u4e0b\u6807\u8bb0\u5f55\u4e0b\u6765\u3002", 
            "title": "one-hot\u7f16\u7801"
        }, 
        {
            "location": "/preprocessing/text/#_4", 
            "text": "n\uff1a\u6574\u6570\uff0c\u5b57\u5178\u957f\u5ea6", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/preprocessing/text/#_5", 
            "text": "\u6574\u6570\u5217\u8868\uff0c\u6bcf\u4e2a\u6574\u6570\u662f[1,n]\u4e4b\u95f4\u7684\u503c\uff0c\u4ee3\u8868\u4e00\u4e2a\u5355\u8bcd\uff08\u4e0d\u4fdd\u8bc1\u552f\u4e00\u6027\uff0c\u5373\u5982\u679c\u8bcd\u5178\u957f\u5ea6\u4e0d\u591f\uff0c\u4e0d\u540c\u7684\u5355\u8bcd\u53ef\u80fd\u4f1a\u88ab\u7f16\u4e3a\u540c\u4e00\u4e2a\u7801\uff09\u3002", 
            "title": "\u8fd4\u56de\u503c"
        }, 
        {
            "location": "/preprocessing/text/#tokenizer", 
            "text": "keras.preprocessing.text.Tokenizer(nb_words=None, filters=base_filter(), \n    lower=True, split=   )  Tokenizer\u662f\u4e00\u4e2a\u7528\u4e8e\u5411\u91cf\u5316\u6587\u672c\uff0c\u6216\u5c06\u6587\u672c\u8f6c\u6362\u4e3a\u5e8f\u5217\uff08\u5373\u5355\u8bcd\u5728\u5b57\u5178\u4e2d\u7684\u4e0b\u6807\u6784\u6210\u7684\u5217\u8868\uff0c\u4ece1\u7b97\u8d77\uff09\u7684\u7c7b\u3002", 
            "title": "\u5206\u8bcd\u5668Tokenizer"
        }, 
        {
            "location": "/preprocessing/text/#_6", 
            "text": "\u4e0e text_to_word_sequence \u540c\u540d\u53c2\u6570\u542b\u4e49\u76f8\u540c    nb_words\uff1aNone\u6216\u6574\u6570\uff0c\u5904\u7406\u7684\u6700\u5927\u5355\u8bcd\u6570\u91cf\u3002\u82e5\u88ab\u8bbe\u7f6e\u4e3a\u6574\u6570\uff0c\u5219\u5206\u8bcd\u5668\u5c06\u88ab\u9650\u5236\u4e3a\u5904\u7406\u6570\u636e\u96c6\u4e2d\u6700\u5e38\u89c1\u7684 nb_words \u4e2a\u5355\u8bcd", 
            "title": "\u6784\u9020\u53c2\u6570"
        }, 
        {
            "location": "/preprocessing/text/#_7", 
            "text": "fit_on_texts(texts)   texts\uff1a\u8981\u7528\u4ee5\u8bad\u7ec3\u7684\u6587\u672c\u5217\u8868     texts_to_sequences(texts)    texts\uff1a\u5f85\u8f6c\u4e3a\u5e8f\u5217\u7684\u6587\u672c\u5217\u8868    \u8fd4\u56de\u503c\uff1a\u5e8f\u5217\u7684\u5217\u8868\uff0c\u5217\u8868\u4e2d\u6bcf\u4e2a\u5e8f\u5217\u5bf9\u5e94\u4e8e\u4e00\u6bb5\u8f93\u5165\u6587\u672c      texts_to_sequences_generator(texts)    \u672c\u51fd\u6570\u662f texts_to_sequences \u7684\u751f\u6210\u5668\u51fd\u6570\u7248    texts\uff1a\u5f85\u8f6c\u4e3a\u5e8f\u5217\u7684\u6587\u672c\u5217\u8868    \u8fd4\u56de\u503c\uff1a\u6bcf\u6b21\u8c03\u7528\u8fd4\u56de\u5bf9\u5e94\u4e8e\u4e00\u6bb5\u8f93\u5165\u6587\u672c\u7684\u5e8f\u5217      texts_to_matrix(texts, mode)\uff1a    texts\uff1a\u5f85\u5411\u91cf\u5316\u7684\u6587\u672c\u5217\u8868    mode\uff1a\u2018binary\u2019\uff0c\u2018count\u2019\uff0c\u2018tfidf\u2019\uff0c\u2018freq\u2019\u4e4b\u4e00\uff0c\u9ed8\u8ba4\u4e3a\u2018binary\u2019    \u8fd4\u56de\u503c\uff1a\u5f62\u5982 (len(texts), nb_words) \u7684numpy array      fit_on_sequences(sequences):   sequences\uff1a\u8981\u7528\u4ee5\u8bad\u7ec3\u7684\u5e8f\u5217\u5217\u8868     sequences_to_matrix(sequences):    sequences\uff1a\u5f85\u5411\u91cf\u5316\u7684\u5e8f\u5217\u5217\u8868    mode\uff1a\u2018binary\u2019\uff0c\u2018count\u2019\uff0c\u2018tfidf\u2019\uff0c\u2018freq\u2019\u4e4b\u4e00\uff0c\u9ed8\u8ba4\u4e3a\u2018binary\u2019    \u8fd4\u56de\u503c\uff1a\u5f62\u5982 (len(sequences), nb_words) \u7684numpy array", 
            "title": "\u7c7b\u65b9\u6cd5"
        }, 
        {
            "location": "/preprocessing/text/#_8", 
            "text": "word_counts:\u5b57\u5178\uff0c\u5c06\u5355\u8bcd\uff08\u5b57\u7b26\u4e32\uff09\u6620\u5c04\u4e3a\u5b83\u4eec\u5728\u8bad\u7ec3\u671f\u95f4\u51fa\u73b0\u7684\u6b21\u6570\u3002\u4ec5\u5728\u8c03\u7528fit_on_texts\u4e4b\u540e\u8bbe\u7f6e\u3002  word_docs: \u5b57\u5178\uff0c\u5c06\u5355\u8bcd\uff08\u5b57\u7b26\u4e32\uff09\u6620\u5c04\u4e3a\u5b83\u4eec\u5728\u8bad\u7ec3\u671f\u95f4\u6240\u51fa\u73b0\u7684\u6587\u6863\u6216\u6587\u672c\u7684\u6570\u91cf\u3002\u4ec5\u5728\u8c03\u7528fit_on_texts\u4e4b\u540e\u8bbe\u7f6e\u3002  word_index: \u5b57\u5178\uff0c\u5c06\u5355\u8bcd\uff08\u5b57\u7b26\u4e32\uff09\u6620\u5c04\u4e3a\u5b83\u4eec\u7684\u6392\u540d\u6216\u8005\u7d22\u5f15\u3002\u4ec5\u5728\u8c03\u7528fit_on_texts\u4e4b\u540e\u8bbe\u7f6e\u3002  document_count: \u6574\u6570\u3002\u5206\u8bcd\u5668\u88ab\u8bad\u7ec3\u7684\u6587\u6863\uff08\u6587\u672c\u6216\u8005\u5e8f\u5217\uff09\u6570\u91cf\u3002\u4ec5\u5728\u8c03\u7528fit_on_texts\u6216fit_on_sequences\u4e4b\u540e\u8bbe\u7f6e\u3002", 
            "title": "\u5c5e\u6027"
        }, 
        {
            "location": "/preprocessing/image/", 
            "text": "\u56fe\u7247\u9884\u5904\u7406\n\n\n\u56fe\u7247\u751f\u6210\u5668ImageDataGenerator\n\n\nkeras.preprocessing.image.ImageDataGenerator(featurewise_center=False,\n    samplewise_center=False,\n    featurewise_std_normalization=False,\n    samplewise_std_normalization=False,\n    zca_whitening=False,\n    rotation_range=0.,\n    width_shift_range=0.,\n    height_shift_range=0.,\n    shear_range=0.,\n    zoom_range=0.,\n    channel_shift_range=0.,\n    fill_mode='nearest',\n    cval=0.,\n    horizontal_flip=False,\n    vertical_flip=False,\n    rescale=None,\n    dim_ordering=K.image_dim_ordering())\n\n\n\n\n\u7528\u4ee5\u751f\u6210\u4e00\u4e2abatch\u7684\u56fe\u50cf\u6570\u636e\uff0c\u652f\u6301\u5b9e\u65f6\u6570\u636e\u63d0\u5347\u3002\u8bad\u7ec3\u65f6\u8be5\u51fd\u6570\u4f1a\u65e0\u9650\u751f\u6210\u6570\u636e\uff0c\u76f4\u5230\u8fbe\u5230\u89c4\u5b9a\u7684epoch\u6b21\u6570\u4e3a\u6b62\u3002\n\n\n\u53c2\u6570\n\n\n\n\n\n\nfeaturewise_center\uff1a\u5e03\u5c14\u503c\uff0c\u4f7f\u8f93\u5165\u6570\u636e\u96c6\u53bb\u4e2d\u5fc3\u5316\uff08\u5747\u503c\u4e3a0\uff09, \u6309feature\u6267\u884c\n\n\n\n\n\n\nsamplewise_center\uff1a\u5e03\u5c14\u503c\uff0c\u4f7f\u8f93\u5165\u6570\u636e\u7684\u6bcf\u4e2a\u6837\u672c\u5747\u503c\u4e3a0\n\n\n\n\n\n\nfeaturewise_std_normalization\uff1a\u5e03\u5c14\u503c\uff0c\u5c06\u8f93\u5165\u9664\u4ee5\u6570\u636e\u96c6\u7684\u6807\u51c6\u5dee\u4ee5\u5b8c\u6210\u6807\u51c6\u5316, \u6309feature\u6267\u884c\n\n\n\n\n\n\nsamplewise_std_normalization\uff1a\u5e03\u5c14\u503c\uff0c\u5c06\u8f93\u5165\u7684\u6bcf\u4e2a\u6837\u672c\u9664\u4ee5\u5176\u81ea\u8eab\u7684\u6807\u51c6\u5dee\n\n\n\n\n\n\nzca_whitening\uff1a\u5e03\u5c14\u503c\uff0c\u5bf9\u8f93\u5165\u6570\u636e\u65bd\u52a0ZCA\u767d\u5316\n\n\n\n\n\n\nrotation_range\uff1a\u6574\u6570\uff0c\u6570\u636e\u63d0\u5347\u65f6\u56fe\u7247\u968f\u673a\u8f6c\u52a8\u7684\u89d2\u5ea6\n\n\n\n\n\n\nwidth_shift_range\uff1a\u6d6e\u70b9\u6570\uff0c\u56fe\u7247\u5bbd\u5ea6\u7684\u67d0\u4e2a\u6bd4\u4f8b\uff0c\u6570\u636e\u63d0\u5347\u65f6\u56fe\u7247\u6c34\u5e73\u504f\u79fb\u7684\u5e45\u5ea6\n\n\n\n\n\n\nheight_shift_range\uff1a\u6d6e\u70b9\u6570\uff0c\u56fe\u7247\u9ad8\u5ea6\u7684\u67d0\u4e2a\u6bd4\u4f8b\uff0c\u6570\u636e\u63d0\u5347\u65f6\u56fe\u7247\u7ad6\u76f4\u504f\u79fb\u7684\u5e45\u5ea6\n\n\n\n\n\n\nshear_range\uff1a\u6d6e\u70b9\u6570\uff0c\u526a\u5207\u5f3a\u5ea6\uff08\u9006\u65f6\u9488\u65b9\u5411\u7684\u526a\u5207\u53d8\u6362\u89d2\u5ea6\uff09\n\n\n\n\n\n\nzoom_range\uff1a\u6d6e\u70b9\u6570\u6216\u5f62\u5982\n[lower,upper]\n\u7684\u5217\u8868\uff0c\u968f\u673a\u7f29\u653e\u7684\u5e45\u5ea6\uff0c\u82e5\u4e3a\u6d6e\u70b9\u6570\uff0c\u5219\u76f8\u5f53\u4e8e\n[lower,upper] = [1 - zoom_range, 1+zoom_range]\n\n\n\n\n\n\nchannel_shift_range\uff1a\u6d6e\u70b9\u6570\uff0c\u968f\u673a\u901a\u9053\u504f\u79fb\u7684\u5e45\u5ea6\n\n\n\n\n\n\nfill_mode\uff1a\uff1b\u2018constant\u2019\uff0c\u2018nearest\u2019\uff0c\u2018reflect\u2019\u6216\u2018wrap\u2019\u4e4b\u4e00\uff0c\u5f53\u8fdb\u884c\u53d8\u6362\u65f6\u8d85\u51fa\u8fb9\u754c\u7684\u70b9\u5c06\u6839\u636e\u672c\u53c2\u6570\u7ed9\u5b9a\u7684\u65b9\u6cd5\u8fdb\u884c\u5904\u7406\n\n\n\n\n\n\ncval\uff1a\u6d6e\u70b9\u6570\u6216\u6574\u6570\uff0c\u5f53\nfill_mode=constant\n\u65f6\uff0c\u6307\u5b9a\u8981\u5411\u8d85\u51fa\u8fb9\u754c\u7684\u70b9\u586b\u5145\u7684\u503c\n\n\n\n\n\n\nhorizontal_flip\uff1a\u5e03\u5c14\u503c\uff0c\u8fdb\u884c\u968f\u673a\u6c34\u5e73\u7ffb\u8f6c\n\n\n\n\n\n\nvertical_flip\uff1a\u5e03\u5c14\u503c\uff0c\u8fdb\u884c\u968f\u673a\u7ad6\u76f4\u7ffb\u8f6c\n\n\n\n\n\n\nrescale: \u91cd\u653e\u7f29\u56e0\u5b50,\u9ed8\u8ba4\u4e3aNone. \u5982\u679c\u4e3aNone\u62160\u5219\u4e0d\u8fdb\u884c\u653e\u7f29,\u5426\u5219\u4f1a\u5c06\u8be5\u6570\u503c\u4e58\u5230\u6570\u636e\u4e0a(\u5728\u5e94\u7528\u5176\u4ed6\u53d8\u6362\u4e4b\u524d)\n\n\n\n\n\n\ndim_ordering\uff1a\u2018tf\u2019\u548c\u2018th\u2019\u4e4b\u4e00\uff0c\u89c4\u5b9a\u6570\u636e\u7684\u7ef4\u5ea6\u987a\u5e8f\u3002\u2018tf\u2019\u6a21\u5f0f\u4e0b\u6570\u636e\u7684\u5f62\u72b6\u4e3a\nsamples, height, width, channels\n\uff0c\u2018th\u2019\u4e0b\u5f62\u72b6\u4e3a\n(samples, channels, height, width).\n\u8be5\u53c2\u6570\u7684\u9ed8\u8ba4\u503c\u662fKeras\u914d\u7f6e\u6587\u4ef6\n~/.keras/keras.json\n\u7684\nimage_dim_ordering\n\u503c,\u5982\u679c\u4f60\u4ece\u672a\u8bbe\u7f6e\u8fc7\u7684\u8bdd,\u5c31\u662f'tf'\n\n\n\n\n\n\n\n\n\u65b9\u6cd5\n\n\n\n\n\n\nfit(X, augment=False, rounds=1)\uff1a\u8ba1\u7b97\u4f9d\u8d56\u4e8e\u6570\u636e\u7684\u53d8\u6362\u6240\u9700\u8981\u7684\u7edf\u8ba1\u4fe1\u606f(\u5747\u503c\u65b9\u5dee\u7b49),\u53ea\u6709\u4f7f\u7528\nfeaturewise_center\n\uff0c\nfeaturewise_std_normalization\n\u6216\nzca_whitening\n\u65f6\u9700\u8981\u6b64\u51fd\u6570\u3002\n\n\n\n\n\n\nX\uff1anumpy array\uff0c\u6837\u672c\u6570\u636e\uff0c\u79e9\u5e94\u4e3a4.\u5728\u9ed1\u767d\u56fe\u50cf\u7684\u60c5\u51b5\u4e0bchannel\u8f74\u7684\u503c\u4e3a1\uff0c\u5728\u5f69\u8272\u56fe\u50cf\u60c5\u51b5\u4e0b\u503c\u4e3a3\n\n\n\n\n\n\naugment\uff1a\u5e03\u5c14\u503c\uff0c\u786e\u5b9a\u662f\u5426\u4f7f\u7528\u968f\u5373\u63d0\u5347\u8fc7\u7684\u6570\u636e\n\n\n\n\n\n\nround\uff1a\u82e5\u8bbe\naugment=True\n\uff0c\u786e\u5b9a\u8981\u5728\u6570\u636e\u4e0a\u8fdb\u884c\u591a\u5c11\u8f6e\u6570\u636e\u63d0\u5347\uff0c\u9ed8\u8ba4\u503c\u4e3a1\n\n\n\n\n\n\nseed: \u6574\u6570,\u968f\u673a\u6570\u79cd\u5b50\n\n\n\n\n\n\n\n\n\n\nflow(self, X, y, batch_size=32, shuffle=True, seed=None, save_to_dir=None, save_prefix='', save_format='jpeg')\uff1a\u63a5\u6536numpy\u6570\u7ec4\u548c\u6807\u7b7e\u4e3a\u53c2\u6570,\u751f\u6210\u7ecf\u8fc7\u6570\u636e\u63d0\u5347\u6216\u6807\u51c6\u5316\u540e\u7684batch\u6570\u636e,\u5e76\u5728\u4e00\u4e2a\u65e0\u9650\u5faa\u73af\u4e2d\u4e0d\u65ad\u7684\u8fd4\u56debatch\u6570\u636e\n\n\n\n\n\n\nX\uff1a\u6837\u672c\u6570\u636e\uff0c\u79e9\u5e94\u4e3a4.\u5728\u9ed1\u767d\u56fe\u50cf\u7684\u60c5\u51b5\u4e0bchannel\u8f74\u7684\u503c\u4e3a1\uff0c\u5728\u5f69\u8272\u56fe\u50cf\u60c5\u51b5\u4e0b\u503c\u4e3a3\n\n\n\n\n\n\ny\uff1a\u6807\u7b7e\n\n\n\n\n\n\nbatch_size\uff1a\u6574\u6570\uff0c\u9ed8\u8ba432\n\n\n\n\n\n\nshuffle\uff1a\u5e03\u5c14\u503c\uff0c\u662f\u5426\u968f\u673a\u6253\u4e71\u6570\u636e\uff0c\u9ed8\u8ba4\u4e3aTrue\n\n\n\n\n\n\nsave_to_dir\uff1aNone\u6216\u5b57\u7b26\u4e32\uff0c\u8be5\u53c2\u6570\u80fd\u8ba9\u4f60\u5c06\u63d0\u5347\u540e\u7684\u56fe\u7247\u4fdd\u5b58\u8d77\u6765\uff0c\u7528\u4ee5\u53ef\u89c6\u5316\n\n\n\n\n\n\nsave_prefix\uff1a\u5b57\u7b26\u4e32\uff0c\u4fdd\u5b58\u63d0\u5347\u540e\u56fe\u7247\u65f6\u4f7f\u7528\u7684\u524d\u7f00, \u4ec5\u5f53\u8bbe\u7f6e\u4e86\nsave_to_dir\n\u65f6\u751f\u6548\n\n\n\n\n\n\nsave_format\uff1a\"png\"\u6216\"jpeg\"\u4e4b\u4e00\uff0c\u6307\u5b9a\u4fdd\u5b58\u56fe\u7247\u7684\u6570\u636e\u683c\u5f0f,\u9ed8\u8ba4\"jpeg\"\n\n\n\n\n\n\nyields:\u5f62\u5982(x,y)\u7684tuple,x\u662f\u4ee3\u8868\u56fe\u50cf\u6570\u636e\u7684numpy\u6570\u7ec4.y\u662f\u4ee3\u8868\u6807\u7b7e\u7684numpy\u6570\u7ec4.\u8be5\u8fed\u4ee3\u5668\u65e0\u9650\u5faa\u73af.\n\n\n\n\n\n\nseed: \u6574\u6570,\u968f\u673a\u6570\u79cd\u5b50\n\n\n\n\n\n\n\n\n\n\nflow_from_directory(directory): \u4ee5\u6587\u4ef6\u5939\u8def\u5f84\u4e3a\u53c2\u6570,\u751f\u6210\u7ecf\u8fc7\u6570\u636e\u63d0\u5347/\u5f52\u4e00\u5316\u540e\u7684\u6570\u636e,\u5728\u4e00\u4e2a\u65e0\u9650\u5faa\u73af\u4e2d\u65e0\u9650\u4ea7\u751fbatch\u6570\u636e\n\n\n\n\ndirectory: \u76ee\u6807\u6587\u4ef6\u5939\u8def\u5f84,\u5bf9\u4e8e\u6bcf\u4e00\u4e2a\u7c7b,\u8be5\u6587\u4ef6\u5939\u90fd\u8981\u5305\u542b\u4e00\u4e2a\u5b50\u6587\u4ef6\u5939.\u5b50\u6587\u4ef6\u5939\u4e2d\u4efb\u4f55JPG\u3001PNG\u548cBNP\u7684\u56fe\u7247\u90fd\u4f1a\u88ab\u751f\u6210\u5668\u4f7f\u7528.\u8be6\u60c5\u8bf7\u67e5\u770b\n\u6b64\u811a\u672c\n\n\ntarget_size: \u6574\u6570tuple,\u9ed8\u8ba4\u4e3a(256, 256). \u56fe\u50cf\u5c06\u88abresize\u6210\u8be5\u5c3a\u5bf8\n\n\ncolor_mode: \u989c\u8272\u6a21\u5f0f,\u4e3a\"grayscale\",\"rgb\"\u4e4b\u4e00,\u9ed8\u8ba4\u4e3a\"rgb\".\u4ee3\u8868\u8fd9\u4e9b\u56fe\u7247\u662f\u5426\u4f1a\u88ab\u8f6c\u6362\u4e3a\u5355\u901a\u9053\u6216\u4e09\u901a\u9053\u7684\u56fe\u7247.\n\n\nclasses: \u53ef\u9009\u53c2\u6570,\u4e3a\u5b50\u6587\u4ef6\u5939\u7684\u5217\u8868,\u5982['dogs','cats']\u9ed8\u8ba4\u4e3aNone. \u82e5\u672a\u63d0\u4f9b,\u5219\u8be5\u7c7b\u522b\u5217\u8868\u5c06\u81ea\u52a8\u63a8\u65ad(\u7c7b\u522b\u7684\u987a\u5e8f\u5c06\u6309\u7167\u5b57\u6bcd\u8868\u987a\u5e8f\u6620\u5c04\u5230\u6807\u7b7e\u503c)\n\n\nclass_mode: \"categorical\", \"binary\", \"sparse\"\u6216None\u4e4b\u4e00. \u9ed8\u8ba4\u4e3a\"categorical. \u8be5\u53c2\u6570\u51b3\u5b9a\u4e86\u8fd4\u56de\u7684\u6807\u7b7e\u6570\u7ec4\u7684\u5f62\u5f0f, \"categorical\"\u4f1a\u8fd4\u56de2D\u7684one-hot\u7f16\u7801\u6807\u7b7e,\"binary\"\u8fd4\u56de1D\u7684\u4e8c\u503c\u6807\u7b7e.\"sparse\"\u8fd4\u56de1D\u7684\u6574\u6570\u6807\u7b7e,\u5982\u679c\u4e3aNone\u5219\u4e0d\u8fd4\u56de\u4efb\u4f55\u6807\u7b7e, \u751f\u6210\u5668\u5c06\u4ec5\u4ec5\u751f\u6210batch\u6570\u636e, \u8fd9\u79cd\u60c5\u51b5\u5728\u4f7f\u7528\nmodel.predict_generator()\n\u548c\nmodel.evaluate_generator()\n\u7b49\u51fd\u6570\u65f6\u4f1a\u7528\u5230.\n\n\nbatch_size: batch\u6570\u636e\u7684\u5927\u5c0f,\u9ed8\u8ba432\n\n\nshuffle: \u662f\u5426\u6253\u4e71\u6570\u636e,\u9ed8\u8ba4\u4e3aTrue\n\n\nseed: \u53ef\u9009\u53c2\u6570,\u6253\u4e71\u6570\u636e\u548c\u8fdb\u884c\u53d8\u6362\u65f6\u7684\u968f\u673a\u6570\u79cd\u5b50\n\n\nsave_to_dir: None\u6216\u5b57\u7b26\u4e32\uff0c\u8be5\u53c2\u6570\u80fd\u8ba9\u4f60\u5c06\u63d0\u5347\u540e\u7684\u56fe\u7247\u4fdd\u5b58\u8d77\u6765\uff0c\u7528\u4ee5\u53ef\u89c6\u5316\n\n\nsave_prefix\uff1a\u5b57\u7b26\u4e32\uff0c\u4fdd\u5b58\u63d0\u5347\u540e\u56fe\u7247\u65f6\u4f7f\u7528\u7684\u524d\u7f00, \u4ec5\u5f53\u8bbe\u7f6e\u4e86\nsave_to_dir\n\u65f6\u751f\u6548\n\n\nsave_format\uff1a\"png\"\u6216\"jpeg\"\u4e4b\u4e00\uff0c\u6307\u5b9a\u4fdd\u5b58\u56fe\u7247\u7684\u6570\u636e\u683c\u5f0f,\u9ed8\u8ba4\"jpeg\"\n\n\nflollow_links: \u662f\u5426\u8bbf\u95ee\u5b50\u6587\u4ef6\u5939\u4e2d\u7684\u8f6f\u94fe\u63a5\n\n\n\n\n\n\n\n\n\u4f8b\u5b50\n\n\n\u4f7f\u7528\n.flow()\n\u7684\u4f8b\u5b50\n\n\n(X_train, y_train), (X_test, y_test) = cifar10.load_data()\nY_train = np_utils.to_categorical(y_train, nb_classes)\nY_test = np_utils.to_categorical(y_test, nb_classes)\n\ndatagen = ImageDataGenerator(\n    featurewise_center=True,\n    featurewise_std_normalization=True,\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip=True)\n\n# compute quantities required for featurewise normalization\n# (std, mean, and principal components if ZCA whitening is applied)\ndatagen.fit(X_train)\n\n# fits the model on batches with real-time data augmentation:\nmodel.fit_generator(datagen.flow(X_train, Y_train, batch_size=32),\n                    samples_per_epoch=len(X_train), nb_epoch=nb_epoch)\n\n# here's a more \nmanual\n example\nfor e in range(nb_epoch):\n    print 'Epoch', e\n    batches = 0\n    for X_batch, Y_batch in datagen.flow(X_train, Y_train, batch_size=32):\n        loss = model.train(X_batch, Y_batch)\n        batches += 1\n        if batches \n= len(X_train) / 32:\n            # we need to break the loop by hand because\n            # the generator loops indefinitely\n            break\n\n\n\n\n\u4f7f\u7528\n.flow_from_directory(directory)\n\u7684\u4f8b\u5b50\n\n\ntrain_datagen = ImageDataGenerator(\n        rescale=1./255,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True)\n\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_generator = train_datagen.flow_from_directory(\n        'data/train',\n        target_size=(150, 150),\n        batch_size=32,\n        class_mode='binary')\n\nvalidation_generator = test_datagen.flow_from_directory(\n        'data/validation',\n        target_size=(150, 150),\n        batch_size=32,\n        class_mode='binary')\n\nmodel.fit_generator(\n        train_generator,\n        samples_per_epoch=2000,\n        nb_epoch=50,\n        validation_data=validation_generator,\n        nb_val_samples=800)\n\n\n\n\n\u540c\u65f6\u53d8\u6362\u56fe\u50cf\u548cmask\n\n\n# we create two instances with the same arguments\ndata_gen_args = dict(featurewise_center=True,\n                     featurewise_std_normalization=True,\n                     rotation_range=90.,\n                     width_shift_range=0.1,\n                     height_shift_range=0.1,\n                     zoom_range=0.2)\nimage_datagen = ImageDataGenerator(**data_gen_args)\nmask_datagen = ImageDataGenerator(**data_gen_args)\n\n# Provide the same seed and keyword arguments to the fit and flow methods\nseed = 1\nimage_datagen.fit(images, augment=True, seed=seed)\nmask_datagen.fit(masks, augment=True, seed=seed)\n\nimage_generator = image_datagen.flow_from_directory(\n    'data/images',\n    class_mode=None,\n    seed=seed)\n\nmask_generator = mask_datagen.flow_from_directory(\n    'data/masks',\n    class_mode=None,\n    seed=seed)\n\n# combine generators into one which yields image and masks\ntrain_generator = zip(image_generator, mask_generator)\n\nmodel.fit_generator(\n    train_generator,\n    samples_per_epoch=2000,\n    nb_epoch=50)", 
            "title": "\u56fe\u7247\u9884\u5904\u7406"
        }, 
        {
            "location": "/preprocessing/image/#_1", 
            "text": "", 
            "title": "\u56fe\u7247\u9884\u5904\u7406"
        }, 
        {
            "location": "/preprocessing/image/#imagedatagenerator", 
            "text": "keras.preprocessing.image.ImageDataGenerator(featurewise_center=False,\n    samplewise_center=False,\n    featurewise_std_normalization=False,\n    samplewise_std_normalization=False,\n    zca_whitening=False,\n    rotation_range=0.,\n    width_shift_range=0.,\n    height_shift_range=0.,\n    shear_range=0.,\n    zoom_range=0.,\n    channel_shift_range=0.,\n    fill_mode='nearest',\n    cval=0.,\n    horizontal_flip=False,\n    vertical_flip=False,\n    rescale=None,\n    dim_ordering=K.image_dim_ordering())  \u7528\u4ee5\u751f\u6210\u4e00\u4e2abatch\u7684\u56fe\u50cf\u6570\u636e\uff0c\u652f\u6301\u5b9e\u65f6\u6570\u636e\u63d0\u5347\u3002\u8bad\u7ec3\u65f6\u8be5\u51fd\u6570\u4f1a\u65e0\u9650\u751f\u6210\u6570\u636e\uff0c\u76f4\u5230\u8fbe\u5230\u89c4\u5b9a\u7684epoch\u6b21\u6570\u4e3a\u6b62\u3002", 
            "title": "\u56fe\u7247\u751f\u6210\u5668ImageDataGenerator"
        }, 
        {
            "location": "/preprocessing/image/#_2", 
            "text": "featurewise_center\uff1a\u5e03\u5c14\u503c\uff0c\u4f7f\u8f93\u5165\u6570\u636e\u96c6\u53bb\u4e2d\u5fc3\u5316\uff08\u5747\u503c\u4e3a0\uff09, \u6309feature\u6267\u884c    samplewise_center\uff1a\u5e03\u5c14\u503c\uff0c\u4f7f\u8f93\u5165\u6570\u636e\u7684\u6bcf\u4e2a\u6837\u672c\u5747\u503c\u4e3a0    featurewise_std_normalization\uff1a\u5e03\u5c14\u503c\uff0c\u5c06\u8f93\u5165\u9664\u4ee5\u6570\u636e\u96c6\u7684\u6807\u51c6\u5dee\u4ee5\u5b8c\u6210\u6807\u51c6\u5316, \u6309feature\u6267\u884c    samplewise_std_normalization\uff1a\u5e03\u5c14\u503c\uff0c\u5c06\u8f93\u5165\u7684\u6bcf\u4e2a\u6837\u672c\u9664\u4ee5\u5176\u81ea\u8eab\u7684\u6807\u51c6\u5dee    zca_whitening\uff1a\u5e03\u5c14\u503c\uff0c\u5bf9\u8f93\u5165\u6570\u636e\u65bd\u52a0ZCA\u767d\u5316    rotation_range\uff1a\u6574\u6570\uff0c\u6570\u636e\u63d0\u5347\u65f6\u56fe\u7247\u968f\u673a\u8f6c\u52a8\u7684\u89d2\u5ea6    width_shift_range\uff1a\u6d6e\u70b9\u6570\uff0c\u56fe\u7247\u5bbd\u5ea6\u7684\u67d0\u4e2a\u6bd4\u4f8b\uff0c\u6570\u636e\u63d0\u5347\u65f6\u56fe\u7247\u6c34\u5e73\u504f\u79fb\u7684\u5e45\u5ea6    height_shift_range\uff1a\u6d6e\u70b9\u6570\uff0c\u56fe\u7247\u9ad8\u5ea6\u7684\u67d0\u4e2a\u6bd4\u4f8b\uff0c\u6570\u636e\u63d0\u5347\u65f6\u56fe\u7247\u7ad6\u76f4\u504f\u79fb\u7684\u5e45\u5ea6    shear_range\uff1a\u6d6e\u70b9\u6570\uff0c\u526a\u5207\u5f3a\u5ea6\uff08\u9006\u65f6\u9488\u65b9\u5411\u7684\u526a\u5207\u53d8\u6362\u89d2\u5ea6\uff09    zoom_range\uff1a\u6d6e\u70b9\u6570\u6216\u5f62\u5982 [lower,upper] \u7684\u5217\u8868\uff0c\u968f\u673a\u7f29\u653e\u7684\u5e45\u5ea6\uff0c\u82e5\u4e3a\u6d6e\u70b9\u6570\uff0c\u5219\u76f8\u5f53\u4e8e [lower,upper] = [1 - zoom_range, 1+zoom_range]    channel_shift_range\uff1a\u6d6e\u70b9\u6570\uff0c\u968f\u673a\u901a\u9053\u504f\u79fb\u7684\u5e45\u5ea6    fill_mode\uff1a\uff1b\u2018constant\u2019\uff0c\u2018nearest\u2019\uff0c\u2018reflect\u2019\u6216\u2018wrap\u2019\u4e4b\u4e00\uff0c\u5f53\u8fdb\u884c\u53d8\u6362\u65f6\u8d85\u51fa\u8fb9\u754c\u7684\u70b9\u5c06\u6839\u636e\u672c\u53c2\u6570\u7ed9\u5b9a\u7684\u65b9\u6cd5\u8fdb\u884c\u5904\u7406    cval\uff1a\u6d6e\u70b9\u6570\u6216\u6574\u6570\uff0c\u5f53 fill_mode=constant \u65f6\uff0c\u6307\u5b9a\u8981\u5411\u8d85\u51fa\u8fb9\u754c\u7684\u70b9\u586b\u5145\u7684\u503c    horizontal_flip\uff1a\u5e03\u5c14\u503c\uff0c\u8fdb\u884c\u968f\u673a\u6c34\u5e73\u7ffb\u8f6c    vertical_flip\uff1a\u5e03\u5c14\u503c\uff0c\u8fdb\u884c\u968f\u673a\u7ad6\u76f4\u7ffb\u8f6c    rescale: \u91cd\u653e\u7f29\u56e0\u5b50,\u9ed8\u8ba4\u4e3aNone. \u5982\u679c\u4e3aNone\u62160\u5219\u4e0d\u8fdb\u884c\u653e\u7f29,\u5426\u5219\u4f1a\u5c06\u8be5\u6570\u503c\u4e58\u5230\u6570\u636e\u4e0a(\u5728\u5e94\u7528\u5176\u4ed6\u53d8\u6362\u4e4b\u524d)    dim_ordering\uff1a\u2018tf\u2019\u548c\u2018th\u2019\u4e4b\u4e00\uff0c\u89c4\u5b9a\u6570\u636e\u7684\u7ef4\u5ea6\u987a\u5e8f\u3002\u2018tf\u2019\u6a21\u5f0f\u4e0b\u6570\u636e\u7684\u5f62\u72b6\u4e3a samples, height, width, channels \uff0c\u2018th\u2019\u4e0b\u5f62\u72b6\u4e3a (samples, channels, height, width). \u8be5\u53c2\u6570\u7684\u9ed8\u8ba4\u503c\u662fKeras\u914d\u7f6e\u6587\u4ef6 ~/.keras/keras.json \u7684 image_dim_ordering \u503c,\u5982\u679c\u4f60\u4ece\u672a\u8bbe\u7f6e\u8fc7\u7684\u8bdd,\u5c31\u662f'tf'", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/preprocessing/image/#_3", 
            "text": "fit(X, augment=False, rounds=1)\uff1a\u8ba1\u7b97\u4f9d\u8d56\u4e8e\u6570\u636e\u7684\u53d8\u6362\u6240\u9700\u8981\u7684\u7edf\u8ba1\u4fe1\u606f(\u5747\u503c\u65b9\u5dee\u7b49),\u53ea\u6709\u4f7f\u7528 featurewise_center \uff0c featurewise_std_normalization \u6216 zca_whitening \u65f6\u9700\u8981\u6b64\u51fd\u6570\u3002    X\uff1anumpy array\uff0c\u6837\u672c\u6570\u636e\uff0c\u79e9\u5e94\u4e3a4.\u5728\u9ed1\u767d\u56fe\u50cf\u7684\u60c5\u51b5\u4e0bchannel\u8f74\u7684\u503c\u4e3a1\uff0c\u5728\u5f69\u8272\u56fe\u50cf\u60c5\u51b5\u4e0b\u503c\u4e3a3    augment\uff1a\u5e03\u5c14\u503c\uff0c\u786e\u5b9a\u662f\u5426\u4f7f\u7528\u968f\u5373\u63d0\u5347\u8fc7\u7684\u6570\u636e    round\uff1a\u82e5\u8bbe augment=True \uff0c\u786e\u5b9a\u8981\u5728\u6570\u636e\u4e0a\u8fdb\u884c\u591a\u5c11\u8f6e\u6570\u636e\u63d0\u5347\uff0c\u9ed8\u8ba4\u503c\u4e3a1    seed: \u6574\u6570,\u968f\u673a\u6570\u79cd\u5b50      flow(self, X, y, batch_size=32, shuffle=True, seed=None, save_to_dir=None, save_prefix='', save_format='jpeg')\uff1a\u63a5\u6536numpy\u6570\u7ec4\u548c\u6807\u7b7e\u4e3a\u53c2\u6570,\u751f\u6210\u7ecf\u8fc7\u6570\u636e\u63d0\u5347\u6216\u6807\u51c6\u5316\u540e\u7684batch\u6570\u636e,\u5e76\u5728\u4e00\u4e2a\u65e0\u9650\u5faa\u73af\u4e2d\u4e0d\u65ad\u7684\u8fd4\u56debatch\u6570\u636e    X\uff1a\u6837\u672c\u6570\u636e\uff0c\u79e9\u5e94\u4e3a4.\u5728\u9ed1\u767d\u56fe\u50cf\u7684\u60c5\u51b5\u4e0bchannel\u8f74\u7684\u503c\u4e3a1\uff0c\u5728\u5f69\u8272\u56fe\u50cf\u60c5\u51b5\u4e0b\u503c\u4e3a3    y\uff1a\u6807\u7b7e    batch_size\uff1a\u6574\u6570\uff0c\u9ed8\u8ba432    shuffle\uff1a\u5e03\u5c14\u503c\uff0c\u662f\u5426\u968f\u673a\u6253\u4e71\u6570\u636e\uff0c\u9ed8\u8ba4\u4e3aTrue    save_to_dir\uff1aNone\u6216\u5b57\u7b26\u4e32\uff0c\u8be5\u53c2\u6570\u80fd\u8ba9\u4f60\u5c06\u63d0\u5347\u540e\u7684\u56fe\u7247\u4fdd\u5b58\u8d77\u6765\uff0c\u7528\u4ee5\u53ef\u89c6\u5316    save_prefix\uff1a\u5b57\u7b26\u4e32\uff0c\u4fdd\u5b58\u63d0\u5347\u540e\u56fe\u7247\u65f6\u4f7f\u7528\u7684\u524d\u7f00, \u4ec5\u5f53\u8bbe\u7f6e\u4e86 save_to_dir \u65f6\u751f\u6548    save_format\uff1a\"png\"\u6216\"jpeg\"\u4e4b\u4e00\uff0c\u6307\u5b9a\u4fdd\u5b58\u56fe\u7247\u7684\u6570\u636e\u683c\u5f0f,\u9ed8\u8ba4\"jpeg\"    yields:\u5f62\u5982(x,y)\u7684tuple,x\u662f\u4ee3\u8868\u56fe\u50cf\u6570\u636e\u7684numpy\u6570\u7ec4.y\u662f\u4ee3\u8868\u6807\u7b7e\u7684numpy\u6570\u7ec4.\u8be5\u8fed\u4ee3\u5668\u65e0\u9650\u5faa\u73af.    seed: \u6574\u6570,\u968f\u673a\u6570\u79cd\u5b50      flow_from_directory(directory): \u4ee5\u6587\u4ef6\u5939\u8def\u5f84\u4e3a\u53c2\u6570,\u751f\u6210\u7ecf\u8fc7\u6570\u636e\u63d0\u5347/\u5f52\u4e00\u5316\u540e\u7684\u6570\u636e,\u5728\u4e00\u4e2a\u65e0\u9650\u5faa\u73af\u4e2d\u65e0\u9650\u4ea7\u751fbatch\u6570\u636e   directory: \u76ee\u6807\u6587\u4ef6\u5939\u8def\u5f84,\u5bf9\u4e8e\u6bcf\u4e00\u4e2a\u7c7b,\u8be5\u6587\u4ef6\u5939\u90fd\u8981\u5305\u542b\u4e00\u4e2a\u5b50\u6587\u4ef6\u5939.\u5b50\u6587\u4ef6\u5939\u4e2d\u4efb\u4f55JPG\u3001PNG\u548cBNP\u7684\u56fe\u7247\u90fd\u4f1a\u88ab\u751f\u6210\u5668\u4f7f\u7528.\u8be6\u60c5\u8bf7\u67e5\u770b \u6b64\u811a\u672c  target_size: \u6574\u6570tuple,\u9ed8\u8ba4\u4e3a(256, 256). \u56fe\u50cf\u5c06\u88abresize\u6210\u8be5\u5c3a\u5bf8  color_mode: \u989c\u8272\u6a21\u5f0f,\u4e3a\"grayscale\",\"rgb\"\u4e4b\u4e00,\u9ed8\u8ba4\u4e3a\"rgb\".\u4ee3\u8868\u8fd9\u4e9b\u56fe\u7247\u662f\u5426\u4f1a\u88ab\u8f6c\u6362\u4e3a\u5355\u901a\u9053\u6216\u4e09\u901a\u9053\u7684\u56fe\u7247.  classes: \u53ef\u9009\u53c2\u6570,\u4e3a\u5b50\u6587\u4ef6\u5939\u7684\u5217\u8868,\u5982['dogs','cats']\u9ed8\u8ba4\u4e3aNone. \u82e5\u672a\u63d0\u4f9b,\u5219\u8be5\u7c7b\u522b\u5217\u8868\u5c06\u81ea\u52a8\u63a8\u65ad(\u7c7b\u522b\u7684\u987a\u5e8f\u5c06\u6309\u7167\u5b57\u6bcd\u8868\u987a\u5e8f\u6620\u5c04\u5230\u6807\u7b7e\u503c)  class_mode: \"categorical\", \"binary\", \"sparse\"\u6216None\u4e4b\u4e00. \u9ed8\u8ba4\u4e3a\"categorical. \u8be5\u53c2\u6570\u51b3\u5b9a\u4e86\u8fd4\u56de\u7684\u6807\u7b7e\u6570\u7ec4\u7684\u5f62\u5f0f, \"categorical\"\u4f1a\u8fd4\u56de2D\u7684one-hot\u7f16\u7801\u6807\u7b7e,\"binary\"\u8fd4\u56de1D\u7684\u4e8c\u503c\u6807\u7b7e.\"sparse\"\u8fd4\u56de1D\u7684\u6574\u6570\u6807\u7b7e,\u5982\u679c\u4e3aNone\u5219\u4e0d\u8fd4\u56de\u4efb\u4f55\u6807\u7b7e, \u751f\u6210\u5668\u5c06\u4ec5\u4ec5\u751f\u6210batch\u6570\u636e, \u8fd9\u79cd\u60c5\u51b5\u5728\u4f7f\u7528 model.predict_generator() \u548c model.evaluate_generator() \u7b49\u51fd\u6570\u65f6\u4f1a\u7528\u5230.  batch_size: batch\u6570\u636e\u7684\u5927\u5c0f,\u9ed8\u8ba432  shuffle: \u662f\u5426\u6253\u4e71\u6570\u636e,\u9ed8\u8ba4\u4e3aTrue  seed: \u53ef\u9009\u53c2\u6570,\u6253\u4e71\u6570\u636e\u548c\u8fdb\u884c\u53d8\u6362\u65f6\u7684\u968f\u673a\u6570\u79cd\u5b50  save_to_dir: None\u6216\u5b57\u7b26\u4e32\uff0c\u8be5\u53c2\u6570\u80fd\u8ba9\u4f60\u5c06\u63d0\u5347\u540e\u7684\u56fe\u7247\u4fdd\u5b58\u8d77\u6765\uff0c\u7528\u4ee5\u53ef\u89c6\u5316  save_prefix\uff1a\u5b57\u7b26\u4e32\uff0c\u4fdd\u5b58\u63d0\u5347\u540e\u56fe\u7247\u65f6\u4f7f\u7528\u7684\u524d\u7f00, \u4ec5\u5f53\u8bbe\u7f6e\u4e86 save_to_dir \u65f6\u751f\u6548  save_format\uff1a\"png\"\u6216\"jpeg\"\u4e4b\u4e00\uff0c\u6307\u5b9a\u4fdd\u5b58\u56fe\u7247\u7684\u6570\u636e\u683c\u5f0f,\u9ed8\u8ba4\"jpeg\"  flollow_links: \u662f\u5426\u8bbf\u95ee\u5b50\u6587\u4ef6\u5939\u4e2d\u7684\u8f6f\u94fe\u63a5", 
            "title": "\u65b9\u6cd5"
        }, 
        {
            "location": "/preprocessing/image/#_4", 
            "text": "\u4f7f\u7528 .flow() \u7684\u4f8b\u5b50  (X_train, y_train), (X_test, y_test) = cifar10.load_data()\nY_train = np_utils.to_categorical(y_train, nb_classes)\nY_test = np_utils.to_categorical(y_test, nb_classes)\n\ndatagen = ImageDataGenerator(\n    featurewise_center=True,\n    featurewise_std_normalization=True,\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip=True)\n\n# compute quantities required for featurewise normalization\n# (std, mean, and principal components if ZCA whitening is applied)\ndatagen.fit(X_train)\n\n# fits the model on batches with real-time data augmentation:\nmodel.fit_generator(datagen.flow(X_train, Y_train, batch_size=32),\n                    samples_per_epoch=len(X_train), nb_epoch=nb_epoch)\n\n# here's a more  manual  example\nfor e in range(nb_epoch):\n    print 'Epoch', e\n    batches = 0\n    for X_batch, Y_batch in datagen.flow(X_train, Y_train, batch_size=32):\n        loss = model.train(X_batch, Y_batch)\n        batches += 1\n        if batches  = len(X_train) / 32:\n            # we need to break the loop by hand because\n            # the generator loops indefinitely\n            break  \u4f7f\u7528 .flow_from_directory(directory) \u7684\u4f8b\u5b50  train_datagen = ImageDataGenerator(\n        rescale=1./255,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True)\n\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_generator = train_datagen.flow_from_directory(\n        'data/train',\n        target_size=(150, 150),\n        batch_size=32,\n        class_mode='binary')\n\nvalidation_generator = test_datagen.flow_from_directory(\n        'data/validation',\n        target_size=(150, 150),\n        batch_size=32,\n        class_mode='binary')\n\nmodel.fit_generator(\n        train_generator,\n        samples_per_epoch=2000,\n        nb_epoch=50,\n        validation_data=validation_generator,\n        nb_val_samples=800)  \u540c\u65f6\u53d8\u6362\u56fe\u50cf\u548cmask  # we create two instances with the same arguments\ndata_gen_args = dict(featurewise_center=True,\n                     featurewise_std_normalization=True,\n                     rotation_range=90.,\n                     width_shift_range=0.1,\n                     height_shift_range=0.1,\n                     zoom_range=0.2)\nimage_datagen = ImageDataGenerator(**data_gen_args)\nmask_datagen = ImageDataGenerator(**data_gen_args)\n\n# Provide the same seed and keyword arguments to the fit and flow methods\nseed = 1\nimage_datagen.fit(images, augment=True, seed=seed)\nmask_datagen.fit(masks, augment=True, seed=seed)\n\nimage_generator = image_datagen.flow_from_directory(\n    'data/images',\n    class_mode=None,\n    seed=seed)\n\nmask_generator = mask_datagen.flow_from_directory(\n    'data/masks',\n    class_mode=None,\n    seed=seed)\n\n# combine generators into one which yields image and masks\ntrain_generator = zip(image_generator, mask_generator)\n\nmodel.fit_generator(\n    train_generator,\n    samples_per_epoch=2000,\n    nb_epoch=50)", 
            "title": "\u4f8b\u5b50"
        }, 
        {
            "location": "/other/objectives/", 
            "text": "\u76ee\u6807\u51fd\u6570objectives\n\n\n\u76ee\u6807\u51fd\u6570\uff0c\u6216\u79f0\u635f\u5931\u51fd\u6570\uff0c\u662f\u7f16\u8bd1\u4e00\u4e2a\u6a21\u578b\u5fc5\u987b\u7684\u4e24\u4e2a\u53c2\u6570\u4e4b\u4e00\uff1a\n\n\nmodel.compile(loss='mean_squared_error', optimizer='sgd')\n\n\n\n\n\u53ef\u4ee5\u901a\u8fc7\u4f20\u9012\u9884\u5b9a\u4e49\u76ee\u6807\u51fd\u6570\u540d\u5b57\u6307\u5b9a\u76ee\u6807\u51fd\u6570\uff0c\u4e5f\u53ef\u4ee5\u4f20\u9012\u4e00\u4e2aTheano/TensroFlow\u7684\u7b26\u53f7\u51fd\u6570\u4f5c\u4e3a\u76ee\u6807\u51fd\u6570\uff0c\u8be5\u51fd\u6570\u5bf9\u6bcf\u4e2a\u6570\u636e\u70b9\u5e94\u8be5\u53ea\u8fd4\u56de\u4e00\u4e2a\u6807\u91cf\u503c\uff0c\u5e76\u4ee5\u4e0b\u5217\u4e24\u4e2a\u53c2\u6570\u4e3a\u53c2\u6570\uff1a\n\n\n\n\n\n\ny_true\uff1a\u771f\u5b9e\u7684\u6570\u636e\u6807\u7b7e\uff0cTheano/TensorFlow\u5f20\u91cf\n\n\n\n\n\n\ny_pred\uff1a\u9884\u6d4b\u503c\uff0c\u4e0ey_true\u76f8\u540cshape\u7684Theano/TensorFlow\u5f20\u91cf\n\n\n\n\n\n\n\u771f\u5b9e\u7684\u4f18\u5316\u76ee\u6807\u51fd\u6570\u662f\u5728\u5404\u4e2a\u6570\u636e\u70b9\u5f97\u5230\u7684\u635f\u5931\u51fd\u6570\u503c\u4e4b\u548c\u7684\u5747\u503c\n\n\n\u8bf7\u53c2\u8003\n\u76ee\u6807\u5b9e\u73b0\u4ee3\u7801\n\u83b7\u53d6\u66f4\u591a\u4fe1\u606f\n\n\n\u53ef\u7528\u7684\u76ee\u6807\u51fd\u6570\n\n\n\n\n\n\nmean_squared_error\u6216mse\n\n\n\n\n\n\nmean_absolute_error\u6216mae\n\n\n\n\n\n\nmean_absolute_percentage_error\u6216mape\n\n\n\n\n\n\nmean_squared_logarithmic_error\u6216msle\n\n\n\n\n\n\nsquared_hinge\n\n\n\n\n\n\nhinge\n\n\n\n\n\n\nbinary_crossentropy\uff08\u4ea6\u79f0\u4f5c\u5bf9\u6570\u635f\u5931\uff0clogloss\uff09\n\n\n\n\n\n\ncategorical_crossentropy\uff1a\u4ea6\u79f0\u4f5c\u591a\u7c7b\u7684\u5bf9\u6570\u635f\u5931\uff0c\u6ce8\u610f\u4f7f\u7528\u8be5\u76ee\u6807\u51fd\u6570\u65f6\uff0c\u9700\u8981\u5c06\u6807\u7b7e\u8f6c\u5316\u4e3a\u5f62\u5982\n(nb_samples, nb_classes)\n\u7684\u4e8c\u503c\u5e8f\u5217\n\n\n\n\n\n\nsparse_categorical_crossentrop\uff1a\u5982\u4e0a\uff0c\u4f46\u63a5\u53d7\u7a00\u758f\u6807\u7b7e\u3002\u6ce8\u610f\uff0c\u4f7f\u7528\u8be5\u51fd\u6570\u65f6\u4ecd\u7136\u9700\u8981\u4f60\u7684\u6807\u7b7e\u4e0e\u8f93\u51fa\u503c\u7684\u7ef4\u5ea6\u76f8\u540c\uff0c\u4f60\u53ef\u80fd\u9700\u8981\u5728\u6807\u7b7e\u6570\u636e\u4e0a\u589e\u52a0\u4e00\u4e2a\u7ef4\u5ea6\uff1a\nnp.expand_dims(y,-1)\n\n\n\n\n\n\nkullback_leibler_divergence:\u4ece\u9884\u6d4b\u503c\u6982\u7387\u5206\u5e03Q\u5230\u771f\u503c\u6982\u7387\u5206\u5e03P\u7684\u4fe1\u606f\u589e\u76ca,\u7528\u4ee5\u5ea6\u91cf\u4e24\u4e2a\u5206\u5e03\u7684\u5dee\u5f02.\n\n\n\n\n\n\npoisson\uff1a\u5373\n(predictions - targets * log(predictions))\n\u7684\u5747\u503c\n\n\n\n\n\n\ncosine_proximity\uff1a\u5373\u9884\u6d4b\u503c\u4e0e\u771f\u5b9e\u6807\u7b7e\u7684\u4f59\u5f26\u8ddd\u79bb\u5e73\u5747\u503c\u7684\u76f8\u53cd\u6570\n\n\n\n\n\n\n\u6ce8\u610f\n: \u5f53\u4f7f\u7528\"categorical_crossentropy\"\u4f5c\u4e3a\u76ee\u6807\u51fd\u6570\u65f6,\u6807\u7b7e\u5e94\u8be5\u4e3a\u591a\u7c7b\u6a21\u5f0f,\u5373one-hot\u7f16\u7801\u7684\u5411\u91cf,\u800c\u4e0d\u662f\u5355\u4e2a\u6570\u503c. \u53ef\u4ee5\u4f7f\u7528\u5de5\u5177\u4e2d\u7684\nto_categorical\n\u51fd\u6570\u5b8c\u6210\u8be5\u8f6c\u6362.\u793a\u4f8b\u5982\u4e0b:\n\n\nfrom keras.utils.np_utils import to_categorical\n\ncategorical_labels = to_categorical(int_labels, nb_classes=None)\n\n\n\n\n\u3010Tips\u3011\u8fc7\u4e00\u6bb5\u65f6\u95f4\uff08\u7b49\u6211\u6216\u8005\u8c01\u6709\u65f6\u95f4\u5427\u2026\u2026\uff09\u6211\u4eec\u5c06\u628a\u5404\u79cd\u76ee\u6807\u51fd\u6570\u7684\u8868\u8fbe\u5f0f\u548c\u5e38\u7528\u573a\u666f\u603b\u7ed3\u4e00\u4e0b\u3002", 
            "title": "\u76ee\u6807\u51fd\u6570Objective"
        }, 
        {
            "location": "/other/objectives/#objectives", 
            "text": "\u76ee\u6807\u51fd\u6570\uff0c\u6216\u79f0\u635f\u5931\u51fd\u6570\uff0c\u662f\u7f16\u8bd1\u4e00\u4e2a\u6a21\u578b\u5fc5\u987b\u7684\u4e24\u4e2a\u53c2\u6570\u4e4b\u4e00\uff1a  model.compile(loss='mean_squared_error', optimizer='sgd')  \u53ef\u4ee5\u901a\u8fc7\u4f20\u9012\u9884\u5b9a\u4e49\u76ee\u6807\u51fd\u6570\u540d\u5b57\u6307\u5b9a\u76ee\u6807\u51fd\u6570\uff0c\u4e5f\u53ef\u4ee5\u4f20\u9012\u4e00\u4e2aTheano/TensroFlow\u7684\u7b26\u53f7\u51fd\u6570\u4f5c\u4e3a\u76ee\u6807\u51fd\u6570\uff0c\u8be5\u51fd\u6570\u5bf9\u6bcf\u4e2a\u6570\u636e\u70b9\u5e94\u8be5\u53ea\u8fd4\u56de\u4e00\u4e2a\u6807\u91cf\u503c\uff0c\u5e76\u4ee5\u4e0b\u5217\u4e24\u4e2a\u53c2\u6570\u4e3a\u53c2\u6570\uff1a    y_true\uff1a\u771f\u5b9e\u7684\u6570\u636e\u6807\u7b7e\uff0cTheano/TensorFlow\u5f20\u91cf    y_pred\uff1a\u9884\u6d4b\u503c\uff0c\u4e0ey_true\u76f8\u540cshape\u7684Theano/TensorFlow\u5f20\u91cf    \u771f\u5b9e\u7684\u4f18\u5316\u76ee\u6807\u51fd\u6570\u662f\u5728\u5404\u4e2a\u6570\u636e\u70b9\u5f97\u5230\u7684\u635f\u5931\u51fd\u6570\u503c\u4e4b\u548c\u7684\u5747\u503c  \u8bf7\u53c2\u8003 \u76ee\u6807\u5b9e\u73b0\u4ee3\u7801 \u83b7\u53d6\u66f4\u591a\u4fe1\u606f", 
            "title": "\u76ee\u6807\u51fd\u6570objectives"
        }, 
        {
            "location": "/other/objectives/#_1", 
            "text": "mean_squared_error\u6216mse    mean_absolute_error\u6216mae    mean_absolute_percentage_error\u6216mape    mean_squared_logarithmic_error\u6216msle    squared_hinge    hinge    binary_crossentropy\uff08\u4ea6\u79f0\u4f5c\u5bf9\u6570\u635f\u5931\uff0clogloss\uff09    categorical_crossentropy\uff1a\u4ea6\u79f0\u4f5c\u591a\u7c7b\u7684\u5bf9\u6570\u635f\u5931\uff0c\u6ce8\u610f\u4f7f\u7528\u8be5\u76ee\u6807\u51fd\u6570\u65f6\uff0c\u9700\u8981\u5c06\u6807\u7b7e\u8f6c\u5316\u4e3a\u5f62\u5982 (nb_samples, nb_classes) \u7684\u4e8c\u503c\u5e8f\u5217    sparse_categorical_crossentrop\uff1a\u5982\u4e0a\uff0c\u4f46\u63a5\u53d7\u7a00\u758f\u6807\u7b7e\u3002\u6ce8\u610f\uff0c\u4f7f\u7528\u8be5\u51fd\u6570\u65f6\u4ecd\u7136\u9700\u8981\u4f60\u7684\u6807\u7b7e\u4e0e\u8f93\u51fa\u503c\u7684\u7ef4\u5ea6\u76f8\u540c\uff0c\u4f60\u53ef\u80fd\u9700\u8981\u5728\u6807\u7b7e\u6570\u636e\u4e0a\u589e\u52a0\u4e00\u4e2a\u7ef4\u5ea6\uff1a np.expand_dims(y,-1)    kullback_leibler_divergence:\u4ece\u9884\u6d4b\u503c\u6982\u7387\u5206\u5e03Q\u5230\u771f\u503c\u6982\u7387\u5206\u5e03P\u7684\u4fe1\u606f\u589e\u76ca,\u7528\u4ee5\u5ea6\u91cf\u4e24\u4e2a\u5206\u5e03\u7684\u5dee\u5f02.    poisson\uff1a\u5373 (predictions - targets * log(predictions)) \u7684\u5747\u503c    cosine_proximity\uff1a\u5373\u9884\u6d4b\u503c\u4e0e\u771f\u5b9e\u6807\u7b7e\u7684\u4f59\u5f26\u8ddd\u79bb\u5e73\u5747\u503c\u7684\u76f8\u53cd\u6570    \u6ce8\u610f : \u5f53\u4f7f\u7528\"categorical_crossentropy\"\u4f5c\u4e3a\u76ee\u6807\u51fd\u6570\u65f6,\u6807\u7b7e\u5e94\u8be5\u4e3a\u591a\u7c7b\u6a21\u5f0f,\u5373one-hot\u7f16\u7801\u7684\u5411\u91cf,\u800c\u4e0d\u662f\u5355\u4e2a\u6570\u503c. \u53ef\u4ee5\u4f7f\u7528\u5de5\u5177\u4e2d\u7684 to_categorical \u51fd\u6570\u5b8c\u6210\u8be5\u8f6c\u6362.\u793a\u4f8b\u5982\u4e0b:  from keras.utils.np_utils import to_categorical\n\ncategorical_labels = to_categorical(int_labels, nb_classes=None)  \u3010Tips\u3011\u8fc7\u4e00\u6bb5\u65f6\u95f4\uff08\u7b49\u6211\u6216\u8005\u8c01\u6709\u65f6\u95f4\u5427\u2026\u2026\uff09\u6211\u4eec\u5c06\u628a\u5404\u79cd\u76ee\u6807\u51fd\u6570\u7684\u8868\u8fbe\u5f0f\u548c\u5e38\u7528\u573a\u666f\u603b\u7ed3\u4e00\u4e0b\u3002", 
            "title": "\u53ef\u7528\u7684\u76ee\u6807\u51fd\u6570"
        }, 
        {
            "location": "/other/optimizers/", 
            "text": "\u4f18\u5316\u5668optimizers\n\n\n\u4f18\u5316\u5668\u662f\u7f16\u8bd1Keras\u6a21\u578b\u5fc5\u8981\u7684\u4e24\u4e2a\u53c2\u6570\u4e4b\u4e00\n\n\nmodel = Sequential()\nmodel.add(Dense(64, init='uniform', input_dim=10))\nmodel.add(Activation('tanh'))\nmodel.add(Activation('softmax'))\n\nsgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\nmodel.compile(loss='mean_squared_error', optimizer=sgd)\n\n\n\n\n\u53ef\u4ee5\u5728\u8c03\u7528\nmodel.compile()\n\u4e4b\u524d\u521d\u59cb\u5316\u4e00\u4e2a\u4f18\u5316\u5668\u5bf9\u8c61\uff0c\u7136\u540e\u4f20\u5165\u8be5\u51fd\u6570\uff08\u5982\u4e0a\u6240\u793a\uff09\uff0c\u4e5f\u53ef\u4ee5\u5728\u8c03\u7528\nmodel.compile()\n\u65f6\u4f20\u9012\u4e00\u4e2a\u9884\u5b9a\u4e49\u4f18\u5316\u5668\u540d\u3002\u5728\u540e\u8005\u60c5\u5f62\u4e0b\uff0c\u4f18\u5316\u5668\u7684\u53c2\u6570\u5c06\u4f7f\u7528\u9ed8\u8ba4\u503c\u3002\n\n\n# pass optimizer by name: default parameters will be used\nmodel.compile(loss='mean_squared_error', optimizer='sgd')\n\n\n\n\n\u6240\u6709\u4f18\u5316\u5668\u90fd\u53ef\u7528\u7684\u53c2\u6570\n\n\n\u53c2\u6570\nclipnorm\n\u548c\nclipvalue\n\u662f\u6240\u6709\u4f18\u5316\u5668\u90fd\u53ef\u4ee5\u4f7f\u7528\u7684\u53c2\u6570,\u7528\u4e8e\u5bf9\u68af\u5ea6\u8fdb\u884c\u88c1\u526a.\u793a\u4f8b\u5982\u4e0b:\n\n\n# all parameter gradients will be clipped to\n# a maximum norm of 1.\nsgd = SGD(lr=0.01, clipnorm=1.)\n\n\n\n\n# all parameter gradients will be clipped to\n# a maximum value of 0.5 and\n# a minimum value of -0.5.\nsgd = SGD(lr=0.01, clipvalue=0.5)\n\n\n\n\nSGD\n\n\nkeras.optimizers.SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False)\n\n\n\n\n\u968f\u673a\u68af\u5ea6\u4e0b\u964d\u6cd5\uff0c\u652f\u6301\u52a8\u91cf\u53c2\u6570\uff0c\u652f\u6301\u5b66\u4e60\u8870\u51cf\u7387\uff0c\u652f\u6301Nesterov\u52a8\u91cf\n\n\n\u53c2\u6570\n\n\n\n\n\n\nlr\uff1a\u5927\u4e8e0\u7684\u6d6e\u70b9\u6570\uff0c\u5b66\u4e60\u7387\n\n\n\n\n\n\nmomentum\uff1a\u5927\u4e8e0\u7684\u6d6e\u70b9\u6570\uff0c\u52a8\u91cf\u53c2\u6570\n\n\n\n\n\n\ndecay\uff1a\u5927\u4e8e0\u7684\u6d6e\u70b9\u6570\uff0c\u6bcf\u6b21\u66f4\u65b0\u540e\u7684\u5b66\u4e60\u7387\u8870\u51cf\u503c\n\n\n\n\n\n\nnesterov\uff1a\u5e03\u5c14\u503c\uff0c\u786e\u5b9a\u662f\u5426\u4f7f\u7528Nesterov\u52a8\u91cf\n\n\n\n\n\n\n\n\nRMSprop\n\n\nkeras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-06)\n\n\n\n\n\u9664\u5b66\u4e60\u7387\u53ef\u8c03\u6574\u5916\uff0c\u5efa\u8bae\u4fdd\u6301\u4f18\u5316\u5668\u7684\u5176\u4ed6\u9ed8\u8ba4\u53c2\u6570\u4e0d\u53d8\n\n\n\u8be5\u4f18\u5316\u5668\u901a\u5e38\u662f\u9762\u5bf9\u9012\u5f52\u795e\u7ecf\u7f51\u7edc\u65f6\u7684\u4e00\u4e2a\u826f\u597d\u9009\u62e9\n\n\n\u53c2\u6570\n\n\n\n\n\n\nlr\uff1a\u5927\u4e8e0\u7684\u6d6e\u70b9\u6570\uff0c\u5b66\u4e60\u7387\n\n\n\n\n\n\nrho\uff1a\u5927\u4e8e0\u7684\u6d6e\u70b9\u6570\n\n\n\n\n\n\nepsilon\uff1a\u5927\u4e8e0\u7684\u5c0f\u6d6e\u70b9\u6570\uff0c\u9632\u6b62\u96640\u9519\u8bef\n\n\n\n\n\n\n\n\nAdagrad\n\n\nkeras.optimizers.Adagrad(lr=0.01, epsilon=1e-06)\n\n\n\n\n\u5efa\u8bae\u4fdd\u6301\u4f18\u5316\u5668\u7684\u9ed8\u8ba4\u53c2\u6570\u4e0d\u53d8\n\n\nAdagrad\n\n\n\n\n\n\nlr\uff1a\u5927\u4e8e0\u7684\u6d6e\u70b9\u6570\uff0c\u5b66\u4e60\u7387\n\n\n\n\n\n\nepsilon\uff1a\u5927\u4e8e0\u7684\u5c0f\u6d6e\u70b9\u6570\uff0c\u9632\u6b62\u96640\u9519\u8bef\n\n\n\n\n\n\n\n\nAdadelta\n\n\nkeras.optimizers.Adadelta(lr=1.0, rho=0.95, epsilon=1e-06)\n\n\n\n\n\u5efa\u8bae\u4fdd\u6301\u4f18\u5316\u5668\u7684\u9ed8\u8ba4\u53c2\u6570\u4e0d\u53d8\n\n\n\u53c2\u6570\n\n\n\n\n\n\nlr\uff1a\u5927\u4e8e0\u7684\u6d6e\u70b9\u6570\uff0c\u5b66\u4e60\u7387\n\n\n\n\n\n\nrho\uff1a\u5927\u4e8e0\u7684\u6d6e\u70b9\u6570\n\n\n\n\n\n\nepsilon\uff1a\u5927\u4e8e0\u7684\u5c0f\u6d6e\u70b9\u6570\uff0c\u9632\u6b62\u96640\u9519\u8bef\n\n\n\n\n\n\n\u53c2\u8003\u6587\u732e\n\n\n\n\n\n\nAdadelta - an adaptive learning rate method\n\n\n\n\nAdam\n\n\nkeras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n\n\n\n\n\u8be5\u4f18\u5316\u5668\u7684\u9ed8\u8ba4\u503c\u6765\u6e90\u4e8e\u53c2\u8003\u6587\u732e\n\n\n\u53c2\u6570\n\n\n\n\n\n\nlr\uff1a\u5927\u4e8e0\u7684\u6d6e\u70b9\u6570\uff0c\u5b66\u4e60\u7387\n\n\n\n\n\n\nbeta_1/beta_2\uff1a\u6d6e\u70b9\u6570\uff0c 0\nbeta\n1\uff0c\u901a\u5e38\u5f88\u63a5\u8fd11\n\n\n\n\n\n\nepsilon\uff1a\u5927\u4e8e0\u7684\u5c0f\u6d6e\u70b9\u6570\uff0c\u9632\u6b62\u96640\u9519\u8bef\n\n\n\n\n\n\n\u53c2\u8003\u6587\u732e\n\n\n\n\nAdam - A Method for Stochastic Optimization\n\n\n\n\n\n\nAdamax\n\n\nkeras.optimizers.Adamax(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n\n\n\n\nAdamax\u4f18\u5316\u5668\u6765\u81ea\u4e8eAdam\u7684\u8bba\u6587\u7684Section7\uff0c\u8be5\u65b9\u6cd5\u662f\u57fa\u4e8e\u65e0\u7a77\u8303\u6570\u7684Adam\u65b9\u6cd5\u7684\u53d8\u4f53\u3002\n\n\n\u9ed8\u8ba4\u53c2\u6570\u7531\u8bba\u6587\u63d0\u4f9b\n\n\n\u53c2\u6570\n\n\n\n\n\n\nlr\uff1a\u5927\u4e8e0\u7684\u6d6e\u70b9\u6570\uff0c\u5b66\u4e60\u7387\n\n\n\n\n\n\nbeta_1/beta_2\uff1a\u6d6e\u70b9\u6570\uff0c 0\nbeta\n1\uff0c\u901a\u5e38\u5f88\u63a5\u8fd11\n\n\n\n\n\n\nepsilon\uff1a\u5927\u4e8e0\u7684\u5c0f\u6d6e\u70b9\u6570\uff0c\u9632\u6b62\u96640\u9519\u8bef\n\n\n\n\n\n\n\u53c2\u8003\u6587\u732e\n\n\n\n\nAdam - A Method for Stochastic Optimization\n\n\n\n\n\n\nNadam\n\n\nkeras.optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08, schedule_decay=0.004)\n\n\n\n\nNesterov Adam optimizer: Adam\u672c\u8d28\u4e0a\u50cf\u662f\u5e26\u6709\u52a8\u91cf\u9879\u7684RMSprop\uff0cNadam\u5c31\u662f\u5e26\u6709Nesterov \u52a8\u91cf\u7684Adam RMSprop\n\n\n\u9ed8\u8ba4\u53c2\u6570\u6765\u81ea\u4e8e\u8bba\u6587\uff0c\u63a8\u8350\u4e0d\u8981\u5bf9\u9ed8\u8ba4\u53c2\u6570\u8fdb\u884c\u66f4\u6539\u3002\n\n\n\u53c2\u6570\n\n\n\n\n\n\nlr\uff1a\u5927\u4e8e0\u7684\u6d6e\u70b9\u6570\uff0c\u5b66\u4e60\u7387\n\n\n\n\n\n\nbeta_1/beta_2\uff1a\u6d6e\u70b9\u6570\uff0c 0\nbeta\n1\uff0c\u901a\u5e38\u5f88\u63a5\u8fd11\n\n\n\n\n\n\nepsilon\uff1a\u5927\u4e8e0\u7684\u5c0f\u6d6e\u70b9\u6570\uff0c\u9632\u6b62\u96640\u9519\u8bef\n\n\n\n\n\n\n\u53c2\u8003\u6587\u732e\n\n\n\n\n\n\nNadam report\n\n\n\n\n\n\nOn the importance of initialization and momentum in deep learning\n\n\n\n\n\n\n\u3010Tips\u3011\u5f88\u5feb\uff08\u8fc7\u4e24\u5929\uff09\u6211\u4eec\u4f1a\u5c06\u5404\u79cd\u4f18\u5316\u5668\u7684\u7b97\u6cd5\u53ca\u7279\u70b9\u603b\u7ed3\u4e00\u4e0b\uff0c\u656c\u8bf7\u5173\u6ce8", 
            "title": "\u4f18\u5316\u5668Optimizer"
        }, 
        {
            "location": "/other/optimizers/#optimizers", 
            "text": "\u4f18\u5316\u5668\u662f\u7f16\u8bd1Keras\u6a21\u578b\u5fc5\u8981\u7684\u4e24\u4e2a\u53c2\u6570\u4e4b\u4e00  model = Sequential()\nmodel.add(Dense(64, init='uniform', input_dim=10))\nmodel.add(Activation('tanh'))\nmodel.add(Activation('softmax'))\n\nsgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\nmodel.compile(loss='mean_squared_error', optimizer=sgd)  \u53ef\u4ee5\u5728\u8c03\u7528 model.compile() \u4e4b\u524d\u521d\u59cb\u5316\u4e00\u4e2a\u4f18\u5316\u5668\u5bf9\u8c61\uff0c\u7136\u540e\u4f20\u5165\u8be5\u51fd\u6570\uff08\u5982\u4e0a\u6240\u793a\uff09\uff0c\u4e5f\u53ef\u4ee5\u5728\u8c03\u7528 model.compile() \u65f6\u4f20\u9012\u4e00\u4e2a\u9884\u5b9a\u4e49\u4f18\u5316\u5668\u540d\u3002\u5728\u540e\u8005\u60c5\u5f62\u4e0b\uff0c\u4f18\u5316\u5668\u7684\u53c2\u6570\u5c06\u4f7f\u7528\u9ed8\u8ba4\u503c\u3002  # pass optimizer by name: default parameters will be used\nmodel.compile(loss='mean_squared_error', optimizer='sgd')", 
            "title": "\u4f18\u5316\u5668optimizers"
        }, 
        {
            "location": "/other/optimizers/#_1", 
            "text": "\u53c2\u6570 clipnorm \u548c clipvalue \u662f\u6240\u6709\u4f18\u5316\u5668\u90fd\u53ef\u4ee5\u4f7f\u7528\u7684\u53c2\u6570,\u7528\u4e8e\u5bf9\u68af\u5ea6\u8fdb\u884c\u88c1\u526a.\u793a\u4f8b\u5982\u4e0b:  # all parameter gradients will be clipped to\n# a maximum norm of 1.\nsgd = SGD(lr=0.01, clipnorm=1.)  # all parameter gradients will be clipped to\n# a maximum value of 0.5 and\n# a minimum value of -0.5.\nsgd = SGD(lr=0.01, clipvalue=0.5)", 
            "title": "\u6240\u6709\u4f18\u5316\u5668\u90fd\u53ef\u7528\u7684\u53c2\u6570"
        }, 
        {
            "location": "/other/optimizers/#sgd", 
            "text": "keras.optimizers.SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False)  \u968f\u673a\u68af\u5ea6\u4e0b\u964d\u6cd5\uff0c\u652f\u6301\u52a8\u91cf\u53c2\u6570\uff0c\u652f\u6301\u5b66\u4e60\u8870\u51cf\u7387\uff0c\u652f\u6301Nesterov\u52a8\u91cf", 
            "title": "SGD"
        }, 
        {
            "location": "/other/optimizers/#_2", 
            "text": "lr\uff1a\u5927\u4e8e0\u7684\u6d6e\u70b9\u6570\uff0c\u5b66\u4e60\u7387    momentum\uff1a\u5927\u4e8e0\u7684\u6d6e\u70b9\u6570\uff0c\u52a8\u91cf\u53c2\u6570    decay\uff1a\u5927\u4e8e0\u7684\u6d6e\u70b9\u6570\uff0c\u6bcf\u6b21\u66f4\u65b0\u540e\u7684\u5b66\u4e60\u7387\u8870\u51cf\u503c    nesterov\uff1a\u5e03\u5c14\u503c\uff0c\u786e\u5b9a\u662f\u5426\u4f7f\u7528Nesterov\u52a8\u91cf", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/other/optimizers/#rmsprop", 
            "text": "keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-06)  \u9664\u5b66\u4e60\u7387\u53ef\u8c03\u6574\u5916\uff0c\u5efa\u8bae\u4fdd\u6301\u4f18\u5316\u5668\u7684\u5176\u4ed6\u9ed8\u8ba4\u53c2\u6570\u4e0d\u53d8  \u8be5\u4f18\u5316\u5668\u901a\u5e38\u662f\u9762\u5bf9\u9012\u5f52\u795e\u7ecf\u7f51\u7edc\u65f6\u7684\u4e00\u4e2a\u826f\u597d\u9009\u62e9", 
            "title": "RMSprop"
        }, 
        {
            "location": "/other/optimizers/#_3", 
            "text": "lr\uff1a\u5927\u4e8e0\u7684\u6d6e\u70b9\u6570\uff0c\u5b66\u4e60\u7387    rho\uff1a\u5927\u4e8e0\u7684\u6d6e\u70b9\u6570    epsilon\uff1a\u5927\u4e8e0\u7684\u5c0f\u6d6e\u70b9\u6570\uff0c\u9632\u6b62\u96640\u9519\u8bef", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/other/optimizers/#adagrad", 
            "text": "keras.optimizers.Adagrad(lr=0.01, epsilon=1e-06)  \u5efa\u8bae\u4fdd\u6301\u4f18\u5316\u5668\u7684\u9ed8\u8ba4\u53c2\u6570\u4e0d\u53d8", 
            "title": "Adagrad"
        }, 
        {
            "location": "/other/optimizers/#adagrad_1", 
            "text": "lr\uff1a\u5927\u4e8e0\u7684\u6d6e\u70b9\u6570\uff0c\u5b66\u4e60\u7387    epsilon\uff1a\u5927\u4e8e0\u7684\u5c0f\u6d6e\u70b9\u6570\uff0c\u9632\u6b62\u96640\u9519\u8bef", 
            "title": "Adagrad"
        }, 
        {
            "location": "/other/optimizers/#adadelta", 
            "text": "keras.optimizers.Adadelta(lr=1.0, rho=0.95, epsilon=1e-06)  \u5efa\u8bae\u4fdd\u6301\u4f18\u5316\u5668\u7684\u9ed8\u8ba4\u53c2\u6570\u4e0d\u53d8", 
            "title": "Adadelta"
        }, 
        {
            "location": "/other/optimizers/#_4", 
            "text": "lr\uff1a\u5927\u4e8e0\u7684\u6d6e\u70b9\u6570\uff0c\u5b66\u4e60\u7387    rho\uff1a\u5927\u4e8e0\u7684\u6d6e\u70b9\u6570    epsilon\uff1a\u5927\u4e8e0\u7684\u5c0f\u6d6e\u70b9\u6570\uff0c\u9632\u6b62\u96640\u9519\u8bef", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/other/optimizers/#_5", 
            "text": "Adadelta - an adaptive learning rate method", 
            "title": "\u53c2\u8003\u6587\u732e"
        }, 
        {
            "location": "/other/optimizers/#adam", 
            "text": "keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)  \u8be5\u4f18\u5316\u5668\u7684\u9ed8\u8ba4\u503c\u6765\u6e90\u4e8e\u53c2\u8003\u6587\u732e", 
            "title": "Adam"
        }, 
        {
            "location": "/other/optimizers/#_6", 
            "text": "lr\uff1a\u5927\u4e8e0\u7684\u6d6e\u70b9\u6570\uff0c\u5b66\u4e60\u7387    beta_1/beta_2\uff1a\u6d6e\u70b9\u6570\uff0c 0 beta 1\uff0c\u901a\u5e38\u5f88\u63a5\u8fd11    epsilon\uff1a\u5927\u4e8e0\u7684\u5c0f\u6d6e\u70b9\u6570\uff0c\u9632\u6b62\u96640\u9519\u8bef", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/other/optimizers/#_7", 
            "text": "Adam - A Method for Stochastic Optimization", 
            "title": "\u53c2\u8003\u6587\u732e"
        }, 
        {
            "location": "/other/optimizers/#adamax", 
            "text": "keras.optimizers.Adamax(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08)  Adamax\u4f18\u5316\u5668\u6765\u81ea\u4e8eAdam\u7684\u8bba\u6587\u7684Section7\uff0c\u8be5\u65b9\u6cd5\u662f\u57fa\u4e8e\u65e0\u7a77\u8303\u6570\u7684Adam\u65b9\u6cd5\u7684\u53d8\u4f53\u3002  \u9ed8\u8ba4\u53c2\u6570\u7531\u8bba\u6587\u63d0\u4f9b", 
            "title": "Adamax"
        }, 
        {
            "location": "/other/optimizers/#_8", 
            "text": "lr\uff1a\u5927\u4e8e0\u7684\u6d6e\u70b9\u6570\uff0c\u5b66\u4e60\u7387    beta_1/beta_2\uff1a\u6d6e\u70b9\u6570\uff0c 0 beta 1\uff0c\u901a\u5e38\u5f88\u63a5\u8fd11    epsilon\uff1a\u5927\u4e8e0\u7684\u5c0f\u6d6e\u70b9\u6570\uff0c\u9632\u6b62\u96640\u9519\u8bef", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/other/optimizers/#_9", 
            "text": "Adam - A Method for Stochastic Optimization", 
            "title": "\u53c2\u8003\u6587\u732e"
        }, 
        {
            "location": "/other/optimizers/#nadam", 
            "text": "keras.optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08, schedule_decay=0.004)  Nesterov Adam optimizer: Adam\u672c\u8d28\u4e0a\u50cf\u662f\u5e26\u6709\u52a8\u91cf\u9879\u7684RMSprop\uff0cNadam\u5c31\u662f\u5e26\u6709Nesterov \u52a8\u91cf\u7684Adam RMSprop  \u9ed8\u8ba4\u53c2\u6570\u6765\u81ea\u4e8e\u8bba\u6587\uff0c\u63a8\u8350\u4e0d\u8981\u5bf9\u9ed8\u8ba4\u53c2\u6570\u8fdb\u884c\u66f4\u6539\u3002", 
            "title": "Nadam"
        }, 
        {
            "location": "/other/optimizers/#_10", 
            "text": "lr\uff1a\u5927\u4e8e0\u7684\u6d6e\u70b9\u6570\uff0c\u5b66\u4e60\u7387    beta_1/beta_2\uff1a\u6d6e\u70b9\u6570\uff0c 0 beta 1\uff0c\u901a\u5e38\u5f88\u63a5\u8fd11    epsilon\uff1a\u5927\u4e8e0\u7684\u5c0f\u6d6e\u70b9\u6570\uff0c\u9632\u6b62\u96640\u9519\u8bef", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/other/optimizers/#_11", 
            "text": "Nadam report    On the importance of initialization and momentum in deep learning    \u3010Tips\u3011\u5f88\u5feb\uff08\u8fc7\u4e24\u5929\uff09\u6211\u4eec\u4f1a\u5c06\u5404\u79cd\u4f18\u5316\u5668\u7684\u7b97\u6cd5\u53ca\u7279\u70b9\u603b\u7ed3\u4e00\u4e0b\uff0c\u656c\u8bf7\u5173\u6ce8", 
            "title": "\u53c2\u8003\u6587\u732e"
        }, 
        {
            "location": "/other/activations/", 
            "text": "\u6fc0\u6d3b\u51fd\u6570Activations\n\n\n\u6fc0\u6d3b\u51fd\u6570\u53ef\u4ee5\u901a\u8fc7\u8bbe\u7f6e\u5355\u72ec\u7684\n\u6fc0\u6d3b\u5c42\n\u5b9e\u73b0\uff0c\u4e5f\u53ef\u4ee5\u5728\u6784\u9020\u5c42\u5bf9\u8c61\u65f6\u901a\u8fc7\u4f20\u9012\nactivation\n\u53c2\u6570\u5b9e\u73b0\u3002\n\n\nfrom keras.layers.core import Activation, Dense\n\nmodel.add(Dense(64))\nmodel.add(Activation('tanh'))\n\n\n\n\n\u7b49\u4ef7\u4e8e\n\n\nmodel.add(Dense(64, activation='tanh'))\n\n\n\n\n\u4e5f\u53ef\u4ee5\u901a\u8fc7\u4f20\u9012\u4e00\u4e2a\u9010\u5143\u7d20\u8fd0\u7b97\u7684Theano/TensorFlow\u51fd\u6570\u6765\u4f5c\u4e3a\u6fc0\u6d3b\u51fd\u6570\uff1a\n\n\nfrom keras import backend as K\n\ndef tanh(x):\n    return K.tanh(x)\n\nmodel.add(Dense(64, activation=tanh))\nmodel.add(Activation(tanh)\n\n\n\n\n\n\n\u9884\u5b9a\u4e49\u6fc0\u6d3b\u51fd\u6570\n\n\n\n\n\n\nsoftmax\uff1a\u5bf9\u8f93\u5165\u6570\u636e\u7684\u6700\u540e\u4e00\u7ef4\u8fdb\u884csoftmax\uff0c\u8f93\u5165\u6570\u636e\u5e94\u5f62\u5982\n(nb_samples, nb_timesteps, nb_dims)\n\u6216\n(nb_samples,nb_dims)\n\n\n\n\n\n\nsoftplus\n\n\n\n\n\n\nsoftsign\n\n\n\n\n\n\nrelu\n\n\n\n\n\n\ntanh\n\n\n\n\n\n\nsigmoid\n\n\n\n\n\n\nhard_sigmoid\n\n\n\n\n\n\nlinear\n\n\n\n\n\n\n\u9ad8\u7ea7\u6fc0\u6d3b\u51fd\u6570\n\n\n\u5bf9\u4e8e\u7b80\u5355\u7684Theano/TensorFlow\u4e0d\u80fd\u8868\u8fbe\u7684\u590d\u6742\u6fc0\u6d3b\u51fd\u6570\uff0c\u5982\u542b\u6709\u53ef\u5b66\u4e60\u53c2\u6570\u7684\u6fc0\u6d3b\u51fd\u6570\uff0c\u53ef\u901a\u8fc7\n\u9ad8\u7ea7\u6fc0\u6d3b\u51fd\u6570\n\u5b9e\u73b0\uff0c\u5982PReLU\uff0cLeakyReLU\u7b49\n\n\n\u3010Tips\u3011\u5f85\u4f1a\u513f\uff08\u5927\u6982\u51e0\u5929\u5427\uff09\u6211\u4eec\u5c06\u628a\u5404\u4e2a\u6fc0\u6d3b\u51fd\u6570\u7684\u8868\u8fbe\u5f0f\u3001\u56fe\u5f62\u548c\u7279\u70b9\u603b\u7ed3\u4e00\u4e0b\u3002\u8bf7\u5927\u5bb6\u6301\u7eed\u5173\u6ce8~", 
            "title": "\u6fc0\u6d3b\u51fd\u6570Activation"
        }, 
        {
            "location": "/other/activations/#activations", 
            "text": "\u6fc0\u6d3b\u51fd\u6570\u53ef\u4ee5\u901a\u8fc7\u8bbe\u7f6e\u5355\u72ec\u7684 \u6fc0\u6d3b\u5c42 \u5b9e\u73b0\uff0c\u4e5f\u53ef\u4ee5\u5728\u6784\u9020\u5c42\u5bf9\u8c61\u65f6\u901a\u8fc7\u4f20\u9012 activation \u53c2\u6570\u5b9e\u73b0\u3002  from keras.layers.core import Activation, Dense\n\nmodel.add(Dense(64))\nmodel.add(Activation('tanh'))  \u7b49\u4ef7\u4e8e  model.add(Dense(64, activation='tanh'))  \u4e5f\u53ef\u4ee5\u901a\u8fc7\u4f20\u9012\u4e00\u4e2a\u9010\u5143\u7d20\u8fd0\u7b97\u7684Theano/TensorFlow\u51fd\u6570\u6765\u4f5c\u4e3a\u6fc0\u6d3b\u51fd\u6570\uff1a  from keras import backend as K\n\ndef tanh(x):\n    return K.tanh(x)\n\nmodel.add(Dense(64, activation=tanh))\nmodel.add(Activation(tanh)", 
            "title": "\u6fc0\u6d3b\u51fd\u6570Activations"
        }, 
        {
            "location": "/other/activations/#_1", 
            "text": "softmax\uff1a\u5bf9\u8f93\u5165\u6570\u636e\u7684\u6700\u540e\u4e00\u7ef4\u8fdb\u884csoftmax\uff0c\u8f93\u5165\u6570\u636e\u5e94\u5f62\u5982 (nb_samples, nb_timesteps, nb_dims) \u6216 (nb_samples,nb_dims)    softplus    softsign    relu    tanh    sigmoid    hard_sigmoid    linear", 
            "title": "\u9884\u5b9a\u4e49\u6fc0\u6d3b\u51fd\u6570"
        }, 
        {
            "location": "/other/activations/#_2", 
            "text": "\u5bf9\u4e8e\u7b80\u5355\u7684Theano/TensorFlow\u4e0d\u80fd\u8868\u8fbe\u7684\u590d\u6742\u6fc0\u6d3b\u51fd\u6570\uff0c\u5982\u542b\u6709\u53ef\u5b66\u4e60\u53c2\u6570\u7684\u6fc0\u6d3b\u51fd\u6570\uff0c\u53ef\u901a\u8fc7 \u9ad8\u7ea7\u6fc0\u6d3b\u51fd\u6570 \u5b9e\u73b0\uff0c\u5982PReLU\uff0cLeakyReLU\u7b49  \u3010Tips\u3011\u5f85\u4f1a\u513f\uff08\u5927\u6982\u51e0\u5929\u5427\uff09\u6211\u4eec\u5c06\u628a\u5404\u4e2a\u6fc0\u6d3b\u51fd\u6570\u7684\u8868\u8fbe\u5f0f\u3001\u56fe\u5f62\u548c\u7279\u70b9\u603b\u7ed3\u4e00\u4e0b\u3002\u8bf7\u5927\u5bb6\u6301\u7eed\u5173\u6ce8~", 
            "title": "\u9ad8\u7ea7\u6fc0\u6d3b\u51fd\u6570"
        }, 
        {
            "location": "/other/callbacks/", 
            "text": "\u56de\u8c03\u51fd\u6570Callbacks\n\n\n\u56de\u8c03\u51fd\u6570\u662f\u4e00\u7ec4\u5728\u8bad\u7ec3\u7684\u7279\u5b9a\u9636\u6bb5\u88ab\u8c03\u7528\u7684\u51fd\u6570\u96c6\uff0c\u4f60\u53ef\u4ee5\u4f7f\u7528\u56de\u8c03\u51fd\u6570\u6765\u89c2\u5bdf\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7f51\u7edc\u5185\u90e8\u7684\u72b6\u6001\u548c\u7edf\u8ba1\u4fe1\u606f\u3002\u901a\u8fc7\u4f20\u9012\u56de\u8c03\u51fd\u6570\u5217\u8868\u5230\u6a21\u578b\u7684\n.fit()\n\u4e2d\uff0c\u5373\u53ef\u5728\u7ed9\u5b9a\u7684\u8bad\u7ec3\u9636\u6bb5\u8c03\u7528\u8be5\u51fd\u6570\u96c6\u4e2d\u7684\u51fd\u6570\u3002\n\n\n\u3010Tips\u3011\u867d\u7136\u6211\u4eec\u79f0\u4e4b\u4e3a\u56de\u8c03\u201c\u51fd\u6570\u201d\uff0c\u4f46\u4e8b\u5b9e\u4e0aKeras\u7684\u56de\u8c03\u51fd\u6570\u662f\u4e00\u4e2a\u7c7b\uff0c\u56de\u8c03\u51fd\u6570\u53ea\u662f\u4e60\u60ef\u6027\u79f0\u547c\n\n\nCallbackList\n\n\nkeras.callbacks.CallbackList(callbacks=[], queue_length=10)\n\n\n\n\nCallback\n\n\nkeras.callbacks.Callback()\n\n\n\n\n\u8fd9\u662f\u56de\u8c03\u51fd\u6570\u7684\u62bd\u8c61\u7c7b\uff0c\u5b9a\u4e49\u65b0\u7684\u56de\u8c03\u51fd\u6570\u5fc5\u987b\u7ee7\u627f\u81ea\u8be5\u7c7b\n\n\n\u7c7b\u5c5e\u6027\n\n\n\n\n\n\nparams\uff1a\u5b57\u5178\uff0c\u8bad\u7ec3\u53c2\u6570\u96c6\uff08\u5982\u4fe1\u606f\u663e\u793a\u65b9\u6cd5verbosity\uff0cbatch\u5927\u5c0f\uff0cepoch\u6570\uff09\n\n\n\n\n\n\nmodel\uff1a\nkeras.models.Model\n\u5bf9\u8c61\uff0c\u4e3a\u6b63\u5728\u8bad\u7ec3\u7684\u6a21\u578b\u7684\u5f15\u7528\n\n\n\n\n\n\n\u56de\u8c03\u51fd\u6570\u4ee5\u5b57\u5178\nlogs\n\u4e3a\u53c2\u6570\uff0c\u8be5\u5b57\u5178\u5305\u542b\u4e86\u4e00\u7cfb\u5217\u4e0e\u5f53\u524dbatch\u6216epoch\u76f8\u5173\u7684\u4fe1\u606f\u3002\n\n\n\u76ee\u524d\uff0c\u6a21\u578b\u7684\n.fit()\n\u4e2d\u6709\u4e0b\u5217\u53c2\u6570\u4f1a\u88ab\u8bb0\u5f55\u5230\nlogs\n\u4e2d\uff1a\n\n\n\n\n\n\n\u5728\u6bcf\u4e2aepoch\u7684\u7ed3\u5c3e\u5904\uff08on_epoch_end\uff09\uff0c\nlogs\n\u5c06\u5305\u542b\u8bad\u7ec3\u7684\u6b63\u786e\u7387\u548c\u8bef\u5dee\uff0c\nacc\n\u548c\nloss\n\uff0c\u5982\u679c\u6307\u5b9a\u4e86\u9a8c\u8bc1\u96c6\uff0c\u8fd8\u4f1a\u5305\u542b\u9a8c\u8bc1\u96c6\u6b63\u786e\u7387\u548c\u8bef\u5dee\nval_acc)\n\u548c\nval_loss\n\uff0c\nval_acc\n\u8fd8\u989d\u5916\u9700\u8981\u5728\n.compile\n\u4e2d\u542f\u7528\nmetrics=['accuracy']\n\u3002\n\n\n\n\n\n\n\u5728\u6bcf\u4e2abatch\u7684\u5f00\u59cb\u5904\uff08on_batch_begin\uff09\uff1a\nlogs\n\u5305\u542b\nsize\n\uff0c\u5373\u5f53\u524dbatch\u7684\u6837\u672c\u6570\n\n\n\n\n\n\n\u5728\u6bcf\u4e2abatch\u7684\u7ed3\u5c3e\u5904\uff08on_batch_end\uff09\uff1a\nlogs\n\u5305\u542b\nloss\n\uff0c\u82e5\u542f\u7528\naccuracy\n\u5219\u8fd8\u5305\u542b\nacc\n\n\n\n\n\n\n\n\nBaseLogger\n\n\nkeras.callbacks.BaseLogger()\n\n\n\n\n\u8be5\u56de\u8c03\u51fd\u6570\u7528\u6765\u5bf9\u6bcf\u4e2aepoch\u7d2f\u52a0\nmetrics\n\u6307\u5b9a\u7684\u76d1\u89c6\u6307\u6807\u7684epoch\u5e73\u5747\u503c\n\n\n\u8be5\u56de\u8c03\u51fd\u6570\u5728\u6bcf\u4e2aKeras\u6a21\u578b\u4e2d\u90fd\u4f1a\u88ab\u81ea\u52a8\u8c03\u7528\n\n\n\n\nProgbarLogger\n\n\nkeras.callbacks.ProgbarLogger()\n\n\n\n\n\u8be5\u56de\u8c03\u51fd\u6570\u7528\u6765\u5c06\nmetrics\n\u6307\u5b9a\u7684\u76d1\u89c6\u6307\u6807\u8f93\u51fa\u5230\u6807\u51c6\u8f93\u51fa\u4e0a\n\n\n\n\nHistory\n\n\nkeras.callbacks.History()\n\n\n\n\n\u8be5\u56de\u8c03\u51fd\u6570\u5728Keras\u6a21\u578b\u4e0a\u4f1a\u88ab\u81ea\u52a8\u8c03\u7528\uff0c\nHistory\n\u5bf9\u8c61\u5373\u4e3a\nfit\n\u65b9\u6cd5\u7684\u8fd4\u56de\u503c\n\n\n\n\nModelCheckpoint\n\n\nkeras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n\n\n\n\n\u8be5\u56de\u8c03\u51fd\u6570\u5c06\u5728\u6bcf\u4e2aepoch\u540e\u4fdd\u5b58\u6a21\u578b\u5230\nfilepath\n\n\nfilepath\n\u53ef\u4ee5\u662f\u683c\u5f0f\u5316\u7684\u5b57\u7b26\u4e32\uff0c\u91cc\u9762\u7684\u5360\u4f4d\u7b26\u5c06\u4f1a\u88ab\nepoch\n\u503c\u548c\u4f20\u5165\non_epoch_end\n\u7684\nlogs\n\u5173\u952e\u5b57\u6240\u586b\u5165\n\n\n\u4f8b\u5982\uff0c\nfilepath\n\u82e5\u4e3a\nweights.{epoch:02d-{val_loss:.2f}}.hdf5\n\uff0c\u5219\u4f1a\u751f\u6210\u5bf9\u5e94epoch\u548c\u9a8c\u8bc1\u96c6loss\u7684\u591a\u4e2a\u6587\u4ef6\u3002\n\n\n\u53c2\u6570\n\n\n\n\n\n\nfilename\uff1a\u5b57\u7b26\u4e32\uff0c\u4fdd\u5b58\u6a21\u578b\u7684\u8def\u5f84\n\n\n\n\n\n\nmonitor\uff1a\u9700\u8981\u76d1\u89c6\u7684\u503c\n\n\n\n\n\n\nverbose\uff1a\u4fe1\u606f\u5c55\u793a\u6a21\u5f0f\uff0c0\u62161\n\n\n\n\n\n\nsave_best_only\uff1a\u5f53\u8bbe\u7f6e\u4e3a\nTrue\n\u65f6\uff0c\u5c06\u53ea\u4fdd\u5b58\u5728\u9a8c\u8bc1\u96c6\u4e0a\u6027\u80fd\u6700\u597d\u7684\u6a21\u578b\n\n\n\n\n\n\nmode\uff1a\u2018auto\u2019\uff0c\u2018min\u2019\uff0c\u2018max\u2019\u4e4b\u4e00\uff0c\u5728\nsave_best_only=True\n\u65f6\u51b3\u5b9a\u6027\u80fd\u6700\u4f73\u6a21\u578b\u7684\u8bc4\u5224\u51c6\u5219\uff0c\u4f8b\u5982\uff0c\u5f53\u76d1\u6d4b\u503c\u4e3a\nval_acc\n\u65f6\uff0c\u6a21\u5f0f\u5e94\u4e3a\nmax\n\uff0c\u5f53\u68c0\u6d4b\u503c\u4e3a\nval_loss\n\u65f6\uff0c\u6a21\u5f0f\u5e94\u4e3a\nmin\n\u3002\u5728\nauto\n\u6a21\u5f0f\u4e0b\uff0c\u8bc4\u4ef7\u51c6\u5219\u7531\u88ab\u76d1\u6d4b\u503c\u7684\u540d\u5b57\u81ea\u52a8\u63a8\u65ad\u3002\n\n\n\n\n\n\nsave_weights_only\uff1a\u82e5\u8bbe\u7f6e\u4e3aTrue\uff0c\u5219\u53ea\u4fdd\u5b58\u6a21\u578b\u6743\u91cd\uff0c\u5426\u5219\u5c06\u4fdd\u5b58\u6574\u4e2a\u6a21\u578b\uff08\u5305\u62ec\u6a21\u578b\u7ed3\u6784\uff0c\u914d\u7f6e\u4fe1\u606f\u7b49\uff09\n\n\n\n\n\n\nperiod\uff1aCheckPoint\u4e4b\u95f4\u7684\u95f4\u9694\u7684epoch\u6570\n\n\n\n\n\n\n\n\nEarlyStopping\n\n\nkeras.callbacks.EarlyStopping(monitor='val_loss', patience=0, verbose=0, mode='auto')\n\n\n\n\n\u5f53\u76d1\u6d4b\u503c\u4e0d\u518d\u6539\u5584\u65f6\uff0c\u8be5\u56de\u8c03\u51fd\u6570\u5c06\u4e2d\u6b62\u8bad\u7ec3\n\n\n\u53c2\u6570\n\n\n\n\n\n\nmonitor\uff1a\u9700\u8981\u76d1\u89c6\u7684\u91cf\n\n\n\n\n\n\npatience\uff1a\u5f53early stop\u88ab\u6fc0\u6d3b\uff08\u5982\u53d1\u73b0loss\u76f8\u6bd4\u4e0a\u4e00\u4e2aepoch\u8bad\u7ec3\u6ca1\u6709\u4e0b\u964d\uff09\uff0c\u5219\u7ecf\u8fc7\npatience\n\u4e2aepoch\u540e\u505c\u6b62\u8bad\u7ec3\u3002\n\n\n\n\n\n\nverbose\uff1a\u4fe1\u606f\u5c55\u793a\u6a21\u5f0f\n\n\n\n\n\n\nmode\uff1a\u2018auto\u2019\uff0c\u2018min\u2019\uff0c\u2018max\u2019\u4e4b\u4e00\uff0c\u5728\nmin\n\u6a21\u5f0f\u4e0b\uff0c\u5982\u679c\u68c0\u6d4b\u503c\u505c\u6b62\u4e0b\u964d\u5219\u4e2d\u6b62\u8bad\u7ec3\u3002\u5728\nmax\n\u6a21\u5f0f\u4e0b\uff0c\u5f53\u68c0\u6d4b\u503c\u4e0d\u518d\u4e0a\u5347\u5219\u505c\u6b62\u8bad\u7ec3\u3002\n\n\n\n\n\n\n\n\nRemoteMonitor\n\n\nkeras.callbacks.RemoteMonitor(root='http://localhost:9000')\n\n\n\n\n\u8be5\u56de\u8c03\u51fd\u6570\u7528\u4e8e\u5411\u670d\u52a1\u5668\u53d1\u9001\u4e8b\u4ef6\u6d41\uff0c\u8be5\u56de\u8c03\u51fd\u6570\u9700\u8981\nrequests\n\u5e93\n\n\n\u53c2\u6570\n\n\n\n\nroot\uff1a\u8be5\u53c2\u6570\u4e3a\u6839url\uff0c\u56de\u8c03\u51fd\u6570\u5c06\u5728\u6bcf\u4e2aepoch\u540e\u628a\u4ea7\u751f\u7684\u4e8b\u4ef6\u6d41\u53d1\u9001\u5230\u8be5\u5730\u5740\uff0c\u4e8b\u4ef6\u5c06\u88ab\u53d1\u5f80\nroot + '/publish/epoch/end/'\n\u3002\u53d1\u9001\u65b9\u6cd5\u4e3aHTTP POST\uff0c\u5176\ndata\n\u5b57\u6bb5\u7684\u6570\u636e\u662f\u6309JSON\u683c\u5f0f\u7f16\u7801\u7684\u4e8b\u4ef6\u5b57\u5178\u3002\n\n\n\n\n\n\nLearningRateScheduler\n\n\nkeras.callbacks.LearningRateScheduler(schedule)\n\n\n\n\n\u8be5\u56de\u8c03\u51fd\u6570\u662f\u5b66\u4e60\u7387\u8c03\u5ea6\u5668\n\n\n\u53c2\u6570\n\n\n\n\nschedule\uff1a\u51fd\u6570\uff0c\u8be5\u51fd\u6570\u4ee5epoch\u53f7\u4e3a\u53c2\u6570\uff08\u4ece0\u7b97\u8d77\u7684\u6574\u6570\uff09\uff0c\u8fd4\u56de\u4e00\u4e2a\u65b0\u5b66\u4e60\u7387\uff08\u6d6e\u70b9\u6570\uff09\n\n\n\n\n\n\nTensorBoard\n\n\nkeras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=0)\n\n\n\n\n\u8be5\u56de\u8c03\u51fd\u6570\u662f\u4e00\u4e2a\u53ef\u89c6\u5316\u7684\u5c55\u793a\u5668\n\n\nTensorBoard\u662fTensorFlow\u63d0\u4f9b\u7684\u53ef\u89c6\u5316\u5de5\u5177\uff0c\u8be5\u56de\u8c03\u51fd\u6570\u5c06\u65e5\u5fd7\u4fe1\u606f\u5199\u5165TensorBorad\uff0c\u4f7f\u5f97\u4f60\u53ef\u4ee5\u52a8\u6001\u7684\u89c2\u5bdf\u8bad\u7ec3\u548c\u6d4b\u8bd5\u6307\u6807\u7684\u56fe\u50cf\u4ee5\u53ca\u4e0d\u540c\u5c42\u7684\u6fc0\u6d3b\u503c\u76f4\u65b9\u56fe\u3002\n\n\n\u5982\u679c\u5df2\u7ecf\u901a\u8fc7pip\u5b89\u88c5\u4e86TensorFlow\uff0c\u6211\u4eec\u53ef\u901a\u8fc7\u4e0b\u9762\u7684\u547d\u4ee4\u542f\u52a8TensorBoard\uff1a\n\n\ntensorboard --logdir=/full_path_to_your_logs\n\n\n\n\n\u66f4\u591a\u7684\u53c2\u8003\u4fe1\u606f\uff0c\u8bf7\u70b9\u51fb\n\u8fd9\u91cc\n\n\n\u53c2\u6570\n\n\n\n\n\n\nlog_dir\uff1a\u4fdd\u5b58\u65e5\u5fd7\u6587\u4ef6\u7684\u5730\u5740\uff0c\u8be5\u6587\u4ef6\u5c06\u88abTensorBoard\u89e3\u6790\u4ee5\u7528\u4e8e\u53ef\u89c6\u5316\n\n\n\n\n\n\nhistogram_freq\uff1a\u8ba1\u7b97\u5404\u4e2a\u5c42\u6fc0\u6d3b\u503c\u76f4\u65b9\u56fe\u7684\u9891\u7387\uff08\u6bcf\u591a\u5c11\u4e2aepoch\u8ba1\u7b97\u4e00\u6b21\uff09\uff0c\u5982\u679c\u8bbe\u7f6e\u4e3a0\u5219\u4e0d\u8ba1\u7b97\u3002\n\n\n\n\n\n\n\n\nReduceLROnPlateau\n\n\nkeras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, verbose=0, mode='auto', epsilon=0.0001, cooldown=0, min_lr=0)\n\n\n\n\n\u5f53\u8bc4\u4ef7\u6307\u6807\u4e0d\u5728\u63d0\u5347\u65f6\uff0c\u51cf\u5c11\u5b66\u4e60\u7387\n\n\n\u5f53\u5b66\u4e60\u505c\u6ede\u65f6\uff0c\u51cf\u5c112\u500d\u621610\u500d\u7684\u5b66\u4e60\u7387\u5e38\u5e38\u80fd\u83b7\u5f97\u8f83\u597d\u7684\u6548\u679c\u3002\u8be5\u56de\u8c03\u51fd\u6570\u68c0\u6d4b\u6307\u6807\u7684\u60c5\u51b5\uff0c\u5982\u679c\u5728\npatience\n\u4e2aepoch\u4e2d\u770b\u4e0d\u5230\u6a21\u578b\u6027\u80fd\u63d0\u5347\uff0c\u5219\u51cf\u5c11\u5b66\u4e60\u7387\n\n\n\u53c2\u6570\n\n\n\n\nmonitor\uff1a\u88ab\u76d1\u6d4b\u7684\u91cf\n\n\nfactor\uff1a\u6bcf\u6b21\u51cf\u5c11\u5b66\u4e60\u7387\u7684\u56e0\u5b50\uff0c\u5b66\u4e60\u7387\u5c06\u4ee5\nlr = lr*factor\n\u7684\u5f62\u5f0f\u88ab\u51cf\u5c11\n\n\npatience\uff1a\u5f53patience\u4e2aepoch\u8fc7\u53bb\u800c\u6a21\u578b\u6027\u80fd\u4e0d\u63d0\u5347\u65f6\uff0c\u5b66\u4e60\u7387\u51cf\u5c11\u7684\u52a8\u4f5c\u4f1a\u88ab\u89e6\u53d1\n\n\nmode\uff1a\u2018auto\u2019\uff0c\u2018min\u2019\uff0c\u2018max\u2019\u4e4b\u4e00\uff0c\u5728\nmin\n\u6a21\u5f0f\u4e0b\uff0c\u5982\u679c\u68c0\u6d4b\u503c\u89e6\u53d1\u5b66\u4e60\u7387\u51cf\u5c11\u3002\u5728\nmax\n\u6a21\u5f0f\u4e0b\uff0c\u5f53\u68c0\u6d4b\u503c\u4e0d\u518d\u4e0a\u5347\u5219\u89e6\u53d1\u5b66\u4e60\u7387\u51cf\u5c11\u3002\n\n\nepsilon\uff1a\u9608\u503c\uff0c\u7528\u6765\u786e\u5b9a\u662f\u5426\u8fdb\u5165\u68c0\u6d4b\u503c\u7684\u201c\u5e73\u539f\u533a\u201d\n\n\ncooldown\uff1a\u5b66\u4e60\u7387\u51cf\u5c11\u540e\uff0c\u4f1a\u7ecf\u8fc7cooldown\u4e2aepoch\u624d\u91cd\u65b0\u8fdb\u884c\u6b63\u5e38\u64cd\u4f5c\n\n\nmin_lr\uff1a\u5b66\u4e60\u7387\u7684\u4e0b\u9650\n\n\n\n\n\u793a\u4f8b\uff1a\n\n\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n            patience=5, min_lr=0.001)\nmodel.fit(X_train, Y_train, callbacks=[reduce_lr])\n\n\n\n\nCSVLogger\n\n\nkeras.callbacks.CSVLogger(filename, separator=',', append=False)\n\n\n\n\n\u5c06epoch\u7684\u8bad\u7ec3\u7ed3\u679c\u4fdd\u5b58\u5728csv\u6587\u4ef6\u4e2d\uff0c\u652f\u6301\u6240\u6709\u53ef\u88ab\u8f6c\u6362\u4e3astring\u7684\u503c\uff0c\u5305\u62ec1D\u7684\u53ef\u8fed\u4ee3\u6570\u503c\u5982np.ndarray.\n\n\n\u53c2\u6570\n\n\n\n\nfiename\uff1a\u4fdd\u5b58\u7684csv\u6587\u4ef6\u540d\uff0c\u5982\nrun/log.csv\n\n\nseparator\uff1a\u5b57\u7b26\u4e32\uff0ccsv\u5206\u9694\u7b26\n\n\nappend\uff1a\u9ed8\u8ba4\u4e3aFalse\uff0c\u4e3aTrue\u65f6csv\u6587\u4ef6\u5982\u679c\u5b58\u5728\u5219\u7ee7\u7eed\u5199\u5165\uff0c\u4e3aFalse\u65f6\u603b\u662f\u8986\u76d6csv\u6587\u4ef6\n\n\n\n\n\u793a\u4f8b\n\n\ncsv_logger = CSVLogger('training.log')\nmodel.fit(X_train, Y_train, callbacks=[csv_logger])\n\n\n\n\nLambdaCallback\n\n\nkeras.callbacks.LambdaCallback(on_epoch_begin=None, on_epoch_end=None, on_batch_begin=None, on_batch_end=None, on_train_begin=None, on_train_end=None)\n\n\n\n\n\u7528\u4e8e\u521b\u5efa\u7b80\u5355\u7684callback\u7684callback\u7c7b\n\n\n\u8be5callback\u7684\u533f\u540d\u51fd\u6570\u5c06\u4f1a\u5728\u9002\u5f53\u7684\u65f6\u5019\u8c03\u7528\uff0c\u6ce8\u610f\uff0c\u8be5\u56de\u8c03\u51fd\u6570\u5047\u5b9a\u4e86\u4e00\u4e9b\u4f4d\u7f6e\u53c2\u6570\non_eopoch_begin\n\u548c\non_epoch_end\n\u5047\u5b9a\u8f93\u5165\u7684\u53c2\u6570\u662f\nepoch, logs\n. \non_batch_begin\n\u548c\non_batch_end\n\u5047\u5b9a\u8f93\u5165\u7684\u53c2\u6570\u662f\nbatch, logs\n\uff0c\non_train_begin\n\u548c\non_train_end\n\u5047\u5b9a\u8f93\u5165\u7684\u53c2\u6570\u662f\nlogs\n\n\n\u53c2\u6570\n\n\n\n\non_epoch_begin: \u5728\u6bcf\u4e2aepoch\u5f00\u59cb\u65f6\u8c03\u7528\n\n\non_epoch_end: \u5728\u6bcf\u4e2aepoch\u7ed3\u675f\u65f6\u8c03\u7528\n\n\non_batch_begin: \u5728\u6bcf\u4e2abatch\u5f00\u59cb\u65f6\u8c03\u7528\n\n\non_batch_end: \u5728\u6bcf\u4e2abatch\u7ed3\u675f\u65f6\u8c03\u7528\n\n\non_train_begin: \u5728\u8bad\u7ec3\u5f00\u59cb\u65f6\u8c03\u7528\n\n\non_train_end: \u5728\u8bad\u7ec3\u7ed3\u675f\u65f6\u8c03\u7528\n\n\n\n\n\u793a\u4f8b\n\n\n# Print the batch number at the beginning of every batch.\nbatch_print_callback = LambdaCallback(on_batch_begin=lambda batch, logs: print(batch))\n\n# Plot the loss after every epoch.\nimport numpy as np\nimport matplotlib.pyplot as plt\nplot_loss_callback = LambdaCallback(on_epoch_end=lambda epoch, logs: plt.plot(np.arange(epoch), logs['loss']))\n\n# Terminate some processes after having finished model training.\nprocesses = ...\ncleanup_callback = LambdaCallback(on_train_end=lambda logs: [p.terminate() for p in processes if p.is_alive()])\n\nmodel.fit(..., callbacks=[batch_print_callback, plot_loss_callback, cleanup_callback])\n\n\n\n\n\u7f16\u5199\u81ea\u5df1\u7684\u56de\u8c03\u51fd\u6570\n\n\n\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u7ee7\u627f\nkeras.callbacks.Callback\n\u7f16\u5199\u81ea\u5df1\u7684\u56de\u8c03\u51fd\u6570\uff0c\u56de\u8c03\u51fd\u6570\u901a\u8fc7\u7c7b\u6210\u5458\nself.model\n\u8bbf\u95ee\u8bbf\u95ee\uff0c\u8be5\u6210\u5458\u662f\u6a21\u578b\u7684\u4e00\u4e2a\u5f15\u7528\u3002\n\n\n\u8fd9\u91cc\u662f\u4e00\u4e2a\u7b80\u5355\u7684\u4fdd\u5b58\u6bcf\u4e2abatch\u7684loss\u7684\u56de\u8c03\u51fd\u6570\uff1a\n\n\nclass LossHistory(keras.callbacks.Callback):\n    def on_train_begin(self, logs={}):\n        self.losses = []\n\n    def on_batch_end(self, batch, logs={}):\n        self.losses.append(logs.get('loss'))\n\n\n\n\n\u4f8b\u5b50\uff1a\u8bb0\u5f55\u635f\u5931\u51fd\u6570\u7684\u5386\u53f2\u6570\u636e\n\n\nclass LossHistory(keras.callbacks.Callback):\n    def on_train_begin(self, logs={}):\n        self.losses = []\n\n    def on_batch_end(self, batch, logs={}):\n        self.losses.append(logs.get('loss'))\n\nmodel = Sequential()\nmodel.add(Dense(10, input_dim=784, init='uniform'))\nmodel.add(Activation('softmax'))\nmodel.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n\nhistory = LossHistory()\nmodel.fit(X_train, Y_train, batch_size=128, nb_epoch=20, verbose=0, callbacks=[history])\n\nprint history.losses\n# outputs\n'''\n[0.66047596406559383, 0.3547245744908703, ..., 0.25953155204159617, 0.25901699725311789]\n\n\n\n\n\u4f8b\u5b50\uff1a\u6a21\u578b\u68c0\u67e5\u70b9\n\n\nfrom keras.callbacks import ModelCheckpoint\n\nmodel = Sequential()\nmodel.add(Dense(10, input_dim=784, init='uniform'))\nmodel.add(Activation('softmax'))\nmodel.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n\n'''\nsaves the model weights after each epoch if the validation loss decreased\n'''\ncheckpointer = ModelCheckpoint(filepath=\n/tmp/weights.hdf5\n, verbose=1, save_best_only=True)\nmodel.fit(X_train, Y_train, batch_size=128, nb_epoch=20, verbose=0, validation_data=(X_test, Y_test), callbacks=[checkpointer])", 
            "title": "\u56de\u8c03\u51fd\u6570Callback"
        }, 
        {
            "location": "/other/callbacks/#callbacks", 
            "text": "\u56de\u8c03\u51fd\u6570\u662f\u4e00\u7ec4\u5728\u8bad\u7ec3\u7684\u7279\u5b9a\u9636\u6bb5\u88ab\u8c03\u7528\u7684\u51fd\u6570\u96c6\uff0c\u4f60\u53ef\u4ee5\u4f7f\u7528\u56de\u8c03\u51fd\u6570\u6765\u89c2\u5bdf\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7f51\u7edc\u5185\u90e8\u7684\u72b6\u6001\u548c\u7edf\u8ba1\u4fe1\u606f\u3002\u901a\u8fc7\u4f20\u9012\u56de\u8c03\u51fd\u6570\u5217\u8868\u5230\u6a21\u578b\u7684 .fit() \u4e2d\uff0c\u5373\u53ef\u5728\u7ed9\u5b9a\u7684\u8bad\u7ec3\u9636\u6bb5\u8c03\u7528\u8be5\u51fd\u6570\u96c6\u4e2d\u7684\u51fd\u6570\u3002  \u3010Tips\u3011\u867d\u7136\u6211\u4eec\u79f0\u4e4b\u4e3a\u56de\u8c03\u201c\u51fd\u6570\u201d\uff0c\u4f46\u4e8b\u5b9e\u4e0aKeras\u7684\u56de\u8c03\u51fd\u6570\u662f\u4e00\u4e2a\u7c7b\uff0c\u56de\u8c03\u51fd\u6570\u53ea\u662f\u4e60\u60ef\u6027\u79f0\u547c", 
            "title": "\u56de\u8c03\u51fd\u6570Callbacks"
        }, 
        {
            "location": "/other/callbacks/#callbacklist", 
            "text": "keras.callbacks.CallbackList(callbacks=[], queue_length=10)", 
            "title": "CallbackList"
        }, 
        {
            "location": "/other/callbacks/#callback", 
            "text": "keras.callbacks.Callback()  \u8fd9\u662f\u56de\u8c03\u51fd\u6570\u7684\u62bd\u8c61\u7c7b\uff0c\u5b9a\u4e49\u65b0\u7684\u56de\u8c03\u51fd\u6570\u5fc5\u987b\u7ee7\u627f\u81ea\u8be5\u7c7b", 
            "title": "Callback"
        }, 
        {
            "location": "/other/callbacks/#_1", 
            "text": "params\uff1a\u5b57\u5178\uff0c\u8bad\u7ec3\u53c2\u6570\u96c6\uff08\u5982\u4fe1\u606f\u663e\u793a\u65b9\u6cd5verbosity\uff0cbatch\u5927\u5c0f\uff0cepoch\u6570\uff09    model\uff1a keras.models.Model \u5bf9\u8c61\uff0c\u4e3a\u6b63\u5728\u8bad\u7ec3\u7684\u6a21\u578b\u7684\u5f15\u7528    \u56de\u8c03\u51fd\u6570\u4ee5\u5b57\u5178 logs \u4e3a\u53c2\u6570\uff0c\u8be5\u5b57\u5178\u5305\u542b\u4e86\u4e00\u7cfb\u5217\u4e0e\u5f53\u524dbatch\u6216epoch\u76f8\u5173\u7684\u4fe1\u606f\u3002  \u76ee\u524d\uff0c\u6a21\u578b\u7684 .fit() \u4e2d\u6709\u4e0b\u5217\u53c2\u6570\u4f1a\u88ab\u8bb0\u5f55\u5230 logs \u4e2d\uff1a    \u5728\u6bcf\u4e2aepoch\u7684\u7ed3\u5c3e\u5904\uff08on_epoch_end\uff09\uff0c logs \u5c06\u5305\u542b\u8bad\u7ec3\u7684\u6b63\u786e\u7387\u548c\u8bef\u5dee\uff0c acc \u548c loss \uff0c\u5982\u679c\u6307\u5b9a\u4e86\u9a8c\u8bc1\u96c6\uff0c\u8fd8\u4f1a\u5305\u542b\u9a8c\u8bc1\u96c6\u6b63\u786e\u7387\u548c\u8bef\u5dee val_acc) \u548c val_loss \uff0c val_acc \u8fd8\u989d\u5916\u9700\u8981\u5728 .compile \u4e2d\u542f\u7528 metrics=['accuracy'] \u3002    \u5728\u6bcf\u4e2abatch\u7684\u5f00\u59cb\u5904\uff08on_batch_begin\uff09\uff1a logs \u5305\u542b size \uff0c\u5373\u5f53\u524dbatch\u7684\u6837\u672c\u6570    \u5728\u6bcf\u4e2abatch\u7684\u7ed3\u5c3e\u5904\uff08on_batch_end\uff09\uff1a logs \u5305\u542b loss \uff0c\u82e5\u542f\u7528 accuracy \u5219\u8fd8\u5305\u542b acc", 
            "title": "\u7c7b\u5c5e\u6027"
        }, 
        {
            "location": "/other/callbacks/#baselogger", 
            "text": "keras.callbacks.BaseLogger()  \u8be5\u56de\u8c03\u51fd\u6570\u7528\u6765\u5bf9\u6bcf\u4e2aepoch\u7d2f\u52a0 metrics \u6307\u5b9a\u7684\u76d1\u89c6\u6307\u6807\u7684epoch\u5e73\u5747\u503c  \u8be5\u56de\u8c03\u51fd\u6570\u5728\u6bcf\u4e2aKeras\u6a21\u578b\u4e2d\u90fd\u4f1a\u88ab\u81ea\u52a8\u8c03\u7528", 
            "title": "BaseLogger"
        }, 
        {
            "location": "/other/callbacks/#progbarlogger", 
            "text": "keras.callbacks.ProgbarLogger()  \u8be5\u56de\u8c03\u51fd\u6570\u7528\u6765\u5c06 metrics \u6307\u5b9a\u7684\u76d1\u89c6\u6307\u6807\u8f93\u51fa\u5230\u6807\u51c6\u8f93\u51fa\u4e0a", 
            "title": "ProgbarLogger"
        }, 
        {
            "location": "/other/callbacks/#history", 
            "text": "keras.callbacks.History()  \u8be5\u56de\u8c03\u51fd\u6570\u5728Keras\u6a21\u578b\u4e0a\u4f1a\u88ab\u81ea\u52a8\u8c03\u7528\uff0c History \u5bf9\u8c61\u5373\u4e3a fit \u65b9\u6cd5\u7684\u8fd4\u56de\u503c", 
            "title": "History"
        }, 
        {
            "location": "/other/callbacks/#modelcheckpoint", 
            "text": "keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)  \u8be5\u56de\u8c03\u51fd\u6570\u5c06\u5728\u6bcf\u4e2aepoch\u540e\u4fdd\u5b58\u6a21\u578b\u5230 filepath  filepath \u53ef\u4ee5\u662f\u683c\u5f0f\u5316\u7684\u5b57\u7b26\u4e32\uff0c\u91cc\u9762\u7684\u5360\u4f4d\u7b26\u5c06\u4f1a\u88ab epoch \u503c\u548c\u4f20\u5165 on_epoch_end \u7684 logs \u5173\u952e\u5b57\u6240\u586b\u5165  \u4f8b\u5982\uff0c filepath \u82e5\u4e3a weights.{epoch:02d-{val_loss:.2f}}.hdf5 \uff0c\u5219\u4f1a\u751f\u6210\u5bf9\u5e94epoch\u548c\u9a8c\u8bc1\u96c6loss\u7684\u591a\u4e2a\u6587\u4ef6\u3002", 
            "title": "ModelCheckpoint"
        }, 
        {
            "location": "/other/callbacks/#_2", 
            "text": "filename\uff1a\u5b57\u7b26\u4e32\uff0c\u4fdd\u5b58\u6a21\u578b\u7684\u8def\u5f84    monitor\uff1a\u9700\u8981\u76d1\u89c6\u7684\u503c    verbose\uff1a\u4fe1\u606f\u5c55\u793a\u6a21\u5f0f\uff0c0\u62161    save_best_only\uff1a\u5f53\u8bbe\u7f6e\u4e3a True \u65f6\uff0c\u5c06\u53ea\u4fdd\u5b58\u5728\u9a8c\u8bc1\u96c6\u4e0a\u6027\u80fd\u6700\u597d\u7684\u6a21\u578b    mode\uff1a\u2018auto\u2019\uff0c\u2018min\u2019\uff0c\u2018max\u2019\u4e4b\u4e00\uff0c\u5728 save_best_only=True \u65f6\u51b3\u5b9a\u6027\u80fd\u6700\u4f73\u6a21\u578b\u7684\u8bc4\u5224\u51c6\u5219\uff0c\u4f8b\u5982\uff0c\u5f53\u76d1\u6d4b\u503c\u4e3a val_acc \u65f6\uff0c\u6a21\u5f0f\u5e94\u4e3a max \uff0c\u5f53\u68c0\u6d4b\u503c\u4e3a val_loss \u65f6\uff0c\u6a21\u5f0f\u5e94\u4e3a min \u3002\u5728 auto \u6a21\u5f0f\u4e0b\uff0c\u8bc4\u4ef7\u51c6\u5219\u7531\u88ab\u76d1\u6d4b\u503c\u7684\u540d\u5b57\u81ea\u52a8\u63a8\u65ad\u3002    save_weights_only\uff1a\u82e5\u8bbe\u7f6e\u4e3aTrue\uff0c\u5219\u53ea\u4fdd\u5b58\u6a21\u578b\u6743\u91cd\uff0c\u5426\u5219\u5c06\u4fdd\u5b58\u6574\u4e2a\u6a21\u578b\uff08\u5305\u62ec\u6a21\u578b\u7ed3\u6784\uff0c\u914d\u7f6e\u4fe1\u606f\u7b49\uff09    period\uff1aCheckPoint\u4e4b\u95f4\u7684\u95f4\u9694\u7684epoch\u6570", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/other/callbacks/#earlystopping", 
            "text": "keras.callbacks.EarlyStopping(monitor='val_loss', patience=0, verbose=0, mode='auto')  \u5f53\u76d1\u6d4b\u503c\u4e0d\u518d\u6539\u5584\u65f6\uff0c\u8be5\u56de\u8c03\u51fd\u6570\u5c06\u4e2d\u6b62\u8bad\u7ec3", 
            "title": "EarlyStopping"
        }, 
        {
            "location": "/other/callbacks/#_3", 
            "text": "monitor\uff1a\u9700\u8981\u76d1\u89c6\u7684\u91cf    patience\uff1a\u5f53early stop\u88ab\u6fc0\u6d3b\uff08\u5982\u53d1\u73b0loss\u76f8\u6bd4\u4e0a\u4e00\u4e2aepoch\u8bad\u7ec3\u6ca1\u6709\u4e0b\u964d\uff09\uff0c\u5219\u7ecf\u8fc7 patience \u4e2aepoch\u540e\u505c\u6b62\u8bad\u7ec3\u3002    verbose\uff1a\u4fe1\u606f\u5c55\u793a\u6a21\u5f0f    mode\uff1a\u2018auto\u2019\uff0c\u2018min\u2019\uff0c\u2018max\u2019\u4e4b\u4e00\uff0c\u5728 min \u6a21\u5f0f\u4e0b\uff0c\u5982\u679c\u68c0\u6d4b\u503c\u505c\u6b62\u4e0b\u964d\u5219\u4e2d\u6b62\u8bad\u7ec3\u3002\u5728 max \u6a21\u5f0f\u4e0b\uff0c\u5f53\u68c0\u6d4b\u503c\u4e0d\u518d\u4e0a\u5347\u5219\u505c\u6b62\u8bad\u7ec3\u3002", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/other/callbacks/#remotemonitor", 
            "text": "keras.callbacks.RemoteMonitor(root='http://localhost:9000')  \u8be5\u56de\u8c03\u51fd\u6570\u7528\u4e8e\u5411\u670d\u52a1\u5668\u53d1\u9001\u4e8b\u4ef6\u6d41\uff0c\u8be5\u56de\u8c03\u51fd\u6570\u9700\u8981 requests \u5e93", 
            "title": "RemoteMonitor"
        }, 
        {
            "location": "/other/callbacks/#_4", 
            "text": "root\uff1a\u8be5\u53c2\u6570\u4e3a\u6839url\uff0c\u56de\u8c03\u51fd\u6570\u5c06\u5728\u6bcf\u4e2aepoch\u540e\u628a\u4ea7\u751f\u7684\u4e8b\u4ef6\u6d41\u53d1\u9001\u5230\u8be5\u5730\u5740\uff0c\u4e8b\u4ef6\u5c06\u88ab\u53d1\u5f80 root + '/publish/epoch/end/' \u3002\u53d1\u9001\u65b9\u6cd5\u4e3aHTTP POST\uff0c\u5176 data \u5b57\u6bb5\u7684\u6570\u636e\u662f\u6309JSON\u683c\u5f0f\u7f16\u7801\u7684\u4e8b\u4ef6\u5b57\u5178\u3002", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/other/callbacks/#learningratescheduler", 
            "text": "keras.callbacks.LearningRateScheduler(schedule)  \u8be5\u56de\u8c03\u51fd\u6570\u662f\u5b66\u4e60\u7387\u8c03\u5ea6\u5668", 
            "title": "LearningRateScheduler"
        }, 
        {
            "location": "/other/callbacks/#_5", 
            "text": "schedule\uff1a\u51fd\u6570\uff0c\u8be5\u51fd\u6570\u4ee5epoch\u53f7\u4e3a\u53c2\u6570\uff08\u4ece0\u7b97\u8d77\u7684\u6574\u6570\uff09\uff0c\u8fd4\u56de\u4e00\u4e2a\u65b0\u5b66\u4e60\u7387\uff08\u6d6e\u70b9\u6570\uff09", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/other/callbacks/#tensorboard", 
            "text": "keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=0)  \u8be5\u56de\u8c03\u51fd\u6570\u662f\u4e00\u4e2a\u53ef\u89c6\u5316\u7684\u5c55\u793a\u5668  TensorBoard\u662fTensorFlow\u63d0\u4f9b\u7684\u53ef\u89c6\u5316\u5de5\u5177\uff0c\u8be5\u56de\u8c03\u51fd\u6570\u5c06\u65e5\u5fd7\u4fe1\u606f\u5199\u5165TensorBorad\uff0c\u4f7f\u5f97\u4f60\u53ef\u4ee5\u52a8\u6001\u7684\u89c2\u5bdf\u8bad\u7ec3\u548c\u6d4b\u8bd5\u6307\u6807\u7684\u56fe\u50cf\u4ee5\u53ca\u4e0d\u540c\u5c42\u7684\u6fc0\u6d3b\u503c\u76f4\u65b9\u56fe\u3002  \u5982\u679c\u5df2\u7ecf\u901a\u8fc7pip\u5b89\u88c5\u4e86TensorFlow\uff0c\u6211\u4eec\u53ef\u901a\u8fc7\u4e0b\u9762\u7684\u547d\u4ee4\u542f\u52a8TensorBoard\uff1a  tensorboard --logdir=/full_path_to_your_logs  \u66f4\u591a\u7684\u53c2\u8003\u4fe1\u606f\uff0c\u8bf7\u70b9\u51fb \u8fd9\u91cc", 
            "title": "TensorBoard"
        }, 
        {
            "location": "/other/callbacks/#_6", 
            "text": "log_dir\uff1a\u4fdd\u5b58\u65e5\u5fd7\u6587\u4ef6\u7684\u5730\u5740\uff0c\u8be5\u6587\u4ef6\u5c06\u88abTensorBoard\u89e3\u6790\u4ee5\u7528\u4e8e\u53ef\u89c6\u5316    histogram_freq\uff1a\u8ba1\u7b97\u5404\u4e2a\u5c42\u6fc0\u6d3b\u503c\u76f4\u65b9\u56fe\u7684\u9891\u7387\uff08\u6bcf\u591a\u5c11\u4e2aepoch\u8ba1\u7b97\u4e00\u6b21\uff09\uff0c\u5982\u679c\u8bbe\u7f6e\u4e3a0\u5219\u4e0d\u8ba1\u7b97\u3002", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/other/callbacks/#reducelronplateau", 
            "text": "keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, verbose=0, mode='auto', epsilon=0.0001, cooldown=0, min_lr=0)  \u5f53\u8bc4\u4ef7\u6307\u6807\u4e0d\u5728\u63d0\u5347\u65f6\uff0c\u51cf\u5c11\u5b66\u4e60\u7387  \u5f53\u5b66\u4e60\u505c\u6ede\u65f6\uff0c\u51cf\u5c112\u500d\u621610\u500d\u7684\u5b66\u4e60\u7387\u5e38\u5e38\u80fd\u83b7\u5f97\u8f83\u597d\u7684\u6548\u679c\u3002\u8be5\u56de\u8c03\u51fd\u6570\u68c0\u6d4b\u6307\u6807\u7684\u60c5\u51b5\uff0c\u5982\u679c\u5728 patience \u4e2aepoch\u4e2d\u770b\u4e0d\u5230\u6a21\u578b\u6027\u80fd\u63d0\u5347\uff0c\u5219\u51cf\u5c11\u5b66\u4e60\u7387", 
            "title": "ReduceLROnPlateau"
        }, 
        {
            "location": "/other/callbacks/#_7", 
            "text": "monitor\uff1a\u88ab\u76d1\u6d4b\u7684\u91cf  factor\uff1a\u6bcf\u6b21\u51cf\u5c11\u5b66\u4e60\u7387\u7684\u56e0\u5b50\uff0c\u5b66\u4e60\u7387\u5c06\u4ee5 lr = lr*factor \u7684\u5f62\u5f0f\u88ab\u51cf\u5c11  patience\uff1a\u5f53patience\u4e2aepoch\u8fc7\u53bb\u800c\u6a21\u578b\u6027\u80fd\u4e0d\u63d0\u5347\u65f6\uff0c\u5b66\u4e60\u7387\u51cf\u5c11\u7684\u52a8\u4f5c\u4f1a\u88ab\u89e6\u53d1  mode\uff1a\u2018auto\u2019\uff0c\u2018min\u2019\uff0c\u2018max\u2019\u4e4b\u4e00\uff0c\u5728 min \u6a21\u5f0f\u4e0b\uff0c\u5982\u679c\u68c0\u6d4b\u503c\u89e6\u53d1\u5b66\u4e60\u7387\u51cf\u5c11\u3002\u5728 max \u6a21\u5f0f\u4e0b\uff0c\u5f53\u68c0\u6d4b\u503c\u4e0d\u518d\u4e0a\u5347\u5219\u89e6\u53d1\u5b66\u4e60\u7387\u51cf\u5c11\u3002  epsilon\uff1a\u9608\u503c\uff0c\u7528\u6765\u786e\u5b9a\u662f\u5426\u8fdb\u5165\u68c0\u6d4b\u503c\u7684\u201c\u5e73\u539f\u533a\u201d  cooldown\uff1a\u5b66\u4e60\u7387\u51cf\u5c11\u540e\uff0c\u4f1a\u7ecf\u8fc7cooldown\u4e2aepoch\u624d\u91cd\u65b0\u8fdb\u884c\u6b63\u5e38\u64cd\u4f5c  min_lr\uff1a\u5b66\u4e60\u7387\u7684\u4e0b\u9650", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/other/callbacks/#_8", 
            "text": "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n            patience=5, min_lr=0.001)\nmodel.fit(X_train, Y_train, callbacks=[reduce_lr])", 
            "title": "\u793a\u4f8b\uff1a"
        }, 
        {
            "location": "/other/callbacks/#csvlogger", 
            "text": "keras.callbacks.CSVLogger(filename, separator=',', append=False)  \u5c06epoch\u7684\u8bad\u7ec3\u7ed3\u679c\u4fdd\u5b58\u5728csv\u6587\u4ef6\u4e2d\uff0c\u652f\u6301\u6240\u6709\u53ef\u88ab\u8f6c\u6362\u4e3astring\u7684\u503c\uff0c\u5305\u62ec1D\u7684\u53ef\u8fed\u4ee3\u6570\u503c\u5982np.ndarray.", 
            "title": "CSVLogger"
        }, 
        {
            "location": "/other/callbacks/#_9", 
            "text": "fiename\uff1a\u4fdd\u5b58\u7684csv\u6587\u4ef6\u540d\uff0c\u5982 run/log.csv  separator\uff1a\u5b57\u7b26\u4e32\uff0ccsv\u5206\u9694\u7b26  append\uff1a\u9ed8\u8ba4\u4e3aFalse\uff0c\u4e3aTrue\u65f6csv\u6587\u4ef6\u5982\u679c\u5b58\u5728\u5219\u7ee7\u7eed\u5199\u5165\uff0c\u4e3aFalse\u65f6\u603b\u662f\u8986\u76d6csv\u6587\u4ef6", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/other/callbacks/#_10", 
            "text": "csv_logger = CSVLogger('training.log')\nmodel.fit(X_train, Y_train, callbacks=[csv_logger])", 
            "title": "\u793a\u4f8b"
        }, 
        {
            "location": "/other/callbacks/#lambdacallback", 
            "text": "keras.callbacks.LambdaCallback(on_epoch_begin=None, on_epoch_end=None, on_batch_begin=None, on_batch_end=None, on_train_begin=None, on_train_end=None)  \u7528\u4e8e\u521b\u5efa\u7b80\u5355\u7684callback\u7684callback\u7c7b  \u8be5callback\u7684\u533f\u540d\u51fd\u6570\u5c06\u4f1a\u5728\u9002\u5f53\u7684\u65f6\u5019\u8c03\u7528\uff0c\u6ce8\u610f\uff0c\u8be5\u56de\u8c03\u51fd\u6570\u5047\u5b9a\u4e86\u4e00\u4e9b\u4f4d\u7f6e\u53c2\u6570 on_eopoch_begin \u548c on_epoch_end \u5047\u5b9a\u8f93\u5165\u7684\u53c2\u6570\u662f epoch, logs .  on_batch_begin \u548c on_batch_end \u5047\u5b9a\u8f93\u5165\u7684\u53c2\u6570\u662f batch, logs \uff0c on_train_begin \u548c on_train_end \u5047\u5b9a\u8f93\u5165\u7684\u53c2\u6570\u662f logs", 
            "title": "LambdaCallback"
        }, 
        {
            "location": "/other/callbacks/#_11", 
            "text": "on_epoch_begin: \u5728\u6bcf\u4e2aepoch\u5f00\u59cb\u65f6\u8c03\u7528  on_epoch_end: \u5728\u6bcf\u4e2aepoch\u7ed3\u675f\u65f6\u8c03\u7528  on_batch_begin: \u5728\u6bcf\u4e2abatch\u5f00\u59cb\u65f6\u8c03\u7528  on_batch_end: \u5728\u6bcf\u4e2abatch\u7ed3\u675f\u65f6\u8c03\u7528  on_train_begin: \u5728\u8bad\u7ec3\u5f00\u59cb\u65f6\u8c03\u7528  on_train_end: \u5728\u8bad\u7ec3\u7ed3\u675f\u65f6\u8c03\u7528", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/other/callbacks/#_12", 
            "text": "# Print the batch number at the beginning of every batch.\nbatch_print_callback = LambdaCallback(on_batch_begin=lambda batch, logs: print(batch))\n\n# Plot the loss after every epoch.\nimport numpy as np\nimport matplotlib.pyplot as plt\nplot_loss_callback = LambdaCallback(on_epoch_end=lambda epoch, logs: plt.plot(np.arange(epoch), logs['loss']))\n\n# Terminate some processes after having finished model training.\nprocesses = ...\ncleanup_callback = LambdaCallback(on_train_end=lambda logs: [p.terminate() for p in processes if p.is_alive()])\n\nmodel.fit(..., callbacks=[batch_print_callback, plot_loss_callback, cleanup_callback])", 
            "title": "\u793a\u4f8b"
        }, 
        {
            "location": "/other/callbacks/#_13", 
            "text": "\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u7ee7\u627f keras.callbacks.Callback \u7f16\u5199\u81ea\u5df1\u7684\u56de\u8c03\u51fd\u6570\uff0c\u56de\u8c03\u51fd\u6570\u901a\u8fc7\u7c7b\u6210\u5458 self.model \u8bbf\u95ee\u8bbf\u95ee\uff0c\u8be5\u6210\u5458\u662f\u6a21\u578b\u7684\u4e00\u4e2a\u5f15\u7528\u3002  \u8fd9\u91cc\u662f\u4e00\u4e2a\u7b80\u5355\u7684\u4fdd\u5b58\u6bcf\u4e2abatch\u7684loss\u7684\u56de\u8c03\u51fd\u6570\uff1a  class LossHistory(keras.callbacks.Callback):\n    def on_train_begin(self, logs={}):\n        self.losses = []\n\n    def on_batch_end(self, batch, logs={}):\n        self.losses.append(logs.get('loss'))", 
            "title": "\u7f16\u5199\u81ea\u5df1\u7684\u56de\u8c03\u51fd\u6570"
        }, 
        {
            "location": "/other/callbacks/#_14", 
            "text": "class LossHistory(keras.callbacks.Callback):\n    def on_train_begin(self, logs={}):\n        self.losses = []\n\n    def on_batch_end(self, batch, logs={}):\n        self.losses.append(logs.get('loss'))\n\nmodel = Sequential()\nmodel.add(Dense(10, input_dim=784, init='uniform'))\nmodel.add(Activation('softmax'))\nmodel.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n\nhistory = LossHistory()\nmodel.fit(X_train, Y_train, batch_size=128, nb_epoch=20, verbose=0, callbacks=[history])\n\nprint history.losses\n# outputs\n'''\n[0.66047596406559383, 0.3547245744908703, ..., 0.25953155204159617, 0.25901699725311789]", 
            "title": "\u4f8b\u5b50\uff1a\u8bb0\u5f55\u635f\u5931\u51fd\u6570\u7684\u5386\u53f2\u6570\u636e"
        }, 
        {
            "location": "/other/callbacks/#_15", 
            "text": "from keras.callbacks import ModelCheckpoint\n\nmodel = Sequential()\nmodel.add(Dense(10, input_dim=784, init='uniform'))\nmodel.add(Activation('softmax'))\nmodel.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n\n'''\nsaves the model weights after each epoch if the validation loss decreased\n'''\ncheckpointer = ModelCheckpoint(filepath= /tmp/weights.hdf5 , verbose=1, save_best_only=True)\nmodel.fit(X_train, Y_train, batch_size=128, nb_epoch=20, verbose=0, validation_data=(X_test, Y_test), callbacks=[checkpointer])", 
            "title": "\u4f8b\u5b50\uff1a\u6a21\u578b\u68c0\u67e5\u70b9"
        }, 
        {
            "location": "/other/metrices/", 
            "text": "\u6027\u80fd\u8bc4\u4f30\n\n\n\u4f7f\u7528\u65b9\u6cd5\n\n\n\u6027\u80fd\u8bc4\u4f30\u6a21\u5757\u63d0\u4f9b\u4e86\u4e00\u7cfb\u5217\u7528\u4e8e\u6a21\u578b\u6027\u80fd\u8bc4\u4f30\u7684\u51fd\u6570,\u8fd9\u4e9b\u51fd\u6570\u5728\u6a21\u578b\u7f16\u8bd1\u65f6\u7531\nmetrices\n\u5173\u952e\u5b57\u8bbe\u7f6e\n\n\n\u6027\u80fd\u8bc4\u4f30\u51fd\u6570\u7c7b\u4f3c\u4e0e\n\u76ee\u6807\u51fd\u6570\n, \u53ea\u4e0d\u8fc7\u8be5\u6027\u80fd\u7684\u8bc4\u4f30\u7ed3\u679c\u8bb2\u4e0d\u4f1a\u7528\u4e8e\u8bad\u7ec3.\n\n\n\u53ef\u4ee5\u901a\u8fc7\u5b57\u7b26\u4e32\u6765\u4f7f\u7528\u57df\u5b9a\u4e49\u7684\u6027\u80fd\u8bc4\u4f30\u51fd\u6570,\u4e5f\u53ef\u4ee5\u81ea\u5b9a\u4e49\u4e00\u4e2aTheano/TensorFlow\u51fd\u6570\u5e76\u4f7f\u7528\u4e4b\n\n\n\u53c2\u6570\n\n\n\n\ny_true:\u771f\u5b9e\u6807\u7b7e,theano/tensorflow\u5f20\u91cf\n\n\ny_pred:\u9884\u6d4b\u503c, \u4e0ey_true\u5f62\u5f0f\u76f8\u540c\u7684theano/tensorflow\u5f20\u91cf\n\n\n\n\n\u8fd4\u56de\u503c\n\n\n\u5355\u4e2a\u7528\u4ee5\u4ee3\u8868\u8f93\u51fa\u5404\u4e2a\u6570\u636e\u70b9\u4e0a\u5747\u503c\u7684\u503c\n\n\n\u53ef\u7528\u9884\u5b9a\u4e49\u5f20\u91cf\n\n\n\u9664fbeta_score\u989d\u5916\u62e5\u6709\u9ed8\u8ba4\u53c2\u6570beta=1\u5916,\u5176\u4ed6\u5404\u4e2a\u6027\u80fd\u6307\u6807\u7684\u53c2\u6570\u5747\u4e3ay_true\u548cy_pred\n\n\n\n\nbinary_accuracy: \u5bf9\u4e8c\u5206\u7c7b\u95ee\u9898,\u8ba1\u7b97\u5728\u6240\u6709\u9884\u6d4b\u503c\u4e0a\u7684\u5e73\u5747\u6b63\u786e\u7387\n\n\ncategorical_accuracy:\u5bf9\u591a\u5206\u7c7b\u95ee\u9898,\u8ba1\u7b97\u518d\u6240\u6709\u9884\u6d4b\u503c\u4e0a\u7684\u5e73\u5747\u6b63\u786e\u7387\n\n\nsparse_categorical_accuracy:\u4e0e\ncategorical_accuracy\n\u76f8\u540c,\u5728\u5bf9\u7a00\u758f\u7684\u76ee\u6807\u503c\u9884\u6d4b\u65f6\u6709\u7528\n\n\ntop_k_categorical_accracy: \u8ba1\u7b97top-k\u6b63\u786e\u7387,\u5f53\u9884\u6d4b\u503c\u7684\u524dk\u4e2a\u503c\u4e2d\u5b58\u5728\u76ee\u6807\u7c7b\u522b\u5373\u8ba4\u4e3a\u9884\u6d4b\u6b63\u786e\n\n\nmean_squared_error:\u8ba1\u7b97\u9884\u6d4b\u503c\u4e0e\u771f\u503c\u7684\u5747\u65b9\u5dee\n\n\nmean_absolute_error:\u8ba1\u7b97\u9884\u6d4b\u503c\u4e0e\u771f\u503c\u7684\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee\n\n\nmean_absolute_percentage_error:\u8ba1\u7b97\u9884\u6d4b\u503c\u4e0e\u771f\u503c\u7684\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee\u7387\n\n\nmean_squared_logarithmic_error:\u8ba1\u7b97\u9884\u6d4b\u503c\u4e0e\u771f\u503c\u7684\u5e73\u5747\u6307\u6570\u8bef\u5dee\n\n\nhinge:\u8ba1\u7b97\u9884\u6d4b\u503c\u4e0e\u771f\u503c\u7684hinge loss\n\n\nsquared_hinge:\u8ba1\u7b97\u9884\u6d4b\u503c\u4e0e\u771f\u503c\u7684\u5e73\u65b9hinge loss\n\n\ncategorical_crossentropy:\u8ba1\u7b97\u9884\u6d4b\u503c\u4e0e\u771f\u503c\u7684\u591a\u7c7b\u4ea4\u53c9\u71b5(\u8f93\u5165\u503c\u4e3a\u4e8c\u503c\u77e9\u9635,\u800c\u4e0d\u662f\u5411\u91cf)\n\n\nsparse_categorical_crossentropy:\u4e0e\u591a\u7c7b\u4ea4\u53c9\u71b5\u76f8\u540c,\u9002\u7528\u4e8e\u7a00\u758f\u60c5\u51b5\n\n\nbinary_crossentropy:\u8ba1\u7b97\u9884\u6d4b\u503c\u4e0e\u771f\u503c\u7684\u4ea4\u53c9\u71b5\n\n\npoisson:\u8ba1\u7b97\u9884\u6d4b\u503c\u4e0e\u771f\u503c\u7684\u6cca\u677e\u51fd\u6570\u503c\n\n\ncosine_proximity:\u8ba1\u7b97\u9884\u6d4b\u503c\u4e0e\u771f\u503c\u7684\u4f59\u5f26\u76f8\u4f3c\u6027\n\n\nmatthews_correlation:\u8ba1\u7b97\u9884\u6d4b\u503c\u4e0e\u771f\u503c\u7684\u9a6c\u6c0f\u8ddd\u79bb\n\n\nprecision\uff1a\u8ba1\u7b97\u7cbe\u786e\u5ea6\uff0c\u6ce8\u610fpercision\u8ddfaccuracy\u662f\u4e0d\u540c\u7684\u3002percision\u7528\u4e8e\u8bc4\u4ef7\u591a\u6807\u7b7e\u5206\u7c7b\u4e2d\u6709\u591a\u5c11\u4e2a\u9009\u4e2d\u7684\u9879\u662f\u6b63\u786e\u7684\n\n\nrecall\uff1a\u53ec\u56de\u7387\uff0c\u8ba1\u7b97\u591a\u6807\u7b7e\u5206\u7c7b\u4e2d\u6709\u591a\u5c11\u6b63\u786e\u7684\u9879\u88ab\u9009\u4e2d\n\n\nfbeta_score:\u8ba1\u7b97F\u503c,\u5373\u53ec\u56de\u7387\u4e0e\u51c6\u786e\u7387\u7684\u52a0\u6743\u8c03\u548c\u5e73\u5747,\u8be5\u51fd\u6570\u5728\u591a\u6807\u7b7e\u5206\u7c7b(\u4e00\u4e2a\u6837\u672c\u6709\u591a\u4e2a\u6807\u7b7e)\u65f6\u6709\u7528,\u5982\u679c\u53ea\u4f7f\u7528\u51c6\u786e\u7387\u4f5c\u4e3a\u5ea6\u91cf,\u6a21\u578b\u53ea\u8981\u628a\u6240\u6709\u8f93\u5165\u5206\u7c7b\u4e3a\"\u6240\u6709\u7c7b\u522b\"\u5c31\u53ef\u4ee5\u83b7\u5f97\u5b8c\u7f8e\u7684\u51c6\u786e\u7387,\u4e3a\u4e86\u907f\u514d\u8fd9\u79cd\u60c5\u51b5,\u5ea6\u91cf\u6307\u6807\u5e94\u8be5\u5bf9\u9519\u8bef\u7684\u9009\u62e9\u8fdb\u884c\u60e9\u7f5a. F-beta\u5206\u503c(0\u52301\u4e4b\u95f4)\u901a\u8fc7\u51c6\u786e\u7387\u548c\u53ec\u56de\u7387\u7684\u52a0\u6743\u8c03\u548c\u5e73\u5747\u6765\u66f4\u597d\u7684\u5ea6\u91cf.\u5f53beta\u4e3a1\u65f6,\u8be5\u6307\u6807\u7b49\u4ef7\u4e8eF-measure,beta\n1\u65f6,\u6a21\u578b\u9009\u5bf9\u6b63\u786e\u7684\u6807\u7b7e\u66f4\u52a0\u91cd\u8981,\u800cbeta\n1\u65f6,\u6a21\u578b\u5bf9\u9009\u9519\u6807\u7b7e\u6709\u66f4\u5927\u7684\u60e9\u7f5a.\n\n\nfmeasure\uff1a\u8ba1\u7b97f-measure\uff0c\u5373percision\u548crecall\u7684\u8c03\u548c\u5e73\u5747\n\n\n\n\n\u5b9a\u5236\u8bc4\u4f30\u51fd\u6570\n\n\n\u5b9a\u5236\u7684\u8bc4\u4f30\u51fd\u6570\u53ef\u4ee5\u5728\u6a21\u578b\u7f16\u8bd1\u65f6\u4f20\u5165,\u8be5\u51fd\u6570\u5e94\u8be5\u4ee5\n(y_true, y_pred)\n\u4e3a\u53c2\u6570,\u5e76\u8fd4\u56de\u5355\u4e2a\u5f20\u91cf,\u6216\u4ece\nmetric_name\n\u6620\u5c04\u5230\nmetric_value\n\u7684\u5b57\u5178,\u4e0b\u9762\u662f\u4e00\u4e2a\u793a\u4f8b:\n\n\n# for custom metrics\nimport keras.backend as K\n\ndef mean_pred(y_true, y_pred):\n    return K.mean(y_pred)\n\ndef false_rates(y_true, y_pred):\n    false_neg = ...\n    false_pos = ...\n    return {\n        'false_neg': false_neg,\n        'false_pos': false_pos,\n    }\n\nmodel.compile(optimizer='rmsprop',\n              loss='binary_crossentropy',\n              metrics=['accuracy', mean_pred, false_rates])", 
            "title": "\u6027\u80fd\u8bc4\u4f30Metrices"
        }, 
        {
            "location": "/other/metrices/#_1", 
            "text": "", 
            "title": "\u6027\u80fd\u8bc4\u4f30"
        }, 
        {
            "location": "/other/metrices/#_2", 
            "text": "\u6027\u80fd\u8bc4\u4f30\u6a21\u5757\u63d0\u4f9b\u4e86\u4e00\u7cfb\u5217\u7528\u4e8e\u6a21\u578b\u6027\u80fd\u8bc4\u4f30\u7684\u51fd\u6570,\u8fd9\u4e9b\u51fd\u6570\u5728\u6a21\u578b\u7f16\u8bd1\u65f6\u7531 metrices \u5173\u952e\u5b57\u8bbe\u7f6e  \u6027\u80fd\u8bc4\u4f30\u51fd\u6570\u7c7b\u4f3c\u4e0e \u76ee\u6807\u51fd\u6570 , \u53ea\u4e0d\u8fc7\u8be5\u6027\u80fd\u7684\u8bc4\u4f30\u7ed3\u679c\u8bb2\u4e0d\u4f1a\u7528\u4e8e\u8bad\u7ec3.  \u53ef\u4ee5\u901a\u8fc7\u5b57\u7b26\u4e32\u6765\u4f7f\u7528\u57df\u5b9a\u4e49\u7684\u6027\u80fd\u8bc4\u4f30\u51fd\u6570,\u4e5f\u53ef\u4ee5\u81ea\u5b9a\u4e49\u4e00\u4e2aTheano/TensorFlow\u51fd\u6570\u5e76\u4f7f\u7528\u4e4b", 
            "title": "\u4f7f\u7528\u65b9\u6cd5"
        }, 
        {
            "location": "/other/metrices/#_3", 
            "text": "y_true:\u771f\u5b9e\u6807\u7b7e,theano/tensorflow\u5f20\u91cf  y_pred:\u9884\u6d4b\u503c, \u4e0ey_true\u5f62\u5f0f\u76f8\u540c\u7684theano/tensorflow\u5f20\u91cf", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/other/metrices/#_4", 
            "text": "\u5355\u4e2a\u7528\u4ee5\u4ee3\u8868\u8f93\u51fa\u5404\u4e2a\u6570\u636e\u70b9\u4e0a\u5747\u503c\u7684\u503c", 
            "title": "\u8fd4\u56de\u503c"
        }, 
        {
            "location": "/other/metrices/#_5", 
            "text": "\u9664fbeta_score\u989d\u5916\u62e5\u6709\u9ed8\u8ba4\u53c2\u6570beta=1\u5916,\u5176\u4ed6\u5404\u4e2a\u6027\u80fd\u6307\u6807\u7684\u53c2\u6570\u5747\u4e3ay_true\u548cy_pred   binary_accuracy: \u5bf9\u4e8c\u5206\u7c7b\u95ee\u9898,\u8ba1\u7b97\u5728\u6240\u6709\u9884\u6d4b\u503c\u4e0a\u7684\u5e73\u5747\u6b63\u786e\u7387  categorical_accuracy:\u5bf9\u591a\u5206\u7c7b\u95ee\u9898,\u8ba1\u7b97\u518d\u6240\u6709\u9884\u6d4b\u503c\u4e0a\u7684\u5e73\u5747\u6b63\u786e\u7387  sparse_categorical_accuracy:\u4e0e categorical_accuracy \u76f8\u540c,\u5728\u5bf9\u7a00\u758f\u7684\u76ee\u6807\u503c\u9884\u6d4b\u65f6\u6709\u7528  top_k_categorical_accracy: \u8ba1\u7b97top-k\u6b63\u786e\u7387,\u5f53\u9884\u6d4b\u503c\u7684\u524dk\u4e2a\u503c\u4e2d\u5b58\u5728\u76ee\u6807\u7c7b\u522b\u5373\u8ba4\u4e3a\u9884\u6d4b\u6b63\u786e  mean_squared_error:\u8ba1\u7b97\u9884\u6d4b\u503c\u4e0e\u771f\u503c\u7684\u5747\u65b9\u5dee  mean_absolute_error:\u8ba1\u7b97\u9884\u6d4b\u503c\u4e0e\u771f\u503c\u7684\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee  mean_absolute_percentage_error:\u8ba1\u7b97\u9884\u6d4b\u503c\u4e0e\u771f\u503c\u7684\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee\u7387  mean_squared_logarithmic_error:\u8ba1\u7b97\u9884\u6d4b\u503c\u4e0e\u771f\u503c\u7684\u5e73\u5747\u6307\u6570\u8bef\u5dee  hinge:\u8ba1\u7b97\u9884\u6d4b\u503c\u4e0e\u771f\u503c\u7684hinge loss  squared_hinge:\u8ba1\u7b97\u9884\u6d4b\u503c\u4e0e\u771f\u503c\u7684\u5e73\u65b9hinge loss  categorical_crossentropy:\u8ba1\u7b97\u9884\u6d4b\u503c\u4e0e\u771f\u503c\u7684\u591a\u7c7b\u4ea4\u53c9\u71b5(\u8f93\u5165\u503c\u4e3a\u4e8c\u503c\u77e9\u9635,\u800c\u4e0d\u662f\u5411\u91cf)  sparse_categorical_crossentropy:\u4e0e\u591a\u7c7b\u4ea4\u53c9\u71b5\u76f8\u540c,\u9002\u7528\u4e8e\u7a00\u758f\u60c5\u51b5  binary_crossentropy:\u8ba1\u7b97\u9884\u6d4b\u503c\u4e0e\u771f\u503c\u7684\u4ea4\u53c9\u71b5  poisson:\u8ba1\u7b97\u9884\u6d4b\u503c\u4e0e\u771f\u503c\u7684\u6cca\u677e\u51fd\u6570\u503c  cosine_proximity:\u8ba1\u7b97\u9884\u6d4b\u503c\u4e0e\u771f\u503c\u7684\u4f59\u5f26\u76f8\u4f3c\u6027  matthews_correlation:\u8ba1\u7b97\u9884\u6d4b\u503c\u4e0e\u771f\u503c\u7684\u9a6c\u6c0f\u8ddd\u79bb  precision\uff1a\u8ba1\u7b97\u7cbe\u786e\u5ea6\uff0c\u6ce8\u610fpercision\u8ddfaccuracy\u662f\u4e0d\u540c\u7684\u3002percision\u7528\u4e8e\u8bc4\u4ef7\u591a\u6807\u7b7e\u5206\u7c7b\u4e2d\u6709\u591a\u5c11\u4e2a\u9009\u4e2d\u7684\u9879\u662f\u6b63\u786e\u7684  recall\uff1a\u53ec\u56de\u7387\uff0c\u8ba1\u7b97\u591a\u6807\u7b7e\u5206\u7c7b\u4e2d\u6709\u591a\u5c11\u6b63\u786e\u7684\u9879\u88ab\u9009\u4e2d  fbeta_score:\u8ba1\u7b97F\u503c,\u5373\u53ec\u56de\u7387\u4e0e\u51c6\u786e\u7387\u7684\u52a0\u6743\u8c03\u548c\u5e73\u5747,\u8be5\u51fd\u6570\u5728\u591a\u6807\u7b7e\u5206\u7c7b(\u4e00\u4e2a\u6837\u672c\u6709\u591a\u4e2a\u6807\u7b7e)\u65f6\u6709\u7528,\u5982\u679c\u53ea\u4f7f\u7528\u51c6\u786e\u7387\u4f5c\u4e3a\u5ea6\u91cf,\u6a21\u578b\u53ea\u8981\u628a\u6240\u6709\u8f93\u5165\u5206\u7c7b\u4e3a\"\u6240\u6709\u7c7b\u522b\"\u5c31\u53ef\u4ee5\u83b7\u5f97\u5b8c\u7f8e\u7684\u51c6\u786e\u7387,\u4e3a\u4e86\u907f\u514d\u8fd9\u79cd\u60c5\u51b5,\u5ea6\u91cf\u6307\u6807\u5e94\u8be5\u5bf9\u9519\u8bef\u7684\u9009\u62e9\u8fdb\u884c\u60e9\u7f5a. F-beta\u5206\u503c(0\u52301\u4e4b\u95f4)\u901a\u8fc7\u51c6\u786e\u7387\u548c\u53ec\u56de\u7387\u7684\u52a0\u6743\u8c03\u548c\u5e73\u5747\u6765\u66f4\u597d\u7684\u5ea6\u91cf.\u5f53beta\u4e3a1\u65f6,\u8be5\u6307\u6807\u7b49\u4ef7\u4e8eF-measure,beta 1\u65f6,\u6a21\u578b\u9009\u5bf9\u6b63\u786e\u7684\u6807\u7b7e\u66f4\u52a0\u91cd\u8981,\u800cbeta 1\u65f6,\u6a21\u578b\u5bf9\u9009\u9519\u6807\u7b7e\u6709\u66f4\u5927\u7684\u60e9\u7f5a.  fmeasure\uff1a\u8ba1\u7b97f-measure\uff0c\u5373percision\u548crecall\u7684\u8c03\u548c\u5e73\u5747", 
            "title": "\u53ef\u7528\u9884\u5b9a\u4e49\u5f20\u91cf"
        }, 
        {
            "location": "/other/metrices/#_6", 
            "text": "\u5b9a\u5236\u7684\u8bc4\u4f30\u51fd\u6570\u53ef\u4ee5\u5728\u6a21\u578b\u7f16\u8bd1\u65f6\u4f20\u5165,\u8be5\u51fd\u6570\u5e94\u8be5\u4ee5 (y_true, y_pred) \u4e3a\u53c2\u6570,\u5e76\u8fd4\u56de\u5355\u4e2a\u5f20\u91cf,\u6216\u4ece metric_name \u6620\u5c04\u5230 metric_value \u7684\u5b57\u5178,\u4e0b\u9762\u662f\u4e00\u4e2a\u793a\u4f8b:  # for custom metrics\nimport keras.backend as K\n\ndef mean_pred(y_true, y_pred):\n    return K.mean(y_pred)\n\ndef false_rates(y_true, y_pred):\n    false_neg = ...\n    false_pos = ...\n    return {\n        'false_neg': false_neg,\n        'false_pos': false_pos,\n    }\n\nmodel.compile(optimizer='rmsprop',\n              loss='binary_crossentropy',\n              metrics=['accuracy', mean_pred, false_rates])", 
            "title": "\u5b9a\u5236\u8bc4\u4f30\u51fd\u6570"
        }, 
        {
            "location": "/other/initializations/", 
            "text": "\u521d\u59cb\u5316\u65b9\u6cd5\n\n\n\u521d\u59cb\u5316\u65b9\u6cd5\u5b9a\u4e49\u4e86\u5bf9Keras\u5c42\u8bbe\u7f6e\u521d\u59cb\u5316\u6743\u91cd\u7684\u65b9\u6cd5\n\n\n\u4e0d\u540c\u7684\u5c42\u53ef\u80fd\u4f7f\u7528\u4e0d\u540c\u7684\u5173\u952e\u5b57\u6765\u4f20\u9012\u521d\u59cb\u5316\u65b9\u6cd5\uff0c\u4e00\u822c\u6765\u8bf4\u6307\u5b9a\u521d\u59cb\u5316\u65b9\u6cd5\u7684\u5173\u952e\u5b57\u662f\ninit\n\uff0c\u4f8b\u5982\uff1a\n\n\nmodel.add(Dense(64, init='uniform'))\n\n\n\n\n\u9884\u5b9a\u4e49\u521d\u59cb\u5316\u65b9\u6cd5\n\n\n\n\n\n\nuniform\n\n\n\n\n\n\nlecun_uniform: \u5373\u6709\u8f93\u5165\u8282\u70b9\u6570\u4e4b\u5e73\u65b9\u6839\u653e\u7f29\u540e\u7684\u5747\u5300\u5206\u5e03\u521d\u59cb\u5316\uff08\nLeCun 98\n\uff09.\n\n\n\n\n\n\nnormal\n\n\n\n\n\n\nidentity\uff1a\u4ec5\u7528\u4e8e\u6743\u503c\u77e9\u9635\u4e3a\u65b9\u9635\u76842D\u5c42\uff08\nshape[0]=shape[1]\n\uff09\n\n\n\n\n\n\northogonal\uff1a\u4ec5\u7528\u4e8e\u6743\u503c\u77e9\u9635\u4e3a\u65b9\u9635\u76842D\u5c42\uff08\nshape[0]=shape[1]\n\uff09\uff0c\u53c2\u8003\nSaxe et al.\n\n\n\n\n\n\nzero\n\n\n\n\n\n\nglorot_normal\uff1a\u7531\u6247\u5165\u6247\u51fa\u653e\u7f29\u540e\u7684\u9ad8\u65af\u521d\u59cb\u5316\uff08\nGlorot 2010\n\uff09\n\n\n\n\n\n\nglorot_uniform\n\n\n\n\n\n\nhe_normal\uff1a\u7531\u6247\u5165\u653e\u7f29\u540e\u7684\u9ad8\u65af\u521d\u59cb\u5316\uff08\nHe et al.,2014\n\uff09\n\n\n\n\n\n\nhe_uniform\n\n\n\n\n\n\n\u6307\u5b9a\u521d\u59cb\u5316\u65b9\u6cd5\u4f20\u5165\u7684\u53ef\u4ee5\u662f\u4e00\u4e2a\u5b57\u7b26\u4e32(\u5fc5\u987b\u4e0e\u4e0a\u9762\u67d0\u79cd\u9884\u5b9a\u4e49\u65b9\u6cd5\u5339\u914d),\u4e5f\u53ef\u4ee5\u662f\u4e00\u4e2a\u53ef\u8c03\u7528\u7684\u5bf9\u8c61.\u5982\u679c\u4f20\u5165\u53ef\u8c03\u7528\u7684\u5bf9\u8c61,\u5219\u8be5\u5bf9\u8c61\u5fc5\u987b\u5305\u542b\u4e24\u4e2a\u53c2\u6570:\nshape\n(\u5f85\u521d\u59cb\u5316\u7684\u53d8\u91cf\u7684shape)\u548c\nname\n(\u8be5\u53d8\u91cf\u7684\u540d\u5b57),\u8be5\u53ef\u8c03\u7528\u5bf9\u8c61\u5fc5\u987b\u8fd4\u56de\u4e00\u4e2a(Keras)\u53d8\u91cf,\u4f8b\u5982\nK.variable()\n\u8fd4\u56de\u7684\u5c31\u662f\u8fd9\u79cd\u53d8\u91cf,\u4e0b\u9762\u662f\u4f8b\u5b50:\n\n\nfrom keras import backend as K\nimport numpy as np\n\ndef my_init(shape, name=None):\n    value = np.random.random(shape)\n    return K.variable(value, name=name)\n\nmodel.add(Dense(64, init=my_init))\n\n\n\n\n\u4f60\u4e5f\u53ef\u4ee5\u6309\u8fd9\u79cd\u65b9\u6cd5\u4f7f\u7528\nkeras.initializations\n\u4e2d\u7684\u51fd\u6570:\n\n\nfrom keras import initializations\n\ndef my_init(shape, name=None):\n    return initializations.normal(shape, scale=0.01, name=name)\n\nmodel.add(Dense(64, init=my_init))\n\n\n\n\n\u3010Tips\u3011\u7a0d\u540e\uff08\u4e00\u4e24\u5468\u5427\u2026\u2026\uff09\u6211\u4eec\u5e0c\u671b\u5c06\u5404\u4e2a\u521d\u59cb\u5316\u65b9\u6cd5\u7684\u7279\u70b9\u603b\u7ed3\u4e00\u4e0b\uff0c\u8bf7\u7ee7\u7eed\u5173\u6ce8", 
            "title": "\u521d\u59cb\u5316\u65b9\u6cd5Initialization"
        }, 
        {
            "location": "/other/initializations/#_1", 
            "text": "\u521d\u59cb\u5316\u65b9\u6cd5\u5b9a\u4e49\u4e86\u5bf9Keras\u5c42\u8bbe\u7f6e\u521d\u59cb\u5316\u6743\u91cd\u7684\u65b9\u6cd5  \u4e0d\u540c\u7684\u5c42\u53ef\u80fd\u4f7f\u7528\u4e0d\u540c\u7684\u5173\u952e\u5b57\u6765\u4f20\u9012\u521d\u59cb\u5316\u65b9\u6cd5\uff0c\u4e00\u822c\u6765\u8bf4\u6307\u5b9a\u521d\u59cb\u5316\u65b9\u6cd5\u7684\u5173\u952e\u5b57\u662f init \uff0c\u4f8b\u5982\uff1a  model.add(Dense(64, init='uniform'))", 
            "title": "\u521d\u59cb\u5316\u65b9\u6cd5"
        }, 
        {
            "location": "/other/initializations/#_2", 
            "text": "uniform    lecun_uniform: \u5373\u6709\u8f93\u5165\u8282\u70b9\u6570\u4e4b\u5e73\u65b9\u6839\u653e\u7f29\u540e\u7684\u5747\u5300\u5206\u5e03\u521d\u59cb\u5316\uff08 LeCun 98 \uff09.    normal    identity\uff1a\u4ec5\u7528\u4e8e\u6743\u503c\u77e9\u9635\u4e3a\u65b9\u9635\u76842D\u5c42\uff08 shape[0]=shape[1] \uff09    orthogonal\uff1a\u4ec5\u7528\u4e8e\u6743\u503c\u77e9\u9635\u4e3a\u65b9\u9635\u76842D\u5c42\uff08 shape[0]=shape[1] \uff09\uff0c\u53c2\u8003 Saxe et al.    zero    glorot_normal\uff1a\u7531\u6247\u5165\u6247\u51fa\u653e\u7f29\u540e\u7684\u9ad8\u65af\u521d\u59cb\u5316\uff08 Glorot 2010 \uff09    glorot_uniform    he_normal\uff1a\u7531\u6247\u5165\u653e\u7f29\u540e\u7684\u9ad8\u65af\u521d\u59cb\u5316\uff08 He et al.,2014 \uff09    he_uniform    \u6307\u5b9a\u521d\u59cb\u5316\u65b9\u6cd5\u4f20\u5165\u7684\u53ef\u4ee5\u662f\u4e00\u4e2a\u5b57\u7b26\u4e32(\u5fc5\u987b\u4e0e\u4e0a\u9762\u67d0\u79cd\u9884\u5b9a\u4e49\u65b9\u6cd5\u5339\u914d),\u4e5f\u53ef\u4ee5\u662f\u4e00\u4e2a\u53ef\u8c03\u7528\u7684\u5bf9\u8c61.\u5982\u679c\u4f20\u5165\u53ef\u8c03\u7528\u7684\u5bf9\u8c61,\u5219\u8be5\u5bf9\u8c61\u5fc5\u987b\u5305\u542b\u4e24\u4e2a\u53c2\u6570: shape (\u5f85\u521d\u59cb\u5316\u7684\u53d8\u91cf\u7684shape)\u548c name (\u8be5\u53d8\u91cf\u7684\u540d\u5b57),\u8be5\u53ef\u8c03\u7528\u5bf9\u8c61\u5fc5\u987b\u8fd4\u56de\u4e00\u4e2a(Keras)\u53d8\u91cf,\u4f8b\u5982 K.variable() \u8fd4\u56de\u7684\u5c31\u662f\u8fd9\u79cd\u53d8\u91cf,\u4e0b\u9762\u662f\u4f8b\u5b50:  from keras import backend as K\nimport numpy as np\n\ndef my_init(shape, name=None):\n    value = np.random.random(shape)\n    return K.variable(value, name=name)\n\nmodel.add(Dense(64, init=my_init))  \u4f60\u4e5f\u53ef\u4ee5\u6309\u8fd9\u79cd\u65b9\u6cd5\u4f7f\u7528 keras.initializations \u4e2d\u7684\u51fd\u6570:  from keras import initializations\n\ndef my_init(shape, name=None):\n    return initializations.normal(shape, scale=0.01, name=name)\n\nmodel.add(Dense(64, init=my_init))  \u3010Tips\u3011\u7a0d\u540e\uff08\u4e00\u4e24\u5468\u5427\u2026\u2026\uff09\u6211\u4eec\u5e0c\u671b\u5c06\u5404\u4e2a\u521d\u59cb\u5316\u65b9\u6cd5\u7684\u7279\u70b9\u603b\u7ed3\u4e00\u4e0b\uff0c\u8bf7\u7ee7\u7eed\u5173\u6ce8", 
            "title": "\u9884\u5b9a\u4e49\u521d\u59cb\u5316\u65b9\u6cd5"
        }, 
        {
            "location": "/other/regularizers/", 
            "text": "\u6b63\u5219\u9879\n\n\n\u6b63\u5219\u9879\u5728\u4f18\u5316\u8fc7\u7a0b\u4e2d\u5c42\u7684\u53c2\u6570\u6216\u5c42\u7684\u6fc0\u6d3b\u503c\u6dfb\u52a0\u60e9\u7f5a\u9879\uff0c\u8fd9\u4e9b\u60e9\u7f5a\u9879\u5c06\u4e0e\u635f\u5931\u51fd\u6570\u4e00\u8d77\u4f5c\u4e3a\u7f51\u7edc\u7684\u6700\u7ec8\u4f18\u5316\u76ee\u6807\n\n\n\u60e9\u7f5a\u9879\u57fa\u4e8e\u5c42\u8fdb\u884c\u60e9\u7f5a\uff0c\u76ee\u524d\u60e9\u7f5a\u9879\u7684\u63a5\u53e3\u4e0e\u5c42\u6709\u5173\uff0c\u4f46\nDense, TimeDistributedDense, MaxoutDense, Covolution1D, Covolution2D, Convolution3D\n\u5177\u6709\u5171\u540c\u7684\u63a5\u53e3\u3002\n\n\n\u8fd9\u4e9b\u5c42\u6709\u4e09\u4e2a\u5173\u952e\u5b57\u53c2\u6570\u4ee5\u65bd\u52a0\u6b63\u5219\u9879\uff1a\n\n\n\n\n\n\nW_regularizer\n\uff1a\u65bd\u52a0\u5728\u6743\u91cd\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a\nWeightRegularizer\n\u5bf9\u8c61\n\n\n\n\n\n\nb_regularizer\n\uff1a\u65bd\u52a0\u5728\u504f\u7f6e\u5411\u91cf\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a\nWeightRegularizer\n\u5bf9\u8c61\n\n\n\n\n\n\nactivity_regularizer\n\uff1a\u65bd\u52a0\u5728\u8f93\u51fa\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a\nActivityRegularizer\n\u5bf9\u8c61\n\n\n\n\n\n\n\u4f8b\u5b50\n\n\nfrom keras.regularizers import l2, activity_l2\nmodel.add(Dense(64, input_dim=64, W_regularizer=l2(0.01), activity_regularizer=activity_l2(0.01)))\n\n\n\n\n\u9884\u5b9a\u4e49\u6b63\u5219\u9879\n\n\nkeras.regularizers.WeightRegularizer(l1=0., l2=0.)\n\n\n\n\nkeras.regularizers.ActivityRegularizer(l1=0., l2=0.)\n\n\n\n\n\u7f29\u5199\n\n\nkeras.regularizers\n\u652f\u6301\u4ee5\u4e0b\u7f29\u5199\n\n\n\n\n\n\nl1(l=0.01)\uff1aL1\u6b63\u5219\u9879\uff0c\u53c8\u79f0LASSO\n\n\n\n\n\n\nl2(l=0.01)\uff1aL2\u6b63\u5219\u9879\uff0c\u53c8\u79f0\u6743\u91cd\u8870\u51cf\u6216Ridge\n\n\n\n\n\n\nl1l2(l1=0.01, l2=0.01)\uff1a L1-L2\u6df7\u5408\u6b63\u5219\u9879, \u53c8\u79f0ElasticNet\n\n\n\n\n\n\nactivity_l1(l=0.01)\uff1a L1\u6fc0\u6d3b\u503c\u6b63\u5219\u9879\n\n\n\n\n\n\nactivity_l2(l=0.01)\uff1a L2\u6fc0\u6d3b\u503c\u6b63\u5219\u9879\n\n\n\n\n\n\nactivity_l1l2(l1=0.01, l2=0.01)\uff1a L1+L2\u6fc0\u6d3b\u503c\u6b63\u5219\u9879\n\n\n\n\n\n\n\u3010Tips\u3011\u6b63\u5219\u9879\u901a\u5e38\u7528\u4e8e\u5bf9\u6a21\u578b\u7684\u8bad\u7ec3\u65bd\u52a0\u67d0\u79cd\u7ea6\u675f\uff0cL1\u6b63\u5219\u9879\u5373L1\u8303\u6570\u7ea6\u675f\uff0c\u8be5\u7ea6\u675f\u4f1a\u4f7f\u88ab\u7ea6\u675f\u77e9\u9635/\u5411\u91cf\u66f4\u7a00\u758f\u3002L2\u6b63\u5219\u9879\u5373L2\u8303\u6570\u7ea6\u675f\uff0c\u8be5\u7ea6\u675f\u4f1a\u4f7f\u88ab\u7ea6\u675f\u7684\u77e9\u9635/\u5411\u91cf\u66f4\u5e73\u6ed1\uff0c\u56e0\u4e3a\u5b83\u5bf9\u8109\u51b2\u578b\u7684\u503c\u6709\u5f88\u5927\u7684\u60e9\u7f5a\u3002\u3010@Bigmoyan\u3011", 
            "title": "\u6b63\u5219\u9879Regularizer"
        }, 
        {
            "location": "/other/regularizers/#_1", 
            "text": "\u6b63\u5219\u9879\u5728\u4f18\u5316\u8fc7\u7a0b\u4e2d\u5c42\u7684\u53c2\u6570\u6216\u5c42\u7684\u6fc0\u6d3b\u503c\u6dfb\u52a0\u60e9\u7f5a\u9879\uff0c\u8fd9\u4e9b\u60e9\u7f5a\u9879\u5c06\u4e0e\u635f\u5931\u51fd\u6570\u4e00\u8d77\u4f5c\u4e3a\u7f51\u7edc\u7684\u6700\u7ec8\u4f18\u5316\u76ee\u6807  \u60e9\u7f5a\u9879\u57fa\u4e8e\u5c42\u8fdb\u884c\u60e9\u7f5a\uff0c\u76ee\u524d\u60e9\u7f5a\u9879\u7684\u63a5\u53e3\u4e0e\u5c42\u6709\u5173\uff0c\u4f46 Dense, TimeDistributedDense, MaxoutDense, Covolution1D, Covolution2D, Convolution3D \u5177\u6709\u5171\u540c\u7684\u63a5\u53e3\u3002  \u8fd9\u4e9b\u5c42\u6709\u4e09\u4e2a\u5173\u952e\u5b57\u53c2\u6570\u4ee5\u65bd\u52a0\u6b63\u5219\u9879\uff1a    W_regularizer \uff1a\u65bd\u52a0\u5728\u6743\u91cd\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a WeightRegularizer \u5bf9\u8c61    b_regularizer \uff1a\u65bd\u52a0\u5728\u504f\u7f6e\u5411\u91cf\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a WeightRegularizer \u5bf9\u8c61    activity_regularizer \uff1a\u65bd\u52a0\u5728\u8f93\u51fa\u4e0a\u7684\u6b63\u5219\u9879\uff0c\u4e3a ActivityRegularizer \u5bf9\u8c61", 
            "title": "\u6b63\u5219\u9879"
        }, 
        {
            "location": "/other/regularizers/#_2", 
            "text": "from keras.regularizers import l2, activity_l2\nmodel.add(Dense(64, input_dim=64, W_regularizer=l2(0.01), activity_regularizer=activity_l2(0.01)))", 
            "title": "\u4f8b\u5b50"
        }, 
        {
            "location": "/other/regularizers/#_3", 
            "text": "keras.regularizers.WeightRegularizer(l1=0., l2=0.)  keras.regularizers.ActivityRegularizer(l1=0., l2=0.)", 
            "title": "\u9884\u5b9a\u4e49\u6b63\u5219\u9879"
        }, 
        {
            "location": "/other/regularizers/#_4", 
            "text": "keras.regularizers \u652f\u6301\u4ee5\u4e0b\u7f29\u5199    l1(l=0.01)\uff1aL1\u6b63\u5219\u9879\uff0c\u53c8\u79f0LASSO    l2(l=0.01)\uff1aL2\u6b63\u5219\u9879\uff0c\u53c8\u79f0\u6743\u91cd\u8870\u51cf\u6216Ridge    l1l2(l1=0.01, l2=0.01)\uff1a L1-L2\u6df7\u5408\u6b63\u5219\u9879, \u53c8\u79f0ElasticNet    activity_l1(l=0.01)\uff1a L1\u6fc0\u6d3b\u503c\u6b63\u5219\u9879    activity_l2(l=0.01)\uff1a L2\u6fc0\u6d3b\u503c\u6b63\u5219\u9879    activity_l1l2(l1=0.01, l2=0.01)\uff1a L1+L2\u6fc0\u6d3b\u503c\u6b63\u5219\u9879    \u3010Tips\u3011\u6b63\u5219\u9879\u901a\u5e38\u7528\u4e8e\u5bf9\u6a21\u578b\u7684\u8bad\u7ec3\u65bd\u52a0\u67d0\u79cd\u7ea6\u675f\uff0cL1\u6b63\u5219\u9879\u5373L1\u8303\u6570\u7ea6\u675f\uff0c\u8be5\u7ea6\u675f\u4f1a\u4f7f\u88ab\u7ea6\u675f\u77e9\u9635/\u5411\u91cf\u66f4\u7a00\u758f\u3002L2\u6b63\u5219\u9879\u5373L2\u8303\u6570\u7ea6\u675f\uff0c\u8be5\u7ea6\u675f\u4f1a\u4f7f\u88ab\u7ea6\u675f\u7684\u77e9\u9635/\u5411\u91cf\u66f4\u5e73\u6ed1\uff0c\u56e0\u4e3a\u5b83\u5bf9\u8109\u51b2\u578b\u7684\u503c\u6709\u5f88\u5927\u7684\u60e9\u7f5a\u3002\u3010@Bigmoyan\u3011", 
            "title": "\u7f29\u5199"
        }, 
        {
            "location": "/other/constraints/", 
            "text": "\u7ea6\u675f\u9879\n\n\n\u6765\u81ea\nconstraints\n\u6a21\u5757\u7684\u51fd\u6570\u5728\u4f18\u5316\u8fc7\u7a0b\u4e2d\u4e3a\u7f51\u7edc\u7684\u53c2\u6570\u65bd\u52a0\u7ea6\u675f\n\n\n\u60e9\u7f5a\u9879\u57fa\u4e8e\u5c42\u8fdb\u884c\u60e9\u7f5a\uff0c\u76ee\u524d\u60e9\u7f5a\u9879\u7684\u63a5\u53e3\u4e0e\u5c42\u6709\u5173\uff0c\u4f46\nDense, TimeDistributedDense, MaxoutDense, Covolution1D, Covolution2D, Convolution3D\n\u5177\u6709\u5171\u540c\u7684\u63a5\u53e3\u3002\n\n\n\u8fd9\u4e9b\u5c42\u901a\u8fc7\u4e00\u4e0b\u5173\u952e\u5b57\u65bd\u52a0\u7ea6\u675f\u9879\n\n\n\n\n\n\nW_constraint\n\uff1a\u5bf9\u4e3b\u6743\u91cd\u77e9\u9635\u8fdb\u884c\u7ea6\u675f\n\n\n\n\n\n\nb_constraint\n\uff1a\u5bf9\u504f\u7f6e\u5411\u91cf\u8fdb\u884c\u7ea6\u675f\n\n\n\n\n\n\nfrom keras.constraints import maxnorm\nmodel.add(Dense(64, W_constraint = maxnorm(2)))\n\n\n\n\n\u9884\u5b9a\u4e49\u7ea6\u675f\u9879\n\n\n\n\n\n\nmaxnorm(m=2)\uff1a\u6700\u5927\u6a21\u7ea6\u675f\n\n\n\n\n\n\nnonneg()\uff1a\u975e\u8d1f\u6027\u7ea6\u675f\n\n\n\n\n\n\nunitnorm()\uff1a\u5355\u4f4d\u8303\u6570\u7ea6\u675f, \u5f3a\u5236\u77e9\u9635\u6cbf\u6700\u540e\u4e00\u4e2a\u8f74\u62e5\u6709\u5355\u4f4d\u8303\u6570", 
            "title": "\u7ea6\u675f\u9879Constraint"
        }, 
        {
            "location": "/other/constraints/#_1", 
            "text": "\u6765\u81ea constraints \u6a21\u5757\u7684\u51fd\u6570\u5728\u4f18\u5316\u8fc7\u7a0b\u4e2d\u4e3a\u7f51\u7edc\u7684\u53c2\u6570\u65bd\u52a0\u7ea6\u675f  \u60e9\u7f5a\u9879\u57fa\u4e8e\u5c42\u8fdb\u884c\u60e9\u7f5a\uff0c\u76ee\u524d\u60e9\u7f5a\u9879\u7684\u63a5\u53e3\u4e0e\u5c42\u6709\u5173\uff0c\u4f46 Dense, TimeDistributedDense, MaxoutDense, Covolution1D, Covolution2D, Convolution3D \u5177\u6709\u5171\u540c\u7684\u63a5\u53e3\u3002  \u8fd9\u4e9b\u5c42\u901a\u8fc7\u4e00\u4e0b\u5173\u952e\u5b57\u65bd\u52a0\u7ea6\u675f\u9879    W_constraint \uff1a\u5bf9\u4e3b\u6743\u91cd\u77e9\u9635\u8fdb\u884c\u7ea6\u675f    b_constraint \uff1a\u5bf9\u504f\u7f6e\u5411\u91cf\u8fdb\u884c\u7ea6\u675f    from keras.constraints import maxnorm\nmodel.add(Dense(64, W_constraint = maxnorm(2)))", 
            "title": "\u7ea6\u675f\u9879"
        }, 
        {
            "location": "/other/constraints/#_2", 
            "text": "maxnorm(m=2)\uff1a\u6700\u5927\u6a21\u7ea6\u675f    nonneg()\uff1a\u975e\u8d1f\u6027\u7ea6\u675f    unitnorm()\uff1a\u5355\u4f4d\u8303\u6570\u7ea6\u675f, \u5f3a\u5236\u77e9\u9635\u6cbf\u6700\u540e\u4e00\u4e2a\u8f74\u62e5\u6709\u5355\u4f4d\u8303\u6570", 
            "title": "\u9884\u5b9a\u4e49\u7ea6\u675f\u9879"
        }, 
        {
            "location": "/other/application/", 
            "text": "Application\u5e94\u7528\n\n\nKera\u7684\u5e94\u7528\u6a21\u5757Application\u63d0\u4f9b\u4e86\u5e26\u6709\u9884\u8bad\u7ec3\u6743\u91cd\u7684Keras\u6a21\u578b\uff0c\u8fd9\u4e9b\u6a21\u578b\u53ef\u4ee5\u7528\u6765\u8fdb\u884c\u9884\u6d4b\u3001\u7279\u5f81\u63d0\u53d6\u548cfinetune\n\n\n\u6a21\u578b\u7684\u9884\u8bad\u7ec3\u6743\u91cd\u5c06\u4e0b\u8f7d\u5230\n~/.keras/models/\n\u5e76\u5728\u8f7d\u5165\u6a21\u578b\u65f6\u81ea\u52a8\u8f7d\u5165\n\n\n\u53ef\u7528\u7684\u6a21\u578b\n\n\n\u5e94\u7528\u4e8e\u56fe\u50cf\u5206\u7c7b\u7684\u6a21\u578b,\u6743\u91cd\u8bad\u7ec3\u81eaImageNet\uff1a\n\n \nXception\n\n\n \nVGG16\n\n\n \nVGG19\n\n\n \nResNet50\n\n* \nInceptionV3\n\n\n\u6240\u6709\u7684\u8fd9\u4e9b\u6a21\u578b(\u9664\u4e86Xception)\u90fd\u517c\u5bb9Theano\u548cTensorflow\uff0c\u5e76\u4f1a\u81ea\u52a8\u57fa\u4e8e\n~/.keras/keras.json\n\u7684Keras\u7684\u56fe\u50cf\u7ef4\u5ea6\u8fdb\u884c\u81ea\u52a8\u8bbe\u7f6e\u3002\u4f8b\u5982\uff0c\u5982\u679c\u4f60\u8bbe\u7f6e\nimage_dim_ordering=tf\n\uff0c\u5219\u52a0\u8f7d\u7684\u6a21\u578b\u5c06\u6309\u7167TensorFlow\u7684\u7ef4\u5ea6\u987a\u5e8f\u6765\u6784\u9020\uff0c\u5373\u201cWidth-Height-Depth\u201d\u7684\u987a\u5e8f\n\n\n\u5e94\u7528\u4e8e\u97f3\u4e50\u81ea\u52a8\u6807\u7b7e(\u4ee5Mel-spectrograms\u4e3a\u8f93\u5165)\n\n\n\n\nMusicTaggerCRNN\n\n\n\n\n\n\n\u56fe\u7247\u5206\u7c7b\u6a21\u578b\u7684\u793a\u4f8b\n\n\n\u5229\u7528ResNet50\u7f51\u7edc\u8fdb\u884cImageNet\u5206\u7c7b\n\n\nfrom keras.applications.resnet50 import ResNet50\nfrom keras.preprocessing import image\nfrom keras.applications.resnet50 import preprocess_input, decode_predictions\nimport numpy as np\n\nmodel = ResNet50(weights='imagenet')\n\nimg_path = 'elephant.jpg'\nimg = image.load_img(img_path, target_size=(224, 224))\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis=0)\nx = preprocess_input(x)\n\npreds = model.predict(x)\n# decode the results into a list of tuples (class, description, probability)\n# (one such list for each sample in the batch)\nprint('Predicted:', decode_predictions(preds, top=3)[0])\n# Predicted: [(u'n02504013', u'Indian_elephant', 0.82658225), (u'n01871265', u'tusker', 0.1122357), (u'n02504458', u'African_elephant', 0.061040461)]\n\n\n\n\n\u5229\u7528VGG16\u63d0\u53d6\u7279\u5f81\n\n\nfrom keras.applications.vgg16 import VGG16\nfrom keras.preprocessing import image\nfrom keras.applications.vgg16 import preprocess_input\nimport numpy as np\n\nmodel = VGG16(weights='imagenet', include_top=False)\n\nimg_path = 'elephant.jpg'\nimg = image.load_img(img_path, target_size=(224, 224))\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis=0)\nx = preprocess_input(x)\n\nfeatures = model.predict(x)\n\n\n\n\n\u4eceVGG19\u7684\u4efb\u610f\u4e2d\u95f4\u5c42\u4e2d\u62bd\u53d6\u7279\u5f81\n\n\nfrom keras.applications.vgg19 import VGG19\nfrom keras.preprocessing import image\nfrom keras.applications.vgg19 import preprocess_input\nfrom keras.models import Model\nimport numpy as np\n\nbase_model = VGG19(weights='imagenet')\nmodel = Model(input=base_model.input, output=base_model.get_layer('block4_pool').output)\n\nimg_path = 'elephant.jpg'\nimg = image.load_img(img_path, target_size=(224, 224))\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis=0)\nx = preprocess_input(x)\n\nblock4_pool_features = model.predict(x)\n\n\n\n\n\u5229\u7528\u65b0\u6570\u636e\u96c6finetune InceptionV3\n\n\nfrom keras.applications.inception_v3 import InceptionV3\nfrom keras.preprocessing import image\nfrom keras.models import Model\nfrom keras.layers import Dense, GlobalAveragePooling2D\nfrom keras import backend as K\n\n# create the base pre-trained model\nbase_model = InceptionV3(weights='imagenet', include_top=False)\n\n# add a global spatial average pooling layer\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\n# let's add a fully-connected layer\nx = Dense(1024, activation='relu')(x)\n# and a logistic layer -- let's say we have 200 classes\npredictions = Dense(200, activation='softmax')(x)\n\n# this is the model we will train\nmodel = Model(input=base_model.input, output=predictions)\n\n# first: train only the top layers (which were randomly initialized)\n# i.e. freeze all convolutional InceptionV3 layers\nfor layer in base_model.layers:\n    layer.trainable = False\n\n# compile the model (should be done *after* setting layers to non-trainable)\nmodel.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n\n# train the model on the new data for a few epochs\nmodel.fit_generator(...)\n\n# at this point, the top layers are well trained and we can start fine-tuning\n# convolutional layers from inception V3. We will freeze the bottom N layers\n# and train the remaining top layers.\n\n# let's visualize layer names and layer indices to see how many layers\n# we should freeze:\nfor i, layer in enumerate(base_model.layers):\n   print(i, layer.name)\n\n# we chose to train the top 2 inception blocks, i.e. we will freeze\n# the first 172 layers and unfreeze the rest:\nfor layer in model.layers[:172]:\n   layer.trainable = False\nfor layer in model.layers[172:]:\n   layer.trainable = True\n\n# we need to recompile the model for these modifications to take effect\n# we use SGD with a low learning rate\nfrom keras.optimizers import SGD\nmodel.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy')\n\n# we train our model again (this time fine-tuning the top 2 inception blocks\n# alongside the top Dense layers\nmodel.fit_generator(...)\n\n\n\n\n\u5728\u5b9a\u5236\u7684\u8f93\u5165tensor\u4e0a\u6784\u5efaInceptionV3\n\n\nfrom keras.applications.inception_v3 import InceptionV3\nfrom keras.layers import Input\n\n# this could also be the output a different Keras model or layer\ninput_tensor = Input(shape=(224, 224, 3))  # this assumes K.image_dim_ordering() == 'tf'\n\nmodel = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=True)\n\n\n\n\n\n\n\u6a21\u578b\u6587\u6863\n\n\n\n\nXception\n\n\nVGG16\n\n\nVGG19\n\n\nResNet50\n\n\nInceptionV3\n\n\nMusicTaggerCRNN\n\n\n\n\n\n\n\n\n\n\nXception\u6a21\u578b\n\n\n\n\n\n\nkeras.applications.xception.Xception(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, classes=1000)\n\n\n\n\nXception V1 \u6a21\u578b, \u6743\u91cd\u7531ImageNet\u8bad\u7ec3\u800c\u8a00\n\n\n\u5728ImageNet\u4e0a,\u8be5\u6a21\u578b\u53d6\u5f97\u4e86\u9a8c\u8bc1\u96c6top1 0.790\u548ctop5 0.945\u7684\u6b63\u786e\u7387\n\n\n\u6ce8\u610f,\u8be5\u6a21\u578b\u76ee\u524d\u4ec5\u80fd\u4ee5TensorFlow\u4e3a\u540e\u7aef\u4f7f\u7528,\u7531\u4e8e\u5b83\u4f9d\u8d56\u4e8e\"SeparableConvolution\"\u5c42,\u76ee\u524d\u8be5\u6a21\u578b\u53ea\u652f\u6301tf\u7684\u7ef4\u5ea6\u987a\u5e8f(width, height, channels)\n\n\n\u9ed8\u8ba4\u8f93\u5165\u56fe\u7247\u5927\u5c0f\u4e3a299x299\n\n\n\u53c2\u6570\n\n\n\n\ninclude_top\uff1a\u662f\u5426\u4fdd\u7559\u9876\u5c42\u76843\u4e2a\u5168\u8fde\u63a5\u7f51\u7edc\n\n\nweights\uff1aNone\u4ee3\u8868\u968f\u673a\u521d\u59cb\u5316\uff0c\u5373\u4e0d\u52a0\u8f7d\u9884\u8bad\u7ec3\u6743\u91cd\u3002'imagenet'\u4ee3\u8868\u52a0\u8f7d\u9884\u8bad\u7ec3\u6743\u91cd\n\n\ninput_tensor\uff1a\u53ef\u586b\u5165Keras tensor\u4f5c\u4e3a\u6a21\u578b\u7684\u56fe\u50cf\u8f93\u51fatensor\n\n\ninput_shape\uff1a\u53ef\u9009\uff0c\u4ec5\u5f53\ninclude_top=False\n\u6709\u6548\uff0c\u5e94\u4e3a\u957f\u4e3a3\u7684tuple\uff0c\u6307\u660e\u8f93\u5165\u56fe\u7247\u7684shape\uff0c\u56fe\u7247\u7684\u5bbd\u9ad8\u5fc5\u987b\u5927\u4e8e71\uff0c\u5982(150,150,3)\n\n\nclasses\uff1a\u53ef\u9009\uff0c\u56fe\u7247\u5206\u7c7b\u7684\u7c7b\u522b\u6570\uff0c\u4ec5\u5f53\ninclude_top=True\n\u5e76\u4e14\u4e0d\u52a0\u8f7d\u9884\u8bad\u7ec3\u6743\u91cd\u65f6\u53ef\u7528\u3002\n\n\n\n\n\u8fd4\u56de\u503c\n\n\nKeras \u6a21\u578b\u5bf9\u8c61\n\n\n\u53c2\u8003\u6587\u732e\n\n\n\n\nXception: Deep Learning with Depthwise Separable Convolutions\n\n\n\n\nLicense\n\n\n\u9884\u8bad\u7ec3\u6743\u91cd\u7531\u6211\u4eec\u81ea\u5df1\u8bad\u7ec3\u800c\u6765\uff0c\u57fa\u4e8eMIT license\u53d1\u5e03\n\n\n\n\n\n\n\n\nVGG16\u6a21\u578b\n\n\n\n\n\n\nkeras.applications.vgg16.VGG16(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, classes=1000)\n\n\n\n\nVGG16\u6a21\u578b,\u6743\u91cd\u7531ImageNet\u8bad\u7ec3\u800c\u6765\n\n\n\u8be5\u6a21\u578b\u518dTheano\u548cTensorFlow\u540e\u7aef\u5747\u53ef\u4f7f\u7528,\u5e76\u63a5\u53d7th\u548ctf\u4e24\u79cd\u8f93\u5165\u7ef4\u5ea6\u987a\u5e8f\n\n\n\u6a21\u578b\u7684\u9ed8\u8ba4\u8f93\u5165\u5c3a\u5bf8\u65f6224x224\n\n\n\u53c2\u6570\n\n\n\n\ninclude_top\uff1a\u662f\u5426\u4fdd\u7559\u9876\u5c42\u76843\u4e2a\u5168\u8fde\u63a5\u7f51\u7edc\n\n\nweights\uff1aNone\u4ee3\u8868\u968f\u673a\u521d\u59cb\u5316\uff0c\u5373\u4e0d\u52a0\u8f7d\u9884\u8bad\u7ec3\u6743\u91cd\u3002'imagenet'\u4ee3\u8868\u52a0\u8f7d\u9884\u8bad\u7ec3\u6743\u91cd\n\n\ninput_tensor\uff1a\u53ef\u586b\u5165Keras tensor\u4f5c\u4e3a\u6a21\u578b\u7684\u56fe\u50cf\u8f93\u51fatensor\n\n\ninput_shape\uff1a\u53ef\u9009\uff0c\u4ec5\u5f53\ninclude_top=False\n\u6709\u6548\uff0c\u5e94\u4e3a\u957f\u4e3a3\u7684tuple\uff0c\u6307\u660e\u8f93\u5165\u56fe\u7247\u7684shape\uff0c\u56fe\u7247\u7684\u5bbd\u9ad8\u5fc5\u987b\u5927\u4e8e48\uff0c\u5982(200,200,3)\n\n\n\n\n\u8fd4\u56de\u503c\n\n\n\n\nclasses\uff1a\u53ef\u9009\uff0c\u56fe\u7247\u5206\u7c7b\u7684\u7c7b\u522b\u6570\uff0c\u4ec5\u5f53\ninclude_top=True\n\u5e76\u4e14\u4e0d\u52a0\u8f7d\u9884\u8bad\u7ec3\u6743\u91cd\u65f6\u53ef\u7528\u3002\n\n\n\n\nKeras \u6a21\u578b\u5bf9\u8c61\n\n\n\u53c2\u8003\u6587\u732e\n\n\n\n\nVery Deep Convolutional Networks for Large-Scale Image Recognition\n\uff1a\u5982\u679c\u5728\u7814\u7a76\u4e2d\u4f7f\u7528\u4e86VGG\uff0c\u8bf7\u5f15\u7528\u8be5\u6587\n\n\n\n\nLicense\n\n\n\u9884\u8bad\u7ec3\u6743\u91cd\u7531\n\u725b\u6d25VGG\u7ec4\n\u53d1\u5e03\u7684\u9884\u8bad\u7ec3\u6743\u91cd\u79fb\u690d\u800c\u6765\uff0c\u57fa\u4e8e\nCreative Commons Attribution License\n\n\n\n\n\n\n\n\nVGG19\u6a21\u578b\n\n\n\n\n\n\nkeras.applications.vgg19.VGG19(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, classes=1000)\n\n\n\n\nVGG19\u6a21\u578b,\u6743\u91cd\u7531ImageNet\u8bad\u7ec3\u800c\u6765\n\n\n\u8be5\u6a21\u578b\u518dTheano\u548cTensorFlow\u540e\u7aef\u5747\u53ef\u4f7f\u7528,\u5e76\u63a5\u53d7th\u548ctf\u4e24\u79cd\u8f93\u5165\u7ef4\u5ea6\u987a\u5e8f\n\n\n\u6a21\u578b\u7684\u9ed8\u8ba4\u8f93\u5165\u5c3a\u5bf8\u65f6224x224\n\n\n\u53c2\u6570\n\n\n\n\ninclude_top\uff1a\u662f\u5426\u4fdd\u7559\u9876\u5c42\u76843\u4e2a\u5168\u8fde\u63a5\u7f51\u7edc\n\n\nweights\uff1aNone\u4ee3\u8868\u968f\u673a\u521d\u59cb\u5316\uff0c\u5373\u4e0d\u52a0\u8f7d\u9884\u8bad\u7ec3\u6743\u91cd\u3002'imagenet'\u4ee3\u8868\u52a0\u8f7d\u9884\u8bad\u7ec3\u6743\u91cd\n\n\ninput_tensor\uff1a\u53ef\u586b\u5165Keras tensor\u4f5c\u4e3a\u6a21\u578b\u7684\u56fe\u50cf\u8f93\u51fatensor\n\n\ninput_shape\uff1a\u53ef\u9009\uff0c\u4ec5\u5f53\ninclude_top=False\n\u6709\u6548\uff0c\u5e94\u4e3a\u957f\u4e3a3\u7684tuple\uff0c\u6307\u660e\u8f93\u5165\u56fe\u7247\u7684shape\uff0c\u56fe\u7247\u7684\u5bbd\u9ad8\u5fc5\u987b\u5927\u4e8e48\uff0c\u5982(200,200,3)\n\n\nclasses\uff1a\u53ef\u9009\uff0c\u56fe\u7247\u5206\u7c7b\u7684\u7c7b\u522b\u6570\uff0c\u4ec5\u5f53\ninclude_top=True\n\u5e76\u4e14\u4e0d\u52a0\u8f7d\u9884\u8bad\u7ec3\u6743\u91cd\u65f6\u53ef\u7528\u3002\n\n\n\n\n\u8fd4\u56de\u503c\n\n\n\u8fd4\u56de\u503c\n\n\nKeras \u6a21\u578b\u5bf9\u8c61\n\n\n\u53c2\u8003\u6587\u732e\n\n\n\n\nVery Deep Convolutional Networks for Large-Scale Image Recognition\n\uff1a\u5982\u679c\u5728\u7814\u7a76\u4e2d\u4f7f\u7528\u4e86VGG\uff0c\u8bf7\u5f15\u7528\u8be5\u6587\n\n\n\n\nLicense\n\n\n\u9884\u8bad\u7ec3\u6743\u91cd\u7531\n\u725b\u6d25VGG\u7ec4\n\u53d1\u5e03\u7684\u9884\u8bad\u7ec3\u6743\u91cd\u79fb\u690d\u800c\u6765\uff0c\u57fa\u4e8e\nCreative Commons Attribution License\n\n\n\n\n\n\n\n\nResNet50\u6a21\u578b\n\n\n\n\n\n\nkeras.applications.resnet50.ResNet50(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, classes=1000)\n\n\n\n\n50\u5c42\u6b8b\u5dee\u7f51\u7edc\u6a21\u578b,\u6743\u91cd\u8bad\u7ec3\u81eaImageNet\n\n\n\u8be5\u6a21\u578b\u518dTheano\u548cTensorFlow\u540e\u7aef\u5747\u53ef\u4f7f\u7528,\u5e76\u63a5\u53d7th\u548ctf\u4e24\u79cd\u8f93\u5165\u7ef4\u5ea6\u987a\u5e8f\n\n\n\u6a21\u578b\u7684\u9ed8\u8ba4\u8f93\u5165\u5c3a\u5bf8\u65f6224x224\n\n\n\u53c2\u6570\n\n\n\n\ninclude_top\uff1a\u662f\u5426\u4fdd\u7559\u9876\u5c42\u7684\u5168\u8fde\u63a5\u7f51\u7edc\n\n\nweights\uff1aNone\u4ee3\u8868\u968f\u673a\u521d\u59cb\u5316\uff0c\u5373\u4e0d\u52a0\u8f7d\u9884\u8bad\u7ec3\u6743\u91cd\u3002'imagenet'\u4ee3\u8868\u52a0\u8f7d\u9884\u8bad\u7ec3\u6743\u91cd\n\n\ninput_tensor\uff1a\u53ef\u586b\u5165Keras tensor\u4f5c\u4e3a\u6a21\u578b\u7684\u56fe\u50cf\u8f93\u51fatensor\n\n\ninput_shape\uff1a\u53ef\u9009\uff0c\u4ec5\u5f53\ninclude_top=False\n\u6709\u6548\uff0c\u5e94\u4e3a\u957f\u4e3a3\u7684tuple\uff0c\u6307\u660e\u8f93\u5165\u56fe\u7247\u7684shape\uff0c\u56fe\u7247\u7684\u5bbd\u9ad8\u5fc5\u987b\u5927\u4e8e197\uff0c\u5982(200,200,3)\n\n\nclasses\uff1a\u53ef\u9009\uff0c\u56fe\u7247\u5206\u7c7b\u7684\u7c7b\u522b\u6570\uff0c\u4ec5\u5f53\ninclude_top=True\n\u5e76\u4e14\u4e0d\u52a0\u8f7d\u9884\u8bad\u7ec3\u6743\u91cd\u65f6\u53ef\u7528\u3002\n\n\n\n\n\u8fd4\u56de\u503c\n\n\nKeras \u6a21\u578b\u5bf9\u8c61\n\n\n\u53c2\u8003\u6587\u732e\n\n\n\n\nDeep Residual Learning for Image Recognition\n\uff1a\u5982\u679c\u5728\u7814\u7a76\u4e2d\u4f7f\u7528\u4e86ResNet50\uff0c\u8bf7\u5f15\u7528\u8be5\u6587\n\n\n\n\nLicense\n\n\n\u9884\u8bad\u7ec3\u6743\u91cd\u7531\nKaiming He\n\u53d1\u5e03\u7684\u9884\u8bad\u7ec3\u6743\u91cd\u79fb\u690d\u800c\u6765\uff0c\u57fa\u4e8e\nMIT License\n\n\n\n\n\n\n\n\nInceptionV3\u6a21\u578b\n\n\n\n\n\n\nkeras.applications.inception_v3.InceptionV3(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, classes=1000)\n\n\n\n\nInceptionV3\u7f51\u7edc,\u6743\u91cd\u8bad\u7ec3\u81eaImageNet\n\n\n\u8be5\u6a21\u578b\u518dTheano\u548cTensorFlow\u540e\u7aef\u5747\u53ef\u4f7f\u7528,\u5e76\u63a5\u53d7th\u548ctf\u4e24\u79cd\u8f93\u5165\u7ef4\u5ea6\u987a\u5e8f\n\n\n\u6a21\u578b\u7684\u9ed8\u8ba4\u8f93\u5165\u5c3a\u5bf8\u65f6299x299\n\n\n\u53c2\u6570\n\n\n\n\ninclude_top\uff1a\u662f\u5426\u4fdd\u7559\u9876\u5c42\u7684\u5168\u8fde\u63a5\u7f51\u7edc\n\n\nweights\uff1aNone\u4ee3\u8868\u968f\u673a\u521d\u59cb\u5316\uff0c\u5373\u4e0d\u52a0\u8f7d\u9884\u8bad\u7ec3\u6743\u91cd\u3002'imagenet'\u4ee3\u8868\u52a0\u8f7d\u9884\u8bad\u7ec3\u6743\u91cd\n\n\ninput_tensor\uff1a\u53ef\u586b\u5165Keras tensor\u4f5c\u4e3a\u6a21\u578b\u7684\u56fe\u50cf\u8f93\u51fatensor\n\n\nclasses\uff1a\u53ef\u9009\uff0c\u56fe\u7247\u5206\u7c7b\u7684\u7c7b\u522b\u6570\uff0c\u4ec5\u5f53\ninclude_top=True\n\u5e76\u4e14\u4e0d\u52a0\u8f7d\u9884\u8bad\u7ec3\u6743\u91cd\u65f6\u53ef\u7528\u3002\n\n\n\n\n\u8fd4\u56de\u503c\n\n\nKeras \u6a21\u578b\u5bf9\u8c61\n\n\n\u53c2\u8003\u6587\u732e\n\n\n\n\nRethinking the Inception Architecture for Computer Vision\n\uff1a\u5982\u679c\u5728\u7814\u7a76\u4e2d\u4f7f\u7528\u4e86InceptionV3\uff0c\u8bf7\u5f15\u7528\u8be5\u6587\n\n\n\n\nLicense\n\n\n\u9884\u8bad\u7ec3\u6743\u91cd\u7531\u6211\u4eec\u81ea\u5df1\u8bad\u7ec3\u800c\u6765\uff0c\u57fa\u4e8e\nMIT License\n\n\n\n\n\n\n\n\nMusicTaggerCRNN\u6a21\u578b\n\n\n\n\n\n\nkeras.applications.music_tagger_crnn.MusicTaggerCRNN(weights='msd', input_tensor=None, include_top=True, classes=50)\n\n\n\n\n\u8be5\u6a21\u578b\u65f6\u4e00\u4e2a\u5377\u79ef\u5faa\u73af\u6a21\u578b,\u4ee5\u5411\u91cf\u5316\u7684MelSpectrogram\u97f3\u4e50\u6570\u636e\u4e3a\u8f93\u5165,\u80fd\u591f\u8f93\u51fa\u97f3\u4e50\u7684\u98ce\u683c. \u4f60\u53ef\u4ee5\u7528\nkeras.applications.music_tagger_crnn.preprocess_input\n\u6765\u5c06\u4e00\u4e2a\u97f3\u4e50\u6587\u4ef6\u5411\u91cf\u5316\u4e3aspectrogram.\u6ce8\u610f,\u4f7f\u7528\u8be5\u529f\u80fd\u9700\u8981\u5b89\u88c5\nLibrosa\n,\u8bf7\u53c2\u8003\u4e0b\u9762\u7684\u4f7f\u7528\u8303\u4f8b.\n\n\n\u53c2\u6570\n\n\n\n\ninclude_top\uff1a\u662f\u5426\u4fdd\u7559\u9876\u5c42\u76841\u5c42\u5168\u8fde\u63a5\u7f51\u7edc,\u82e5\u8bbe\u7f6e\u4e3aFalse,\u5219\u7f51\u7edc\u8f93\u51fa32\u7ef4\u7684\u7279\u5f81\n\n\nweights\uff1aNone\u4ee3\u8868\u968f\u673a\u521d\u59cb\u5316\uff0c\u5373\u4e0d\u52a0\u8f7d\u9884\u8bad\u7ec3\u6743\u91cd\u3002'msd'\u4ee3\u8868\u52a0\u8f7d\u9884\u8bad\u7ec3\u6743\u91cd(\u8bad\u7ec3\u81ea\nMillion Song Dataset\n)\n\n\ninput_tensor\uff1a\u53ef\u586b\u5165Keras tensor\u4f5c\u4e3a\u6a21\u578b\u7684\u8f93\u51fatensor,\u5982\u4f7f\u7528layer.input\u9009\u7528\u4e00\u5c42\u7684\u8f93\u5165\u5f20\u91cf\u4e3a\u6a21\u578b\u7684\u8f93\u5165\u5f20\u91cf.\n\n\n\n\n\u8fd4\u56de\u503c\n\n\nKeras \u6a21\u578b\u5bf9\u8c61\n\n\n\u53c2\u8003\u6587\u732e\n\n\n\n\nConvolutional Recurrent Neural Networks for Music Classification\n\n\n\n\nLicense\n\n\n\u9884\u8bad\u7ec3\u6743\u91cd\u7531\u6211\u4eec\u81ea\u5df1\u8bad\u7ec3\u800c\u6765\uff0c\u57fa\u4e8e\nMIT License\n\n\n\u4f7f\u7528\u8303\u4f8b:\u97f3\u4e50\u7279\u5f81\u62bd\u53d6\u4e0e\u98ce\u683c\u6807\u5b9a\n\n\nfrom keras.applications.music_tagger_crnn import MusicTaggerCRNN\nfrom keras.applications.music_tagger_crnn import preprocess_input, decode_predictions\nimport numpy as np\n\n# 1. Tagging\nmodel = MusicTaggerCRNN(weights='msd')\n\naudio_path = 'audio_file.mp3'\nmelgram = preprocess_input(audio_path)\nmelgrams = np.expand_dims(melgram, axis=0)\n\npreds = model.predict(melgrams)\nprint('Predicted:')\nprint(decode_predictions(preds))\n# print: ('Predicted:', [[('rock', 0.097071797), ('pop', 0.042456303), ('alternative', 0.032439161), ('indie', 0.024491295), ('female vocalists', 0.016455274)]])\n\n#. 2. Feature extraction\nmodel = MusicTaggerCRNN(weights='msd', include_top=False)\n\naudio_path = 'audio_file.mp3'\nmelgram = preprocess_input(audio_path)\nmelgrams = np.expand_dims(melgram, axis=0)\n\nfeats = model.predict(melgrams)\nprint('Features:')\nprint(feats[0, :10])\n# print: ('Features:', [-0.19160545 0.94259131 -0.9991011 0.47644514 -0.19089699 0.99033844 0.1103896 -0.00340496 0.14823607 0.59856361])", 
            "title": "\u9884\u8bad\u7ec3\u6a21\u578bApplication"
        }, 
        {
            "location": "/other/application/#application", 
            "text": "Kera\u7684\u5e94\u7528\u6a21\u5757Application\u63d0\u4f9b\u4e86\u5e26\u6709\u9884\u8bad\u7ec3\u6743\u91cd\u7684Keras\u6a21\u578b\uff0c\u8fd9\u4e9b\u6a21\u578b\u53ef\u4ee5\u7528\u6765\u8fdb\u884c\u9884\u6d4b\u3001\u7279\u5f81\u63d0\u53d6\u548cfinetune  \u6a21\u578b\u7684\u9884\u8bad\u7ec3\u6743\u91cd\u5c06\u4e0b\u8f7d\u5230 ~/.keras/models/ \u5e76\u5728\u8f7d\u5165\u6a21\u578b\u65f6\u81ea\u52a8\u8f7d\u5165", 
            "title": "Application\u5e94\u7528"
        }, 
        {
            "location": "/other/application/#_1", 
            "text": "\u5e94\u7528\u4e8e\u56fe\u50cf\u5206\u7c7b\u7684\u6a21\u578b,\u6743\u91cd\u8bad\u7ec3\u81eaImageNet\uff1a   Xception    VGG16    VGG19    ResNet50 \n*  InceptionV3  \u6240\u6709\u7684\u8fd9\u4e9b\u6a21\u578b(\u9664\u4e86Xception)\u90fd\u517c\u5bb9Theano\u548cTensorflow\uff0c\u5e76\u4f1a\u81ea\u52a8\u57fa\u4e8e ~/.keras/keras.json \u7684Keras\u7684\u56fe\u50cf\u7ef4\u5ea6\u8fdb\u884c\u81ea\u52a8\u8bbe\u7f6e\u3002\u4f8b\u5982\uff0c\u5982\u679c\u4f60\u8bbe\u7f6e image_dim_ordering=tf \uff0c\u5219\u52a0\u8f7d\u7684\u6a21\u578b\u5c06\u6309\u7167TensorFlow\u7684\u7ef4\u5ea6\u987a\u5e8f\u6765\u6784\u9020\uff0c\u5373\u201cWidth-Height-Depth\u201d\u7684\u987a\u5e8f  \u5e94\u7528\u4e8e\u97f3\u4e50\u81ea\u52a8\u6807\u7b7e(\u4ee5Mel-spectrograms\u4e3a\u8f93\u5165)   MusicTaggerCRNN", 
            "title": "\u53ef\u7528\u7684\u6a21\u578b"
        }, 
        {
            "location": "/other/application/#_2", 
            "text": "", 
            "title": "\u56fe\u7247\u5206\u7c7b\u6a21\u578b\u7684\u793a\u4f8b"
        }, 
        {
            "location": "/other/application/#resnet50imagenet", 
            "text": "from keras.applications.resnet50 import ResNet50\nfrom keras.preprocessing import image\nfrom keras.applications.resnet50 import preprocess_input, decode_predictions\nimport numpy as np\n\nmodel = ResNet50(weights='imagenet')\n\nimg_path = 'elephant.jpg'\nimg = image.load_img(img_path, target_size=(224, 224))\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis=0)\nx = preprocess_input(x)\n\npreds = model.predict(x)\n# decode the results into a list of tuples (class, description, probability)\n# (one such list for each sample in the batch)\nprint('Predicted:', decode_predictions(preds, top=3)[0])\n# Predicted: [(u'n02504013', u'Indian_elephant', 0.82658225), (u'n01871265', u'tusker', 0.1122357), (u'n02504458', u'African_elephant', 0.061040461)]", 
            "title": "\u5229\u7528ResNet50\u7f51\u7edc\u8fdb\u884cImageNet\u5206\u7c7b"
        }, 
        {
            "location": "/other/application/#vgg16", 
            "text": "from keras.applications.vgg16 import VGG16\nfrom keras.preprocessing import image\nfrom keras.applications.vgg16 import preprocess_input\nimport numpy as np\n\nmodel = VGG16(weights='imagenet', include_top=False)\n\nimg_path = 'elephant.jpg'\nimg = image.load_img(img_path, target_size=(224, 224))\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis=0)\nx = preprocess_input(x)\n\nfeatures = model.predict(x)", 
            "title": "\u5229\u7528VGG16\u63d0\u53d6\u7279\u5f81"
        }, 
        {
            "location": "/other/application/#vgg19", 
            "text": "from keras.applications.vgg19 import VGG19\nfrom keras.preprocessing import image\nfrom keras.applications.vgg19 import preprocess_input\nfrom keras.models import Model\nimport numpy as np\n\nbase_model = VGG19(weights='imagenet')\nmodel = Model(input=base_model.input, output=base_model.get_layer('block4_pool').output)\n\nimg_path = 'elephant.jpg'\nimg = image.load_img(img_path, target_size=(224, 224))\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis=0)\nx = preprocess_input(x)\n\nblock4_pool_features = model.predict(x)", 
            "title": "\u4eceVGG19\u7684\u4efb\u610f\u4e2d\u95f4\u5c42\u4e2d\u62bd\u53d6\u7279\u5f81"
        }, 
        {
            "location": "/other/application/#finetune-inceptionv3", 
            "text": "from keras.applications.inception_v3 import InceptionV3\nfrom keras.preprocessing import image\nfrom keras.models import Model\nfrom keras.layers import Dense, GlobalAveragePooling2D\nfrom keras import backend as K\n\n# create the base pre-trained model\nbase_model = InceptionV3(weights='imagenet', include_top=False)\n\n# add a global spatial average pooling layer\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\n# let's add a fully-connected layer\nx = Dense(1024, activation='relu')(x)\n# and a logistic layer -- let's say we have 200 classes\npredictions = Dense(200, activation='softmax')(x)\n\n# this is the model we will train\nmodel = Model(input=base_model.input, output=predictions)\n\n# first: train only the top layers (which were randomly initialized)\n# i.e. freeze all convolutional InceptionV3 layers\nfor layer in base_model.layers:\n    layer.trainable = False\n\n# compile the model (should be done *after* setting layers to non-trainable)\nmodel.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n\n# train the model on the new data for a few epochs\nmodel.fit_generator(...)\n\n# at this point, the top layers are well trained and we can start fine-tuning\n# convolutional layers from inception V3. We will freeze the bottom N layers\n# and train the remaining top layers.\n\n# let's visualize layer names and layer indices to see how many layers\n# we should freeze:\nfor i, layer in enumerate(base_model.layers):\n   print(i, layer.name)\n\n# we chose to train the top 2 inception blocks, i.e. we will freeze\n# the first 172 layers and unfreeze the rest:\nfor layer in model.layers[:172]:\n   layer.trainable = False\nfor layer in model.layers[172:]:\n   layer.trainable = True\n\n# we need to recompile the model for these modifications to take effect\n# we use SGD with a low learning rate\nfrom keras.optimizers import SGD\nmodel.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy')\n\n# we train our model again (this time fine-tuning the top 2 inception blocks\n# alongside the top Dense layers\nmodel.fit_generator(...)", 
            "title": "\u5229\u7528\u65b0\u6570\u636e\u96c6finetune InceptionV3"
        }, 
        {
            "location": "/other/application/#tensorinceptionv3", 
            "text": "from keras.applications.inception_v3 import InceptionV3\nfrom keras.layers import Input\n\n# this could also be the output a different Keras model or layer\ninput_tensor = Input(shape=(224, 224, 3))  # this assumes K.image_dim_ordering() == 'tf'\n\nmodel = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=True)", 
            "title": "\u5728\u5b9a\u5236\u7684\u8f93\u5165tensor\u4e0a\u6784\u5efaInceptionV3"
        }, 
        {
            "location": "/other/application/#_3", 
            "text": "Xception  VGG16  VGG19  ResNet50  InceptionV3  MusicTaggerCRNN", 
            "title": "\u6a21\u578b\u6587\u6863"
        }, 
        {
            "location": "/other/application/#xception", 
            "text": "keras.applications.xception.Xception(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, classes=1000)  Xception V1 \u6a21\u578b, \u6743\u91cd\u7531ImageNet\u8bad\u7ec3\u800c\u8a00  \u5728ImageNet\u4e0a,\u8be5\u6a21\u578b\u53d6\u5f97\u4e86\u9a8c\u8bc1\u96c6top1 0.790\u548ctop5 0.945\u7684\u6b63\u786e\u7387  \u6ce8\u610f,\u8be5\u6a21\u578b\u76ee\u524d\u4ec5\u80fd\u4ee5TensorFlow\u4e3a\u540e\u7aef\u4f7f\u7528,\u7531\u4e8e\u5b83\u4f9d\u8d56\u4e8e\"SeparableConvolution\"\u5c42,\u76ee\u524d\u8be5\u6a21\u578b\u53ea\u652f\u6301tf\u7684\u7ef4\u5ea6\u987a\u5e8f(width, height, channels)  \u9ed8\u8ba4\u8f93\u5165\u56fe\u7247\u5927\u5c0f\u4e3a299x299", 
            "title": "Xception\u6a21\u578b"
        }, 
        {
            "location": "/other/application/#_4", 
            "text": "include_top\uff1a\u662f\u5426\u4fdd\u7559\u9876\u5c42\u76843\u4e2a\u5168\u8fde\u63a5\u7f51\u7edc  weights\uff1aNone\u4ee3\u8868\u968f\u673a\u521d\u59cb\u5316\uff0c\u5373\u4e0d\u52a0\u8f7d\u9884\u8bad\u7ec3\u6743\u91cd\u3002'imagenet'\u4ee3\u8868\u52a0\u8f7d\u9884\u8bad\u7ec3\u6743\u91cd  input_tensor\uff1a\u53ef\u586b\u5165Keras tensor\u4f5c\u4e3a\u6a21\u578b\u7684\u56fe\u50cf\u8f93\u51fatensor  input_shape\uff1a\u53ef\u9009\uff0c\u4ec5\u5f53 include_top=False \u6709\u6548\uff0c\u5e94\u4e3a\u957f\u4e3a3\u7684tuple\uff0c\u6307\u660e\u8f93\u5165\u56fe\u7247\u7684shape\uff0c\u56fe\u7247\u7684\u5bbd\u9ad8\u5fc5\u987b\u5927\u4e8e71\uff0c\u5982(150,150,3)  classes\uff1a\u53ef\u9009\uff0c\u56fe\u7247\u5206\u7c7b\u7684\u7c7b\u522b\u6570\uff0c\u4ec5\u5f53 include_top=True \u5e76\u4e14\u4e0d\u52a0\u8f7d\u9884\u8bad\u7ec3\u6743\u91cd\u65f6\u53ef\u7528\u3002", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/other/application/#_5", 
            "text": "Keras \u6a21\u578b\u5bf9\u8c61", 
            "title": "\u8fd4\u56de\u503c"
        }, 
        {
            "location": "/other/application/#_6", 
            "text": "Xception: Deep Learning with Depthwise Separable Convolutions", 
            "title": "\u53c2\u8003\u6587\u732e"
        }, 
        {
            "location": "/other/application/#license", 
            "text": "\u9884\u8bad\u7ec3\u6743\u91cd\u7531\u6211\u4eec\u81ea\u5df1\u8bad\u7ec3\u800c\u6765\uff0c\u57fa\u4e8eMIT license\u53d1\u5e03", 
            "title": "License"
        }, 
        {
            "location": "/other/application/#vgg16_1", 
            "text": "keras.applications.vgg16.VGG16(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, classes=1000)  VGG16\u6a21\u578b,\u6743\u91cd\u7531ImageNet\u8bad\u7ec3\u800c\u6765  \u8be5\u6a21\u578b\u518dTheano\u548cTensorFlow\u540e\u7aef\u5747\u53ef\u4f7f\u7528,\u5e76\u63a5\u53d7th\u548ctf\u4e24\u79cd\u8f93\u5165\u7ef4\u5ea6\u987a\u5e8f  \u6a21\u578b\u7684\u9ed8\u8ba4\u8f93\u5165\u5c3a\u5bf8\u65f6224x224", 
            "title": "VGG16\u6a21\u578b"
        }, 
        {
            "location": "/other/application/#_7", 
            "text": "include_top\uff1a\u662f\u5426\u4fdd\u7559\u9876\u5c42\u76843\u4e2a\u5168\u8fde\u63a5\u7f51\u7edc  weights\uff1aNone\u4ee3\u8868\u968f\u673a\u521d\u59cb\u5316\uff0c\u5373\u4e0d\u52a0\u8f7d\u9884\u8bad\u7ec3\u6743\u91cd\u3002'imagenet'\u4ee3\u8868\u52a0\u8f7d\u9884\u8bad\u7ec3\u6743\u91cd  input_tensor\uff1a\u53ef\u586b\u5165Keras tensor\u4f5c\u4e3a\u6a21\u578b\u7684\u56fe\u50cf\u8f93\u51fatensor  input_shape\uff1a\u53ef\u9009\uff0c\u4ec5\u5f53 include_top=False \u6709\u6548\uff0c\u5e94\u4e3a\u957f\u4e3a3\u7684tuple\uff0c\u6307\u660e\u8f93\u5165\u56fe\u7247\u7684shape\uff0c\u56fe\u7247\u7684\u5bbd\u9ad8\u5fc5\u987b\u5927\u4e8e48\uff0c\u5982(200,200,3)", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/other/application/#_8", 
            "text": "classes\uff1a\u53ef\u9009\uff0c\u56fe\u7247\u5206\u7c7b\u7684\u7c7b\u522b\u6570\uff0c\u4ec5\u5f53 include_top=True \u5e76\u4e14\u4e0d\u52a0\u8f7d\u9884\u8bad\u7ec3\u6743\u91cd\u65f6\u53ef\u7528\u3002   Keras \u6a21\u578b\u5bf9\u8c61", 
            "title": "\u8fd4\u56de\u503c"
        }, 
        {
            "location": "/other/application/#_9", 
            "text": "Very Deep Convolutional Networks for Large-Scale Image Recognition \uff1a\u5982\u679c\u5728\u7814\u7a76\u4e2d\u4f7f\u7528\u4e86VGG\uff0c\u8bf7\u5f15\u7528\u8be5\u6587", 
            "title": "\u53c2\u8003\u6587\u732e"
        }, 
        {
            "location": "/other/application/#license_1", 
            "text": "\u9884\u8bad\u7ec3\u6743\u91cd\u7531 \u725b\u6d25VGG\u7ec4 \u53d1\u5e03\u7684\u9884\u8bad\u7ec3\u6743\u91cd\u79fb\u690d\u800c\u6765\uff0c\u57fa\u4e8e Creative Commons Attribution License", 
            "title": "License"
        }, 
        {
            "location": "/other/application/#vgg19_1", 
            "text": "keras.applications.vgg19.VGG19(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, classes=1000)  VGG19\u6a21\u578b,\u6743\u91cd\u7531ImageNet\u8bad\u7ec3\u800c\u6765  \u8be5\u6a21\u578b\u518dTheano\u548cTensorFlow\u540e\u7aef\u5747\u53ef\u4f7f\u7528,\u5e76\u63a5\u53d7th\u548ctf\u4e24\u79cd\u8f93\u5165\u7ef4\u5ea6\u987a\u5e8f  \u6a21\u578b\u7684\u9ed8\u8ba4\u8f93\u5165\u5c3a\u5bf8\u65f6224x224", 
            "title": "VGG19\u6a21\u578b"
        }, 
        {
            "location": "/other/application/#_10", 
            "text": "include_top\uff1a\u662f\u5426\u4fdd\u7559\u9876\u5c42\u76843\u4e2a\u5168\u8fde\u63a5\u7f51\u7edc  weights\uff1aNone\u4ee3\u8868\u968f\u673a\u521d\u59cb\u5316\uff0c\u5373\u4e0d\u52a0\u8f7d\u9884\u8bad\u7ec3\u6743\u91cd\u3002'imagenet'\u4ee3\u8868\u52a0\u8f7d\u9884\u8bad\u7ec3\u6743\u91cd  input_tensor\uff1a\u53ef\u586b\u5165Keras tensor\u4f5c\u4e3a\u6a21\u578b\u7684\u56fe\u50cf\u8f93\u51fatensor  input_shape\uff1a\u53ef\u9009\uff0c\u4ec5\u5f53 include_top=False \u6709\u6548\uff0c\u5e94\u4e3a\u957f\u4e3a3\u7684tuple\uff0c\u6307\u660e\u8f93\u5165\u56fe\u7247\u7684shape\uff0c\u56fe\u7247\u7684\u5bbd\u9ad8\u5fc5\u987b\u5927\u4e8e48\uff0c\u5982(200,200,3)  classes\uff1a\u53ef\u9009\uff0c\u56fe\u7247\u5206\u7c7b\u7684\u7c7b\u522b\u6570\uff0c\u4ec5\u5f53 include_top=True \u5e76\u4e14\u4e0d\u52a0\u8f7d\u9884\u8bad\u7ec3\u6743\u91cd\u65f6\u53ef\u7528\u3002", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/other/application/#_11", 
            "text": "", 
            "title": "\u8fd4\u56de\u503c"
        }, 
        {
            "location": "/other/application/#_12", 
            "text": "Keras \u6a21\u578b\u5bf9\u8c61", 
            "title": "\u8fd4\u56de\u503c"
        }, 
        {
            "location": "/other/application/#_13", 
            "text": "Very Deep Convolutional Networks for Large-Scale Image Recognition \uff1a\u5982\u679c\u5728\u7814\u7a76\u4e2d\u4f7f\u7528\u4e86VGG\uff0c\u8bf7\u5f15\u7528\u8be5\u6587", 
            "title": "\u53c2\u8003\u6587\u732e"
        }, 
        {
            "location": "/other/application/#license_2", 
            "text": "\u9884\u8bad\u7ec3\u6743\u91cd\u7531 \u725b\u6d25VGG\u7ec4 \u53d1\u5e03\u7684\u9884\u8bad\u7ec3\u6743\u91cd\u79fb\u690d\u800c\u6765\uff0c\u57fa\u4e8e Creative Commons Attribution License", 
            "title": "License"
        }, 
        {
            "location": "/other/application/#resnet50", 
            "text": "keras.applications.resnet50.ResNet50(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, classes=1000)  50\u5c42\u6b8b\u5dee\u7f51\u7edc\u6a21\u578b,\u6743\u91cd\u8bad\u7ec3\u81eaImageNet  \u8be5\u6a21\u578b\u518dTheano\u548cTensorFlow\u540e\u7aef\u5747\u53ef\u4f7f\u7528,\u5e76\u63a5\u53d7th\u548ctf\u4e24\u79cd\u8f93\u5165\u7ef4\u5ea6\u987a\u5e8f  \u6a21\u578b\u7684\u9ed8\u8ba4\u8f93\u5165\u5c3a\u5bf8\u65f6224x224", 
            "title": "ResNet50\u6a21\u578b"
        }, 
        {
            "location": "/other/application/#_14", 
            "text": "include_top\uff1a\u662f\u5426\u4fdd\u7559\u9876\u5c42\u7684\u5168\u8fde\u63a5\u7f51\u7edc  weights\uff1aNone\u4ee3\u8868\u968f\u673a\u521d\u59cb\u5316\uff0c\u5373\u4e0d\u52a0\u8f7d\u9884\u8bad\u7ec3\u6743\u91cd\u3002'imagenet'\u4ee3\u8868\u52a0\u8f7d\u9884\u8bad\u7ec3\u6743\u91cd  input_tensor\uff1a\u53ef\u586b\u5165Keras tensor\u4f5c\u4e3a\u6a21\u578b\u7684\u56fe\u50cf\u8f93\u51fatensor  input_shape\uff1a\u53ef\u9009\uff0c\u4ec5\u5f53 include_top=False \u6709\u6548\uff0c\u5e94\u4e3a\u957f\u4e3a3\u7684tuple\uff0c\u6307\u660e\u8f93\u5165\u56fe\u7247\u7684shape\uff0c\u56fe\u7247\u7684\u5bbd\u9ad8\u5fc5\u987b\u5927\u4e8e197\uff0c\u5982(200,200,3)  classes\uff1a\u53ef\u9009\uff0c\u56fe\u7247\u5206\u7c7b\u7684\u7c7b\u522b\u6570\uff0c\u4ec5\u5f53 include_top=True \u5e76\u4e14\u4e0d\u52a0\u8f7d\u9884\u8bad\u7ec3\u6743\u91cd\u65f6\u53ef\u7528\u3002", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/other/application/#_15", 
            "text": "Keras \u6a21\u578b\u5bf9\u8c61", 
            "title": "\u8fd4\u56de\u503c"
        }, 
        {
            "location": "/other/application/#_16", 
            "text": "Deep Residual Learning for Image Recognition \uff1a\u5982\u679c\u5728\u7814\u7a76\u4e2d\u4f7f\u7528\u4e86ResNet50\uff0c\u8bf7\u5f15\u7528\u8be5\u6587", 
            "title": "\u53c2\u8003\u6587\u732e"
        }, 
        {
            "location": "/other/application/#license_3", 
            "text": "\u9884\u8bad\u7ec3\u6743\u91cd\u7531 Kaiming He \u53d1\u5e03\u7684\u9884\u8bad\u7ec3\u6743\u91cd\u79fb\u690d\u800c\u6765\uff0c\u57fa\u4e8e MIT License", 
            "title": "License"
        }, 
        {
            "location": "/other/application/#inceptionv3", 
            "text": "keras.applications.inception_v3.InceptionV3(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, classes=1000)  InceptionV3\u7f51\u7edc,\u6743\u91cd\u8bad\u7ec3\u81eaImageNet  \u8be5\u6a21\u578b\u518dTheano\u548cTensorFlow\u540e\u7aef\u5747\u53ef\u4f7f\u7528,\u5e76\u63a5\u53d7th\u548ctf\u4e24\u79cd\u8f93\u5165\u7ef4\u5ea6\u987a\u5e8f  \u6a21\u578b\u7684\u9ed8\u8ba4\u8f93\u5165\u5c3a\u5bf8\u65f6299x299", 
            "title": "InceptionV3\u6a21\u578b"
        }, 
        {
            "location": "/other/application/#_17", 
            "text": "include_top\uff1a\u662f\u5426\u4fdd\u7559\u9876\u5c42\u7684\u5168\u8fde\u63a5\u7f51\u7edc  weights\uff1aNone\u4ee3\u8868\u968f\u673a\u521d\u59cb\u5316\uff0c\u5373\u4e0d\u52a0\u8f7d\u9884\u8bad\u7ec3\u6743\u91cd\u3002'imagenet'\u4ee3\u8868\u52a0\u8f7d\u9884\u8bad\u7ec3\u6743\u91cd  input_tensor\uff1a\u53ef\u586b\u5165Keras tensor\u4f5c\u4e3a\u6a21\u578b\u7684\u56fe\u50cf\u8f93\u51fatensor  classes\uff1a\u53ef\u9009\uff0c\u56fe\u7247\u5206\u7c7b\u7684\u7c7b\u522b\u6570\uff0c\u4ec5\u5f53 include_top=True \u5e76\u4e14\u4e0d\u52a0\u8f7d\u9884\u8bad\u7ec3\u6743\u91cd\u65f6\u53ef\u7528\u3002", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/other/application/#_18", 
            "text": "Keras \u6a21\u578b\u5bf9\u8c61", 
            "title": "\u8fd4\u56de\u503c"
        }, 
        {
            "location": "/other/application/#_19", 
            "text": "Rethinking the Inception Architecture for Computer Vision \uff1a\u5982\u679c\u5728\u7814\u7a76\u4e2d\u4f7f\u7528\u4e86InceptionV3\uff0c\u8bf7\u5f15\u7528\u8be5\u6587", 
            "title": "\u53c2\u8003\u6587\u732e"
        }, 
        {
            "location": "/other/application/#license_4", 
            "text": "\u9884\u8bad\u7ec3\u6743\u91cd\u7531\u6211\u4eec\u81ea\u5df1\u8bad\u7ec3\u800c\u6765\uff0c\u57fa\u4e8e MIT License", 
            "title": "License"
        }, 
        {
            "location": "/other/application/#musictaggercrnn", 
            "text": "keras.applications.music_tagger_crnn.MusicTaggerCRNN(weights='msd', input_tensor=None, include_top=True, classes=50)  \u8be5\u6a21\u578b\u65f6\u4e00\u4e2a\u5377\u79ef\u5faa\u73af\u6a21\u578b,\u4ee5\u5411\u91cf\u5316\u7684MelSpectrogram\u97f3\u4e50\u6570\u636e\u4e3a\u8f93\u5165,\u80fd\u591f\u8f93\u51fa\u97f3\u4e50\u7684\u98ce\u683c. \u4f60\u53ef\u4ee5\u7528 keras.applications.music_tagger_crnn.preprocess_input \u6765\u5c06\u4e00\u4e2a\u97f3\u4e50\u6587\u4ef6\u5411\u91cf\u5316\u4e3aspectrogram.\u6ce8\u610f,\u4f7f\u7528\u8be5\u529f\u80fd\u9700\u8981\u5b89\u88c5 Librosa ,\u8bf7\u53c2\u8003\u4e0b\u9762\u7684\u4f7f\u7528\u8303\u4f8b.", 
            "title": "MusicTaggerCRNN\u6a21\u578b"
        }, 
        {
            "location": "/other/application/#_20", 
            "text": "include_top\uff1a\u662f\u5426\u4fdd\u7559\u9876\u5c42\u76841\u5c42\u5168\u8fde\u63a5\u7f51\u7edc,\u82e5\u8bbe\u7f6e\u4e3aFalse,\u5219\u7f51\u7edc\u8f93\u51fa32\u7ef4\u7684\u7279\u5f81  weights\uff1aNone\u4ee3\u8868\u968f\u673a\u521d\u59cb\u5316\uff0c\u5373\u4e0d\u52a0\u8f7d\u9884\u8bad\u7ec3\u6743\u91cd\u3002'msd'\u4ee3\u8868\u52a0\u8f7d\u9884\u8bad\u7ec3\u6743\u91cd(\u8bad\u7ec3\u81ea Million Song Dataset )  input_tensor\uff1a\u53ef\u586b\u5165Keras tensor\u4f5c\u4e3a\u6a21\u578b\u7684\u8f93\u51fatensor,\u5982\u4f7f\u7528layer.input\u9009\u7528\u4e00\u5c42\u7684\u8f93\u5165\u5f20\u91cf\u4e3a\u6a21\u578b\u7684\u8f93\u5165\u5f20\u91cf.", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/other/application/#_21", 
            "text": "Keras \u6a21\u578b\u5bf9\u8c61", 
            "title": "\u8fd4\u56de\u503c"
        }, 
        {
            "location": "/other/application/#_22", 
            "text": "Convolutional Recurrent Neural Networks for Music Classification", 
            "title": "\u53c2\u8003\u6587\u732e"
        }, 
        {
            "location": "/other/application/#license_5", 
            "text": "\u9884\u8bad\u7ec3\u6743\u91cd\u7531\u6211\u4eec\u81ea\u5df1\u8bad\u7ec3\u800c\u6765\uff0c\u57fa\u4e8e MIT License", 
            "title": "License"
        }, 
        {
            "location": "/other/application/#_23", 
            "text": "from keras.applications.music_tagger_crnn import MusicTaggerCRNN\nfrom keras.applications.music_tagger_crnn import preprocess_input, decode_predictions\nimport numpy as np\n\n# 1. Tagging\nmodel = MusicTaggerCRNN(weights='msd')\n\naudio_path = 'audio_file.mp3'\nmelgram = preprocess_input(audio_path)\nmelgrams = np.expand_dims(melgram, axis=0)\n\npreds = model.predict(melgrams)\nprint('Predicted:')\nprint(decode_predictions(preds))\n# print: ('Predicted:', [[('rock', 0.097071797), ('pop', 0.042456303), ('alternative', 0.032439161), ('indie', 0.024491295), ('female vocalists', 0.016455274)]])\n\n#. 2. Feature extraction\nmodel = MusicTaggerCRNN(weights='msd', include_top=False)\n\naudio_path = 'audio_file.mp3'\nmelgram = preprocess_input(audio_path)\nmelgrams = np.expand_dims(melgram, axis=0)\n\nfeats = model.predict(melgrams)\nprint('Features:')\nprint(feats[0, :10])\n# print: ('Features:', [-0.19160545 0.94259131 -0.9991011 0.47644514 -0.19089699 0.99033844 0.1103896 -0.00340496 0.14823607 0.59856361])", 
            "title": "\u4f7f\u7528\u8303\u4f8b:\u97f3\u4e50\u7279\u5f81\u62bd\u53d6\u4e0e\u98ce\u683c\u6807\u5b9a"
        }, 
        {
            "location": "/other/datasets/", 
            "text": "\u5e38\u7528\u6570\u636e\u5e93\n\n\nCIFAR10 \u5c0f\u56fe\u7247\u5206\u7c7b\u6570\u636e\u96c6\n\n\n\u8be5\u6570\u636e\u5e93\u5177\u670950,000\u4e2a32*32\u7684\u5f69\u8272\u56fe\u7247\u4f5c\u4e3a\u8bad\u7ec3\u96c6\uff0c10,000\u4e2a\u56fe\u7247\u4f5c\u4e3a\u6d4b\u8bd5\u96c6\u3002\u56fe\u7247\u4e00\u5171\u670910\u4e2a\u7c7b\u522b\u3002\n\n\n\u4f7f\u7528\u65b9\u6cd5\n\n\nfrom keras.datasets import cifar10\n\n(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n\n\n\n\n\u8fd4\u56de\u503c\uff1a\n\n\n\u4e24\u4e2aTuple\n\n\nX_train\n\u548c\nX_test\n\u662f\u5f62\u5982\uff08nb_samples, 3, 32, 32\uff09\u7684RGB\u4e09\u901a\u9053\u56fe\u50cf\u6570\u636e\uff0c\u6570\u636e\u7c7b\u578b\u662f\u65e0\u7b26\u53f78\u4f4d\u6574\u5f62\uff08uint8\uff09\n\n\nY_train\n\u548c \nY_test\n\u662f\u5f62\u5982\uff08nb_samples,\uff09\u6807\u7b7e\u6570\u636e\uff0c\u6807\u7b7e\u7684\u8303\u56f4\u662f0~9\n\n\n\n\nCIFAR100 \u5c0f\u56fe\u7247\u5206\u7c7b\u6570\u636e\u5e93\n\n\n\u8be5\u6570\u636e\u5e93\u5177\u670950,000\u4e2a32*32\u7684\u5f69\u8272\u56fe\u7247\u4f5c\u4e3a\u8bad\u7ec3\u96c6\uff0c10,000\u4e2a\u56fe\u7247\u4f5c\u4e3a\u6d4b\u8bd5\u96c6\u3002\u56fe\u7247\u4e00\u5171\u6709100\u4e2a\u7c7b\u522b\uff0c\u6bcf\u4e2a\u7c7b\u522b\u6709600\u5f20\u56fe\u7247\u3002\u8fd9100\u4e2a\u7c7b\u522b\u53c8\u5206\u4e3a20\u4e2a\u5927\u7c7b\u3002\n\n\n\u4f7f\u7528\u65b9\u6cd5\n\n\nfrom keras.datasets import cifar100\n\n(X_train, y_train), (X_test, y_test) = cifar100.load_data(label_mode='fine')\n\n\n\n\n\u53c2\u6570\n\n\n\n\nlabel_mode\uff1a\u4e3a\u2018fine\u2019\u6216\u2018coarse\u2019\u4e4b\u4e00\uff0c\u63a7\u5236\u6807\u7b7e\u7684\u7cbe\u7ec6\u5ea6\uff0c\u2018fine\u2019\u83b7\u5f97\u7684\u6807\u7b7e\u662f100\u4e2a\u5c0f\u7c7b\u7684\u6807\u7b7e\uff0c\u2018coarse\u2019\u83b7\u5f97\u7684\u6807\u7b7e\u662f\u5927\u7c7b\u7684\u6807\u7b7e\n\n\n\n\n\u8fd4\u56de\u503c\n\n\n\u4e24\u4e2aTuple,\n(X_train, y_train), (X_test, y_test)\n\uff0c\u5176\u4e2d\n\n\n\n\n\n\nX_train\u548cX_test\uff1a\u662f\u5f62\u5982\uff08nb_samples, 3, 32, 32\uff09\u7684RGB\u4e09\u901a\u9053\u56fe\u50cf\u6570\u636e\uff0c\u6570\u636e\u7c7b\u578b\u662f\u65e0\u7b26\u53f78\u4f4d\u6574\u5f62\uff08uint8\uff09\n\n\n\n\n\n\ny_train\u548cy_test\uff1a\u662f\u5f62\u5982\uff08nb_samples,\uff09\u6807\u7b7e\u6570\u636e\uff0c\u6807\u7b7e\u7684\u8303\u56f4\u662f0~9\n\n\n\n\n\n\n\n\nIMDB\u5f71\u8bc4\u503e\u5411\u5206\u7c7b\n\n\n\u672c\u6570\u636e\u5e93\u542b\u6709\u6765\u81eaIMDB\u768425,000\u6761\u5f71\u8bc4\uff0c\u88ab\u6807\u8bb0\u4e3a\u6b63\u9762/\u8d1f\u9762\u4e24\u79cd\u8bc4\u4ef7\u3002\u5f71\u8bc4\u5df2\u88ab\u9884\u5904\u7406\u4e3a\u8bcd\u4e0b\u6807\u6784\u6210\u7684\n\u5e8f\u5217\n\u3002\u65b9\u4fbf\u8d77\u89c1\uff0c\u5355\u8bcd\u7684\u4e0b\u6807\u57fa\u4e8e\u5b83\u5728\u6570\u636e\u96c6\u4e2d\u51fa\u73b0\u7684\u9891\u7387\u6807\u5b9a\uff0c\u4f8b\u5982\u6574\u65703\u6240\u7f16\u7801\u7684\u8bcd\u4e3a\u6570\u636e\u96c6\u4e2d\u7b2c3\u5e38\u51fa\u73b0\u7684\u8bcd\u3002\u8fd9\u6837\u7684\u7ec4\u7ec7\u65b9\u6cd5\u4f7f\u5f97\u7528\u6237\u53ef\u4ee5\u5feb\u901f\u5b8c\u6210\u8bf8\u5982\u201c\u53ea\u8003\u8651\u6700\u5e38\u51fa\u73b0\u768410,000\u4e2a\u8bcd\uff0c\u4f46\u4e0d\u8003\u8651\u6700\u5e38\u51fa\u73b0\u768420\u4e2a\u8bcd\u201d\u8fd9\u6837\u7684\u64cd\u4f5c\n\n\n\u6309\u7167\u60ef\u4f8b\uff0c0\u4e0d\u4ee3\u8868\u4efb\u4f55\u7279\u5b9a\u7684\u8bcd\uff0c\u800c\u7528\u6765\u7f16\u7801\u4efb\u4f55\u672a\u77e5\u5355\u8bcd\n\n\n\u4f7f\u7528\u65b9\u6cd5\n\n\nfrom keras.datasets import imdb\n\n(X_train, y_train), (X_test, y_test) = imdb.load_data(path=\nimdb_full.pkl\n,\n                                                      nb_words=None,\n                                                      skip_top=0,\n                                                      maxlen=None,\n                                                      test_split=0.1)\n                                                      seed=113,\n                                                      start_char=1,\n                                                      oov_char=2,\n                                                      index_from=3)\n\n\n\n\n\u53c2\u6570\n\n\n\n\n\n\npath\uff1a\u5982\u679c\u4f60\u5728\u672c\u673a\u4e0a\u5df2\u6709\u6b64\u6570\u636e\u96c6\uff08\u4f4d\u4e8e\n'~/.keras/datasets/'+path\n\uff09\uff0c\u5219\u8f7d\u5165\u3002\u5426\u5219\u6570\u636e\u5c06\u4e0b\u8f7d\u5230\u8be5\u76ee\u5f55\u4e0b\n\n\n\n\n\n\nnb_words\uff1a\u6574\u6570\u6216None\uff0c\u8981\u8003\u8651\u7684\u6700\u5e38\u89c1\u7684\u5355\u8bcd\u6570\uff0c\u4efb\u4f55\u51fa\u73b0\u9891\u7387\u66f4\u4f4e\u7684\u5355\u8bcd\u5c06\u4f1a\u88ab\u7f16\u7801\u52300\u7684\u4f4d\u7f6e\u3002\n\n\n\n\n\n\nskip_top\uff1a\u6574\u6570\uff0c\u5ffd\u7565\u6700\u5e38\u51fa\u73b0\u7684\u82e5\u5e72\u5355\u8bcd\uff0c\u8fd9\u4e9b\u5355\u8bcd\u5c06\u4f1a\u88ab\u7f16\u7801\u4e3a0\n\n\n\n\n\n\nmaxlen\uff1a\u6574\u6570\uff0c\u6700\u5927\u5e8f\u5217\u957f\u5ea6\uff0c\u4efb\u4f55\u957f\u5ea6\u5927\u4e8e\u6b64\u503c\u7684\u5e8f\u5217\u5c06\u88ab\u622a\u65ad\n\n\n\n\n\n\nseed\uff1a\u6574\u6570\uff0c\u7528\u4e8e\u6570\u636e\u91cd\u6392\u7684\u968f\u673a\u6570\u79cd\u5b50\n\n\n\n\n\n\nstart_char\uff1a\u5b57\u7b26\uff0c\u5e8f\u5217\u7684\u8d77\u59cb\u5c06\u4ee5\u8be5\u5b57\u7b26\u6807\u8bb0\uff0c\u9ed8\u8ba4\u4e3a1\u56e0\u4e3a0\u901a\u5e38\u7528\u4f5cpadding\n\n\n\n\n\n\noov_char\uff1a\u5b57\u7b26\uff0c\u56e0\nnb_words\n\u6216\nskip_top\n\u9650\u5236\u800ccut\u6389\u7684\u5355\u8bcd\u5c06\u88ab\u8be5\u5b57\u7b26\u4ee3\u66ff\n\n\n\n\n\n\nindex_from\uff1a\u6574\u6570\uff0c\u771f\u5b9e\u7684\u5355\u8bcd\uff08\u800c\u4e0d\u662f\u7c7b\u4f3c\u4e8e\nstart_char\n\u7684\u7279\u6b8a\u5360\u4f4d\u7b26\uff09\u5c06\u4ece\u8fd9\u4e2a\u4e0b\u6807\u5f00\u59cb\n\n\n\n\n\n\n\u8fd4\u56de\u503c\n\n\n\u4e24\u4e2aTuple,\n(X_train, y_train), (X_test, y_test)\n\uff0c\u5176\u4e2d\n\n\n\n\n\n\nX_train\u548cX_test\uff1a\u5e8f\u5217\u7684\u5217\u8868\uff0c\u6bcf\u4e2a\u5e8f\u5217\u90fd\u662f\u8bcd\u4e0b\u6807\u7684\u5217\u8868\u3002\u5982\u679c\u6307\u5b9a\u4e86\nnb_words\n\uff0c\u5219\u5e8f\u5217\u4e2d\u53ef\u80fd\u7684\u6700\u5927\u4e0b\u6807\u4e3a\nnb_words-1\n\u3002\u5982\u679c\u6307\u5b9a\u4e86\nmaxlen\n\uff0c\u5219\u5e8f\u5217\u7684\u6700\u5927\u53ef\u80fd\u957f\u5ea6\u4e3a\nmaxlen\n\n\n\n\n\n\ny_train\u548cy_test\uff1a\u4e3a\u5e8f\u5217\u7684\u6807\u7b7e\uff0c\u662f\u4e00\u4e2a\u4e8c\u503clist\n\n\n\n\n\n\n\n\n\u8def\u900f\u793e\u65b0\u95fb\u4e3b\u9898\u5206\u7c7b\n\n\n\u672c\u6570\u636e\u5e93\u5305\u542b\u6765\u81ea\u8def\u900f\u793e\u768411,228\u6761\u65b0\u95fb\uff0c\u5206\u4e3a\u4e8646\u4e2a\u4e3b\u9898\u3002\u4e0eIMDB\u5e93\u4e00\u6837\uff0c\u6bcf\u6761\u65b0\u95fb\u88ab\u7f16\u7801\u4e3a\u4e00\u4e2a\u8bcd\u4e0b\u6807\u7684\u5e8f\u5217\u3002\n\n\n\u4f7f\u7528\u65b9\u6cd5\n\n\nfrom keras.datasets import reuters\n\n\n(X_train, y_train), (X_test, y_test) = reuters.load_data(path=\nreuters.pkl\n,\n                                                         nb_words=None,\n                                                         skip_top=0,\n                                                         maxlen=None,\n                                                         test_split=0.2,\n                                                         seed=113,\n                                                         start_char=1,\n                                                         oov_char=2,\n                                                         index_from=3)\n\n\n\n\n\u53c2\u6570\u7684\u542b\u4e49\u4e0eIMDB\u540c\u540d\u53c2\u6570\u76f8\u540c\uff0c\u552f\u4e00\u591a\u7684\u53c2\u6570\u662f\uff1a\n\ntest_split\n\uff0c\u7528\u4e8e\u6307\u5b9a\u4ece\u539f\u6570\u636e\u4e2d\u5206\u5272\u51fa\u4f5c\u4e3a\u6d4b\u8bd5\u96c6\u7684\u6bd4\u4f8b\u3002\u8be5\u6570\u636e\u5e93\u652f\u6301\u83b7\u53d6\u7528\u4e8e\u7f16\u7801\u5e8f\u5217\u7684\u8bcd\u4e0b\u6807\uff1a\n\n\nword_index = reuters.get_word_index(path=\nreuters_word_index.pkl\n)\n\n\n\n\n\u4e0a\u9762\u4ee3\u7801\u7684\u8fd4\u56de\u503c\u662f\u4e00\u4e2a\u4ee5\u5355\u8bcd\u4e3a\u5173\u952e\u5b57\uff0c\u4ee5\u5176\u4e0b\u6807\u4e3a\u503c\u7684\u5b57\u5178\u3002\u4f8b\u5982\uff0c\nword_index['giraffe']\n\u7684\u503c\u53ef\u80fd\u4e3a\n1234\n\n\n\u6570\u636e\u5e93\u5c06\u4f1a\u88ab\u4e0b\u8f7d\u5230\n'~/.keras/datasets/'+path\n\n\n\n\nMNIST\u624b\u5199\u6570\u5b57\u8bc6\u522b\n\n\n\u672c\u6570\u636e\u5e93\u670960,000\u4e2a\u7528\u4e8e\u8bad\u7ec3\u768428*28\u7684\u7070\u5ea6\u624b\u5199\u6570\u5b57\u56fe\u7247\uff0c10,000\u4e2a\u6d4b\u8bd5\u56fe\u7247\n\n\n\u4f7f\u7528\u65b9\u6cd5\n\n\nfrom keras.datasets import mnist\n\n(X_train, y_train), (X_test, y_test) = mnist.load_data()\n\n\n\n\n\u8fd4\u56de\u503c\n\n\n\u4e24\u4e2aTuple,\n(X_train, y_train), (X_test, y_test)\n\uff0c\u5176\u4e2d\n\n\n\n\n\n\nX_train\u548cX_test\uff1a\u662f\u5f62\u5982\uff08nb_samples, 28, 28\uff09\u7684\u7070\u5ea6\u56fe\u7247\u6570\u636e\uff0c\u6570\u636e\u7c7b\u578b\u662f\u65e0\u7b26\u53f78\u4f4d\u6574\u5f62\uff08uint8\uff09\n\n\n\n\n\n\ny_train\u548cy_test\uff1a\u662f\u5f62\u5982\uff08nb_samples,\uff09\u6807\u7b7e\u6570\u636e\uff0c\u6807\u7b7e\u7684\u8303\u56f4\u662f0~9\n\n\n\n\n\n\n\u6570\u636e\u5e93\u5c06\u4f1a\u88ab\u4e0b\u8f7d\u5230\n'~/.keras/datasets/'+path", 
            "title": "\u5e38\u7528\u6570\u636e\u5e93Dataset"
        }, 
        {
            "location": "/other/datasets/#_1", 
            "text": "", 
            "title": "\u5e38\u7528\u6570\u636e\u5e93"
        }, 
        {
            "location": "/other/datasets/#cifar10", 
            "text": "\u8be5\u6570\u636e\u5e93\u5177\u670950,000\u4e2a32*32\u7684\u5f69\u8272\u56fe\u7247\u4f5c\u4e3a\u8bad\u7ec3\u96c6\uff0c10,000\u4e2a\u56fe\u7247\u4f5c\u4e3a\u6d4b\u8bd5\u96c6\u3002\u56fe\u7247\u4e00\u5171\u670910\u4e2a\u7c7b\u522b\u3002", 
            "title": "CIFAR10 \u5c0f\u56fe\u7247\u5206\u7c7b\u6570\u636e\u96c6"
        }, 
        {
            "location": "/other/datasets/#_2", 
            "text": "from keras.datasets import cifar10\n\n(X_train, y_train), (X_test, y_test) = cifar10.load_data()", 
            "title": "\u4f7f\u7528\u65b9\u6cd5"
        }, 
        {
            "location": "/other/datasets/#_3", 
            "text": "\u4e24\u4e2aTuple  X_train \u548c X_test \u662f\u5f62\u5982\uff08nb_samples, 3, 32, 32\uff09\u7684RGB\u4e09\u901a\u9053\u56fe\u50cf\u6570\u636e\uff0c\u6570\u636e\u7c7b\u578b\u662f\u65e0\u7b26\u53f78\u4f4d\u6574\u5f62\uff08uint8\uff09  Y_train \u548c  Y_test \u662f\u5f62\u5982\uff08nb_samples,\uff09\u6807\u7b7e\u6570\u636e\uff0c\u6807\u7b7e\u7684\u8303\u56f4\u662f0~9", 
            "title": "\u8fd4\u56de\u503c\uff1a"
        }, 
        {
            "location": "/other/datasets/#cifar100", 
            "text": "\u8be5\u6570\u636e\u5e93\u5177\u670950,000\u4e2a32*32\u7684\u5f69\u8272\u56fe\u7247\u4f5c\u4e3a\u8bad\u7ec3\u96c6\uff0c10,000\u4e2a\u56fe\u7247\u4f5c\u4e3a\u6d4b\u8bd5\u96c6\u3002\u56fe\u7247\u4e00\u5171\u6709100\u4e2a\u7c7b\u522b\uff0c\u6bcf\u4e2a\u7c7b\u522b\u6709600\u5f20\u56fe\u7247\u3002\u8fd9100\u4e2a\u7c7b\u522b\u53c8\u5206\u4e3a20\u4e2a\u5927\u7c7b\u3002", 
            "title": "CIFAR100 \u5c0f\u56fe\u7247\u5206\u7c7b\u6570\u636e\u5e93"
        }, 
        {
            "location": "/other/datasets/#_4", 
            "text": "from keras.datasets import cifar100\n\n(X_train, y_train), (X_test, y_test) = cifar100.load_data(label_mode='fine')", 
            "title": "\u4f7f\u7528\u65b9\u6cd5"
        }, 
        {
            "location": "/other/datasets/#_5", 
            "text": "label_mode\uff1a\u4e3a\u2018fine\u2019\u6216\u2018coarse\u2019\u4e4b\u4e00\uff0c\u63a7\u5236\u6807\u7b7e\u7684\u7cbe\u7ec6\u5ea6\uff0c\u2018fine\u2019\u83b7\u5f97\u7684\u6807\u7b7e\u662f100\u4e2a\u5c0f\u7c7b\u7684\u6807\u7b7e\uff0c\u2018coarse\u2019\u83b7\u5f97\u7684\u6807\u7b7e\u662f\u5927\u7c7b\u7684\u6807\u7b7e", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/other/datasets/#_6", 
            "text": "\u4e24\u4e2aTuple, (X_train, y_train), (X_test, y_test) \uff0c\u5176\u4e2d    X_train\u548cX_test\uff1a\u662f\u5f62\u5982\uff08nb_samples, 3, 32, 32\uff09\u7684RGB\u4e09\u901a\u9053\u56fe\u50cf\u6570\u636e\uff0c\u6570\u636e\u7c7b\u578b\u662f\u65e0\u7b26\u53f78\u4f4d\u6574\u5f62\uff08uint8\uff09    y_train\u548cy_test\uff1a\u662f\u5f62\u5982\uff08nb_samples,\uff09\u6807\u7b7e\u6570\u636e\uff0c\u6807\u7b7e\u7684\u8303\u56f4\u662f0~9", 
            "title": "\u8fd4\u56de\u503c"
        }, 
        {
            "location": "/other/datasets/#imdb", 
            "text": "\u672c\u6570\u636e\u5e93\u542b\u6709\u6765\u81eaIMDB\u768425,000\u6761\u5f71\u8bc4\uff0c\u88ab\u6807\u8bb0\u4e3a\u6b63\u9762/\u8d1f\u9762\u4e24\u79cd\u8bc4\u4ef7\u3002\u5f71\u8bc4\u5df2\u88ab\u9884\u5904\u7406\u4e3a\u8bcd\u4e0b\u6807\u6784\u6210\u7684 \u5e8f\u5217 \u3002\u65b9\u4fbf\u8d77\u89c1\uff0c\u5355\u8bcd\u7684\u4e0b\u6807\u57fa\u4e8e\u5b83\u5728\u6570\u636e\u96c6\u4e2d\u51fa\u73b0\u7684\u9891\u7387\u6807\u5b9a\uff0c\u4f8b\u5982\u6574\u65703\u6240\u7f16\u7801\u7684\u8bcd\u4e3a\u6570\u636e\u96c6\u4e2d\u7b2c3\u5e38\u51fa\u73b0\u7684\u8bcd\u3002\u8fd9\u6837\u7684\u7ec4\u7ec7\u65b9\u6cd5\u4f7f\u5f97\u7528\u6237\u53ef\u4ee5\u5feb\u901f\u5b8c\u6210\u8bf8\u5982\u201c\u53ea\u8003\u8651\u6700\u5e38\u51fa\u73b0\u768410,000\u4e2a\u8bcd\uff0c\u4f46\u4e0d\u8003\u8651\u6700\u5e38\u51fa\u73b0\u768420\u4e2a\u8bcd\u201d\u8fd9\u6837\u7684\u64cd\u4f5c  \u6309\u7167\u60ef\u4f8b\uff0c0\u4e0d\u4ee3\u8868\u4efb\u4f55\u7279\u5b9a\u7684\u8bcd\uff0c\u800c\u7528\u6765\u7f16\u7801\u4efb\u4f55\u672a\u77e5\u5355\u8bcd", 
            "title": "IMDB\u5f71\u8bc4\u503e\u5411\u5206\u7c7b"
        }, 
        {
            "location": "/other/datasets/#_7", 
            "text": "from keras.datasets import imdb\n\n(X_train, y_train), (X_test, y_test) = imdb.load_data(path= imdb_full.pkl ,\n                                                      nb_words=None,\n                                                      skip_top=0,\n                                                      maxlen=None,\n                                                      test_split=0.1)\n                                                      seed=113,\n                                                      start_char=1,\n                                                      oov_char=2,\n                                                      index_from=3)", 
            "title": "\u4f7f\u7528\u65b9\u6cd5"
        }, 
        {
            "location": "/other/datasets/#_8", 
            "text": "path\uff1a\u5982\u679c\u4f60\u5728\u672c\u673a\u4e0a\u5df2\u6709\u6b64\u6570\u636e\u96c6\uff08\u4f4d\u4e8e '~/.keras/datasets/'+path \uff09\uff0c\u5219\u8f7d\u5165\u3002\u5426\u5219\u6570\u636e\u5c06\u4e0b\u8f7d\u5230\u8be5\u76ee\u5f55\u4e0b    nb_words\uff1a\u6574\u6570\u6216None\uff0c\u8981\u8003\u8651\u7684\u6700\u5e38\u89c1\u7684\u5355\u8bcd\u6570\uff0c\u4efb\u4f55\u51fa\u73b0\u9891\u7387\u66f4\u4f4e\u7684\u5355\u8bcd\u5c06\u4f1a\u88ab\u7f16\u7801\u52300\u7684\u4f4d\u7f6e\u3002    skip_top\uff1a\u6574\u6570\uff0c\u5ffd\u7565\u6700\u5e38\u51fa\u73b0\u7684\u82e5\u5e72\u5355\u8bcd\uff0c\u8fd9\u4e9b\u5355\u8bcd\u5c06\u4f1a\u88ab\u7f16\u7801\u4e3a0    maxlen\uff1a\u6574\u6570\uff0c\u6700\u5927\u5e8f\u5217\u957f\u5ea6\uff0c\u4efb\u4f55\u957f\u5ea6\u5927\u4e8e\u6b64\u503c\u7684\u5e8f\u5217\u5c06\u88ab\u622a\u65ad    seed\uff1a\u6574\u6570\uff0c\u7528\u4e8e\u6570\u636e\u91cd\u6392\u7684\u968f\u673a\u6570\u79cd\u5b50    start_char\uff1a\u5b57\u7b26\uff0c\u5e8f\u5217\u7684\u8d77\u59cb\u5c06\u4ee5\u8be5\u5b57\u7b26\u6807\u8bb0\uff0c\u9ed8\u8ba4\u4e3a1\u56e0\u4e3a0\u901a\u5e38\u7528\u4f5cpadding    oov_char\uff1a\u5b57\u7b26\uff0c\u56e0 nb_words \u6216 skip_top \u9650\u5236\u800ccut\u6389\u7684\u5355\u8bcd\u5c06\u88ab\u8be5\u5b57\u7b26\u4ee3\u66ff    index_from\uff1a\u6574\u6570\uff0c\u771f\u5b9e\u7684\u5355\u8bcd\uff08\u800c\u4e0d\u662f\u7c7b\u4f3c\u4e8e start_char \u7684\u7279\u6b8a\u5360\u4f4d\u7b26\uff09\u5c06\u4ece\u8fd9\u4e2a\u4e0b\u6807\u5f00\u59cb", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/other/datasets/#_9", 
            "text": "\u4e24\u4e2aTuple, (X_train, y_train), (X_test, y_test) \uff0c\u5176\u4e2d    X_train\u548cX_test\uff1a\u5e8f\u5217\u7684\u5217\u8868\uff0c\u6bcf\u4e2a\u5e8f\u5217\u90fd\u662f\u8bcd\u4e0b\u6807\u7684\u5217\u8868\u3002\u5982\u679c\u6307\u5b9a\u4e86 nb_words \uff0c\u5219\u5e8f\u5217\u4e2d\u53ef\u80fd\u7684\u6700\u5927\u4e0b\u6807\u4e3a nb_words-1 \u3002\u5982\u679c\u6307\u5b9a\u4e86 maxlen \uff0c\u5219\u5e8f\u5217\u7684\u6700\u5927\u53ef\u80fd\u957f\u5ea6\u4e3a maxlen    y_train\u548cy_test\uff1a\u4e3a\u5e8f\u5217\u7684\u6807\u7b7e\uff0c\u662f\u4e00\u4e2a\u4e8c\u503clist", 
            "title": "\u8fd4\u56de\u503c"
        }, 
        {
            "location": "/other/datasets/#_10", 
            "text": "\u672c\u6570\u636e\u5e93\u5305\u542b\u6765\u81ea\u8def\u900f\u793e\u768411,228\u6761\u65b0\u95fb\uff0c\u5206\u4e3a\u4e8646\u4e2a\u4e3b\u9898\u3002\u4e0eIMDB\u5e93\u4e00\u6837\uff0c\u6bcf\u6761\u65b0\u95fb\u88ab\u7f16\u7801\u4e3a\u4e00\u4e2a\u8bcd\u4e0b\u6807\u7684\u5e8f\u5217\u3002", 
            "title": "\u8def\u900f\u793e\u65b0\u95fb\u4e3b\u9898\u5206\u7c7b"
        }, 
        {
            "location": "/other/datasets/#_11", 
            "text": "from keras.datasets import reuters\n\n\n(X_train, y_train), (X_test, y_test) = reuters.load_data(path= reuters.pkl ,\n                                                         nb_words=None,\n                                                         skip_top=0,\n                                                         maxlen=None,\n                                                         test_split=0.2,\n                                                         seed=113,\n                                                         start_char=1,\n                                                         oov_char=2,\n                                                         index_from=3)  \u53c2\u6570\u7684\u542b\u4e49\u4e0eIMDB\u540c\u540d\u53c2\u6570\u76f8\u540c\uff0c\u552f\u4e00\u591a\u7684\u53c2\u6570\u662f\uff1a test_split \uff0c\u7528\u4e8e\u6307\u5b9a\u4ece\u539f\u6570\u636e\u4e2d\u5206\u5272\u51fa\u4f5c\u4e3a\u6d4b\u8bd5\u96c6\u7684\u6bd4\u4f8b\u3002\u8be5\u6570\u636e\u5e93\u652f\u6301\u83b7\u53d6\u7528\u4e8e\u7f16\u7801\u5e8f\u5217\u7684\u8bcd\u4e0b\u6807\uff1a  word_index = reuters.get_word_index(path= reuters_word_index.pkl )  \u4e0a\u9762\u4ee3\u7801\u7684\u8fd4\u56de\u503c\u662f\u4e00\u4e2a\u4ee5\u5355\u8bcd\u4e3a\u5173\u952e\u5b57\uff0c\u4ee5\u5176\u4e0b\u6807\u4e3a\u503c\u7684\u5b57\u5178\u3002\u4f8b\u5982\uff0c word_index['giraffe'] \u7684\u503c\u53ef\u80fd\u4e3a 1234  \u6570\u636e\u5e93\u5c06\u4f1a\u88ab\u4e0b\u8f7d\u5230 '~/.keras/datasets/'+path", 
            "title": "\u4f7f\u7528\u65b9\u6cd5"
        }, 
        {
            "location": "/other/datasets/#mnist", 
            "text": "\u672c\u6570\u636e\u5e93\u670960,000\u4e2a\u7528\u4e8e\u8bad\u7ec3\u768428*28\u7684\u7070\u5ea6\u624b\u5199\u6570\u5b57\u56fe\u7247\uff0c10,000\u4e2a\u6d4b\u8bd5\u56fe\u7247", 
            "title": "MNIST\u624b\u5199\u6570\u5b57\u8bc6\u522b"
        }, 
        {
            "location": "/other/datasets/#_12", 
            "text": "from keras.datasets import mnist\n\n(X_train, y_train), (X_test, y_test) = mnist.load_data()", 
            "title": "\u4f7f\u7528\u65b9\u6cd5"
        }, 
        {
            "location": "/other/datasets/#_13", 
            "text": "\u4e24\u4e2aTuple, (X_train, y_train), (X_test, y_test) \uff0c\u5176\u4e2d    X_train\u548cX_test\uff1a\u662f\u5f62\u5982\uff08nb_samples, 28, 28\uff09\u7684\u7070\u5ea6\u56fe\u7247\u6570\u636e\uff0c\u6570\u636e\u7c7b\u578b\u662f\u65e0\u7b26\u53f78\u4f4d\u6574\u5f62\uff08uint8\uff09    y_train\u548cy_test\uff1a\u662f\u5f62\u5982\uff08nb_samples,\uff09\u6807\u7b7e\u6570\u636e\uff0c\u6807\u7b7e\u7684\u8303\u56f4\u662f0~9    \u6570\u636e\u5e93\u5c06\u4f1a\u88ab\u4e0b\u8f7d\u5230 '~/.keras/datasets/'+path", 
            "title": "\u8fd4\u56de\u503c"
        }, 
        {
            "location": "/other/visualization/", 
            "text": "\u6a21\u578b\u53ef\u89c6\u5316\n\n\nkeras.utils.visualize_util\n\u6a21\u5757\u63d0\u4f9b\u4e86\u753b\u51faKeras\u6a21\u578b\u7684\u51fd\u6570\uff08\u5229\u7528graphviz\uff09\n\n\n\u8be5\u51fd\u6570\u5c06\u753b\u51fa\u6a21\u578b\u7ed3\u6784\u56fe\uff0c\u5e76\u4fdd\u5b58\u6210\u56fe\u7247\uff1a\n\n\nfrom keras.utils.visualize_util import plot\nplot(model, to_file='model.png')\n\n\n\n\nplot\n\u63a5\u6536\u4e24\u4e2a\u53ef\u9009\u53c2\u6570\uff1a\n\n\n\n\nshow_shapes\n\uff1a\u6307\u5b9a\u662f\u5426\u663e\u793a\u8f93\u51fa\u6570\u636e\u7684\u5f62\u72b6\uff0c\u9ed8\u8ba4\u4e3a\nFalse\n\n\nshow_layer_names\n:\u6307\u5b9a\u662f\u5426\u663e\u793a\u5c42\u540d\u79f0,\u9ed8\u8ba4\u4e3a\nTrue\n\n\n\n\n\u6211\u4eec\u4e5f\u53ef\u4ee5\u76f4\u63a5\u83b7\u53d6\u4e00\u4e2a\npydot.Graph\n\u5bf9\u8c61\uff0c\u7136\u540e\u6309\u7167\u81ea\u5df1\u7684\u9700\u8981\u914d\u7f6e\u5b83\uff0c\u4f8b\u5982\uff0c\u5982\u679c\u8981\u5728ipython\u4e2d\u5c55\u793a\u56fe\u7247\n\n\nfrom IPython.display import SVG\nfrom keras.utils.visualize_util import model_to_dot\n\nSVG(model_to_dot(model).create(prog='dot', format='svg'))\n\n\n\n\n\u3010Tips\u3011\u4f9d\u8d56 pydot-ng \u548c graphviz\uff0c\u547d\u4ee4\u884c\u8f93\u5165\npip install pydot-ng \n brew install graphviz", 
            "title": "\u53ef\u89c6\u5316Visualization"
        }, 
        {
            "location": "/other/visualization/#_1", 
            "text": "keras.utils.visualize_util \u6a21\u5757\u63d0\u4f9b\u4e86\u753b\u51faKeras\u6a21\u578b\u7684\u51fd\u6570\uff08\u5229\u7528graphviz\uff09  \u8be5\u51fd\u6570\u5c06\u753b\u51fa\u6a21\u578b\u7ed3\u6784\u56fe\uff0c\u5e76\u4fdd\u5b58\u6210\u56fe\u7247\uff1a  from keras.utils.visualize_util import plot\nplot(model, to_file='model.png')  plot \u63a5\u6536\u4e24\u4e2a\u53ef\u9009\u53c2\u6570\uff1a   show_shapes \uff1a\u6307\u5b9a\u662f\u5426\u663e\u793a\u8f93\u51fa\u6570\u636e\u7684\u5f62\u72b6\uff0c\u9ed8\u8ba4\u4e3a False  show_layer_names :\u6307\u5b9a\u662f\u5426\u663e\u793a\u5c42\u540d\u79f0,\u9ed8\u8ba4\u4e3a True   \u6211\u4eec\u4e5f\u53ef\u4ee5\u76f4\u63a5\u83b7\u53d6\u4e00\u4e2a pydot.Graph \u5bf9\u8c61\uff0c\u7136\u540e\u6309\u7167\u81ea\u5df1\u7684\u9700\u8981\u914d\u7f6e\u5b83\uff0c\u4f8b\u5982\uff0c\u5982\u679c\u8981\u5728ipython\u4e2d\u5c55\u793a\u56fe\u7247  from IPython.display import SVG\nfrom keras.utils.visualize_util import model_to_dot\n\nSVG(model_to_dot(model).create(prog='dot', format='svg'))  \u3010Tips\u3011\u4f9d\u8d56 pydot-ng \u548c graphviz\uff0c\u547d\u4ee4\u884c\u8f93\u5165 pip install pydot-ng   brew install graphviz", 
            "title": "\u6a21\u578b\u53ef\u89c6\u5316"
        }, 
        {
            "location": "/backend/", 
            "text": "Keras\u540e\u7aef\n\n\n\u4ec0\u4e48\u662f\u201c\u540e\u7aef\u201d\n\n\nKeras\u662f\u4e00\u4e2a\u6a21\u578b\u7ea7\u7684\u5e93\uff0c\u63d0\u4f9b\u4e86\u5feb\u901f\u6784\u5efa\u6df1\u5ea6\u5b66\u4e60\u7f51\u7edc\u7684\u6a21\u5757\u3002Keras\u5e76\u4e0d\u5904\u7406\u5982\u5f20\u91cf\u4e58\u6cd5\u3001\u5377\u79ef\u7b49\u5e95\u5c42\u64cd\u4f5c\u3002\u8fd9\u4e9b\u64cd\u4f5c\u4f9d\u8d56\u4e8e\u67d0\u79cd\u7279\u5b9a\u7684\u3001\u4f18\u5316\u826f\u597d\u7684\u5f20\u91cf\u64cd\u4f5c\u5e93\u3002Keras\u4f9d\u8d56\u4e8e\u5904\u7406\u5f20\u91cf\u7684\u5e93\u5c31\u79f0\u4e3a\u201c\u540e\u7aef\u5f15\u64ce\u201d\u3002Keras\u63d0\u4f9b\u4e86\u4e24\u79cd\u540e\u7aef\u5f15\u64ceTheano/Tensorflow\uff0c\u5e76\u5c06\u5176\u51fd\u6570\u7edf\u4e00\u5c01\u88c5\uff0c\u4f7f\u5f97\u7528\u6237\u53ef\u4ee5\u4ee5\u540c\u4e00\u4e2a\u63a5\u53e3\u8c03\u7528\u4e0d\u540c\u540e\u7aef\u5f15\u64ce\u7684\u51fd\u6570\n\n\n\n\n\n\nTheano\u662f\u4e00\u4e2a\u5f00\u6e90\u7684\u7b26\u53f7\u4e3b\u4e49\u5f20\u91cf\u64cd\u4f5c\u6846\u67b6\uff0c\u7531\u8499\u7279\u5229\u5c14\u5927\u5b66LISA/MILA\u5b9e\u9a8c\u5ba4\u5f00\u53d1\n\n\n\n\n\n\nTensorFlow\u662f\u4e00\u4e2a\u7b26\u53f7\u4e3b\u4e49\u7684\u5f20\u91cf\u64cd\u4f5c\u6846\u67b6\uff0c\u7531Google\u5f00\u53d1\n\n\n\n\n\n\n\u5728\u672a\u6765\uff0c\u6211\u4eec\u6709\u53ef\u80fd\u8981\u6dfb\u52a0\u66f4\u591a\u7684\u540e\u7aef\u9009\u9879\uff0c\u5982\u679c\u4f60\u6709\u5174\u8da3\u5f00\u53d1\u540e\u7aef\uff0c\u8bf7\u4e0e\u6211\u8054\u7cfb~\n\n\n\u5207\u6362\u540e\u7aef\n\n\n\u5982\u679c\u4f60\u81f3\u5c11\u8fd0\u884c\u8fc7\u4e00\u6b21Keras\uff0c\u4f60\u5c06\u5728\u4e0b\u9762\u7684\u76ee\u5f55\u4e0b\u627e\u5230Keras\u7684\u914d\u7f6e\u6587\u4ef6\uff1a\n\n\n~/.keras/keras.json\n\n\n\u5982\u679c\u8be5\u76ee\u5f55\u4e0b\u6ca1\u6709\u8be5\u6587\u4ef6\uff0c\u4f60\u53ef\u4ee5\u624b\u52a8\u521b\u5efa\u4e00\u4e2a\n\n\n\u6587\u4ef6\u7684\u9ed8\u8ba4\u914d\u7f6e\u5982\u4e0b\uff1a\n\n\n{\n\nimage_dim_ordering\n:\ntf\n,\n\nepsilon\n:1e-07,\n\nfloatx\n:\nfloat32\n,\n\nbackend\n:\ntensorflow\n\n}\n\n\n\n\n\u5c06\nbackend\n\u5b57\u6bb5\u7684\u503c\u6539\u5199\u4e3a\u4f60\u9700\u8981\u4f7f\u7528\u7684\u540e\u7aef\uff1a\ntheano\n\u6216\ntensorflow\n\uff0c\u5373\u53ef\u5b8c\u6210\u540e\u7aef\u7684\u5207\u6362\n\n\n\u6211\u4eec\u4e5f\u53ef\u4ee5\u901a\u8fc7\u5b9a\u4e49\u73af\u5883\u53d8\u91cf\nKERAS_BACKEND\n\u6765\u8986\u76d6\u4e0a\u9762\u914d\u7f6e\u6587\u4ef6\u4e2d\u5b9a\u4e49\u7684\u540e\u7aef\uff1a\n\n\nKERAS_BACKEND=tensorflow python -c \nfrom keras import backend;\n\nUsing TensorFlow backend.\n\n\n\n\nkeras.json \u7ec6\u8282\n\n\n{\n    \nimage_dim_ordering\n: \ntf\n,\n    \nepsilon\n: 1e-07,\n    \nfloatx\n: \nfloat32\n,\n    \nbackend\n: \ntensorflow\n\n}\n\n\n\n\n\u4f60\u53ef\u4ee5\u66f4\u6539\u4ee5\u4e0a\n~/.keras/keras.json\n\u4e2d\u7684\u914d\u7f6e\n\n\n\n\n\n\nimage_dim_ordering\n\uff1a\u5b57\u7b26\u4e32\uff0c\"tf\"\u6216\"th\"\uff0c\u8be5\u9009\u9879\u6307\u5b9a\u4e86Keras\u5c06\u8981\u4f7f\u7528\u7684\u7ef4\u5ea6\u987a\u5e8f\uff0c\u53ef\u901a\u8fc7\nkeras.backend.image_dim_ordering()\n\u6765\u83b7\u53d6\u5f53\u524d\u7684\u7ef4\u5ea6\u987a\u5e8f\u3002\u5bf92D\u6570\u636e\u6765\u8bf4\uff0c\ntf\n\u5047\u5b9a\u7ef4\u5ea6\u987a\u5e8f\u4e3a(rows,cols,channels)\u800c\nth\n\u5047\u5b9a\u7ef4\u5ea6\u987a\u5e8f\u4e3a(channels, rows, cols)\u3002\u5bf93D\u6570\u636e\u800c\u8a00\uff0c\ntf\n\u5047\u5b9a(conv_dim1, conv_dim2, conv_dim3, channels)\uff0c\nth\n\u5219\u662f(channels, conv_dim1, conv_dim2, conv_dim3)\n\n\n\n\n\n\nepsilon\n\uff1a\u6d6e\u70b9\u6570\uff0c\u9632\u6b62\u96640\u9519\u8bef\u7684\u5c0f\u6570\u5b57\n\n\n\n\nfloatx\n\uff1a\u5b57\u7b26\u4e32\uff0c\"float16\", \"float32\", \"float64\"\u4e4b\u4e00\uff0c\u4e3a\u6d6e\u70b9\u6570\u7cbe\u5ea6\n\n\nbackend\n\uff1a\u5b57\u7b26\u4e32\uff0c\u6240\u4f7f\u7528\u7684\u540e\u7aef\uff0c\u4e3a\"tensorflow\"\u6216\"theano\"\n\n\n\n\n\u4f7f\u7528\u62bd\u8c61\u7684Keras\u540e\u7aef\u6765\u7f16\u5199\u4ee3\u7801\n\n\n\u5982\u679c\u4f60\u5e0c\u671b\u4f60\u7f16\u5199\u7684Keras\u6a21\u5757\u80fd\u591f\u540c\u65f6\u5728Theano\u548cTensorFlow\u4e24\u4e2a\u540e\u7aef\u4e0a\u4f7f\u7528\uff0c\u4f60\u53ef\u4ee5\u901a\u8fc7Keras\u540e\u7aef\u63a5\u53e3\u6765\u7f16\u5199\u4ee3\u7801\uff0c\u8fd9\u91cc\u662f\u4e00\u4e2a\u7b80\u4ecb\uff1a\n\n\nfrom keras import backend as K\n\n\n\n\n\u4e0b\u9762\u7684\u4ee3\u7801\u5b9e\u4f8b\u5316\u4e86\u4e00\u4e2a\u8f93\u5165\u5360\u4f4d\u7b26\uff0c\u7b49\u4ef7\u4e8e\ntf.placeholder()\n \uff0c\nT.matrix()\n\uff0c\nT.tensor3()\n\u7b49\n\n\ninput = K.placeholder(shape=(2, 4, 5))\n# also works:\ninput = K.placeholder(shape=(None, 4, 5))\n# also works:\ninput = K.placeholder(ndim=3)\n\n\n\n\n\u4e0b\u9762\u7684\u4ee3\u7801\u5b9e\u4f8b\u5316\u4e86\u4e00\u4e2a\u5171\u4eab\u53d8\u91cf\uff08shared\uff09\uff0c\u7b49\u4ef7\u4e8e\ntf.variable()\n\u6216 \ntheano.shared()\n\n\nval = np.random.random((3, 4, 5))\nvar = K.variable(value=val)\n\n# all-zeros variable:\nvar = K.zeros(shape=(3, 4, 5))\n# all-ones:\nvar = K.ones(shape=(3, 4, 5))\n\n\n\n\n\u5927\u591a\u6570\u4f60\u9700\u8981\u7684\u5f20\u91cf\u64cd\u4f5c\u90fd\u53ef\u4ee5\u901a\u8fc7\u7edf\u4e00\u7684Keras\u540e\u7aef\u63a5\u53e3\u5b8c\u6210\uff0c\u800c\u4e0d\u5173\u5fc3\u5177\u4f53\u6267\u884c\u8fd9\u4e9b\u64cd\u4f5c\u7684\u662fTheano\u8fd8\u662fTensorFlow\n\n\na = b + c * K.abs(d)\nc = K.dot(a, K.transpose(b))\na = K.sum(b, axis=2)\na = K.softmax(b)\na = concatenate([b, c], axis=-1)\n# etc...\n\n\n\n\nKera\u540e\u7aef\u51fd\u6570\n\n\nepsilon\n\n\nepsilon()\n\n\n\n\n\u4ee5\u6570\u503c\u5f62\u5f0f\u8fd4\u56de\u4e00\u4e2a\uff08\u4e00\u822c\u6765\u8bf4\u5f88\u5c0f\u7684\uff09\u6570\uff0c\u7528\u4ee5\u9632\u6b62\u96640\u9519\u8bef\n\n\nset_epsilon\n\n\nset_epsilon(e)\n\n\n\n\n\u8bbe\u7f6e\u5728\u6570\u503c\u8868\u8fbe\u5f0f\u4e2d\u4f7f\u7528\u7684fuzz factor\uff0c\u7528\u4e8e\u9632\u6b62\u96640\u9519\u8bef\uff0c\u8be5\u503c\u5e94\u8be5\u662f\u4e00\u4e2a\u8f83\u5c0f\u7684\u6d6e\u70b9\u6570\uff0c\u793a\u4f8b\uff1a\n\n\n from keras import backend as K\n\n K.epsilon()\n1e-08\n\n K.set_epsilon(1e-05)\n\n K.epsilon()\n1e-05\n\n\n\n\nfloatx\n\n\nfloatx()\n\n\n\n\n\u8fd4\u56de\u9ed8\u8ba4\u7684\u6d6e\u70b9\u6570\u6570\u636e\u7c7b\u578b\uff0c\u4e3a\u5b57\u7b26\u4e32\uff0c\u5982 'float16', 'float32', 'float64'\n\n\nset_floatx(floatx)\n\n\nfloatx()\n\n\n\n\n\u8bbe\u7f6e\u9ed8\u8ba4\u7684\u6d6e\u70b9\u6570\u6570\u636e\u7c7b\u578b\uff0c\u4e3a\u5b57\u7b26\u4e32\uff0c\u5982 'float16', 'float32', 'float64',\u793a\u4f8b\uff1a\n\n\n from keras import backend as K\n\n K.floatx()\n'float32'\n\n K.set_floatx('float16')\n\n K.floatx()\n'float16'\n\n\n\n\ncast_to_floatx\n\n\ncast_to_floatx(x)\n\n\n\n\n\u5c06numpy array\u8f6c\u6362\u4e3a\u9ed8\u8ba4\u7684Keras floatx\u7c7b\u578b\uff0cx\u4e3anumpy array\uff0c\u8fd4\u56de\u503c\u4e5f\u4e3anumpy array\u4f46\u5176\u6570\u636e\u7c7b\u578b\u53d8\u4e3afloatx\u3002\u793a\u4f8b\uff1a\n\n\n from keras import backend as K\n\n K.floatx()\n'float32'\n\n arr = numpy.array([1.0, 2.0], dtype='float64')\n\n arr.dtype\ndtype('float64')\n\n new_arr = K.cast_to_floatx(arr)\n\n new_arr\narray([ 1.,  2.], dtype=float32)\n\n new_arr.dtype\ndtype('float32')\n\n\n\n\nimage_dim_ordering\n\n\nimage_dim_ordering()\n\n\n\n\n\u8fd4\u56de\u9ed8\u8ba4\u7684\u56fe\u50cf\u7684\u7ef4\u5ea6\u987a\u5e8f\uff08\u2018tf\u2019\u6216\u2018th\u2019\uff09\n\n\nset_image_dim_ordering\n\n\nset_image_dim_ordering(dim_ordering)\n\n\n\n\n\u8bbe\u7f6e\u56fe\u50cf\u7684\u7ef4\u5ea6\u987a\u5e8f\uff08\u2018tf\u2019\u6216\u2018th\u2019\uff09,\u793a\u4f8b\uff1a\n\n\n from keras import backend as K\n\n K.image_dim_ordering()\n'th'\n\n K.set_image_dim_ordering('tf')\n\n K.image_dim_ordering()\n'tf'\n\n\n\n\nget_uid\n\n\nget_uid(prefix='')\n\n\n\n\n\u4f9d\u636e\u7ed9\u5b9a\u7684\u524d\u7f00\u63d0\u4f9b\u4e00\u4e2a\u552f\u4e00\u7684UID\uff0c\u53c2\u6570\u4e3a\u8868\u793a\u524d\u7f00\u7684\u5b57\u7b26\u4e32\uff0c\u8fd4\u56de\u503c\u4e3a\u6574\u6570\uff0c\u793a\u4f8b\uff1a\n\n\n keras.backend.get_uid('dense')\n\n 1\n\n keras.backend.get_uid('dense')\n\n 2\n\n\n\n\nis_keras_tensor\n\n\nis_keras_tensor(x)\n\n\n\n\n\u5224\u65adx\u662f\u5426\u662f\u4e00\u4e2aKeras tensor\uff0c\u8fd4\u56de\u4e00\u4e2a\u5e03\u5c14\u503c\uff0c\u793a\u4f8b\n\n\n from keras import backend as K\n\n np_var = numpy.array([1, 2])\n\n K.is_keras_tensor(np_var)\nFalse\n\n keras_var = K.variable(np_var)\n\n K.is_keras_tensor(keras_var)  # A variable is not a Tensor.\nFalse\n\n keras_placeholder = K.placeholder(shape=(2, 4, 5))\n\n K.is_keras_tensor(keras_placeholder)  # A placeholder is a Tensor.\nTrue\n\n\n\n\nclear_session\n\n\nclear_session()\n\n\n\n\n\u7ed3\u675f\u5f53\u524d\u7684TF\u8ba1\u7b97\u56fe\uff0c\u5e76\u65b0\u5efa\u4e00\u4e2a\u3002\u6709\u6548\u7684\u907f\u514d\u6a21\u578b/\u5c42\u7684\u6df7\u4e71\n\n\nmanual_variable_initialization\n\n\nmanual_variable_initialization(value)\n\n\n\n\n\u6307\u51fa\u53d8\u91cf\u5e94\u8be5\u4ee5\u5176\u9ed8\u8ba4\u503c\u88ab\u521d\u59cb\u5316\u8fd8\u662f\u7531\u7528\u6237\u624b\u52a8\u521d\u59cb\u5316\uff0c\u53c2\u6570value\u4e3a\u5e03\u5c14\u503c\uff0c\u9ed8\u8ba4False\u4ee3\u8868\u53d8\u91cf\u7531\u5176\u9ed8\u8ba4\u503c\u521d\u59cb\u5316\n\n\nlearning_phase\n\n\nlearning_phase()\n\n\n\n\n\u8fd4\u56de\u8bad\u7ec3\u6a21\u5f0f/\u6d4b\u8bd5\u6a21\u5f0f\u7684flag\uff0c\u8be5flag\u662f\u4e00\u4e2a\u7528\u4ee5\u4f20\u5165Keras\u6a21\u578b\u7684\u6807\u8bb0\uff0c\u4ee5\u51b3\u5b9a\u5f53\u524d\u6a21\u578b\u6267\u884c\u4e8e\u8bad\u7ec3\u6a21\u5f0f\u4e0b\u8fd8\u662f\u6d4b\u8bd5\u6a21\u5f0f\u4e0b\n\n\nset_learning_phase\n\n\nset_learning_phase()\n\n\n\n\n\u8bbe\u7f6e\u8bad\u7ec3\u6a21\u5f0f/\u6d4b\u8bd5\u6a21\u5f0f0\u62161\n\n\nis_sparse\n\n\nis_sparse(tensor)\n\n\n\n\n\u5224\u65ad\u4e00\u4e2atensor\u662f\u4e0d\u662f\u4e00\u4e2a\u7a00\u758f\u7684tensor(\u7a00\u4e0d\u7a00\u758f\u7531tensor\u7684\u7c7b\u578b\u51b3\u5b9a\uff0c\u800c\u4e0d\u662ftensor\u5b9e\u9645\u4e0a\u6709\u591a\u7a00\u758f)\uff0c\u8fd4\u56de\u503c\u662f\u4e00\u4e2a\u5e03\u5c14\u503c\uff0c\u793a\u4f8b\uff1a\n\n\n from keras import backend as K\n\n a = K.placeholder((2, 2), sparse=False)\n\n print(K.is_sparse(a))\nFalse\n\n b = K.placeholder((2, 2), sparse=True)\n\n print(K.is_sparse(b))\nTrue\n\n\n\n\nto_dense\n\n\nto_dense(tensor)\n\n\n\n\n\u5c06\u4e00\u4e2a\u7a00\u758ftensor\u8f6c\u6362\u4e00\u4e2a\u4e0d\u7a00\u758f\u7684tensor\u5e76\u8fd4\u56de\u4e4b\uff0c\u793a\u4f8b\uff1a\n\n\n from keras import backend as K\n\n b = K.placeholder((2, 2), sparse=True)\n\n print(K.is_sparse(b))\nTrue\n\n c = K.to_dense(b)\n\n print(K.is_sparse(c))\nFalse\n\n\n\n\nvariable\n\n\nvariable(value, dtype='float32', name=None)\n\n\n\n\n\u5b9e\u4f8b\u5316\u4e00\u4e2a\u5f20\u91cf\uff0c\u8fd4\u56de\u4e4b\n\n\n\u53c2\u6570\uff1a\n\n\n\n\nvalue\uff1a\u7528\u6765\u521d\u59cb\u5316\u5f20\u91cf\u7684\u503c\n\n\ndtype\uff1a\u5f20\u91cf\u6570\u636e\u7c7b\u578b\n\n\nname\uff1a\u5f20\u91cf\u7684\u540d\u5b57\uff08\u53ef\u9009\uff09\n\n\n\n\n\u793a\u4f8b\uff1a\n\n\n from keras import backend as K\n\n val = np.array([[1, 2], [3, 4]])\n\n kvar = K.variable(value=val, dtype='float64', name='example_var')\n\n K.dtype(kvar)\n'float64'\n\n print(kvar)\nexample_var\n\n kvar.eval()\narray([[ 1.,  2.],\n   [ 3.,  4.]])\n\n\n\n\nplaceholder\n\n\nplaceholder(shape=None, ndim=None, dtype='float32', name=None)\n\n\n\n\n\u5b9e\u4f8b\u5316\u4e00\u4e2a\u5360\u4f4d\u7b26\uff0c\u8fd4\u56de\u4e4b\n\n\n\u53c2\u6570\uff1a\n\n\n\n\nshape\uff1a\u5360\u4f4d\u7b26\u7684shape\uff08\u6574\u6570tuple\uff0c\u53ef\u80fd\u5305\u542bNone\uff09 \n\n\nndim: \u5360\u4f4d\u7b26\u5f20\u91cf\u7684\u9636\u6570\uff0c\u8981\u521d\u59cb\u5316\u4e00\u4e2a\u5360\u4f4d\u7b26\uff0c\u81f3\u5c11\u6307\u5b9a\nshape\n\u548c\nndim\n\u4e4b\u4e00\uff0c\u5982\u679c\u90fd\u6307\u5b9a\u5219\u4f7f\u7528\nshape\n\n\ndtype: \u5360\u4f4d\u7b26\u6570\u636e\u7c7b\u578b\n\n\nname: \u5360\u4f4d\u7b26\u540d\u79f0\uff08\u53ef\u9009\uff09\n\n\n\n\n\u793a\u4f8b\uff1a\n\n\n from keras import backend as K\n\n input_ph = K.placeholder(shape=(2, 4, 5))\n\n input_ph._keras_shape\n(2, 4, 5)\n\n input_ph\n\ntf.Tensor 'Placeholder_4:0' shape=(2, 4, 5) dtype=float32\n\n\n\n\n\nshape\n\n\nshape(x)\n\n\n\n\n\u8fd4\u56de\u4e00\u4e2a\u5f20\u91cf\u7684\u7b26\u53f7shape\uff0c\u7b26\u53f7shape\u7684\u610f\u601d\u662f\u8fd4\u56de\u503c\u672c\u8eab\u4e5f\u662f\u4e00\u4e2atensor\uff0c\u793a\u4f8b\uff1a\n\n\n from keras import backend as K\n\n tf_session = K.get_session()\n\n val = np.array([[1, 2], [3, 4]])\n\n kvar = K.variable(value=val)\n\n input = keras.backend.placeholder(shape=(2, 4, 5))\n\n K.shape(kvar)\n\ntf.Tensor 'Shape_8:0' shape=(2,) dtype=int32\n\n\n K.shape(input)\n\ntf.Tensor 'Shape_9:0' shape=(3,) dtype=int32\n\n__To get integer shape (Instead, you can use K.int_shape(x))__\n\n\n K.shape(kvar).eval(session=tf_session)\narray([2, 2], dtype=int32)\n\n K.shape(input).eval(session=tf_session)\narray([2, 4, 5], dtype=int32)\n\n\n\n\nint_shape\n\n\nint_shape(x)\n\n\n\n\n\u4ee5\u6574\u6570Tuple\u6216None\u7684\u5f62\u5f0f\u8fd4\u56de\u5f20\u91cfshape\uff0c\u793a\u4f8b\uff1a\n\n\n from keras import backend as K\n\n input = K.placeholder(shape=(2, 4, 5))\n\n K.int_shape(input)\n(2, 4, 5)\n\n val = np.array([[1, 2], [3, 4]])\n\n kvar = K.variable(value=val)\n\n K.int_shape(kvar)\n(2, 2)\n\n\n\n\nndim\n\n\nndim(x)\n\n\n\n\n\u8fd4\u56de\u5f20\u91cf\u7684\u9636\u6570\uff0c\u4e3a\u6574\u6570\uff0c\u793a\u4f8b\uff1a\n\n\n from keras import backend as K\n\n input = K.placeholder(shape=(2, 4, 5))\n\n val = np.array([[1, 2], [3, 4]])\n\n kvar = K.variable(value=val)\n\n K.ndim(input)\n3\n\n K.ndim(kvar)\n2\n\n\n\n\ndtype\n\n\ndtype(x)\n\n\n\n\n\u8fd4\u56de\u5f20\u91cf\u7684\u6570\u636e\u7c7b\u578b\uff0c\u4e3a\u5b57\u7b26\u4e32\uff0c\u793a\u4f8b\uff1a\n\n\n from keras import backend as K\n\n K.dtype(K.placeholder(shape=(2,4,5)))\n'float32'\n\n K.dtype(K.placeholder(shape=(2,4,5), dtype='float32'))\n'float32'\n\n K.dtype(K.placeholder(shape=(2,4,5), dtype='float64'))\n'float64'\n__Keras variable__\n\n\n kvar = K.variable(np.array([[1, 2], [3, 4]]))\n\n K.dtype(kvar)\n'float32_ref'\n\n kvar = K.variable(np.array([[1, 2], [3, 4]]), dtype='float32')\n\n K.dtype(kvar)\n'float32_ref'\n\n\n\n\neval\n\n\neval(x)\n\n\n\n\n\u6c42\u5f97\u5f20\u91cf\u7684\u503c\uff0c\u8fd4\u56de\u4e00\u4e2aNumpy array\uff0c\u793a\u4f8b\uff1a\n\n\n from keras import backend as K\n\n kvar = K.variable(np.array([[1, 2], [3, 4]]), dtype='float32')\n\n K.eval(kvar)\narray([[ 1.,  2.],\n   [ 3.,  4.]], dtype=float32)\n\n\n\n\nzeros\n\n\nzeros(shape, dtype='float32', name=None)\n\n\n\n\n\u751f\u6210\u4e00\u4e2a\u51680\u5f20\u91cf\uff0c\u793a\u4f8b\uff1a\n\n\n from keras import backend as K\n\n kvar = K.zeros((3,4))\n\n K.eval(kvar)\narray([[ 0.,  0.,  0.,  0.],\n   [ 0.,  0.,  0.,  0.],\n   [ 0.,  0.,  0.,  0.]], dtype=float32)\n\n\n\n\nones\n\n\nones(shape, dtype='float32', name=None)\n\n\n\n\n\u751f\u6210\u4e00\u4e2a\u51681\u5f20\u91cf\uff0c\u793a\u4f8b\n\n\n from keras import backend as K\n\n kvar = K.ones((3,4))\n\n K.eval(kvar)\narray([[ 1.,  1.,  1.,  1.],\n   [ 1.,  1.,  1.,  1.],\n   [ 1.,  1.,  1.,  1.]], dtype=float32)\n\n\n\n\neye\n\n\neye(size, dtype='float32', name=None)\n\n\n\n\n\u751f\u6210\u4e00\u4e2a\u5355\u4f4d\u77e9\u9635\uff0c\u793a\u4f8b\uff1a\n\n\n from keras import backend as K\n\n kvar = K.eye(3)\n\n K.eval(kvar)\narray([[ 1.,  0.,  0.],\n   [ 0.,  1.,  0.],\n   [ 0.,  0.,  1.]], dtype=float32)\n\n\n\n\nzeros_like\n\n\nzeros_like(x, name=None)\n\n\n\n\n\u751f\u6210\u4e0e\u53e6\u4e00\u4e2a\u5f20\u91cfx\u7684shape\u76f8\u540c\u7684\u51680\u5f20\u91cf\uff0c\u793a\u4f8b\uff1a\n\n\n from keras import backend as K\n\n kvar = K.variable(np.random.random((2,3)))\n\n kvar_zeros = K.zeros_like(kvar)\n\n K.eval(kvar_zeros)\narray([[ 0.,  0.,  0.],\n   [ 0.,  0.,  0.]], dtype=float32)\n\n\n\n\nones_like\n\n\nones_like(x, name=None)\n\n\n\n\n\u751f\u6210\u4e0e\u53e6\u4e00\u4e2a\u5f20\u91cfshape\u76f8\u540c\u7684\u51681\u5f20\u91cf\uff0c\u793a\u4f8b\uff1a\n\n\n from keras import backend as K\n\n kvar = K.variable(np.random.random((2,3)))\n\n kvar_ones = K.ones_like(kvar)\n\n K.eval(kvar_ones)\narray([[ 1.,  1.,  1.],\n   [ 1.,  1.,  1.]], dtype=float32)\n\n\n\n\nrandom_uniform_variable\n\n\nrandom_uniform_variable(shape, low, high, dtype=None, name=None, seed=None)\n\n\n\n\n\u521d\u59cb\u5316\u4e00\u4e2aKeras\u53d8\u91cf\uff0c\u5176\u6570\u503c\u4e3a\u4ece\u4e00\u4e2a\u5747\u5300\u5206\u5e03\u4e2d\u91c7\u6837\u7684\u6837\u672c\uff0c\u8fd4\u56de\u4e4b\u3002\n\n\n\u53c2\u6570\uff1a\n\n\n\n\nshape\uff1a\u5f20\u91cfshape\n\n\nlow\uff1a\u6d6e\u70b9\u6570\uff0c\u5747\u5300\u5206\u5e03\u4e4b\u4e0b\u754c\n\n\nhigh\uff1a\u6d6e\u70b9\u6570\uff0c\u5747\u5300\u5206\u5e03\u4e4b\u4e0a\u754c\n\n\ndtype\uff1a\u6570\u636e\u7c7b\u578b\n\n\nname\uff1a\u5f20\u91cf\u540d\n\n\nseed\uff1a\u968f\u673a\u6570\u79cd\u5b50\n\n\n\n\n\u793a\u4f8b\uff1a\n\n\n kvar = K.random_uniform_variable((2,3), 0, 1)\n\n kvar\n\ntensorflow.python.ops.variables.Variable object at 0x10ab40b10\n\n\n K.eval(kvar)\narray([[ 0.10940075,  0.10047495,  0.476143  ],\n   [ 0.66137183,  0.00869417,  0.89220798]], dtype=float32)\n\n\n\n\ncount_params\n\n\ncount_params(x)\n\n\n\n\n\u8fd4\u56de\u5f20\u91cf\u4e2d\u6807\u91cf\u7684\u4e2a\u6570\uff0c\u793a\u4f8b\uff1a\n\n\n kvar = K.zeros((2,3))\n\n K.count_params(kvar)\n6\n\n K.eval(kvar)\narray([[ 0.,  0.,  0.],\n   [ 0.,  0.,  0.]], dtype=float32)\n\n\n\n\ncast\n\n\ncast(x, dtype)\n\n\n\n\n\u6539\u53d8\u5f20\u91cf\u7684\u6570\u636e\u7c7b\u578b\uff0cdtype\u53ea\u80fd\u662f\nfloat16\n, \nfloat32\n\u6216\nfloat64\n\u4e4b\u4e00\uff0c\u793a\u4f8b\uff1a\n\n\n from keras import backend as K\n\n input = K.placeholder((2, 3), dtype='float32')\n\n input\n\ntf.Tensor 'Placeholder_2:0' shape=(2, 3) dtype=float32\n\n__It doesn't work in-place as below.__\n\n\n K.cast(input, dtype='float16')\n\ntf.Tensor 'Cast_1:0' shape=(2, 3) dtype=float16\n\n\n input\n\ntf.Tensor 'Placeholder_2:0' shape=(2, 3) dtype=float32\n\n__you need to assign it.__\n\n\n input = K.cast(input, dtype='float16')\n\n input\n\ntf.Tensor 'Cast_2:0' shape=(2, 3) dtype=float16\n```\n\n\n\n\ndot\n\n\ndot(x, y)\n\n\n\n\n\u6c42\u4e24\u4e2a\u5f20\u91cf\u7684\u4e58\u79ef\u3002\u5f53\u8bd5\u56fe\u8ba1\u7b97\u4e24\u4e2aN\u9636\u5f20\u91cf\u7684\u4e58\u79ef\u65f6\uff0c\u4e0eTheano\u884c\u4e3a\u76f8\u540c\uff0c\u5982\n(2, 3).(4, 3, 5) = (2, 4, 5))\n\uff0c\u793a\u4f8b\uff1a\n\n\n x = K.placeholder(shape=(2, 3))\n\n y = K.placeholder(shape=(3, 4))\n\n xy = K.dot(x, y)\n\n xy\n\ntf.Tensor 'MatMul_9:0' shape=(2, 4) dtype=float32\n\n\n\n\n\n x = K.placeholder(shape=(32, 28, 3))\n\n y = K.placeholder(shape=(3, 4))\n\n xy = K.dot(x, y)\n\n xy\n\ntf.Tensor 'MatMul_9:0' shape=(32, 28, 4) dtype=float32\n\n\n\n\n\nTheano-like\u7684\u884c\u4e3a\u793a\u4f8b\uff1a\n\n\n x = K.random_uniform_variable(shape=(2, 3), low=0, high=1)\n\n y = K.ones((4, 3, 5))\n\n xy = K.dot(x, y)\n\n K.int_shape(xy)\n(2, 4, 5)\n\n\n\n\nbatch_dot\n\n\nbatch_dot(x, y, axes=None)\n\n\n\n\n\u6309\u6279\u8fdb\u884c\u5f20\u91cf\u4e58\u6cd5\uff0c\u8be5\u51fd\u6570\u7528\u4e8e\u8ba1\u7b97x\u548cy\u7684\u70b9\u79ef\uff0c\u5176\u4e2dx\u548cy\u90fd\u662f\u6210batch\u51fa\u73b0\u7684\u6570\u636e\u3002\u5373\u5b83\u7684\u6570\u636eshape\u5f62\u5982\n(batch_size,:)\n\u3002batch_dot\u5c06\u4ea7\u751f\u6bd4\u8f93\u5165\u5f20\u91cf\u7ef4\u5ea6\u4f4e\u7684\u5f20\u91cf\uff0c\u5982\u679c\u5f20\u91cf\u7684\u7ef4\u5ea6\u88ab\u51cf\u81f31\uff0c\u5219\u901a\u8fc7\nexpand_dims\n\u4fdd\u8bc1\u5176\u7ef4\u5ea6\u81f3\u5c11\u4e3a2\n\u4f8b\u5982\uff0c\u5047\u8bbe\nx = [[1, 2],[3,4]]\n \uff0c \ny = [[5, 6],[7, 8]]\n\uff0c\u5219\nbatch_dot(x, y, axes=1) = [[17, 53]]\n\uff0c\u5373\nx.dot(y.T)\n\u7684\u4e3b\u5bf9\u89d2\u5143\u7d20\uff0c\u6b64\u8fc7\u7a0b\u4e2d\u6211\u4eec\u6ca1\u6709\u8ba1\u7b97\u8fc7\u53cd\u5bf9\u89d2\u5143\u7d20\u7684\u503c\n\n\n\u53c2\u6570\uff1a\n\n\n\n\nx,y\uff1a\u9636\u6570\u5927\u4e8e\u7b49\u4e8e2\u7684\u5f20\u91cf\uff0c\u5728tensorflow\u4e0b\uff0c\u53ea\u652f\u6301\u5927\u4e8e\u7b49\u4e8e3\u9636\u7684\u5f20\u91cf\n\n\naxes\uff1a\u76ee\u6807\u7ed3\u679c\u7684\u7ef4\u5ea6\uff0c\u4e3a\u6574\u6570\u6216\u6574\u6570\u5217\u8868\uff0c\naxes[0]\n\u548c\naxes[1]\n\u5e94\u76f8\u540c\n\n\n\n\n\u793a\u4f8b\uff1a\n\u5047\u8bbe\nx=[[1,2],[3,4]]\n\uff0c\ny=[[5,6],[7,8]]\n\uff0c\u5219\nbatch_dot(x, y, axes=1)\n\u4e3a\n[[17, 53]]\n\uff0c\u6070\u597d\u4e3a\nx.dot(y.T)\n\u7684\u4e3b\u5bf9\u89d2\u5143\uff0c\u6574\u4e2a\u8fc7\u7a0b\u6ca1\u6709\u8ba1\u7b97\u53cd\u5bf9\u89d2\u5143\u7684\u5143\u7d20\u3002\n\n\n\u6211\u4eec\u505a\u4e00\u4e0bshape\u7684\u63a8\u5bfc\uff0c\u5047\u8bbex\u662f\u4e00\u4e2ashape\u4e3a(100,20)\u7684tensor\uff0cy\u662f\u4e00\u4e2ashape\u4e3a(100,30,20)\u7684tensor\uff0c\u5047\u8bbe\naxes=(1,2)\n\uff0c\u5219\u8f93\u51fatensor\u7684shape\u901a\u8fc7\u5faa\u73afx.shape\u548cy.shape\u786e\u5b9a\uff1a\n\n\n\n\nx.shape[0]\n\uff1a\u503c\u4e3a100\uff0c\u52a0\u5165\u5230\u8f93\u5165shape\u91cc\n\n\nx.shape[1]\n\uff1a20\uff0c\u4e0d\u52a0\u5165\u8f93\u51fashape\u91cc\uff0c\u56e0\u4e3a\u8be5\u7ef4\u5ea6\u7684\u503c\u4f1a\u88ab\u6c42\u548c(dot_axes[0]=1)\n\n\ny.shape[0]\n\uff1a\u503c\u4e3a100\uff0c\u4e0d\u52a0\u5165\u5230\u8f93\u51fashape\u91cc\uff0cy\u7684\u7b2c\u4e00\u7ef4\u603b\u662f\u88ab\u5ffd\u7565\n\n\ny.shape[1]\n\uff1a30\uff0c\u52a0\u5165\u5230\u8f93\u51fashape\u91cc\n\n\n\n\ny.shape[2]\n\uff1a20\uff0c\u4e0d\u52a0\u5230output shape\u91cc\uff0cy\u7684\u7b2c\u4e8c\u4e2a\u7ef4\u5ea6\u4f1a\u88ab\u6c42\u548c(dot_axes[1]=2)\n\n\n\n\n\n\n\u7ed3\u679c\u4e3a(100, 30)\n\n\n\n\n\n\n x_batch = K.ones(shape=(32, 20, 1))\n\n y_batch = K.ones(shape=(32, 30, 20))\n\n xy_batch_dot = K.batch_dot(x_batch, y_batch, axes=[1, 2])\n\n K.int_shape(xy_batch_dot)\n(32, 1, 30)\n\n\n\n\ntranspose\n\n\ntranspose(x)\n\n\n\n\n\u5f20\u91cf\u8f6c\u7f6e\uff0c\u8fd4\u56de\u8f6c\u7f6e\u540e\u7684tensor\uff0c\u793a\u4f8b\uff1a\n\n\n var = K.variable([[1, 2, 3], [4, 5, 6]])\n\n K.eval(var)\narray([[ 1.,  2.,  3.],\n   [ 4.,  5.,  6.]], dtype=float32)\n\n var_transposed = K.transpose(var)\n\n K.eval(var_transposed)\narray([[ 1.,  4.],\n   [ 2.,  5.],\n   [ 3.,  6.]], dtype=float32)\n\n\n input = K.placeholder((2, 3))\n\n input\n\ntf.Tensor 'Placeholder_11:0' shape=(2, 3) dtype=float32\n\n\n input_transposed = K.transpose(input)\n\n input_transposed\n\ntf.Tensor 'transpose_4:0' shape=(3, 2) dtype=float32\n\n\n\n\n\n\ngather\n\n\ngather(reference, indices)\n\n\n\n\n\u5728\u7ed9\u5b9a\u76842D\u5f20\u91cf\u4e2d\u68c0\u7d22\u7ed9\u5b9a\u4e0b\u6807\u7684\u5411\u91cf\n\n\n\u53c2\u6570\uff1a\n\n\n\n\nreference\uff1a2D\u5f20\u91cf\n\n\nindices\uff1a\u6574\u6570\u5f20\u91cf\uff0c\u5176\u5143\u7d20\u4e3a\u8981\u67e5\u8be2\u7684\u4e0b\u6807\n\n\n\n\n\u8fd4\u56de\u503c\uff1a\u4e00\u4e2a\u4e0e\nreference\n\u6570\u636e\u7c7b\u578b\u76f8\u540c\u76843D\u5f20\u91cf\n\n\nmax\n\n\nmax(x, axis=None, keepdims=False)\n\n\n\n\n\u6c42\u5f20\u91cf\u4e2d\u7684\u6700\u5927\u503c\n\n\nmin\n\n\nmin(x, axis=None, keepdims=False)\n\n\n\n\n\u6c42\u5f20\u91cf\u4e2d\u7684\u6700\u5c0f\u503c\n\n\nsum\n\n\nsum(x, axis=None, keepdims=False)\n\n\n\n\n\u5728\u7ed9\u5b9a\u8f74\u4e0a\u8ba1\u7b97\u5f20\u91cf\u4e2d\u5143\u7d20\u4e4b\u548c\n\n\nprod\n\n\nprod(x, axis=None, keepdims=False)\n\n\n\n\n\u5728\u7ed9\u5b9a\u8f74\u4e0a\u8ba1\u7b97\u5f20\u91cf\u4e2d\u5143\u7d20\u4e4b\u79ef\n\n\nvar\n\n\nvar(x, axis=None, keepdims=False)\n\n\n\n\n\u5728\u7ed9\u5b9a\u8f74\u4e0a\u8ba1\u7b97\u5f20\u91cf\u65b9\u5dee\n\n\nstd\n\n\nstd(x, axis=None, keepdims=False)\n\n\n\n\n\u5728\u7ed9\u5b9a\u8f74\u4e0a\u6c42\u5f20\u91cf\u5143\u7d20\u4e4b\u6807\u51c6\u5dee\n\n\nmean\n\n\nmean(x, axis=None, keepdims=False)\n\n\n\n\n\u5728\u7ed9\u5b9a\u8f74\u4e0a\u6c42\u5f20\u91cf\u5143\u7d20\u4e4b\u5747\u503c\n\n\nany\n\n\nany(x, axis=None, keepdims=False)\n\n\n\n\n\u6309\u4f4d\u6216\uff0c\u8fd4\u56de\u6570\u636e\u7c7b\u578b\u4e3auint8\u7684\u5f20\u91cf\uff08\u5143\u7d20\u4e3a0\u62161\uff09\n\n\nall\n\n\nany(x, axis=None, keepdims=False)\n\n\n\n\n\u6309\u4f4d\u4e0e\uff0c\u8fd4\u56de\u7c7b\u578b\u4e3auint8de tensor\n\n\nargmax\n\n\nargmax(x, axis=-1)\n\n\n\n\n\u5728\u7ed9\u5b9a\u8f74\u4e0a\u6c42\u5f20\u91cf\u4e4b\u6700\u5927\u5143\u7d20\u4e0b\u6807\n\n\nargmin\n\n\nargmin(x, axis=-1)\n\n\n\n\n\u5728\u7ed9\u5b9a\u8f74\u4e0a\u6c42\u5f20\u91cf\u4e4b\u6700\u5c0f\u5143\u7d20\u4e0b\u6807\n\n\nsquare\n\n\nsquare(x)\n\n\n\n\n\u9010\u5143\u7d20\u5e73\u65b9\n\n\nabs\n\n\nabs(x)\n\n\n\n\n\u9010\u5143\u7d20\u7edd\u5bf9\u503c\n\n\nsqrt\n\n\nsqrt(x)\n\n\n\n\n\u9010\u5143\u7d20\u5f00\u65b9\n\n\nexp\n\n\nexp(x)\n\n\n\n\n\u9010\u5143\u7d20\u6c42\u81ea\u7136\u6307\u6570\n\n\nlog\n\n\nlog(x)\n\n\n\n\n\u9010\u5143\u7d20\u6c42\u81ea\u7136\u5bf9\u6570\n\n\nround\n\n\nround(x)\n\n\n\n\n\u9010\u5143\u7d20\u56db\u820d\u4e94\u5165\n\n\nsign\n\n\nsign(x)\n\n\n\n\n\u9010\u5143\u7d20\u6c42\u5143\u7d20\u7684\u7b26\u53f7\uff08+1\u6216-1\uff09\n\n\npow\n\n\npow(x, a)\n\n\n\n\n\u9010\u5143\u7d20\u6c42x\u7684a\u6b21\u65b9\n\n\nclip\n\n\nclip(x, min_value, max_value)\n\n\n\n\n\u9010\u5143\u7d20clip\uff08\u5c06\u8d85\u51fa\u6307\u5b9a\u8303\u56f4\u7684\u6570\u5f3a\u5236\u53d8\u4e3a\u8fb9\u754c\u503c\uff09\n\n\nequal\n\n\nequal(x, y)\n\n\n\n\n\u9010\u5143\u7d20\u5224\u76f8\u7b49\u5173\u7cfb\uff0c\u8fd4\u56de\u5e03\u5c14\u5f20\u91cf\n\n\nnot_equal\n\n\nnot_equal(x, y)\n\n\n\n\n\u9010\u5143\u7d20\u5224\u4e0d\u7b49\u5173\u7cfb\uff0c\u8fd4\u56de\u5e03\u5c14\u5f20\u91cf\n\n\ngreater\n\n\ngreater(x,y)\n\n\n\n\n\u9010\u5143\u7d20\u5224\u65adx\ny\u5173\u7cfb\uff0c\u8fd4\u56de\u5e03\u5c14\u5f20\u91cf\n\n\ngreater_equal\n\n\ngreater_equal(x,y)\n\n\n\n\n\u9010\u5143\u7d20\u5224\u65adx\n=y\u5173\u7cfb\uff0c\u8fd4\u56de\u5e03\u5c14\u5f20\u91cf\n\n\nlesser\n\n\nlesser(x,y)\n\n\n\n\n\u9010\u5143\u7d20\u5224\u65adx\ny\u5173\u7cfb\uff0c\u8fd4\u56de\u5e03\u5c14\u5f20\u91cf\n\n\nlesser_equal\n\n\nlesser_equal(x,y)\n\n\n\n\n\u9010\u5143\u7d20\u5224\u65adx\n=y\u5173\u7cfb\uff0c\u8fd4\u56de\u5e03\u5c14\u5f20\u91cf\n\n\nmaximum\n\n\nmaximum(x, y)\n\n\n\n\n\u9010\u5143\u7d20\u53d6\u4e24\u4e2a\u5f20\u91cf\u7684\u6700\u5927\u503c\n\n\nminimum\n\n\nminimum(x, y)\n\n\n\n\n\u9010\u5143\u7d20\u53d6\u4e24\u4e2a\u5f20\u91cf\u7684\u6700\u5c0f\u503c\n\n\nsin\n\n\nsin(x)\n\n\n\n\n\u9010\u5143\u7d20\u6c42\u6b63\u5f26\u503c\n\n\ncos\n\n\ncos(x)\n\n\n\n\n\u9010\u5143\u7d20\u6c42\u4f59\u5f26\u503c\n\n\nnormalize_batch_in_training\n\n\nnormalize_batch_in_training(x, gamma, beta, reduction_axes, epsilon=0.0001)\n\n\n\n\n\u5bf9\u4e00\u4e2abatch\u6570\u636e\u5148\u8ba1\u7b97\u5176\u5747\u503c\u548c\u65b9\u5dee\uff0c\u7136\u540e\u518d\u8fdb\u884cbatch_normalization\n\n\nbatch_normalization\n\n\nbatch_normalization(x, mean, var, beta, gamma, epsilon=0.0001)\n\n\n\n\n\u5bf9\u4e00\u4e2abatch\u7684\u6570\u636e\u8fdb\u884cbatch_normalization\uff0c\u8ba1\u7b97\u516c\u5f0f\u4e3a\uff1a\noutput = (x-mean)/(sqrt(var)+epsilon)*gamma+beta\n\n\nconcatenate\n\n\nconcatenate(tensors, axis=-1)\n\n\n\n\n\u5728\u7ed9\u5b9a\u8f74\u4e0a\u5c06\u4e00\u4e2a\u5217\u8868\u4e2d\u7684\u5f20\u91cf\u4e32\u8054\u4e3a\u4e00\u4e2a\u5f20\u91cf specified axis\n\n\nreshape\n\n\nreshape(x, shape)\n\n\n\n\n\u5c06\u5f20\u91cf\u7684shape\u53d8\u6362\u4e3a\u6307\u5b9ashape\n\n\npermute_dimensions\n\n\npermute_dimensions(x, pattern)\n\n\n\n\n\u6309\u7167\u7ed9\u5b9a\u7684\u6a21\u5f0f\u91cd\u6392\u4e00\u4e2a\u5f20\u91cf\u7684\u8f74\n\n\n\u53c2\u6570\uff1a\n\n\n\n\npattern\uff1a\u4ee3\u8868\u7ef4\u5ea6\u4e0b\u6807\u7684tuple\u5982\n(0, 2, 1)\n\n\n\n\nresize_images\n\n\nresize_images(X, height_factor, width_factor, dim_ordering)\n\n\n\n\n\u4f9d\u636e\u7ed9\u5b9a\u7684\u7f29\u653e\u56e0\u5b50\uff0c\u6539\u53d8\u4e00\u4e2abatch\u56fe\u7247\u7684shape\uff0c\u53c2\u6570\u4e2d\u7684\u4e24\u4e2a\u56e0\u5b50\u90fd\u4e3a\u6b63\u6574\u6570\uff0c\u56fe\u7247\u7684\u6392\u5217\u987a\u5e8f\u4e0e\u7ef4\u5ea6\u7684\u6a21\u5f0f\u76f8\u5173\uff0c\u5982\u2018th\u2019\u548c\u2018tf\u2019\n\n\nresize_volumes\n\n\nresize_volumes(X, depth_factor, height_factor, width_factor, dim_ordering)\n\n\n\n\n\u4f9d\u636e\u7ed9\u5b9a\u7684\u7f29\u653e\u56e0\u5b50\uff0c\u6539\u53d8\u4e00\u4e2a5D\u5f20\u91cf\u6570\u636e\u7684shape\uff0c\u53c2\u6570\u4e2d\u7684\u4e24\u4e2a\u56e0\u5b50\u90fd\u4e3a\u6b63\u6574\u6570\uff0c\u56fe\u7247\u7684\u6392\u5217\u987a\u5e8f\u4e0e\u7ef4\u5ea6\u7684\u6a21\u5f0f\u76f8\u5173\uff0c\u5982\u2018th\u2019\u548c\u2018tf\u2019\u30025D\u6570\u636e\u7684\u5f62\u5f0f\u662f\nbatch, channels, depth, height, width\n\u6216\nbatch, depth, height, width, channels\n\n\nrepeat_elements\n\n\nrepeat_elements(x, rep, axis)\n\n\n\n\n\u5728\u7ed9\u5b9a\u8f74\u4e0a\u91cd\u590d\u5f20\u91cf\u5143\u7d20\nrep\n\u6b21\uff0c\u4e0e\nnp.repeat\n\u7c7b\u4f3c\u3002\u4f8b\u5982\uff0c\u82e5xshape\n(s1, s2, s3)\n\u5e76\u4e14\u7ed9\u5b9a\u8f74\u4e3a\naxis=1`\uff0c\u8f93\u51fa\u5f20\u91cf\u7684shape\u4e3a`(s1, s2 * rep, s3)\n\n\nrepeat\n\n\nrepeat(x, n)\n\n\n\n\n\u91cd\u590d2D\u5f20\u91cf\uff0c\u4f8b\u5982\u82e5xshape\u662f\n(samples, dim)\n\u4e14n\u4e3a2\uff0c\u5219\u8f93\u51fa\u5f20\u91cf\u7684shape\u662f\n(samples, 2, dim)\n\n\narange\n\n\narange(start, stop=None, step=1, dtype='int32')\n\n\n\n\n\u751f\u62101D\u7684\u6574\u6570\u5e8f\u5217\u5f20\u91cf\uff0c\u8be5\u51fd\u6570\u7684\u53c2\u6570\u4e0eTheano\u7684arange\u51fd\u6570\u542b\u4e49\u76f8\u540c\uff0c\u5982\u679c\u53ea\u6709\u4e00\u4e2a\u53c2\u6570\u88ab\u63d0\u4f9b\u4e86\uff0c\u90a3\u4e48\u5b83\u5b9e\u9645\u4e0a\u5c31\u662f\nstop\n\u53c2\u6570\u7684\u503c\n\n\n\u4e3a\u4e86\u4e0etensorflow\u7684\u9ed8\u8ba4\u4fdd\u6301\u5339\u914d\uff0c\u51fd\u6570\u8fd4\u56de\u5f20\u91cf\u7684\u9ed8\u8ba4\u6570\u636e\u7c7b\u578b\u662f\nint32\n\n\nbatch_flatten\n\n\nbatch_flatten(x)\n\n\n\n\n\u5c06\u4e00\u4e2an\u9636\u5f20\u91cf\u8f6c\u53d8\u4e3a2\u9636\u5f20\u91cf\uff0c\u5176\u7b2c\u4e00\u7ef4\u5ea6\u4fdd\u7559\u4e0d\u53d8\n\n\nexpand_dims\n\n\nexpand_dims(x, dim=-1)\n\n\n\n\n\u5728\u4e0b\u6807\u4e3a\ndim\n\u7684\u8f74\u4e0a\u589e\u52a0\u4e00\u7ef4\n\n\nsqueeze\n\n\nsqueeze(x, axis)\n\n\n\n\n\u5c06\u4e0b\u6807\u4e3a\naxis\n\u7684\u4e00\u7ef4\u4ece\u5f20\u91cf\u4e2d\u79fb\u9664\n\n\ntemporal_padding\n\n\ntemporal_padding(x, padding=1)\n\n\n\n\n\u54113D\u5f20\u91cf\u4e2d\u95f4\u7684\u90a3\u4e2a\u7ef4\u5ea6\u7684\u5de6\u53f3\u4e24\u7aef\u586b\u5145\npadding\n\u4e2a0\u503c\n\n\nasymmetric_temporal_padding\n\n\nasymmetric_temporal_padding(x, left_pad=1, right_pad=1)\n\n\n\n\n\u54113D\u5f20\u91cf\u4e2d\u95f4\u7684\u90a3\u4e2a\u7ef4\u5ea6\u7684\u4e00\u7aef\u586b\u5145\npadding\n\u4e2a0\u503c\n\n\nspatial_2d_padding\n\n\nspatial_2d_padding(x, padding=(1, 1), dim_ordering='th')\n\n\n\n\n\u54114D\u5f20\u91cf\u7b2c\u4e8c\u548c\u7b2c\u4e09\u7ef4\u5ea6\u7684\u5de6\u53f3\u4e24\u7aef\u586b\u5145\npadding[0]\n\u548c\npadding[1]\n\u4e2a0\u503c\n\n\nasymmetric_spatial_2d_padding\n\n\nasymmetric_spatial_2d_padding(x, top_pad=1, bottom_pad=1, left_pad=1, right_pad=1, dim_ordering='th')\n\n\n\n\n\u5bf94D\u5f20\u91cf\u7684\u90e8\u5206\u65b9\u5411\u8fdb\u884c\u586b\u5145\n\n\nspatial_3d_padding\n\n\nspatial_3d_padding(x, padding=(1, 1, 1), dim_ordering='th')\n\n\n\n\n\u54115D\u5f20\u91cf\u6df1\u5ea6\u3001\u9ad8\u5ea6\u548c\u5bbd\u5ea6\u4e09\u4e2a\u7ef4\u5ea6\u4e0a\u586b\u5145\npadding[0]\n\uff0c\npadding[1]\n\u548c\npadding[2]\n\u4e2a0\u503c\n\n\none-hot\n\n\none_hot(indices, nb_classes)\n\n\n\n\n\u8f93\u5165\u4e3an\u7ef4\u7684\u6574\u6570\u5f20\u91cf\uff0c\u5f62\u5982(batch_size, dim1, dim2, ... dim(n-1))\uff0c\u8f93\u51fa\u4e3a(n+1)\u7ef4\u7684one-hot\u7f16\u7801\uff0c\u5f62\u5982(batch_size, dim1, dim2, ... dim(n-1), nb_classes)\n\n\nreverse\n\n\nreverse(x, axes)\n\n\n\n\n\u5c06\u4e00\u4e2a\u5f20\u91cf\u5728\u7ed9\u5b9a\u8f74\u4e0a\u53cd\u8f6c\n\n\nget_value\n\n\nget_value(x)\n\n\n\n\n\u4ee5Numpy array\u7684\u5f62\u5f0f\u8fd4\u56de\u5f20\u91cf\u7684\u503c\n\n\nbatch_get_value\n\n\nbatch_get_value(x)\n\n\n\n\n\u4ee5Numpy array list\u7684\u5f62\u5f0f\u8fd4\u56de\u591a\u4e2a\u5f20\u91cf\u7684\u503c\n\n\nset_value\n\n\nset_value(x, value)\n\n\n\n\n\u4ecenumpy array\u5c06\u503c\u8f7d\u5165\u5f20\u91cf\u4e2d\n\n\nbatch_set_value\n\n\nbatch_set_value(tuples)\n\n\n\n\n\u5c06\u591a\u4e2a\u503c\u8f7d\u5165\u591a\u4e2a\u5f20\u91cf\u53d8\u91cf\u4e2d\n\n\n\u53c2\u6570\uff1a\n\n\n\n\ntuples: \u5217\u8868\uff0c\u5176\u4e2d\u7684\u5143\u7d20\u5f62\u5982\n(tensor, value)\n\u3002\nvalue\n\u662f\u8981\u8f7d\u5165\u7684Numpy array\u6570\u636e\n\n\n\n\nprint_tensor\n\n\nprint_tensor(x, message='')\n\n\n\n\n\u5728\u6c42\u503c\u65f6\u6253\u5370\u5f20\u91cf\u7684\u4fe1\u606f\uff0c\u5e76\u8fd4\u56de\u539f\u5f20\u91cf\n\n\nfunction\n\n\nfunction(inputs, outputs, updates=[])\n\n\n\n\n\u5b9e\u4f8b\u5316\u4e00\u4e2aKeras\u51fd\u6570\n\n\n\u53c2\u6570\uff1a\n\n\n\n\ninputs:\uff1a\u5217\u8868\uff0c\u5176\u5143\u7d20\u4e3a\u5360\u4f4d\u7b26\u6216\u5f20\u91cf\u53d8\u91cf\n\n\noutputs\uff1a\u8f93\u51fa\u5f20\u91cf\u7684\u5217\u8868\n\n\nupdates\uff1a\u5217\u8868\uff0c\u5176\u5143\u7d20\u662f\u5f62\u5982\n(old_tensor, new_tensor)\n\u7684tuple.\n\n\n\n\ngradients\n\n\ngradients(loss, variables)\n\n\n\n\n\u8fd4\u56deloss\u51fd\u6570\u5173\u4e8evariables\u7684\u68af\u5ea6\uff0cvariables\u4e3a\u5f20\u91cf\u53d8\u91cf\u7684\u5217\u8868\n\n\nstop_gradient\n\n\nstop_gradient(variables)\n\n\n\n\nReturns \nvariables\n but with zero gradient with respect to every other variables.\n\n\nrnn\n\n\nrnn(step_function, inputs, initial_states, go_backwards=False, mask=None, constants=None, unroll=False, input_length=None)\n\n\n\n\n\u5728\u5f20\u91cf\u7684\u65f6\u95f4\u7ef4\u4e0a\u8fed\u4ee3\n\n\n\u53c2\u6570\uff1a\n\n\n\n\ninputs\uff1a \u5f62\u5982\n(samples, time, ...)\n\u7684\u65f6\u57df\u4fe1\u53f7\u7684\u5f20\u91cf\uff0c\u9636\u6570\u81f3\u5c11\u4e3a3\n\n\nstep_function\uff1a\u6bcf\u4e2a\u65f6\u95f4\u6b65\u8981\u6267\u884c\u7684\u51fd\u6570\n    \u5176\u53c2\u6570\uff1a    \n\n\ninput\uff1a\u5f62\u5982\n(samples, ...)\n\u7684\u5f20\u91cf\uff0c\u4e0d\u542b\u65f6\u95f4\u7ef4\uff0c\u4ee3\u8868\u67d0\u4e2a\u65f6\u95f4\u6b65\u65f6\u4e00\u4e2abatch\u7684\u6837\u672c  \n\n\nstates\uff1a\u5f20\u91cf\u5217\u8868\n\u5176\u8fd4\u56de\u503c\uff1a\n\n\noutput\uff1a\u5f62\u5982\n(samples, ...)\n\u7684\u5f20\u91cf\n\n\nnew_states\uff1a\u5f20\u91cf\u5217\u8868\uff0c\u4e0e\u2018states\u2019\u7684\u957f\u5ea6\u76f8\u540c        \n\n\n\n\n\n\ninitial_states\uff1a\u5f62\u5982\n(samples, ...)\n\u7684\u5f20\u91cf\uff0c\u5305\u542b\u4e86\nstep_function\n\u72b6\u6001\u7684\u521d\u59cb\u503c\u3002\n\n\ngo_backwards\uff1a\u5e03\u5c14\u503c\uff0c\u82e5\u8bbe\u4e3aTrue\uff0c\u5219\u9006\u5411\u8fed\u4ee3\u5e8f\u5217\n\n\nmask\uff1a\u5f62\u5982\n(samples, time, 1)\n\u7684\u4e8c\u503c\u5f20\u91cf\uff0c\u9700\u8981\u5c4f\u853d\u7684\u6570\u636e\u5143\u7d20\u4e0a\u503c\u4e3a1\n\n\nconstants\uff1a\u6309\u65f6\u95f4\u6b65\u4f20\u9012\u7ed9\u51fd\u6570\u7684\u5e38\u6570\u5217\u8868\n\n\nunroll\uff1a\u5f53\u4f7f\u7528TensorFlow\u65f6\uff0cRNN\u603b\u662f\u5c55\u5f00\u7684\u3002\u5f53\u4f7f\u7528Theano\u65f6\uff0c\u8bbe\u7f6e\u8be5\u503c\u4e3a\nTrue\n\u5c06\u5c55\u5f00\u9012\u5f52\u7f51\u7edc\n\n\ninput_length\uff1a\u4f7f\u7528TensorFlow\u65f6\u4e0d\u9700\u8981\u6b64\u503c\uff0c\u5728\u4f7f\u7528Theano\u65f6\uff0c\u5982\u679c\u8981\u5c55\u5f00\u9012\u5f52\u7f51\u7edc\uff0c\u5fc5\u987b\u6307\u5b9a\u8f93\u5165\u5e8f\u5217\n\n\n\n\n\u8fd4\u56de\u503c\uff1a\u5f62\u5982\n(last_output, outputs, new_states)\n\u7684tuple\n\n\n\n\nlast_output\uff1arnn\u6700\u540e\u7684\u8f93\u51fa\uff0c\u5f62\u5982\n(samples, ...)\n\n\noutputs\uff1a\u5f62\u5982\n(samples, time, ...)\n\u7684\u5f20\u91cf\uff0c\u6bcf\u4e2a\u5728[s,t]\u70b9\u7684\u8f93\u51fa\u5bf9\u5e94\u4e8e\u6837\u672cs\u5728t\u65f6\u95f4\u7684\u8f93\u51fa\n\n\nnew_states: \u5217\u8868\uff0c\u5176\u5143\u7d20\u4e3a\u5f62\u5982\n(samples, ...)\n\u7684\u5f20\u91cf\uff0c\u4ee3\u8868\u6bcf\u4e2a\u6837\u672c\u7684\u6700\u540e\u4e00\u4e2a\u72b6\u6001\n\n\n\n\nswitch\n\n\nswitch(condition, then_expression, else_expression)\n\n\n\n\n\u4f9d\u636e\u7ed9\u5b9a\u7684\u6761\u4ef6\u2018condition\u2019\uff08\u6574\u6570\u6216\u5e03\u5c14\u503c\uff09\u5728\u4e24\u4e2a\u8868\u8fbe\u5f0f\u4e4b\u95f4\u5207\u6362\uff0c\u6ce8\u610f\u4e24\u4e2a\u8868\u8fbe\u5f0f\u90fd\u5e94\u8be5\u662f\u5177\u6709\u540c\u6837shape\u7684\u7b26\u53f7\u5316\u5f20\u91cf\u8868\u8fbe\u5f0f\n\n\n\u53c2\u6570\uff1a\n\n\n\n\ncondition\uff1a\u6807\u91cf\u5f20\u91cf\n\n\nthen_expression\uff1aTensorFlow\u8868\u8fbe\u5f0f\n\n\nelse_expression: TensorFlow\u8868\u8fbe\u5f0f\n\n\n\n\nin_train_phase\n\n\nin_train_phase(x, alt)\n\n\n\n\n\u5982\u679c\u5904\u4e8e\u8bad\u7ec3\u6a21\u5f0f\uff0c\u5219\u9009\u62e9x\uff0c\u5426\u5219\u9009\u62e9alt\uff0c\u6ce8\u610falt\u5e94\u8be5\u4e0ex\u7684shape\u76f8\u540c\n\n\nin_test_phase\n\n\nin_test_phase(x, alt)\n\n\n\n\n\u5982\u679c\u5904\u4e8e\u6d4b\u8bd5\u6a21\u5f0f\uff0c\u5219\u9009\u62e9x\uff0c\u5426\u5219\u9009\u62e9alt\uff0c\u6ce8\u610falt\u5e94\u8be5\u4e0ex\u7684shape\u76f8\u540c\n\n\nrelu\n\n\nrelu(x, alpha=0.0, max_value=None)\n\n\n\n\n\u4fee\u6b63\u7ebf\u6027\u5355\u5143\n\n\n\u53c2\u6570\uff1a\n\n\n\n\nalpha\uff1a\u8d1f\u534a\u533a\u659c\u7387\n\n\nmax_value: \u9971\u548c\u95e8\u9650\n\n\n\n\nelu\n\n\nelu(x, alpha=1.0)\n\n\n\n\n\u6307\u6570\u7ebf\u6027\u5355\u5143\n\n\n\u53c2\u6570\uff1a\n\n\n\n\nx\uff1a\u8f93\u5165\u5f20\u91cf\n\n\nalpha: \u6807\u91cf\n\n\n\n\nsoftmax\n\n\nsoftmax(x)\n\n\n\n\n\u8fd4\u56de\u5f20\u91cf\u7684softmax\u503c\n\n\nsoftplus\n\n\nsoftplus(x)\n\n\n\n\n\u8fd4\u56de\u5f20\u91cf\u7684softplus\u503c\n\n\nsoftsign\n\n\nsoftsign(x)\n\n\n\n\n\u8fd4\u56de\u5f20\u91cf\u7684softsign\u503c\n\n\ncategorical_crossentropy\n\n\ncategorical_crossentropy(output, target, from_logits=False)\n\n\n\n\n\u8ba1\u7b97\u8f93\u51fa\u5f20\u91cf\u548c\u76ee\u6807\u5f20\u91cf\u7684Categorical crossentropy\uff08\u7c7b\u522b\u4ea4\u53c9\u71b5\uff09\uff0c\u76ee\u6807\u5f20\u91cf\u4e0e\u8f93\u51fa\u5f20\u91cf\u5fc5\u987bshape\u76f8\u540c\n\n\nsparse_categorical_crossentropy\n\n\nsparse_categorical_crossentropy(output, target, from_logits=False)\n\n\n\n\n\u8ba1\u7b97\u8f93\u51fa\u5f20\u91cf\u548c\u76ee\u6807\u5f20\u91cf\u7684Categorical crossentropy\uff08\u7c7b\u522b\u4ea4\u53c9\u71b5\uff09\uff0c\u76ee\u6807\u5f20\u91cf\u5fc5\u987b\u662f\u6574\u578b\u5f20\u91cf\n\n\nbinary_crossentropy\n\n\nbinary_crossentropy(output, target, from_logits=False)\n\n\n\n\n\u8ba1\u7b97\u8f93\u51fa\u5f20\u91cf\u548c\u76ee\u6807\u5f20\u91cf\u7684\u4ea4\u53c9\u71b5\n\n\nsigmoid\n\n\nsigmoid(x)\n\n\n\n\n\u9010\u5143\u7d20\u8ba1\u7b97sigmoid\u503c\n\n\nhard_sigmoid\n\n\nhard_sigmoid(x)\n\n\n\n\n\u8be5\u51fd\u6570\u662f\u5206\u6bb5\u7ebf\u6027\u8fd1\u4f3c\u7684sigmoid\uff0c\u8ba1\u7b97\u901f\u5ea6\u66f4\u5feb\n\n\ntanh\n\n\ntanh(x)\n\n\n\n\n\u9010\u5143\u7d20\u8ba1\u7b97sigmoid\u503c\n\n\ndropout\n\n\ndropout(x, level, seed=None)\n\n\n\n\n\u968f\u673a\u5c06x\u4e2d\u4e00\u5b9a\u6bd4\u4f8b\u7684\u503c\u8bbe\u7f6e\u4e3a0\uff0c\u5e76\u653e\u7f29\u6574\u4e2atensor\n\n\n\u53c2\u6570\uff1a\n\n\n\n\nx\uff1a\u5f20\u91cf\n\n\nlevel\uff1ax\u4e2d\u8bbe\u7f6e\u62100\u7684\u5143\u7d20\u6bd4\u4f8b\n\n\nseed\uff1a\u968f\u673a\u6570\u79cd\u5b50\n\n\n\n\nl2_normalize\n\n\nl2_normalize(x, axis)\n\n\n\n\n\u5728\u7ed9\u5b9a\u8f74\u4e0a\u5bf9\u5f20\u91cf\u8fdb\u884cL2\u8303\u6570\u89c4\u8303\u5316\n\n\nin_top_k\n\n\nin_top_k(predictions, targets, k)\n\n\n\n\n\u5224\u65ad\u76ee\u6807\u662f\u5426\u5728predictions\u7684\u524dk\u5927\u503c\u4f4d\u7f6e\n\n\n\u53c2\u6570\uff1a\n\n\n\n\npredictions\uff1a\u9884\u6d4b\u503c\u5f20\u91cf, shape\u4e3a(batch_size, classes), \u6570\u636e\u7c7b\u578bfloat32\n\n\ntargets\uff1a\u771f\u503c\u5f20\u91cf, shape\u4e3a(batch_size,),\u6570\u636e\u7c7b\u578b\u4e3aint32\u6216int64\n\n\nk\uff1a\u6574\u6570\n\n\n\n\nconv1d\n\n\nconv1d(x, kernel, strides=1, border_mode='valid', image_shape=None, filter_shape=None)\n\n\n\n\n1D\u5377\u79ef\n\n\n\u53c2\u6570\uff1a\n\n\n\n\nkernel\uff1a\u5377\u79ef\u6838\u5f20\u91cf\n\n\nstrides\uff1a\u6b65\u957f\uff0c\u6574\u578b\n\n\nborder_mode\uff1a\u201csame\u201d\uff0c\u201cvalid\u201d\u4e4b\u4e00\u7684\u5b57\u7b26\u4e32\n\n\n\n\nconv2d\n\n\nconv2d(x, kernel, strides=(1, 1), border_mode='valid', dim_ordering='th', image_shape=None, filter_shape=None)\n\n\n\n\n2D\u5377\u79ef\n\n\n\u53c2\u6570\uff1a\n\n\n\n\nkernel\uff1a\u5377\u79ef\u6838\u5f20\u91cf\n\n\nstrides\uff1a\u6b65\u957f\uff0c\u957f\u4e3a2\u7684tuple\n\n\nborder_mode\uff1a\u201csame\u201d\uff0c\u201cvalid\u201d\u4e4b\u4e00\u7684\u5b57\u7b26\u4e32\n\n\ndim_ordering\uff1a\u201ctf\u201d\u548c\u201cth\u201d\u4e4b\u4e00\uff0c\u7ef4\u5ea6\u6392\u5217\u987a\u5e8f\n\n\n\n\ndeconv2d\n\n\ndeconv2d(x, kernel, output_shape, strides=(1, 1), border_mode='valid', dim_ordering='th', image_shape=None, filter_shape=None)\n\n\n\n\n2D\u53cd\u5377\u79ef\uff08\u8f6c\u7f6e\u5377\u79ef\uff09\n\n\n\u53c2\u6570\uff1a\n\n\n\n\nx\uff1a\u8f93\u5165\u5f20\u91cf\n\n\nkernel\uff1a\u5377\u79ef\u6838\u5f20\u91cf\n\n\noutput_shape: \u8f93\u51fashape\u76841D\u7684\u6574\u6570\u5f20\u91cf\n\n\nstrides\uff1a\u6b65\u957f\uff0ctuple\u7c7b\u578b\n\n\nborder_mode\uff1a\u201csame\u201d\u6216\u201cvalid\u201d\n\n\ndim_ordering\uff1a\u201ctf\u201d\u6216\u201cth\u201d\n\n\n\n\nconv3d\n\n\nconv3d(x, kernel, strides=(1, 1, 1), border_mode='valid', dim_ordering='th', volume_shape=None, filter_shape=None)\n\n\n\n\n3D\u5377\u79ef\n\n\n\u53c2\u6570\uff1a\n\n\n\n\nx\uff1a\u8f93\u5165\u5f20\u91cf\n\n\nkernel\uff1a\u5377\u79ef\u6838\u5f20\u91cf\n\n\nstrides\uff1a\u6b65\u957f\uff0ctuple\u7c7b\u578b\n\n\nborder_mode\uff1a\u201csame\u201d\u6216\u201cvalid\u201d\n\n\ndim_ordering\uff1a\u201ctf\u201d\u6216\u201cth\u201d\n\n\n\n\npool2d\n\n\npool2d(x, pool_size, strides=(1, 1), border_mode='valid', dim_ordering='th', pool_mode='max')\n\n\n\n\n2D\u6c60\u5316\n\n\n\u53c2\u6570\uff1a\n\n\n\n\npool_size\uff1a\u542b\u6709\u4e24\u4e2a\u6574\u6570\u7684tuple\uff0c\u6c60\u7684\u5927\u5c0f\n\n\nstrides\uff1a\u542b\u6709\u4e24\u4e2a\u6574\u6570\u7684tuple\uff0c\u6b65\u957f\n\n\nborder_mode\uff1a\u201csame\u201d\uff0c\u201cvalid\u201d\u4e4b\u4e00\u7684\u5b57\u7b26\u4e32\n\n\ndim_ordering\uff1a\u201ctf\u201d\u548c\u201cth\u201d\u4e4b\u4e00\uff0c\u7ef4\u5ea6\u6392\u5217\u987a\u5e8f\n\n\npool_mode: \u201cmax\u201d\uff0c\u201cavg\u201d\u4e4b\u4e00\uff0c\u6c60\u5316\u65b9\u5f0f\n\n\n\n\npool3d\n\n\npool3d(x, pool_size, strides=(1, 1, 1), border_mode='valid', dim_ordering='th', pool_mode='max')\n\n\n\n\n3D\u6c60\u5316\n\n\n\u53c2\u6570\uff1a\n\n\n\n\npool_size\uff1a\u542b\u67093\u4e2a\u6574\u6570\u7684tuple\uff0c\u6c60\u7684\u5927\u5c0f\n\n\nstrides\uff1a\u542b\u67093\u4e2a\u6574\u6570\u7684tuple\uff0c\u6b65\u957f\n\n\nborder_mode\uff1a\u201csame\u201d\uff0c\u201cvalid\u201d\u4e4b\u4e00\u7684\u5b57\u7b26\u4e32\n\n\ndim_ordering\uff1a\u201ctf\u201d\u548c\u201cth\u201d\u4e4b\u4e00\uff0c\u7ef4\u5ea6\u6392\u5217\u987a\u5e8f\n\n\npool_mode: \u201cmax\u201d\uff0c\u201cavg\u201d\u4e4b\u4e00\uff0c\u6c60\u5316\u65b9\u5f0f\n\n\n\n\nctc_batch_cost\n\n\nctc_batch_cost(y_true, y_pred, input_length, label_length)\n\n\n\n\n\u5728batch\u4e0a\u8fd0\u884cCTC\u635f\u5931\u7b97\u6cd5\n\n\n\u53c2\u6570\uff1a\n\n\n\n\ny_true\uff1a\u5f62\u5982(samples\uff0cmax_tring_length)\u7684\u5f20\u91cf\uff0c\u5305\u542b\u6807\u7b7e\u7684\u771f\u503c\n\n\ny_pred\uff1a\u5f62\u5982(samples\uff0ctime_steps\uff0cnum_categories)\u7684\u5f20\u91cf\uff0c\u5305\u542b\u9884\u6d4b\u503c\u6216\u8f93\u51fa\u7684softmax\u503c\n\n\ninput_length\uff1a\u5f62\u5982(samples\uff0c1)\u7684\u5f20\u91cf\uff0c\u5305\u542by_pred\u4e2d\u6bcf\u4e2abatch\u7684\u5e8f\u5217\u957f\n\n\nlabel_length\uff1a\u5f62\u5982(samples\uff0c1)\u7684\u5f20\u91cf\uff0c\u5305\u542by_true\u4e2d\u6bcf\u4e2abatch\u7684\u5e8f\u5217\u957f\n\n\n\n\n\u8fd4\u56de\u503c\uff1a\u5f62\u5982(samoles\uff0c1)\u7684tensor\uff0c\u5305\u542b\u4e86\u6bcf\u4e2a\u5143\u7d20\u7684CTC\u635f\u5931\n\n\nctc_decode\n\n\nctc_decode(y_pred, input_length, greedy=True, beam_width=None, dict_seq_lens=None, dict_values=None)\n\n\n\n\n\u4f7f\u7528\u8d2a\u5a6a\u7b97\u6cd5\u6216\u5e26\u7ea6\u675f\u7684\u5b57\u5178\u641c\u7d22\u7b97\u6cd5\u89e3\u7801softmax\u7684\u8f93\u51fa\n\n\n\u53c2\u6570\uff1a\n\n\n\n\ny_pred\uff1a\u5f62\u5982(samples\uff0ctime_steps\uff0cnum_categories)\u7684\u5f20\u91cf\uff0c\u5305\u542b\u9884\u6d4b\u503c\u6216\u8f93\u51fa\u7684softmax\u503c\n\n\ninput_length\uff1a\u5f62\u5982(samples\uff0c1)\u7684\u5f20\u91cf\uff0c\u5305\u542by_pred\u4e2d\u6bcf\u4e2abatch\u7684\u5e8f\u5217\u957f\n\n\ngreedy\uff1a\u8bbe\u7f6e\u4e3aTrue\u4f7f\u7528\u8d2a\u5a6a\u7b97\u6cd5\uff0c\u901f\u5ea6\u5feb\n\n\ndict_seq_lens\uff1adic_values\u5217\u8868\u4e2d\u5404\u5143\u7d20\u7684\u957f\u5ea6\n\n\ndict_values\uff1a\u5217\u8868\u7684\u5217\u8868\uff0c\u4ee3\u8868\u5b57\u5178\n\n\n\n\n\u8fd4\u56de\u503c\uff1a\u5f62\u5982(samples\uff0ctime_steps\uff0cnum_catgories)\u7684\u5f20\u91cf\uff0c\u5305\u542b\u4e86\u8def\u5f84\u53ef\u80fd\u6027\uff08\u4ee5softmax\u6982\u7387\u7684\u5f62\u5f0f\uff09\u3002\u6ce8\u610f\u4ecd\u7136\u9700\u8981\u4e00\u4e2a\u7528\u6765\u53d6\u51faargmax\u548c\u5904\u7406\u7a7a\u767d\u6807\u7b7e\u7684\u51fd\u6570\n\n\nmap_fn\n\n\nmap_fn(fn, elems, name=None)\n\n\n\n\n\u5143\u7d20elems\u5728\u51fd\u6570fn\u4e0a\u7684\u6620\u5c04\uff0c\u5e76\u8fd4\u56de\u7ed3\u679c\n\n\n\u53c2\u6570\uff1a\n\n\n\n\nfn\uff1a\u51fd\u6570\n\n\nelems\uff1a\u5f20\u91cf\n\n\nname\uff1a\u8282\u70b9\u7684\u540d\u5b57\n\n\n\n\n\u8fd4\u56de\u503c\uff1a\u8fd4\u56de\u4e00\u4e2a\u5f20\u91cf\uff0c\u8be5\u5f20\u91cf\u7684\u7b2c\u4e00\u7ef4\u5ea6\u7b49\u4e8eelems\uff0c\u7b2c\u4e8c\u7ef4\u5ea6\u53d6\u51b3\u4e8efn\n\n\nfoldl\n\n\nfoldl(fn, elems, initializer=None, name=None)\n\n\n\n\n\u51cf\u5c11elems\uff0c\u7528fn\u4ece\u5de6\u5230\u53f3\u8fde\u63a5\u5b83\u4eec\n\n\n\u53c2\u6570\uff1a\n\n\n\n\nfn\uff1a\u51fd\u6570\uff0c\u4f8b\u5982\uff1alambda acc, x: acc + x\n\n\nelems\uff1a\u5f20\u91cf\n\n\ninitializer\uff1a\u521d\u59cb\u5316\u7684\u503c(elems[0])\n\n\nname\uff1a\u8282\u70b9\u540d\n\n\n\n\n\u8fd4\u56de\u503c\uff1a\u4e0einitializer\u7684\u7c7b\u578b\u548c\u5f62\u72b6\u4e00\u81f4\n\n\nfoldr\n\n\nfoldr(fn, elems, initializer=None, name=None)\n\n\n\n\n\u51cf\u5c11elems\uff0c\u7528fn\u4ece\u53f3\u5230\u5de6\u8fde\u63a5\u5b83\u4eec\n\n\n\u53c2\u6570\uff1a\n\n\n\n\nfn\uff1a\u51fd\u6570\uff0c\u4f8b\u5982\uff1alambda acc, x: acc + x\n\n\nelems\uff1a\u5f20\u91cf  \n\n\ninitializer\uff1a\u521d\u59cb\u5316\u7684\u503c\uff08elems[-1]\uff09\n\n\nname\uff1a\u8282\u70b9\u540d\n\n\n\n\n\u8fd4\u56de\u503c\uff1a\u4e0einitializer\u7684\u7c7b\u578b\u548c\u5f62\u72b6\u4e00\u81f4\n\n\nbackend\n\n\nbackend()\n\n\n\n\n\u786e\u5b9a\u5f53\u524d\u4f7f\u7528\u7684\u540e\u7aef", 
            "title": "keras\u540e\u7aefBackend"
        }, 
        {
            "location": "/backend/#keras", 
            "text": "", 
            "title": "Keras\u540e\u7aef"
        }, 
        {
            "location": "/backend/#_1", 
            "text": "Keras\u662f\u4e00\u4e2a\u6a21\u578b\u7ea7\u7684\u5e93\uff0c\u63d0\u4f9b\u4e86\u5feb\u901f\u6784\u5efa\u6df1\u5ea6\u5b66\u4e60\u7f51\u7edc\u7684\u6a21\u5757\u3002Keras\u5e76\u4e0d\u5904\u7406\u5982\u5f20\u91cf\u4e58\u6cd5\u3001\u5377\u79ef\u7b49\u5e95\u5c42\u64cd\u4f5c\u3002\u8fd9\u4e9b\u64cd\u4f5c\u4f9d\u8d56\u4e8e\u67d0\u79cd\u7279\u5b9a\u7684\u3001\u4f18\u5316\u826f\u597d\u7684\u5f20\u91cf\u64cd\u4f5c\u5e93\u3002Keras\u4f9d\u8d56\u4e8e\u5904\u7406\u5f20\u91cf\u7684\u5e93\u5c31\u79f0\u4e3a\u201c\u540e\u7aef\u5f15\u64ce\u201d\u3002Keras\u63d0\u4f9b\u4e86\u4e24\u79cd\u540e\u7aef\u5f15\u64ceTheano/Tensorflow\uff0c\u5e76\u5c06\u5176\u51fd\u6570\u7edf\u4e00\u5c01\u88c5\uff0c\u4f7f\u5f97\u7528\u6237\u53ef\u4ee5\u4ee5\u540c\u4e00\u4e2a\u63a5\u53e3\u8c03\u7528\u4e0d\u540c\u540e\u7aef\u5f15\u64ce\u7684\u51fd\u6570    Theano\u662f\u4e00\u4e2a\u5f00\u6e90\u7684\u7b26\u53f7\u4e3b\u4e49\u5f20\u91cf\u64cd\u4f5c\u6846\u67b6\uff0c\u7531\u8499\u7279\u5229\u5c14\u5927\u5b66LISA/MILA\u5b9e\u9a8c\u5ba4\u5f00\u53d1    TensorFlow\u662f\u4e00\u4e2a\u7b26\u53f7\u4e3b\u4e49\u7684\u5f20\u91cf\u64cd\u4f5c\u6846\u67b6\uff0c\u7531Google\u5f00\u53d1    \u5728\u672a\u6765\uff0c\u6211\u4eec\u6709\u53ef\u80fd\u8981\u6dfb\u52a0\u66f4\u591a\u7684\u540e\u7aef\u9009\u9879\uff0c\u5982\u679c\u4f60\u6709\u5174\u8da3\u5f00\u53d1\u540e\u7aef\uff0c\u8bf7\u4e0e\u6211\u8054\u7cfb~", 
            "title": "\u4ec0\u4e48\u662f\u201c\u540e\u7aef\u201d"
        }, 
        {
            "location": "/backend/#_2", 
            "text": "\u5982\u679c\u4f60\u81f3\u5c11\u8fd0\u884c\u8fc7\u4e00\u6b21Keras\uff0c\u4f60\u5c06\u5728\u4e0b\u9762\u7684\u76ee\u5f55\u4e0b\u627e\u5230Keras\u7684\u914d\u7f6e\u6587\u4ef6\uff1a  ~/.keras/keras.json  \u5982\u679c\u8be5\u76ee\u5f55\u4e0b\u6ca1\u6709\u8be5\u6587\u4ef6\uff0c\u4f60\u53ef\u4ee5\u624b\u52a8\u521b\u5efa\u4e00\u4e2a  \u6587\u4ef6\u7684\u9ed8\u8ba4\u914d\u7f6e\u5982\u4e0b\uff1a  { image_dim_ordering : tf , epsilon :1e-07, floatx : float32 , backend : tensorflow \n}  \u5c06 backend \u5b57\u6bb5\u7684\u503c\u6539\u5199\u4e3a\u4f60\u9700\u8981\u4f7f\u7528\u7684\u540e\u7aef\uff1a theano \u6216 tensorflow \uff0c\u5373\u53ef\u5b8c\u6210\u540e\u7aef\u7684\u5207\u6362  \u6211\u4eec\u4e5f\u53ef\u4ee5\u901a\u8fc7\u5b9a\u4e49\u73af\u5883\u53d8\u91cf KERAS_BACKEND \u6765\u8986\u76d6\u4e0a\u9762\u914d\u7f6e\u6587\u4ef6\u4e2d\u5b9a\u4e49\u7684\u540e\u7aef\uff1a  KERAS_BACKEND=tensorflow python -c  from keras import backend; \nUsing TensorFlow backend.", 
            "title": "\u5207\u6362\u540e\u7aef"
        }, 
        {
            "location": "/backend/#kerasjson", 
            "text": "{\n     image_dim_ordering :  tf ,\n     epsilon : 1e-07,\n     floatx :  float32 ,\n     backend :  tensorflow \n}  \u4f60\u53ef\u4ee5\u66f4\u6539\u4ee5\u4e0a ~/.keras/keras.json \u4e2d\u7684\u914d\u7f6e    image_dim_ordering \uff1a\u5b57\u7b26\u4e32\uff0c\"tf\"\u6216\"th\"\uff0c\u8be5\u9009\u9879\u6307\u5b9a\u4e86Keras\u5c06\u8981\u4f7f\u7528\u7684\u7ef4\u5ea6\u987a\u5e8f\uff0c\u53ef\u901a\u8fc7 keras.backend.image_dim_ordering() \u6765\u83b7\u53d6\u5f53\u524d\u7684\u7ef4\u5ea6\u987a\u5e8f\u3002\u5bf92D\u6570\u636e\u6765\u8bf4\uff0c tf \u5047\u5b9a\u7ef4\u5ea6\u987a\u5e8f\u4e3a(rows,cols,channels)\u800c th \u5047\u5b9a\u7ef4\u5ea6\u987a\u5e8f\u4e3a(channels, rows, cols)\u3002\u5bf93D\u6570\u636e\u800c\u8a00\uff0c tf \u5047\u5b9a(conv_dim1, conv_dim2, conv_dim3, channels)\uff0c th \u5219\u662f(channels, conv_dim1, conv_dim2, conv_dim3)    epsilon \uff1a\u6d6e\u70b9\u6570\uff0c\u9632\u6b62\u96640\u9519\u8bef\u7684\u5c0f\u6570\u5b57   floatx \uff1a\u5b57\u7b26\u4e32\uff0c\"float16\", \"float32\", \"float64\"\u4e4b\u4e00\uff0c\u4e3a\u6d6e\u70b9\u6570\u7cbe\u5ea6  backend \uff1a\u5b57\u7b26\u4e32\uff0c\u6240\u4f7f\u7528\u7684\u540e\u7aef\uff0c\u4e3a\"tensorflow\"\u6216\"theano\"", 
            "title": "keras.json \u7ec6\u8282"
        }, 
        {
            "location": "/backend/#keras_1", 
            "text": "\u5982\u679c\u4f60\u5e0c\u671b\u4f60\u7f16\u5199\u7684Keras\u6a21\u5757\u80fd\u591f\u540c\u65f6\u5728Theano\u548cTensorFlow\u4e24\u4e2a\u540e\u7aef\u4e0a\u4f7f\u7528\uff0c\u4f60\u53ef\u4ee5\u901a\u8fc7Keras\u540e\u7aef\u63a5\u53e3\u6765\u7f16\u5199\u4ee3\u7801\uff0c\u8fd9\u91cc\u662f\u4e00\u4e2a\u7b80\u4ecb\uff1a  from keras import backend as K  \u4e0b\u9762\u7684\u4ee3\u7801\u5b9e\u4f8b\u5316\u4e86\u4e00\u4e2a\u8f93\u5165\u5360\u4f4d\u7b26\uff0c\u7b49\u4ef7\u4e8e tf.placeholder()  \uff0c T.matrix() \uff0c T.tensor3() \u7b49  input = K.placeholder(shape=(2, 4, 5))\n# also works:\ninput = K.placeholder(shape=(None, 4, 5))\n# also works:\ninput = K.placeholder(ndim=3)  \u4e0b\u9762\u7684\u4ee3\u7801\u5b9e\u4f8b\u5316\u4e86\u4e00\u4e2a\u5171\u4eab\u53d8\u91cf\uff08shared\uff09\uff0c\u7b49\u4ef7\u4e8e tf.variable() \u6216  theano.shared()  val = np.random.random((3, 4, 5))\nvar = K.variable(value=val)\n\n# all-zeros variable:\nvar = K.zeros(shape=(3, 4, 5))\n# all-ones:\nvar = K.ones(shape=(3, 4, 5))  \u5927\u591a\u6570\u4f60\u9700\u8981\u7684\u5f20\u91cf\u64cd\u4f5c\u90fd\u53ef\u4ee5\u901a\u8fc7\u7edf\u4e00\u7684Keras\u540e\u7aef\u63a5\u53e3\u5b8c\u6210\uff0c\u800c\u4e0d\u5173\u5fc3\u5177\u4f53\u6267\u884c\u8fd9\u4e9b\u64cd\u4f5c\u7684\u662fTheano\u8fd8\u662fTensorFlow  a = b + c * K.abs(d)\nc = K.dot(a, K.transpose(b))\na = K.sum(b, axis=2)\na = K.softmax(b)\na = concatenate([b, c], axis=-1)\n# etc...", 
            "title": "\u4f7f\u7528\u62bd\u8c61\u7684Keras\u540e\u7aef\u6765\u7f16\u5199\u4ee3\u7801"
        }, 
        {
            "location": "/backend/#kera", 
            "text": "", 
            "title": "Kera\u540e\u7aef\u51fd\u6570"
        }, 
        {
            "location": "/backend/#epsilon", 
            "text": "epsilon()  \u4ee5\u6570\u503c\u5f62\u5f0f\u8fd4\u56de\u4e00\u4e2a\uff08\u4e00\u822c\u6765\u8bf4\u5f88\u5c0f\u7684\uff09\u6570\uff0c\u7528\u4ee5\u9632\u6b62\u96640\u9519\u8bef", 
            "title": "epsilon"
        }, 
        {
            "location": "/backend/#set_epsilon", 
            "text": "set_epsilon(e)  \u8bbe\u7f6e\u5728\u6570\u503c\u8868\u8fbe\u5f0f\u4e2d\u4f7f\u7528\u7684fuzz factor\uff0c\u7528\u4e8e\u9632\u6b62\u96640\u9519\u8bef\uff0c\u8be5\u503c\u5e94\u8be5\u662f\u4e00\u4e2a\u8f83\u5c0f\u7684\u6d6e\u70b9\u6570\uff0c\u793a\u4f8b\uff1a   from keras import backend as K  K.epsilon()\n1e-08  K.set_epsilon(1e-05)  K.epsilon()\n1e-05", 
            "title": "set_epsilon"
        }, 
        {
            "location": "/backend/#floatx", 
            "text": "floatx()  \u8fd4\u56de\u9ed8\u8ba4\u7684\u6d6e\u70b9\u6570\u6570\u636e\u7c7b\u578b\uff0c\u4e3a\u5b57\u7b26\u4e32\uff0c\u5982 'float16', 'float32', 'float64'", 
            "title": "floatx"
        }, 
        {
            "location": "/backend/#set_floatxfloatx", 
            "text": "floatx()  \u8bbe\u7f6e\u9ed8\u8ba4\u7684\u6d6e\u70b9\u6570\u6570\u636e\u7c7b\u578b\uff0c\u4e3a\u5b57\u7b26\u4e32\uff0c\u5982 'float16', 'float32', 'float64',\u793a\u4f8b\uff1a   from keras import backend as K  K.floatx()\n'float32'  K.set_floatx('float16')  K.floatx()\n'float16'", 
            "title": "set_floatx(floatx)"
        }, 
        {
            "location": "/backend/#cast_to_floatx", 
            "text": "cast_to_floatx(x)  \u5c06numpy array\u8f6c\u6362\u4e3a\u9ed8\u8ba4\u7684Keras floatx\u7c7b\u578b\uff0cx\u4e3anumpy array\uff0c\u8fd4\u56de\u503c\u4e5f\u4e3anumpy array\u4f46\u5176\u6570\u636e\u7c7b\u578b\u53d8\u4e3afloatx\u3002\u793a\u4f8b\uff1a   from keras import backend as K  K.floatx()\n'float32'  arr = numpy.array([1.0, 2.0], dtype='float64')  arr.dtype\ndtype('float64')  new_arr = K.cast_to_floatx(arr)  new_arr\narray([ 1.,  2.], dtype=float32)  new_arr.dtype\ndtype('float32')", 
            "title": "cast_to_floatx"
        }, 
        {
            "location": "/backend/#image_dim_ordering", 
            "text": "image_dim_ordering()  \u8fd4\u56de\u9ed8\u8ba4\u7684\u56fe\u50cf\u7684\u7ef4\u5ea6\u987a\u5e8f\uff08\u2018tf\u2019\u6216\u2018th\u2019\uff09", 
            "title": "image_dim_ordering"
        }, 
        {
            "location": "/backend/#set_image_dim_ordering", 
            "text": "set_image_dim_ordering(dim_ordering)  \u8bbe\u7f6e\u56fe\u50cf\u7684\u7ef4\u5ea6\u987a\u5e8f\uff08\u2018tf\u2019\u6216\u2018th\u2019\uff09,\u793a\u4f8b\uff1a   from keras import backend as K  K.image_dim_ordering()\n'th'  K.set_image_dim_ordering('tf')  K.image_dim_ordering()\n'tf'", 
            "title": "set_image_dim_ordering"
        }, 
        {
            "location": "/backend/#get_uid", 
            "text": "get_uid(prefix='')  \u4f9d\u636e\u7ed9\u5b9a\u7684\u524d\u7f00\u63d0\u4f9b\u4e00\u4e2a\u552f\u4e00\u7684UID\uff0c\u53c2\u6570\u4e3a\u8868\u793a\u524d\u7f00\u7684\u5b57\u7b26\u4e32\uff0c\u8fd4\u56de\u503c\u4e3a\u6574\u6570\uff0c\u793a\u4f8b\uff1a   keras.backend.get_uid('dense')  1  keras.backend.get_uid('dense')  2", 
            "title": "get_uid"
        }, 
        {
            "location": "/backend/#is_keras_tensor", 
            "text": "is_keras_tensor(x)  \u5224\u65adx\u662f\u5426\u662f\u4e00\u4e2aKeras tensor\uff0c\u8fd4\u56de\u4e00\u4e2a\u5e03\u5c14\u503c\uff0c\u793a\u4f8b   from keras import backend as K  np_var = numpy.array([1, 2])  K.is_keras_tensor(np_var)\nFalse  keras_var = K.variable(np_var)  K.is_keras_tensor(keras_var)  # A variable is not a Tensor.\nFalse  keras_placeholder = K.placeholder(shape=(2, 4, 5))  K.is_keras_tensor(keras_placeholder)  # A placeholder is a Tensor.\nTrue", 
            "title": "is_keras_tensor"
        }, 
        {
            "location": "/backend/#clear_session", 
            "text": "clear_session()  \u7ed3\u675f\u5f53\u524d\u7684TF\u8ba1\u7b97\u56fe\uff0c\u5e76\u65b0\u5efa\u4e00\u4e2a\u3002\u6709\u6548\u7684\u907f\u514d\u6a21\u578b/\u5c42\u7684\u6df7\u4e71", 
            "title": "clear_session"
        }, 
        {
            "location": "/backend/#manual_variable_initialization", 
            "text": "manual_variable_initialization(value)  \u6307\u51fa\u53d8\u91cf\u5e94\u8be5\u4ee5\u5176\u9ed8\u8ba4\u503c\u88ab\u521d\u59cb\u5316\u8fd8\u662f\u7531\u7528\u6237\u624b\u52a8\u521d\u59cb\u5316\uff0c\u53c2\u6570value\u4e3a\u5e03\u5c14\u503c\uff0c\u9ed8\u8ba4False\u4ee3\u8868\u53d8\u91cf\u7531\u5176\u9ed8\u8ba4\u503c\u521d\u59cb\u5316", 
            "title": "manual_variable_initialization"
        }, 
        {
            "location": "/backend/#learning_phase", 
            "text": "learning_phase()  \u8fd4\u56de\u8bad\u7ec3\u6a21\u5f0f/\u6d4b\u8bd5\u6a21\u5f0f\u7684flag\uff0c\u8be5flag\u662f\u4e00\u4e2a\u7528\u4ee5\u4f20\u5165Keras\u6a21\u578b\u7684\u6807\u8bb0\uff0c\u4ee5\u51b3\u5b9a\u5f53\u524d\u6a21\u578b\u6267\u884c\u4e8e\u8bad\u7ec3\u6a21\u5f0f\u4e0b\u8fd8\u662f\u6d4b\u8bd5\u6a21\u5f0f\u4e0b", 
            "title": "learning_phase"
        }, 
        {
            "location": "/backend/#set_learning_phase", 
            "text": "set_learning_phase()  \u8bbe\u7f6e\u8bad\u7ec3\u6a21\u5f0f/\u6d4b\u8bd5\u6a21\u5f0f0\u62161", 
            "title": "set_learning_phase"
        }, 
        {
            "location": "/backend/#is_sparse", 
            "text": "is_sparse(tensor)  \u5224\u65ad\u4e00\u4e2atensor\u662f\u4e0d\u662f\u4e00\u4e2a\u7a00\u758f\u7684tensor(\u7a00\u4e0d\u7a00\u758f\u7531tensor\u7684\u7c7b\u578b\u51b3\u5b9a\uff0c\u800c\u4e0d\u662ftensor\u5b9e\u9645\u4e0a\u6709\u591a\u7a00\u758f)\uff0c\u8fd4\u56de\u503c\u662f\u4e00\u4e2a\u5e03\u5c14\u503c\uff0c\u793a\u4f8b\uff1a   from keras import backend as K  a = K.placeholder((2, 2), sparse=False)  print(K.is_sparse(a))\nFalse  b = K.placeholder((2, 2), sparse=True)  print(K.is_sparse(b))\nTrue", 
            "title": "is_sparse"
        }, 
        {
            "location": "/backend/#to_dense", 
            "text": "to_dense(tensor)  \u5c06\u4e00\u4e2a\u7a00\u758ftensor\u8f6c\u6362\u4e00\u4e2a\u4e0d\u7a00\u758f\u7684tensor\u5e76\u8fd4\u56de\u4e4b\uff0c\u793a\u4f8b\uff1a   from keras import backend as K  b = K.placeholder((2, 2), sparse=True)  print(K.is_sparse(b))\nTrue  c = K.to_dense(b)  print(K.is_sparse(c))\nFalse", 
            "title": "to_dense"
        }, 
        {
            "location": "/backend/#variable", 
            "text": "variable(value, dtype='float32', name=None)  \u5b9e\u4f8b\u5316\u4e00\u4e2a\u5f20\u91cf\uff0c\u8fd4\u56de\u4e4b  \u53c2\u6570\uff1a   value\uff1a\u7528\u6765\u521d\u59cb\u5316\u5f20\u91cf\u7684\u503c  dtype\uff1a\u5f20\u91cf\u6570\u636e\u7c7b\u578b  name\uff1a\u5f20\u91cf\u7684\u540d\u5b57\uff08\u53ef\u9009\uff09   \u793a\u4f8b\uff1a   from keras import backend as K  val = np.array([[1, 2], [3, 4]])  kvar = K.variable(value=val, dtype='float64', name='example_var')  K.dtype(kvar)\n'float64'  print(kvar)\nexample_var  kvar.eval()\narray([[ 1.,  2.],\n   [ 3.,  4.]])", 
            "title": "variable"
        }, 
        {
            "location": "/backend/#placeholder", 
            "text": "placeholder(shape=None, ndim=None, dtype='float32', name=None)  \u5b9e\u4f8b\u5316\u4e00\u4e2a\u5360\u4f4d\u7b26\uff0c\u8fd4\u56de\u4e4b  \u53c2\u6570\uff1a   shape\uff1a\u5360\u4f4d\u7b26\u7684shape\uff08\u6574\u6570tuple\uff0c\u53ef\u80fd\u5305\u542bNone\uff09   ndim: \u5360\u4f4d\u7b26\u5f20\u91cf\u7684\u9636\u6570\uff0c\u8981\u521d\u59cb\u5316\u4e00\u4e2a\u5360\u4f4d\u7b26\uff0c\u81f3\u5c11\u6307\u5b9a shape \u548c ndim \u4e4b\u4e00\uff0c\u5982\u679c\u90fd\u6307\u5b9a\u5219\u4f7f\u7528 shape  dtype: \u5360\u4f4d\u7b26\u6570\u636e\u7c7b\u578b  name: \u5360\u4f4d\u7b26\u540d\u79f0\uff08\u53ef\u9009\uff09   \u793a\u4f8b\uff1a   from keras import backend as K  input_ph = K.placeholder(shape=(2, 4, 5))  input_ph._keras_shape\n(2, 4, 5)  input_ph tf.Tensor 'Placeholder_4:0' shape=(2, 4, 5) dtype=float32", 
            "title": "placeholder"
        }, 
        {
            "location": "/backend/#shape", 
            "text": "shape(x)  \u8fd4\u56de\u4e00\u4e2a\u5f20\u91cf\u7684\u7b26\u53f7shape\uff0c\u7b26\u53f7shape\u7684\u610f\u601d\u662f\u8fd4\u56de\u503c\u672c\u8eab\u4e5f\u662f\u4e00\u4e2atensor\uff0c\u793a\u4f8b\uff1a   from keras import backend as K  tf_session = K.get_session()  val = np.array([[1, 2], [3, 4]])  kvar = K.variable(value=val)  input = keras.backend.placeholder(shape=(2, 4, 5))  K.shape(kvar) tf.Tensor 'Shape_8:0' shape=(2,) dtype=int32   K.shape(input) tf.Tensor 'Shape_9:0' shape=(3,) dtype=int32 \n__To get integer shape (Instead, you can use K.int_shape(x))__  K.shape(kvar).eval(session=tf_session)\narray([2, 2], dtype=int32)  K.shape(input).eval(session=tf_session)\narray([2, 4, 5], dtype=int32)", 
            "title": "shape"
        }, 
        {
            "location": "/backend/#int_shape", 
            "text": "int_shape(x)  \u4ee5\u6574\u6570Tuple\u6216None\u7684\u5f62\u5f0f\u8fd4\u56de\u5f20\u91cfshape\uff0c\u793a\u4f8b\uff1a   from keras import backend as K  input = K.placeholder(shape=(2, 4, 5))  K.int_shape(input)\n(2, 4, 5)  val = np.array([[1, 2], [3, 4]])  kvar = K.variable(value=val)  K.int_shape(kvar)\n(2, 2)", 
            "title": "int_shape"
        }, 
        {
            "location": "/backend/#ndim", 
            "text": "ndim(x)  \u8fd4\u56de\u5f20\u91cf\u7684\u9636\u6570\uff0c\u4e3a\u6574\u6570\uff0c\u793a\u4f8b\uff1a   from keras import backend as K  input = K.placeholder(shape=(2, 4, 5))  val = np.array([[1, 2], [3, 4]])  kvar = K.variable(value=val)  K.ndim(input)\n3  K.ndim(kvar)\n2", 
            "title": "ndim"
        }, 
        {
            "location": "/backend/#dtype", 
            "text": "dtype(x)  \u8fd4\u56de\u5f20\u91cf\u7684\u6570\u636e\u7c7b\u578b\uff0c\u4e3a\u5b57\u7b26\u4e32\uff0c\u793a\u4f8b\uff1a   from keras import backend as K  K.dtype(K.placeholder(shape=(2,4,5)))\n'float32'  K.dtype(K.placeholder(shape=(2,4,5), dtype='float32'))\n'float32'  K.dtype(K.placeholder(shape=(2,4,5), dtype='float64'))\n'float64'\n__Keras variable__  kvar = K.variable(np.array([[1, 2], [3, 4]]))  K.dtype(kvar)\n'float32_ref'  kvar = K.variable(np.array([[1, 2], [3, 4]]), dtype='float32')  K.dtype(kvar)\n'float32_ref'", 
            "title": "dtype"
        }, 
        {
            "location": "/backend/#eval", 
            "text": "eval(x)  \u6c42\u5f97\u5f20\u91cf\u7684\u503c\uff0c\u8fd4\u56de\u4e00\u4e2aNumpy array\uff0c\u793a\u4f8b\uff1a   from keras import backend as K  kvar = K.variable(np.array([[1, 2], [3, 4]]), dtype='float32')  K.eval(kvar)\narray([[ 1.,  2.],\n   [ 3.,  4.]], dtype=float32)", 
            "title": "eval"
        }, 
        {
            "location": "/backend/#zeros", 
            "text": "zeros(shape, dtype='float32', name=None)  \u751f\u6210\u4e00\u4e2a\u51680\u5f20\u91cf\uff0c\u793a\u4f8b\uff1a   from keras import backend as K  kvar = K.zeros((3,4))  K.eval(kvar)\narray([[ 0.,  0.,  0.,  0.],\n   [ 0.,  0.,  0.,  0.],\n   [ 0.,  0.,  0.,  0.]], dtype=float32)", 
            "title": "zeros"
        }, 
        {
            "location": "/backend/#ones", 
            "text": "ones(shape, dtype='float32', name=None)  \u751f\u6210\u4e00\u4e2a\u51681\u5f20\u91cf\uff0c\u793a\u4f8b   from keras import backend as K  kvar = K.ones((3,4))  K.eval(kvar)\narray([[ 1.,  1.,  1.,  1.],\n   [ 1.,  1.,  1.,  1.],\n   [ 1.,  1.,  1.,  1.]], dtype=float32)", 
            "title": "ones"
        }, 
        {
            "location": "/backend/#eye", 
            "text": "eye(size, dtype='float32', name=None)  \u751f\u6210\u4e00\u4e2a\u5355\u4f4d\u77e9\u9635\uff0c\u793a\u4f8b\uff1a   from keras import backend as K  kvar = K.eye(3)  K.eval(kvar)\narray([[ 1.,  0.,  0.],\n   [ 0.,  1.,  0.],\n   [ 0.,  0.,  1.]], dtype=float32)", 
            "title": "eye"
        }, 
        {
            "location": "/backend/#zeros_like", 
            "text": "zeros_like(x, name=None)  \u751f\u6210\u4e0e\u53e6\u4e00\u4e2a\u5f20\u91cfx\u7684shape\u76f8\u540c\u7684\u51680\u5f20\u91cf\uff0c\u793a\u4f8b\uff1a   from keras import backend as K  kvar = K.variable(np.random.random((2,3)))  kvar_zeros = K.zeros_like(kvar)  K.eval(kvar_zeros)\narray([[ 0.,  0.,  0.],\n   [ 0.,  0.,  0.]], dtype=float32)", 
            "title": "zeros_like"
        }, 
        {
            "location": "/backend/#ones_like", 
            "text": "ones_like(x, name=None)  \u751f\u6210\u4e0e\u53e6\u4e00\u4e2a\u5f20\u91cfshape\u76f8\u540c\u7684\u51681\u5f20\u91cf\uff0c\u793a\u4f8b\uff1a   from keras import backend as K  kvar = K.variable(np.random.random((2,3)))  kvar_ones = K.ones_like(kvar)  K.eval(kvar_ones)\narray([[ 1.,  1.,  1.],\n   [ 1.,  1.,  1.]], dtype=float32)", 
            "title": "ones_like"
        }, 
        {
            "location": "/backend/#random_uniform_variable", 
            "text": "random_uniform_variable(shape, low, high, dtype=None, name=None, seed=None)  \u521d\u59cb\u5316\u4e00\u4e2aKeras\u53d8\u91cf\uff0c\u5176\u6570\u503c\u4e3a\u4ece\u4e00\u4e2a\u5747\u5300\u5206\u5e03\u4e2d\u91c7\u6837\u7684\u6837\u672c\uff0c\u8fd4\u56de\u4e4b\u3002  \u53c2\u6570\uff1a   shape\uff1a\u5f20\u91cfshape  low\uff1a\u6d6e\u70b9\u6570\uff0c\u5747\u5300\u5206\u5e03\u4e4b\u4e0b\u754c  high\uff1a\u6d6e\u70b9\u6570\uff0c\u5747\u5300\u5206\u5e03\u4e4b\u4e0a\u754c  dtype\uff1a\u6570\u636e\u7c7b\u578b  name\uff1a\u5f20\u91cf\u540d  seed\uff1a\u968f\u673a\u6570\u79cd\u5b50   \u793a\u4f8b\uff1a   kvar = K.random_uniform_variable((2,3), 0, 1)  kvar tensorflow.python.ops.variables.Variable object at 0x10ab40b10   K.eval(kvar)\narray([[ 0.10940075,  0.10047495,  0.476143  ],\n   [ 0.66137183,  0.00869417,  0.89220798]], dtype=float32)", 
            "title": "random_uniform_variable"
        }, 
        {
            "location": "/backend/#count_params", 
            "text": "count_params(x)  \u8fd4\u56de\u5f20\u91cf\u4e2d\u6807\u91cf\u7684\u4e2a\u6570\uff0c\u793a\u4f8b\uff1a   kvar = K.zeros((2,3))  K.count_params(kvar)\n6  K.eval(kvar)\narray([[ 0.,  0.,  0.],\n   [ 0.,  0.,  0.]], dtype=float32)", 
            "title": "count_params"
        }, 
        {
            "location": "/backend/#cast", 
            "text": "cast(x, dtype)  \u6539\u53d8\u5f20\u91cf\u7684\u6570\u636e\u7c7b\u578b\uff0cdtype\u53ea\u80fd\u662f float16 ,  float32 \u6216 float64 \u4e4b\u4e00\uff0c\u793a\u4f8b\uff1a   from keras import backend as K  input = K.placeholder((2, 3), dtype='float32')  input tf.Tensor 'Placeholder_2:0' shape=(2, 3) dtype=float32 \n__It doesn't work in-place as below.__  K.cast(input, dtype='float16') tf.Tensor 'Cast_1:0' shape=(2, 3) dtype=float16   input tf.Tensor 'Placeholder_2:0' shape=(2, 3) dtype=float32 \n__you need to assign it.__  input = K.cast(input, dtype='float16')  input tf.Tensor 'Cast_2:0' shape=(2, 3) dtype=float16 ```", 
            "title": "cast"
        }, 
        {
            "location": "/backend/#dot", 
            "text": "dot(x, y)  \u6c42\u4e24\u4e2a\u5f20\u91cf\u7684\u4e58\u79ef\u3002\u5f53\u8bd5\u56fe\u8ba1\u7b97\u4e24\u4e2aN\u9636\u5f20\u91cf\u7684\u4e58\u79ef\u65f6\uff0c\u4e0eTheano\u884c\u4e3a\u76f8\u540c\uff0c\u5982 (2, 3).(4, 3, 5) = (2, 4, 5)) \uff0c\u793a\u4f8b\uff1a   x = K.placeholder(shape=(2, 3))  y = K.placeholder(shape=(3, 4))  xy = K.dot(x, y)  xy tf.Tensor 'MatMul_9:0' shape=(2, 4) dtype=float32    x = K.placeholder(shape=(32, 28, 3))  y = K.placeholder(shape=(3, 4))  xy = K.dot(x, y)  xy tf.Tensor 'MatMul_9:0' shape=(32, 28, 4) dtype=float32   Theano-like\u7684\u884c\u4e3a\u793a\u4f8b\uff1a   x = K.random_uniform_variable(shape=(2, 3), low=0, high=1)  y = K.ones((4, 3, 5))  xy = K.dot(x, y)  K.int_shape(xy)\n(2, 4, 5)", 
            "title": "dot"
        }, 
        {
            "location": "/backend/#batch_dot", 
            "text": "batch_dot(x, y, axes=None)  \u6309\u6279\u8fdb\u884c\u5f20\u91cf\u4e58\u6cd5\uff0c\u8be5\u51fd\u6570\u7528\u4e8e\u8ba1\u7b97x\u548cy\u7684\u70b9\u79ef\uff0c\u5176\u4e2dx\u548cy\u90fd\u662f\u6210batch\u51fa\u73b0\u7684\u6570\u636e\u3002\u5373\u5b83\u7684\u6570\u636eshape\u5f62\u5982 (batch_size,:) \u3002batch_dot\u5c06\u4ea7\u751f\u6bd4\u8f93\u5165\u5f20\u91cf\u7ef4\u5ea6\u4f4e\u7684\u5f20\u91cf\uff0c\u5982\u679c\u5f20\u91cf\u7684\u7ef4\u5ea6\u88ab\u51cf\u81f31\uff0c\u5219\u901a\u8fc7 expand_dims \u4fdd\u8bc1\u5176\u7ef4\u5ea6\u81f3\u5c11\u4e3a2\n\u4f8b\u5982\uff0c\u5047\u8bbe x = [[1, 2],[3,4]]  \uff0c  y = [[5, 6],[7, 8]] \uff0c\u5219 batch_dot(x, y, axes=1) = [[17, 53]] \uff0c\u5373 x.dot(y.T) \u7684\u4e3b\u5bf9\u89d2\u5143\u7d20\uff0c\u6b64\u8fc7\u7a0b\u4e2d\u6211\u4eec\u6ca1\u6709\u8ba1\u7b97\u8fc7\u53cd\u5bf9\u89d2\u5143\u7d20\u7684\u503c  \u53c2\u6570\uff1a   x,y\uff1a\u9636\u6570\u5927\u4e8e\u7b49\u4e8e2\u7684\u5f20\u91cf\uff0c\u5728tensorflow\u4e0b\uff0c\u53ea\u652f\u6301\u5927\u4e8e\u7b49\u4e8e3\u9636\u7684\u5f20\u91cf  axes\uff1a\u76ee\u6807\u7ed3\u679c\u7684\u7ef4\u5ea6\uff0c\u4e3a\u6574\u6570\u6216\u6574\u6570\u5217\u8868\uff0c axes[0] \u548c axes[1] \u5e94\u76f8\u540c   \u793a\u4f8b\uff1a\n\u5047\u8bbe x=[[1,2],[3,4]] \uff0c y=[[5,6],[7,8]] \uff0c\u5219 batch_dot(x, y, axes=1) \u4e3a [[17, 53]] \uff0c\u6070\u597d\u4e3a x.dot(y.T) \u7684\u4e3b\u5bf9\u89d2\u5143\uff0c\u6574\u4e2a\u8fc7\u7a0b\u6ca1\u6709\u8ba1\u7b97\u53cd\u5bf9\u89d2\u5143\u7684\u5143\u7d20\u3002  \u6211\u4eec\u505a\u4e00\u4e0bshape\u7684\u63a8\u5bfc\uff0c\u5047\u8bbex\u662f\u4e00\u4e2ashape\u4e3a(100,20)\u7684tensor\uff0cy\u662f\u4e00\u4e2ashape\u4e3a(100,30,20)\u7684tensor\uff0c\u5047\u8bbe axes=(1,2) \uff0c\u5219\u8f93\u51fatensor\u7684shape\u901a\u8fc7\u5faa\u73afx.shape\u548cy.shape\u786e\u5b9a\uff1a   x.shape[0] \uff1a\u503c\u4e3a100\uff0c\u52a0\u5165\u5230\u8f93\u5165shape\u91cc  x.shape[1] \uff1a20\uff0c\u4e0d\u52a0\u5165\u8f93\u51fashape\u91cc\uff0c\u56e0\u4e3a\u8be5\u7ef4\u5ea6\u7684\u503c\u4f1a\u88ab\u6c42\u548c(dot_axes[0]=1)  y.shape[0] \uff1a\u503c\u4e3a100\uff0c\u4e0d\u52a0\u5165\u5230\u8f93\u51fashape\u91cc\uff0cy\u7684\u7b2c\u4e00\u7ef4\u603b\u662f\u88ab\u5ffd\u7565  y.shape[1] \uff1a30\uff0c\u52a0\u5165\u5230\u8f93\u51fashape\u91cc   y.shape[2] \uff1a20\uff0c\u4e0d\u52a0\u5230output shape\u91cc\uff0cy\u7684\u7b2c\u4e8c\u4e2a\u7ef4\u5ea6\u4f1a\u88ab\u6c42\u548c(dot_axes[1]=2)    \u7ed3\u679c\u4e3a(100, 30)     x_batch = K.ones(shape=(32, 20, 1))  y_batch = K.ones(shape=(32, 30, 20))  xy_batch_dot = K.batch_dot(x_batch, y_batch, axes=[1, 2])  K.int_shape(xy_batch_dot)\n(32, 1, 30)", 
            "title": "batch_dot"
        }, 
        {
            "location": "/backend/#transpose", 
            "text": "transpose(x)  \u5f20\u91cf\u8f6c\u7f6e\uff0c\u8fd4\u56de\u8f6c\u7f6e\u540e\u7684tensor\uff0c\u793a\u4f8b\uff1a   var = K.variable([[1, 2, 3], [4, 5, 6]])  K.eval(var)\narray([[ 1.,  2.,  3.],\n   [ 4.,  5.,  6.]], dtype=float32)  var_transposed = K.transpose(var)  K.eval(var_transposed)\narray([[ 1.,  4.],\n   [ 2.,  5.],\n   [ 3.,  6.]], dtype=float32)  input = K.placeholder((2, 3))  input tf.Tensor 'Placeholder_11:0' shape=(2, 3) dtype=float32   input_transposed = K.transpose(input)  input_transposed tf.Tensor 'transpose_4:0' shape=(3, 2) dtype=float32", 
            "title": "transpose"
        }, 
        {
            "location": "/backend/#gather", 
            "text": "gather(reference, indices)  \u5728\u7ed9\u5b9a\u76842D\u5f20\u91cf\u4e2d\u68c0\u7d22\u7ed9\u5b9a\u4e0b\u6807\u7684\u5411\u91cf  \u53c2\u6570\uff1a   reference\uff1a2D\u5f20\u91cf  indices\uff1a\u6574\u6570\u5f20\u91cf\uff0c\u5176\u5143\u7d20\u4e3a\u8981\u67e5\u8be2\u7684\u4e0b\u6807   \u8fd4\u56de\u503c\uff1a\u4e00\u4e2a\u4e0e reference \u6570\u636e\u7c7b\u578b\u76f8\u540c\u76843D\u5f20\u91cf", 
            "title": "gather"
        }, 
        {
            "location": "/backend/#max", 
            "text": "max(x, axis=None, keepdims=False)  \u6c42\u5f20\u91cf\u4e2d\u7684\u6700\u5927\u503c", 
            "title": "max"
        }, 
        {
            "location": "/backend/#min", 
            "text": "min(x, axis=None, keepdims=False)  \u6c42\u5f20\u91cf\u4e2d\u7684\u6700\u5c0f\u503c", 
            "title": "min"
        }, 
        {
            "location": "/backend/#sum", 
            "text": "sum(x, axis=None, keepdims=False)  \u5728\u7ed9\u5b9a\u8f74\u4e0a\u8ba1\u7b97\u5f20\u91cf\u4e2d\u5143\u7d20\u4e4b\u548c", 
            "title": "sum"
        }, 
        {
            "location": "/backend/#prod", 
            "text": "prod(x, axis=None, keepdims=False)  \u5728\u7ed9\u5b9a\u8f74\u4e0a\u8ba1\u7b97\u5f20\u91cf\u4e2d\u5143\u7d20\u4e4b\u79ef", 
            "title": "prod"
        }, 
        {
            "location": "/backend/#var", 
            "text": "var(x, axis=None, keepdims=False)  \u5728\u7ed9\u5b9a\u8f74\u4e0a\u8ba1\u7b97\u5f20\u91cf\u65b9\u5dee", 
            "title": "var"
        }, 
        {
            "location": "/backend/#std", 
            "text": "std(x, axis=None, keepdims=False)  \u5728\u7ed9\u5b9a\u8f74\u4e0a\u6c42\u5f20\u91cf\u5143\u7d20\u4e4b\u6807\u51c6\u5dee", 
            "title": "std"
        }, 
        {
            "location": "/backend/#mean", 
            "text": "mean(x, axis=None, keepdims=False)  \u5728\u7ed9\u5b9a\u8f74\u4e0a\u6c42\u5f20\u91cf\u5143\u7d20\u4e4b\u5747\u503c", 
            "title": "mean"
        }, 
        {
            "location": "/backend/#any", 
            "text": "any(x, axis=None, keepdims=False)  \u6309\u4f4d\u6216\uff0c\u8fd4\u56de\u6570\u636e\u7c7b\u578b\u4e3auint8\u7684\u5f20\u91cf\uff08\u5143\u7d20\u4e3a0\u62161\uff09", 
            "title": "any"
        }, 
        {
            "location": "/backend/#all", 
            "text": "any(x, axis=None, keepdims=False)  \u6309\u4f4d\u4e0e\uff0c\u8fd4\u56de\u7c7b\u578b\u4e3auint8de tensor", 
            "title": "all"
        }, 
        {
            "location": "/backend/#argmax", 
            "text": "argmax(x, axis=-1)  \u5728\u7ed9\u5b9a\u8f74\u4e0a\u6c42\u5f20\u91cf\u4e4b\u6700\u5927\u5143\u7d20\u4e0b\u6807", 
            "title": "argmax"
        }, 
        {
            "location": "/backend/#argmin", 
            "text": "argmin(x, axis=-1)  \u5728\u7ed9\u5b9a\u8f74\u4e0a\u6c42\u5f20\u91cf\u4e4b\u6700\u5c0f\u5143\u7d20\u4e0b\u6807", 
            "title": "argmin"
        }, 
        {
            "location": "/backend/#square", 
            "text": "square(x)  \u9010\u5143\u7d20\u5e73\u65b9", 
            "title": "square"
        }, 
        {
            "location": "/backend/#abs", 
            "text": "abs(x)  \u9010\u5143\u7d20\u7edd\u5bf9\u503c", 
            "title": "abs"
        }, 
        {
            "location": "/backend/#sqrt", 
            "text": "sqrt(x)  \u9010\u5143\u7d20\u5f00\u65b9", 
            "title": "sqrt"
        }, 
        {
            "location": "/backend/#exp", 
            "text": "exp(x)  \u9010\u5143\u7d20\u6c42\u81ea\u7136\u6307\u6570", 
            "title": "exp"
        }, 
        {
            "location": "/backend/#log", 
            "text": "log(x)  \u9010\u5143\u7d20\u6c42\u81ea\u7136\u5bf9\u6570", 
            "title": "log"
        }, 
        {
            "location": "/backend/#round", 
            "text": "round(x)  \u9010\u5143\u7d20\u56db\u820d\u4e94\u5165", 
            "title": "round"
        }, 
        {
            "location": "/backend/#sign", 
            "text": "sign(x)  \u9010\u5143\u7d20\u6c42\u5143\u7d20\u7684\u7b26\u53f7\uff08+1\u6216-1\uff09", 
            "title": "sign"
        }, 
        {
            "location": "/backend/#pow", 
            "text": "pow(x, a)  \u9010\u5143\u7d20\u6c42x\u7684a\u6b21\u65b9", 
            "title": "pow"
        }, 
        {
            "location": "/backend/#clip", 
            "text": "clip(x, min_value, max_value)  \u9010\u5143\u7d20clip\uff08\u5c06\u8d85\u51fa\u6307\u5b9a\u8303\u56f4\u7684\u6570\u5f3a\u5236\u53d8\u4e3a\u8fb9\u754c\u503c\uff09", 
            "title": "clip"
        }, 
        {
            "location": "/backend/#equal", 
            "text": "equal(x, y)  \u9010\u5143\u7d20\u5224\u76f8\u7b49\u5173\u7cfb\uff0c\u8fd4\u56de\u5e03\u5c14\u5f20\u91cf", 
            "title": "equal"
        }, 
        {
            "location": "/backend/#not_equal", 
            "text": "not_equal(x, y)  \u9010\u5143\u7d20\u5224\u4e0d\u7b49\u5173\u7cfb\uff0c\u8fd4\u56de\u5e03\u5c14\u5f20\u91cf", 
            "title": "not_equal"
        }, 
        {
            "location": "/backend/#greater", 
            "text": "greater(x,y)  \u9010\u5143\u7d20\u5224\u65adx y\u5173\u7cfb\uff0c\u8fd4\u56de\u5e03\u5c14\u5f20\u91cf", 
            "title": "greater"
        }, 
        {
            "location": "/backend/#greater_equal", 
            "text": "greater_equal(x,y)  \u9010\u5143\u7d20\u5224\u65adx =y\u5173\u7cfb\uff0c\u8fd4\u56de\u5e03\u5c14\u5f20\u91cf", 
            "title": "greater_equal"
        }, 
        {
            "location": "/backend/#lesser", 
            "text": "lesser(x,y)  \u9010\u5143\u7d20\u5224\u65adx y\u5173\u7cfb\uff0c\u8fd4\u56de\u5e03\u5c14\u5f20\u91cf", 
            "title": "lesser"
        }, 
        {
            "location": "/backend/#lesser_equal", 
            "text": "lesser_equal(x,y)  \u9010\u5143\u7d20\u5224\u65adx =y\u5173\u7cfb\uff0c\u8fd4\u56de\u5e03\u5c14\u5f20\u91cf", 
            "title": "lesser_equal"
        }, 
        {
            "location": "/backend/#maximum", 
            "text": "maximum(x, y)  \u9010\u5143\u7d20\u53d6\u4e24\u4e2a\u5f20\u91cf\u7684\u6700\u5927\u503c", 
            "title": "maximum"
        }, 
        {
            "location": "/backend/#minimum", 
            "text": "minimum(x, y)  \u9010\u5143\u7d20\u53d6\u4e24\u4e2a\u5f20\u91cf\u7684\u6700\u5c0f\u503c", 
            "title": "minimum"
        }, 
        {
            "location": "/backend/#sin", 
            "text": "sin(x)  \u9010\u5143\u7d20\u6c42\u6b63\u5f26\u503c", 
            "title": "sin"
        }, 
        {
            "location": "/backend/#cos", 
            "text": "cos(x)  \u9010\u5143\u7d20\u6c42\u4f59\u5f26\u503c", 
            "title": "cos"
        }, 
        {
            "location": "/backend/#normalize_batch_in_training", 
            "text": "normalize_batch_in_training(x, gamma, beta, reduction_axes, epsilon=0.0001)  \u5bf9\u4e00\u4e2abatch\u6570\u636e\u5148\u8ba1\u7b97\u5176\u5747\u503c\u548c\u65b9\u5dee\uff0c\u7136\u540e\u518d\u8fdb\u884cbatch_normalization", 
            "title": "normalize_batch_in_training"
        }, 
        {
            "location": "/backend/#batch_normalization", 
            "text": "batch_normalization(x, mean, var, beta, gamma, epsilon=0.0001)  \u5bf9\u4e00\u4e2abatch\u7684\u6570\u636e\u8fdb\u884cbatch_normalization\uff0c\u8ba1\u7b97\u516c\u5f0f\u4e3a\uff1a\noutput = (x-mean)/(sqrt(var)+epsilon)*gamma+beta", 
            "title": "batch_normalization"
        }, 
        {
            "location": "/backend/#concatenate", 
            "text": "concatenate(tensors, axis=-1)  \u5728\u7ed9\u5b9a\u8f74\u4e0a\u5c06\u4e00\u4e2a\u5217\u8868\u4e2d\u7684\u5f20\u91cf\u4e32\u8054\u4e3a\u4e00\u4e2a\u5f20\u91cf specified axis", 
            "title": "concatenate"
        }, 
        {
            "location": "/backend/#reshape", 
            "text": "reshape(x, shape)  \u5c06\u5f20\u91cf\u7684shape\u53d8\u6362\u4e3a\u6307\u5b9ashape", 
            "title": "reshape"
        }, 
        {
            "location": "/backend/#permute_dimensions", 
            "text": "permute_dimensions(x, pattern)  \u6309\u7167\u7ed9\u5b9a\u7684\u6a21\u5f0f\u91cd\u6392\u4e00\u4e2a\u5f20\u91cf\u7684\u8f74  \u53c2\u6570\uff1a   pattern\uff1a\u4ee3\u8868\u7ef4\u5ea6\u4e0b\u6807\u7684tuple\u5982 (0, 2, 1)", 
            "title": "permute_dimensions"
        }, 
        {
            "location": "/backend/#resize_images", 
            "text": "resize_images(X, height_factor, width_factor, dim_ordering)  \u4f9d\u636e\u7ed9\u5b9a\u7684\u7f29\u653e\u56e0\u5b50\uff0c\u6539\u53d8\u4e00\u4e2abatch\u56fe\u7247\u7684shape\uff0c\u53c2\u6570\u4e2d\u7684\u4e24\u4e2a\u56e0\u5b50\u90fd\u4e3a\u6b63\u6574\u6570\uff0c\u56fe\u7247\u7684\u6392\u5217\u987a\u5e8f\u4e0e\u7ef4\u5ea6\u7684\u6a21\u5f0f\u76f8\u5173\uff0c\u5982\u2018th\u2019\u548c\u2018tf\u2019", 
            "title": "resize_images"
        }, 
        {
            "location": "/backend/#resize_volumes", 
            "text": "resize_volumes(X, depth_factor, height_factor, width_factor, dim_ordering)  \u4f9d\u636e\u7ed9\u5b9a\u7684\u7f29\u653e\u56e0\u5b50\uff0c\u6539\u53d8\u4e00\u4e2a5D\u5f20\u91cf\u6570\u636e\u7684shape\uff0c\u53c2\u6570\u4e2d\u7684\u4e24\u4e2a\u56e0\u5b50\u90fd\u4e3a\u6b63\u6574\u6570\uff0c\u56fe\u7247\u7684\u6392\u5217\u987a\u5e8f\u4e0e\u7ef4\u5ea6\u7684\u6a21\u5f0f\u76f8\u5173\uff0c\u5982\u2018th\u2019\u548c\u2018tf\u2019\u30025D\u6570\u636e\u7684\u5f62\u5f0f\u662f batch, channels, depth, height, width \u6216 batch, depth, height, width, channels", 
            "title": "resize_volumes"
        }, 
        {
            "location": "/backend/#repeat_elements", 
            "text": "repeat_elements(x, rep, axis)  \u5728\u7ed9\u5b9a\u8f74\u4e0a\u91cd\u590d\u5f20\u91cf\u5143\u7d20 rep \u6b21\uff0c\u4e0e np.repeat \u7c7b\u4f3c\u3002\u4f8b\u5982\uff0c\u82e5xshape (s1, s2, s3) \u5e76\u4e14\u7ed9\u5b9a\u8f74\u4e3a axis=1`\uff0c\u8f93\u51fa\u5f20\u91cf\u7684shape\u4e3a`(s1, s2 * rep, s3)", 
            "title": "repeat_elements"
        }, 
        {
            "location": "/backend/#repeat", 
            "text": "repeat(x, n)  \u91cd\u590d2D\u5f20\u91cf\uff0c\u4f8b\u5982\u82e5xshape\u662f (samples, dim) \u4e14n\u4e3a2\uff0c\u5219\u8f93\u51fa\u5f20\u91cf\u7684shape\u662f (samples, 2, dim)", 
            "title": "repeat"
        }, 
        {
            "location": "/backend/#arange", 
            "text": "arange(start, stop=None, step=1, dtype='int32')  \u751f\u62101D\u7684\u6574\u6570\u5e8f\u5217\u5f20\u91cf\uff0c\u8be5\u51fd\u6570\u7684\u53c2\u6570\u4e0eTheano\u7684arange\u51fd\u6570\u542b\u4e49\u76f8\u540c\uff0c\u5982\u679c\u53ea\u6709\u4e00\u4e2a\u53c2\u6570\u88ab\u63d0\u4f9b\u4e86\uff0c\u90a3\u4e48\u5b83\u5b9e\u9645\u4e0a\u5c31\u662f stop \u53c2\u6570\u7684\u503c  \u4e3a\u4e86\u4e0etensorflow\u7684\u9ed8\u8ba4\u4fdd\u6301\u5339\u914d\uff0c\u51fd\u6570\u8fd4\u56de\u5f20\u91cf\u7684\u9ed8\u8ba4\u6570\u636e\u7c7b\u578b\u662f int32", 
            "title": "arange"
        }, 
        {
            "location": "/backend/#batch_flatten", 
            "text": "batch_flatten(x)  \u5c06\u4e00\u4e2an\u9636\u5f20\u91cf\u8f6c\u53d8\u4e3a2\u9636\u5f20\u91cf\uff0c\u5176\u7b2c\u4e00\u7ef4\u5ea6\u4fdd\u7559\u4e0d\u53d8", 
            "title": "batch_flatten"
        }, 
        {
            "location": "/backend/#expand_dims", 
            "text": "expand_dims(x, dim=-1)  \u5728\u4e0b\u6807\u4e3a dim \u7684\u8f74\u4e0a\u589e\u52a0\u4e00\u7ef4", 
            "title": "expand_dims"
        }, 
        {
            "location": "/backend/#squeeze", 
            "text": "squeeze(x, axis)  \u5c06\u4e0b\u6807\u4e3a axis \u7684\u4e00\u7ef4\u4ece\u5f20\u91cf\u4e2d\u79fb\u9664", 
            "title": "squeeze"
        }, 
        {
            "location": "/backend/#temporal_padding", 
            "text": "temporal_padding(x, padding=1)  \u54113D\u5f20\u91cf\u4e2d\u95f4\u7684\u90a3\u4e2a\u7ef4\u5ea6\u7684\u5de6\u53f3\u4e24\u7aef\u586b\u5145 padding \u4e2a0\u503c", 
            "title": "temporal_padding"
        }, 
        {
            "location": "/backend/#asymmetric_temporal_padding", 
            "text": "asymmetric_temporal_padding(x, left_pad=1, right_pad=1)  \u54113D\u5f20\u91cf\u4e2d\u95f4\u7684\u90a3\u4e2a\u7ef4\u5ea6\u7684\u4e00\u7aef\u586b\u5145 padding \u4e2a0\u503c", 
            "title": "asymmetric_temporal_padding"
        }, 
        {
            "location": "/backend/#spatial_2d_padding", 
            "text": "spatial_2d_padding(x, padding=(1, 1), dim_ordering='th')  \u54114D\u5f20\u91cf\u7b2c\u4e8c\u548c\u7b2c\u4e09\u7ef4\u5ea6\u7684\u5de6\u53f3\u4e24\u7aef\u586b\u5145 padding[0] \u548c padding[1] \u4e2a0\u503c", 
            "title": "spatial_2d_padding"
        }, 
        {
            "location": "/backend/#asymmetric_spatial_2d_padding", 
            "text": "asymmetric_spatial_2d_padding(x, top_pad=1, bottom_pad=1, left_pad=1, right_pad=1, dim_ordering='th')  \u5bf94D\u5f20\u91cf\u7684\u90e8\u5206\u65b9\u5411\u8fdb\u884c\u586b\u5145", 
            "title": "asymmetric_spatial_2d_padding"
        }, 
        {
            "location": "/backend/#spatial_3d_padding", 
            "text": "spatial_3d_padding(x, padding=(1, 1, 1), dim_ordering='th')  \u54115D\u5f20\u91cf\u6df1\u5ea6\u3001\u9ad8\u5ea6\u548c\u5bbd\u5ea6\u4e09\u4e2a\u7ef4\u5ea6\u4e0a\u586b\u5145 padding[0] \uff0c padding[1] \u548c padding[2] \u4e2a0\u503c", 
            "title": "spatial_3d_padding"
        }, 
        {
            "location": "/backend/#one-hot", 
            "text": "one_hot(indices, nb_classes)  \u8f93\u5165\u4e3an\u7ef4\u7684\u6574\u6570\u5f20\u91cf\uff0c\u5f62\u5982(batch_size, dim1, dim2, ... dim(n-1))\uff0c\u8f93\u51fa\u4e3a(n+1)\u7ef4\u7684one-hot\u7f16\u7801\uff0c\u5f62\u5982(batch_size, dim1, dim2, ... dim(n-1), nb_classes)", 
            "title": "one-hot"
        }, 
        {
            "location": "/backend/#reverse", 
            "text": "reverse(x, axes)  \u5c06\u4e00\u4e2a\u5f20\u91cf\u5728\u7ed9\u5b9a\u8f74\u4e0a\u53cd\u8f6c", 
            "title": "reverse"
        }, 
        {
            "location": "/backend/#get_value", 
            "text": "get_value(x)  \u4ee5Numpy array\u7684\u5f62\u5f0f\u8fd4\u56de\u5f20\u91cf\u7684\u503c", 
            "title": "get_value"
        }, 
        {
            "location": "/backend/#batch_get_value", 
            "text": "batch_get_value(x)  \u4ee5Numpy array list\u7684\u5f62\u5f0f\u8fd4\u56de\u591a\u4e2a\u5f20\u91cf\u7684\u503c", 
            "title": "batch_get_value"
        }, 
        {
            "location": "/backend/#set_value", 
            "text": "set_value(x, value)  \u4ecenumpy array\u5c06\u503c\u8f7d\u5165\u5f20\u91cf\u4e2d", 
            "title": "set_value"
        }, 
        {
            "location": "/backend/#batch_set_value", 
            "text": "batch_set_value(tuples)  \u5c06\u591a\u4e2a\u503c\u8f7d\u5165\u591a\u4e2a\u5f20\u91cf\u53d8\u91cf\u4e2d  \u53c2\u6570\uff1a   tuples: \u5217\u8868\uff0c\u5176\u4e2d\u7684\u5143\u7d20\u5f62\u5982 (tensor, value) \u3002 value \u662f\u8981\u8f7d\u5165\u7684Numpy array\u6570\u636e", 
            "title": "batch_set_value"
        }, 
        {
            "location": "/backend/#print_tensor", 
            "text": "print_tensor(x, message='')  \u5728\u6c42\u503c\u65f6\u6253\u5370\u5f20\u91cf\u7684\u4fe1\u606f\uff0c\u5e76\u8fd4\u56de\u539f\u5f20\u91cf", 
            "title": "print_tensor"
        }, 
        {
            "location": "/backend/#function", 
            "text": "function(inputs, outputs, updates=[])  \u5b9e\u4f8b\u5316\u4e00\u4e2aKeras\u51fd\u6570  \u53c2\u6570\uff1a   inputs:\uff1a\u5217\u8868\uff0c\u5176\u5143\u7d20\u4e3a\u5360\u4f4d\u7b26\u6216\u5f20\u91cf\u53d8\u91cf  outputs\uff1a\u8f93\u51fa\u5f20\u91cf\u7684\u5217\u8868  updates\uff1a\u5217\u8868\uff0c\u5176\u5143\u7d20\u662f\u5f62\u5982 (old_tensor, new_tensor) \u7684tuple.", 
            "title": "function"
        }, 
        {
            "location": "/backend/#gradients", 
            "text": "gradients(loss, variables)  \u8fd4\u56deloss\u51fd\u6570\u5173\u4e8evariables\u7684\u68af\u5ea6\uff0cvariables\u4e3a\u5f20\u91cf\u53d8\u91cf\u7684\u5217\u8868", 
            "title": "gradients"
        }, 
        {
            "location": "/backend/#stop_gradient", 
            "text": "stop_gradient(variables)  Returns  variables  but with zero gradient with respect to every other variables.", 
            "title": "stop_gradient"
        }, 
        {
            "location": "/backend/#rnn", 
            "text": "rnn(step_function, inputs, initial_states, go_backwards=False, mask=None, constants=None, unroll=False, input_length=None)  \u5728\u5f20\u91cf\u7684\u65f6\u95f4\u7ef4\u4e0a\u8fed\u4ee3  \u53c2\u6570\uff1a   inputs\uff1a \u5f62\u5982 (samples, time, ...) \u7684\u65f6\u57df\u4fe1\u53f7\u7684\u5f20\u91cf\uff0c\u9636\u6570\u81f3\u5c11\u4e3a3  step_function\uff1a\u6bcf\u4e2a\u65f6\u95f4\u6b65\u8981\u6267\u884c\u7684\u51fd\u6570\n    \u5176\u53c2\u6570\uff1a      input\uff1a\u5f62\u5982 (samples, ...) \u7684\u5f20\u91cf\uff0c\u4e0d\u542b\u65f6\u95f4\u7ef4\uff0c\u4ee3\u8868\u67d0\u4e2a\u65f6\u95f4\u6b65\u65f6\u4e00\u4e2abatch\u7684\u6837\u672c    states\uff1a\u5f20\u91cf\u5217\u8868\n\u5176\u8fd4\u56de\u503c\uff1a  output\uff1a\u5f62\u5982 (samples, ...) \u7684\u5f20\u91cf  new_states\uff1a\u5f20\u91cf\u5217\u8868\uff0c\u4e0e\u2018states\u2019\u7684\u957f\u5ea6\u76f8\u540c            initial_states\uff1a\u5f62\u5982 (samples, ...) \u7684\u5f20\u91cf\uff0c\u5305\u542b\u4e86 step_function \u72b6\u6001\u7684\u521d\u59cb\u503c\u3002  go_backwards\uff1a\u5e03\u5c14\u503c\uff0c\u82e5\u8bbe\u4e3aTrue\uff0c\u5219\u9006\u5411\u8fed\u4ee3\u5e8f\u5217  mask\uff1a\u5f62\u5982 (samples, time, 1) \u7684\u4e8c\u503c\u5f20\u91cf\uff0c\u9700\u8981\u5c4f\u853d\u7684\u6570\u636e\u5143\u7d20\u4e0a\u503c\u4e3a1  constants\uff1a\u6309\u65f6\u95f4\u6b65\u4f20\u9012\u7ed9\u51fd\u6570\u7684\u5e38\u6570\u5217\u8868  unroll\uff1a\u5f53\u4f7f\u7528TensorFlow\u65f6\uff0cRNN\u603b\u662f\u5c55\u5f00\u7684\u3002\u5f53\u4f7f\u7528Theano\u65f6\uff0c\u8bbe\u7f6e\u8be5\u503c\u4e3a True \u5c06\u5c55\u5f00\u9012\u5f52\u7f51\u7edc  input_length\uff1a\u4f7f\u7528TensorFlow\u65f6\u4e0d\u9700\u8981\u6b64\u503c\uff0c\u5728\u4f7f\u7528Theano\u65f6\uff0c\u5982\u679c\u8981\u5c55\u5f00\u9012\u5f52\u7f51\u7edc\uff0c\u5fc5\u987b\u6307\u5b9a\u8f93\u5165\u5e8f\u5217   \u8fd4\u56de\u503c\uff1a\u5f62\u5982 (last_output, outputs, new_states) \u7684tuple   last_output\uff1arnn\u6700\u540e\u7684\u8f93\u51fa\uff0c\u5f62\u5982 (samples, ...)  outputs\uff1a\u5f62\u5982 (samples, time, ...) \u7684\u5f20\u91cf\uff0c\u6bcf\u4e2a\u5728[s,t]\u70b9\u7684\u8f93\u51fa\u5bf9\u5e94\u4e8e\u6837\u672cs\u5728t\u65f6\u95f4\u7684\u8f93\u51fa  new_states: \u5217\u8868\uff0c\u5176\u5143\u7d20\u4e3a\u5f62\u5982 (samples, ...) \u7684\u5f20\u91cf\uff0c\u4ee3\u8868\u6bcf\u4e2a\u6837\u672c\u7684\u6700\u540e\u4e00\u4e2a\u72b6\u6001", 
            "title": "rnn"
        }, 
        {
            "location": "/backend/#switch", 
            "text": "switch(condition, then_expression, else_expression)  \u4f9d\u636e\u7ed9\u5b9a\u7684\u6761\u4ef6\u2018condition\u2019\uff08\u6574\u6570\u6216\u5e03\u5c14\u503c\uff09\u5728\u4e24\u4e2a\u8868\u8fbe\u5f0f\u4e4b\u95f4\u5207\u6362\uff0c\u6ce8\u610f\u4e24\u4e2a\u8868\u8fbe\u5f0f\u90fd\u5e94\u8be5\u662f\u5177\u6709\u540c\u6837shape\u7684\u7b26\u53f7\u5316\u5f20\u91cf\u8868\u8fbe\u5f0f  \u53c2\u6570\uff1a   condition\uff1a\u6807\u91cf\u5f20\u91cf  then_expression\uff1aTensorFlow\u8868\u8fbe\u5f0f  else_expression: TensorFlow\u8868\u8fbe\u5f0f", 
            "title": "switch"
        }, 
        {
            "location": "/backend/#in_train_phase", 
            "text": "in_train_phase(x, alt)  \u5982\u679c\u5904\u4e8e\u8bad\u7ec3\u6a21\u5f0f\uff0c\u5219\u9009\u62e9x\uff0c\u5426\u5219\u9009\u62e9alt\uff0c\u6ce8\u610falt\u5e94\u8be5\u4e0ex\u7684shape\u76f8\u540c", 
            "title": "in_train_phase"
        }, 
        {
            "location": "/backend/#in_test_phase", 
            "text": "in_test_phase(x, alt)  \u5982\u679c\u5904\u4e8e\u6d4b\u8bd5\u6a21\u5f0f\uff0c\u5219\u9009\u62e9x\uff0c\u5426\u5219\u9009\u62e9alt\uff0c\u6ce8\u610falt\u5e94\u8be5\u4e0ex\u7684shape\u76f8\u540c", 
            "title": "in_test_phase"
        }, 
        {
            "location": "/backend/#relu", 
            "text": "relu(x, alpha=0.0, max_value=None)  \u4fee\u6b63\u7ebf\u6027\u5355\u5143  \u53c2\u6570\uff1a   alpha\uff1a\u8d1f\u534a\u533a\u659c\u7387  max_value: \u9971\u548c\u95e8\u9650", 
            "title": "relu"
        }, 
        {
            "location": "/backend/#elu", 
            "text": "elu(x, alpha=1.0)  \u6307\u6570\u7ebf\u6027\u5355\u5143  \u53c2\u6570\uff1a   x\uff1a\u8f93\u5165\u5f20\u91cf  alpha: \u6807\u91cf", 
            "title": "elu"
        }, 
        {
            "location": "/backend/#softmax", 
            "text": "softmax(x)  \u8fd4\u56de\u5f20\u91cf\u7684softmax\u503c", 
            "title": "softmax"
        }, 
        {
            "location": "/backend/#softplus", 
            "text": "softplus(x)  \u8fd4\u56de\u5f20\u91cf\u7684softplus\u503c", 
            "title": "softplus"
        }, 
        {
            "location": "/backend/#softsign", 
            "text": "softsign(x)  \u8fd4\u56de\u5f20\u91cf\u7684softsign\u503c", 
            "title": "softsign"
        }, 
        {
            "location": "/backend/#categorical_crossentropy", 
            "text": "categorical_crossentropy(output, target, from_logits=False)  \u8ba1\u7b97\u8f93\u51fa\u5f20\u91cf\u548c\u76ee\u6807\u5f20\u91cf\u7684Categorical crossentropy\uff08\u7c7b\u522b\u4ea4\u53c9\u71b5\uff09\uff0c\u76ee\u6807\u5f20\u91cf\u4e0e\u8f93\u51fa\u5f20\u91cf\u5fc5\u987bshape\u76f8\u540c", 
            "title": "categorical_crossentropy"
        }, 
        {
            "location": "/backend/#sparse_categorical_crossentropy", 
            "text": "sparse_categorical_crossentropy(output, target, from_logits=False)  \u8ba1\u7b97\u8f93\u51fa\u5f20\u91cf\u548c\u76ee\u6807\u5f20\u91cf\u7684Categorical crossentropy\uff08\u7c7b\u522b\u4ea4\u53c9\u71b5\uff09\uff0c\u76ee\u6807\u5f20\u91cf\u5fc5\u987b\u662f\u6574\u578b\u5f20\u91cf", 
            "title": "sparse_categorical_crossentropy"
        }, 
        {
            "location": "/backend/#binary_crossentropy", 
            "text": "binary_crossentropy(output, target, from_logits=False)  \u8ba1\u7b97\u8f93\u51fa\u5f20\u91cf\u548c\u76ee\u6807\u5f20\u91cf\u7684\u4ea4\u53c9\u71b5", 
            "title": "binary_crossentropy"
        }, 
        {
            "location": "/backend/#sigmoid", 
            "text": "sigmoid(x)  \u9010\u5143\u7d20\u8ba1\u7b97sigmoid\u503c", 
            "title": "sigmoid"
        }, 
        {
            "location": "/backend/#hard_sigmoid", 
            "text": "hard_sigmoid(x)  \u8be5\u51fd\u6570\u662f\u5206\u6bb5\u7ebf\u6027\u8fd1\u4f3c\u7684sigmoid\uff0c\u8ba1\u7b97\u901f\u5ea6\u66f4\u5feb", 
            "title": "hard_sigmoid"
        }, 
        {
            "location": "/backend/#tanh", 
            "text": "tanh(x)  \u9010\u5143\u7d20\u8ba1\u7b97sigmoid\u503c", 
            "title": "tanh"
        }, 
        {
            "location": "/backend/#dropout", 
            "text": "dropout(x, level, seed=None)  \u968f\u673a\u5c06x\u4e2d\u4e00\u5b9a\u6bd4\u4f8b\u7684\u503c\u8bbe\u7f6e\u4e3a0\uff0c\u5e76\u653e\u7f29\u6574\u4e2atensor  \u53c2\u6570\uff1a   x\uff1a\u5f20\u91cf  level\uff1ax\u4e2d\u8bbe\u7f6e\u62100\u7684\u5143\u7d20\u6bd4\u4f8b  seed\uff1a\u968f\u673a\u6570\u79cd\u5b50", 
            "title": "dropout"
        }, 
        {
            "location": "/backend/#l2_normalize", 
            "text": "l2_normalize(x, axis)  \u5728\u7ed9\u5b9a\u8f74\u4e0a\u5bf9\u5f20\u91cf\u8fdb\u884cL2\u8303\u6570\u89c4\u8303\u5316", 
            "title": "l2_normalize"
        }, 
        {
            "location": "/backend/#in_top_k", 
            "text": "in_top_k(predictions, targets, k)  \u5224\u65ad\u76ee\u6807\u662f\u5426\u5728predictions\u7684\u524dk\u5927\u503c\u4f4d\u7f6e  \u53c2\u6570\uff1a   predictions\uff1a\u9884\u6d4b\u503c\u5f20\u91cf, shape\u4e3a(batch_size, classes), \u6570\u636e\u7c7b\u578bfloat32  targets\uff1a\u771f\u503c\u5f20\u91cf, shape\u4e3a(batch_size,),\u6570\u636e\u7c7b\u578b\u4e3aint32\u6216int64  k\uff1a\u6574\u6570", 
            "title": "in_top_k"
        }, 
        {
            "location": "/backend/#conv1d", 
            "text": "conv1d(x, kernel, strides=1, border_mode='valid', image_shape=None, filter_shape=None)  1D\u5377\u79ef  \u53c2\u6570\uff1a   kernel\uff1a\u5377\u79ef\u6838\u5f20\u91cf  strides\uff1a\u6b65\u957f\uff0c\u6574\u578b  border_mode\uff1a\u201csame\u201d\uff0c\u201cvalid\u201d\u4e4b\u4e00\u7684\u5b57\u7b26\u4e32", 
            "title": "conv1d"
        }, 
        {
            "location": "/backend/#conv2d", 
            "text": "conv2d(x, kernel, strides=(1, 1), border_mode='valid', dim_ordering='th', image_shape=None, filter_shape=None)  2D\u5377\u79ef  \u53c2\u6570\uff1a   kernel\uff1a\u5377\u79ef\u6838\u5f20\u91cf  strides\uff1a\u6b65\u957f\uff0c\u957f\u4e3a2\u7684tuple  border_mode\uff1a\u201csame\u201d\uff0c\u201cvalid\u201d\u4e4b\u4e00\u7684\u5b57\u7b26\u4e32  dim_ordering\uff1a\u201ctf\u201d\u548c\u201cth\u201d\u4e4b\u4e00\uff0c\u7ef4\u5ea6\u6392\u5217\u987a\u5e8f", 
            "title": "conv2d"
        }, 
        {
            "location": "/backend/#deconv2d", 
            "text": "deconv2d(x, kernel, output_shape, strides=(1, 1), border_mode='valid', dim_ordering='th', image_shape=None, filter_shape=None)  2D\u53cd\u5377\u79ef\uff08\u8f6c\u7f6e\u5377\u79ef\uff09  \u53c2\u6570\uff1a   x\uff1a\u8f93\u5165\u5f20\u91cf  kernel\uff1a\u5377\u79ef\u6838\u5f20\u91cf  output_shape: \u8f93\u51fashape\u76841D\u7684\u6574\u6570\u5f20\u91cf  strides\uff1a\u6b65\u957f\uff0ctuple\u7c7b\u578b  border_mode\uff1a\u201csame\u201d\u6216\u201cvalid\u201d  dim_ordering\uff1a\u201ctf\u201d\u6216\u201cth\u201d", 
            "title": "deconv2d"
        }, 
        {
            "location": "/backend/#conv3d", 
            "text": "conv3d(x, kernel, strides=(1, 1, 1), border_mode='valid', dim_ordering='th', volume_shape=None, filter_shape=None)  3D\u5377\u79ef  \u53c2\u6570\uff1a   x\uff1a\u8f93\u5165\u5f20\u91cf  kernel\uff1a\u5377\u79ef\u6838\u5f20\u91cf  strides\uff1a\u6b65\u957f\uff0ctuple\u7c7b\u578b  border_mode\uff1a\u201csame\u201d\u6216\u201cvalid\u201d  dim_ordering\uff1a\u201ctf\u201d\u6216\u201cth\u201d", 
            "title": "conv3d"
        }, 
        {
            "location": "/backend/#pool2d", 
            "text": "pool2d(x, pool_size, strides=(1, 1), border_mode='valid', dim_ordering='th', pool_mode='max')  2D\u6c60\u5316  \u53c2\u6570\uff1a   pool_size\uff1a\u542b\u6709\u4e24\u4e2a\u6574\u6570\u7684tuple\uff0c\u6c60\u7684\u5927\u5c0f  strides\uff1a\u542b\u6709\u4e24\u4e2a\u6574\u6570\u7684tuple\uff0c\u6b65\u957f  border_mode\uff1a\u201csame\u201d\uff0c\u201cvalid\u201d\u4e4b\u4e00\u7684\u5b57\u7b26\u4e32  dim_ordering\uff1a\u201ctf\u201d\u548c\u201cth\u201d\u4e4b\u4e00\uff0c\u7ef4\u5ea6\u6392\u5217\u987a\u5e8f  pool_mode: \u201cmax\u201d\uff0c\u201cavg\u201d\u4e4b\u4e00\uff0c\u6c60\u5316\u65b9\u5f0f", 
            "title": "pool2d"
        }, 
        {
            "location": "/backend/#pool3d", 
            "text": "pool3d(x, pool_size, strides=(1, 1, 1), border_mode='valid', dim_ordering='th', pool_mode='max')  3D\u6c60\u5316  \u53c2\u6570\uff1a   pool_size\uff1a\u542b\u67093\u4e2a\u6574\u6570\u7684tuple\uff0c\u6c60\u7684\u5927\u5c0f  strides\uff1a\u542b\u67093\u4e2a\u6574\u6570\u7684tuple\uff0c\u6b65\u957f  border_mode\uff1a\u201csame\u201d\uff0c\u201cvalid\u201d\u4e4b\u4e00\u7684\u5b57\u7b26\u4e32  dim_ordering\uff1a\u201ctf\u201d\u548c\u201cth\u201d\u4e4b\u4e00\uff0c\u7ef4\u5ea6\u6392\u5217\u987a\u5e8f  pool_mode: \u201cmax\u201d\uff0c\u201cavg\u201d\u4e4b\u4e00\uff0c\u6c60\u5316\u65b9\u5f0f", 
            "title": "pool3d"
        }, 
        {
            "location": "/backend/#ctc_batch_cost", 
            "text": "ctc_batch_cost(y_true, y_pred, input_length, label_length)  \u5728batch\u4e0a\u8fd0\u884cCTC\u635f\u5931\u7b97\u6cd5  \u53c2\u6570\uff1a   y_true\uff1a\u5f62\u5982(samples\uff0cmax_tring_length)\u7684\u5f20\u91cf\uff0c\u5305\u542b\u6807\u7b7e\u7684\u771f\u503c  y_pred\uff1a\u5f62\u5982(samples\uff0ctime_steps\uff0cnum_categories)\u7684\u5f20\u91cf\uff0c\u5305\u542b\u9884\u6d4b\u503c\u6216\u8f93\u51fa\u7684softmax\u503c  input_length\uff1a\u5f62\u5982(samples\uff0c1)\u7684\u5f20\u91cf\uff0c\u5305\u542by_pred\u4e2d\u6bcf\u4e2abatch\u7684\u5e8f\u5217\u957f  label_length\uff1a\u5f62\u5982(samples\uff0c1)\u7684\u5f20\u91cf\uff0c\u5305\u542by_true\u4e2d\u6bcf\u4e2abatch\u7684\u5e8f\u5217\u957f   \u8fd4\u56de\u503c\uff1a\u5f62\u5982(samoles\uff0c1)\u7684tensor\uff0c\u5305\u542b\u4e86\u6bcf\u4e2a\u5143\u7d20\u7684CTC\u635f\u5931", 
            "title": "ctc_batch_cost"
        }, 
        {
            "location": "/backend/#ctc_decode", 
            "text": "ctc_decode(y_pred, input_length, greedy=True, beam_width=None, dict_seq_lens=None, dict_values=None)  \u4f7f\u7528\u8d2a\u5a6a\u7b97\u6cd5\u6216\u5e26\u7ea6\u675f\u7684\u5b57\u5178\u641c\u7d22\u7b97\u6cd5\u89e3\u7801softmax\u7684\u8f93\u51fa  \u53c2\u6570\uff1a   y_pred\uff1a\u5f62\u5982(samples\uff0ctime_steps\uff0cnum_categories)\u7684\u5f20\u91cf\uff0c\u5305\u542b\u9884\u6d4b\u503c\u6216\u8f93\u51fa\u7684softmax\u503c  input_length\uff1a\u5f62\u5982(samples\uff0c1)\u7684\u5f20\u91cf\uff0c\u5305\u542by_pred\u4e2d\u6bcf\u4e2abatch\u7684\u5e8f\u5217\u957f  greedy\uff1a\u8bbe\u7f6e\u4e3aTrue\u4f7f\u7528\u8d2a\u5a6a\u7b97\u6cd5\uff0c\u901f\u5ea6\u5feb  dict_seq_lens\uff1adic_values\u5217\u8868\u4e2d\u5404\u5143\u7d20\u7684\u957f\u5ea6  dict_values\uff1a\u5217\u8868\u7684\u5217\u8868\uff0c\u4ee3\u8868\u5b57\u5178   \u8fd4\u56de\u503c\uff1a\u5f62\u5982(samples\uff0ctime_steps\uff0cnum_catgories)\u7684\u5f20\u91cf\uff0c\u5305\u542b\u4e86\u8def\u5f84\u53ef\u80fd\u6027\uff08\u4ee5softmax\u6982\u7387\u7684\u5f62\u5f0f\uff09\u3002\u6ce8\u610f\u4ecd\u7136\u9700\u8981\u4e00\u4e2a\u7528\u6765\u53d6\u51faargmax\u548c\u5904\u7406\u7a7a\u767d\u6807\u7b7e\u7684\u51fd\u6570", 
            "title": "ctc_decode"
        }, 
        {
            "location": "/backend/#map_fn", 
            "text": "map_fn(fn, elems, name=None)  \u5143\u7d20elems\u5728\u51fd\u6570fn\u4e0a\u7684\u6620\u5c04\uff0c\u5e76\u8fd4\u56de\u7ed3\u679c  \u53c2\u6570\uff1a   fn\uff1a\u51fd\u6570  elems\uff1a\u5f20\u91cf  name\uff1a\u8282\u70b9\u7684\u540d\u5b57   \u8fd4\u56de\u503c\uff1a\u8fd4\u56de\u4e00\u4e2a\u5f20\u91cf\uff0c\u8be5\u5f20\u91cf\u7684\u7b2c\u4e00\u7ef4\u5ea6\u7b49\u4e8eelems\uff0c\u7b2c\u4e8c\u7ef4\u5ea6\u53d6\u51b3\u4e8efn", 
            "title": "map_fn"
        }, 
        {
            "location": "/backend/#foldl", 
            "text": "foldl(fn, elems, initializer=None, name=None)  \u51cf\u5c11elems\uff0c\u7528fn\u4ece\u5de6\u5230\u53f3\u8fde\u63a5\u5b83\u4eec  \u53c2\u6570\uff1a   fn\uff1a\u51fd\u6570\uff0c\u4f8b\u5982\uff1alambda acc, x: acc + x  elems\uff1a\u5f20\u91cf  initializer\uff1a\u521d\u59cb\u5316\u7684\u503c(elems[0])  name\uff1a\u8282\u70b9\u540d   \u8fd4\u56de\u503c\uff1a\u4e0einitializer\u7684\u7c7b\u578b\u548c\u5f62\u72b6\u4e00\u81f4", 
            "title": "foldl"
        }, 
        {
            "location": "/backend/#foldr", 
            "text": "foldr(fn, elems, initializer=None, name=None)  \u51cf\u5c11elems\uff0c\u7528fn\u4ece\u53f3\u5230\u5de6\u8fde\u63a5\u5b83\u4eec  \u53c2\u6570\uff1a   fn\uff1a\u51fd\u6570\uff0c\u4f8b\u5982\uff1alambda acc, x: acc + x  elems\uff1a\u5f20\u91cf    initializer\uff1a\u521d\u59cb\u5316\u7684\u503c\uff08elems[-1]\uff09  name\uff1a\u8282\u70b9\u540d   \u8fd4\u56de\u503c\uff1a\u4e0einitializer\u7684\u7c7b\u578b\u548c\u5f62\u72b6\u4e00\u81f4", 
            "title": "foldr"
        }, 
        {
            "location": "/backend/#backend", 
            "text": "backend()  \u786e\u5b9a\u5f53\u524d\u4f7f\u7528\u7684\u540e\u7aef", 
            "title": "backend"
        }, 
        {
            "location": "/scikit-learn_API/", 
            "text": "Scikit-Learn\u63a5\u53e3\u5305\u88c5\u5668\n\n\n\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u5305\u88c5\u5668\u5c06\nSequential\n\u6a21\u578b\uff08\u4ec5\u6709\u4e00\u4e2a\u8f93\u5165\uff09\u4f5c\u4e3aScikit-Learn\u5de5\u4f5c\u6d41\u7684\u4e00\u90e8\u5206\uff0c\u76f8\u5173\u7684\u5305\u88c5\u5668\u5b9a\u4e49\u5728\nkeras.wrappers.scikit_learn.py\n\u4e2d\n\n\n\u76ee\u524d\uff0c\u6709\u4e24\u4e2a\u5305\u88c5\u5668\u53ef\u7528\uff1a\n\n\nkeras.wrappers.scikit_learn.KerasClassifier(build_fn=None, **sk_params)\n\u5b9e\u73b0\u4e86sklearn\u7684\u5206\u7c7b\u5668\u63a5\u53e3\n\n\nkeras.wrappers.scikit_learn.KerasRegressor(build_fn=None, **sk_params)\n\u5b9e\u73b0\u4e86sklearn\u7684\u56de\u5f52\u5668\u63a5\u53e3\n\n\n\u53c2\u6570\n\n\n\n\n\n\nbuild_fn\uff1a\u53ef\u8c03\u7528\u7684\u51fd\u6570\u6216\u7c7b\u5bf9\u8c61\n\n\n\n\n\n\nsk_params\uff1a\u6a21\u578b\u53c2\u6570\u548c\u8bad\u7ec3\u53c2\u6570\n\n\n\n\n\n\nbuild_fn\n\u5e94\u6784\u9020\u3001\u7f16\u8bd1\u5e76\u8fd4\u56de\u4e00\u4e2aKeras\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u5c06\u7a0d\u540e\u7528\u4e8e\u8bad\u7ec3/\u6d4b\u8bd5\u3002\nbuild_fn\n\u7684\u503c\u53ef\u80fd\u4e3a\u4e0b\u5217\u4e09\u79cd\u4e4b\u4e00\uff1a\n\n\n\n\n\n\n\u4e00\u4e2a\u51fd\u6570\n\n\n\n\n\n\n\u4e00\u4e2a\u5177\u6709\ncall\n\u65b9\u6cd5\u7684\u7c7b\u5bf9\u8c61\n\n\n\n\n\n\nNone\uff0c\u4ee3\u8868\u4f60\u7684\u7c7b\u7ee7\u627f\u81ea\nKerasClassifier\n\u6216\nKerasRegressor\n\uff0c\u5176\ncall\n\u65b9\u6cd5\u4e3a\u5176\u7236\u7c7b\u7684\ncall\n\u65b9\u6cd5\n\n\n\n\n\n\nsk_params\n\u4ee5\u6a21\u578b\u53c2\u6570\u548c\u8bad\u7ec3\uff08\u8d85\uff09\u53c2\u6570\u4f5c\u4e3a\u53c2\u6570\u3002\u5408\u6cd5\u7684\u6a21\u578b\u53c2\u6570\u4e3a\nbuild_fn\n\u7684\u53c2\u6570\u3002\u6ce8\u610f\uff0c\u2018build_fn\u2019\u5e94\u63d0\u4f9b\u5176\u53c2\u6570\u7684\u9ed8\u8ba4\u503c\u3002\u6240\u4ee5\u6211\u4eec\u4e0d\u4f20\u9012\u4efb\u4f55\u503c\u7ed9\nsk_params\n\u4e5f\u53ef\u4ee5\u521b\u5efa\u4e00\u4e2a\u5206\u7c7b\u5668/\u56de\u5f52\u5668\n\n\nsk_params\n\u8fd8\u63a5\u53d7\u7528\u4e8e\u8c03\u7528\nfit\n\uff0c\npredict\n\uff0c\npredict_proba\n\u548c\nscore\n\u65b9\u6cd5\u7684\u53c2\u6570\uff0c\u5982\nnb_epoch\n\uff0c\nbatch_size\n\u7b49\u3002\u8fd9\u4e9b\u7528\u4e8e\u8bad\u7ec3\u6216\u9884\u6d4b\u7684\u53c2\u6570\u6309\u5982\u4e0b\u987a\u5e8f\u9009\u62e9\uff1a\n\n\n\n\n\n\n\u4f20\u9012\u7ed9\nfit\n\uff0c\npredict\n\uff0c\npredict_proba\n\u548c\nscore\n\u7684\u5b57\u5178\u53c2\u6570\n\n\n\n\n\n\n\u4f20\u9012\u4e2a\nsk_params\n\u7684\u53c2\u6570\n\n\n\n\n\n\nkeras.models.Sequential\n\uff0c\nfit\n\uff0c\npredict\n\uff0c\npredict_proba\n\u548c\nscore\n\u7684\u9ed8\u8ba4\u503c\n\n\n\n\n\n\n\u5f53\u4f7f\u7528scikit-learn\u7684\ngrid_search\n\u63a5\u53e3\u65f6\uff0c\u5408\u6cd5\u7684\u53ef\u8f6c\u6362\u53c2\u6570\u662f\u4f60\u53ef\u4ee5\u4f20\u9012\u7ed9\nsk_params\n\u7684\u53c2\u6570\uff0c\u5305\u62ec\u8bad\u7ec3\u53c2\u6570\u3002\u5373\uff0c\u4f60\u53ef\u4ee5\u4f7f\u7528\ngrid_search\n\u6765\u641c\u7d22\u6700\u4f73\u7684\nbatch_size\n\u6216\nnb_epoch\n\u4ee5\u53ca\u5176\u4ed6\u6a21\u578b\u53c2\u6570\n\n\n\u3010Tips\u3011\u8fc7\u6bb5\u65f6\u95f4\uff08\u51e0\u5468\uff1f\uff09\u6211\u4eec\u5e0c\u671b\u80fd\u63d0\u4f9b\u4e00\u4e9bScikit-learn\u4e0eKeras\u8054\u5408\u4f5c\u4e1a\u7684\u4f8b\u5b50\uff0c\u8fd9\u4e2a\u5148\u522b\u592a\u671f\u5f85\u2026\u2026", 
            "title": "scikit-learn\u63a5\u53e3"
        }, 
        {
            "location": "/scikit-learn_API/#scikit-learn", 
            "text": "\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u5305\u88c5\u5668\u5c06 Sequential \u6a21\u578b\uff08\u4ec5\u6709\u4e00\u4e2a\u8f93\u5165\uff09\u4f5c\u4e3aScikit-Learn\u5de5\u4f5c\u6d41\u7684\u4e00\u90e8\u5206\uff0c\u76f8\u5173\u7684\u5305\u88c5\u5668\u5b9a\u4e49\u5728 keras.wrappers.scikit_learn.py \u4e2d  \u76ee\u524d\uff0c\u6709\u4e24\u4e2a\u5305\u88c5\u5668\u53ef\u7528\uff1a  keras.wrappers.scikit_learn.KerasClassifier(build_fn=None, **sk_params) \u5b9e\u73b0\u4e86sklearn\u7684\u5206\u7c7b\u5668\u63a5\u53e3  keras.wrappers.scikit_learn.KerasRegressor(build_fn=None, **sk_params) \u5b9e\u73b0\u4e86sklearn\u7684\u56de\u5f52\u5668\u63a5\u53e3", 
            "title": "Scikit-Learn\u63a5\u53e3\u5305\u88c5\u5668"
        }, 
        {
            "location": "/scikit-learn_API/#_1", 
            "text": "build_fn\uff1a\u53ef\u8c03\u7528\u7684\u51fd\u6570\u6216\u7c7b\u5bf9\u8c61    sk_params\uff1a\u6a21\u578b\u53c2\u6570\u548c\u8bad\u7ec3\u53c2\u6570    build_fn \u5e94\u6784\u9020\u3001\u7f16\u8bd1\u5e76\u8fd4\u56de\u4e00\u4e2aKeras\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u5c06\u7a0d\u540e\u7528\u4e8e\u8bad\u7ec3/\u6d4b\u8bd5\u3002 build_fn \u7684\u503c\u53ef\u80fd\u4e3a\u4e0b\u5217\u4e09\u79cd\u4e4b\u4e00\uff1a    \u4e00\u4e2a\u51fd\u6570    \u4e00\u4e2a\u5177\u6709 call \u65b9\u6cd5\u7684\u7c7b\u5bf9\u8c61    None\uff0c\u4ee3\u8868\u4f60\u7684\u7c7b\u7ee7\u627f\u81ea KerasClassifier \u6216 KerasRegressor \uff0c\u5176 call \u65b9\u6cd5\u4e3a\u5176\u7236\u7c7b\u7684 call \u65b9\u6cd5    sk_params \u4ee5\u6a21\u578b\u53c2\u6570\u548c\u8bad\u7ec3\uff08\u8d85\uff09\u53c2\u6570\u4f5c\u4e3a\u53c2\u6570\u3002\u5408\u6cd5\u7684\u6a21\u578b\u53c2\u6570\u4e3a build_fn \u7684\u53c2\u6570\u3002\u6ce8\u610f\uff0c\u2018build_fn\u2019\u5e94\u63d0\u4f9b\u5176\u53c2\u6570\u7684\u9ed8\u8ba4\u503c\u3002\u6240\u4ee5\u6211\u4eec\u4e0d\u4f20\u9012\u4efb\u4f55\u503c\u7ed9 sk_params \u4e5f\u53ef\u4ee5\u521b\u5efa\u4e00\u4e2a\u5206\u7c7b\u5668/\u56de\u5f52\u5668  sk_params \u8fd8\u63a5\u53d7\u7528\u4e8e\u8c03\u7528 fit \uff0c predict \uff0c predict_proba \u548c score \u65b9\u6cd5\u7684\u53c2\u6570\uff0c\u5982 nb_epoch \uff0c batch_size \u7b49\u3002\u8fd9\u4e9b\u7528\u4e8e\u8bad\u7ec3\u6216\u9884\u6d4b\u7684\u53c2\u6570\u6309\u5982\u4e0b\u987a\u5e8f\u9009\u62e9\uff1a    \u4f20\u9012\u7ed9 fit \uff0c predict \uff0c predict_proba \u548c score \u7684\u5b57\u5178\u53c2\u6570    \u4f20\u9012\u4e2a sk_params \u7684\u53c2\u6570    keras.models.Sequential \uff0c fit \uff0c predict \uff0c predict_proba \u548c score \u7684\u9ed8\u8ba4\u503c    \u5f53\u4f7f\u7528scikit-learn\u7684 grid_search \u63a5\u53e3\u65f6\uff0c\u5408\u6cd5\u7684\u53ef\u8f6c\u6362\u53c2\u6570\u662f\u4f60\u53ef\u4ee5\u4f20\u9012\u7ed9 sk_params \u7684\u53c2\u6570\uff0c\u5305\u62ec\u8bad\u7ec3\u53c2\u6570\u3002\u5373\uff0c\u4f60\u53ef\u4ee5\u4f7f\u7528 grid_search \u6765\u641c\u7d22\u6700\u4f73\u7684 batch_size \u6216 nb_epoch \u4ee5\u53ca\u5176\u4ed6\u6a21\u578b\u53c2\u6570  \u3010Tips\u3011\u8fc7\u6bb5\u65f6\u95f4\uff08\u51e0\u5468\uff1f\uff09\u6211\u4eec\u5e0c\u671b\u80fd\u63d0\u4f9b\u4e00\u4e9bScikit-learn\u4e0eKeras\u8054\u5408\u4f5c\u4e1a\u7684\u4f8b\u5b50\uff0c\u8fd9\u4e2a\u5148\u522b\u592a\u671f\u5f85\u2026\u2026", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/utils/data_utils/", 
            "text": "\u6570\u636e\u5de5\u5177\n\n\nget_file\n\n\nget_file(fname, origin, untar=False, md5_hash=None, cache_subdir='datasets')\n\n\n\n\n\u4ece\u7ed9\u5b9a\u7684URL\u4e2d\u4e0b\u8f7d\u6587\u4ef6, \u53ef\u4ee5\u4f20\u9012MD5\u503c\u7528\u4e8e\u6570\u636e\u6821\u9a8c(\u4e0b\u8f7d\u540e\u6216\u5df2\u7ecf\u7f13\u5b58\u7684\u6570\u636e\u5747\u53ef)\n\n\n\u53c2\u6570\n\n\n\n\n\n\nfname: \u6587\u4ef6\u540d\n\n\n\n\n\n\norigin: \u6587\u4ef6\u7684URL\u5730\u5740\n\n\n\n\n\n\nuntar: \u5e03\u5c14\u503c,\u662f\u5426\u8981\u8fdb\u884c\u89e3\u538b\n\n\n\n\n\n\nmd5_hash: MD5\u54c8\u5e0c\u503c,\u7528\u4e8e\u6570\u636e\u6821\u9a8c\n\n\n\n\n\n\ncache_subdir: \u7528\u4e8e\u7f13\u5b58\u6570\u636e\u7684\u6587\u4ef6\u5939\n\n\n\n\n\n\n\u8fd4\u56de\u503c\n\n\n\u4e0b\u8f7d\u540e\u7684\u6587\u4ef6\u5730\u5740", 
            "title": "\u6570\u636e\u5de5\u5177"
        }, 
        {
            "location": "/utils/data_utils/#_1", 
            "text": "", 
            "title": "\u6570\u636e\u5de5\u5177"
        }, 
        {
            "location": "/utils/data_utils/#get_file", 
            "text": "get_file(fname, origin, untar=False, md5_hash=None, cache_subdir='datasets')  \u4ece\u7ed9\u5b9a\u7684URL\u4e2d\u4e0b\u8f7d\u6587\u4ef6, \u53ef\u4ee5\u4f20\u9012MD5\u503c\u7528\u4e8e\u6570\u636e\u6821\u9a8c(\u4e0b\u8f7d\u540e\u6216\u5df2\u7ecf\u7f13\u5b58\u7684\u6570\u636e\u5747\u53ef)", 
            "title": "get_file"
        }, 
        {
            "location": "/utils/data_utils/#_2", 
            "text": "fname: \u6587\u4ef6\u540d    origin: \u6587\u4ef6\u7684URL\u5730\u5740    untar: \u5e03\u5c14\u503c,\u662f\u5426\u8981\u8fdb\u884c\u89e3\u538b    md5_hash: MD5\u54c8\u5e0c\u503c,\u7528\u4e8e\u6570\u636e\u6821\u9a8c    cache_subdir: \u7528\u4e8e\u7f13\u5b58\u6570\u636e\u7684\u6587\u4ef6\u5939", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/utils/data_utils/#_3", 
            "text": "\u4e0b\u8f7d\u540e\u7684\u6587\u4ef6\u5730\u5740", 
            "title": "\u8fd4\u56de\u503c"
        }, 
        {
            "location": "/utils/io_utils/", 
            "text": "I/O\u5de5\u5177\n\n\nHDF5\u77e9\u9635\n\n\nkeras.utils.io_utils.HDF5Matrix(datapath, dataset, start=0, end=None, normalizer=None)\n\n\n\n\n\u8fd9\u662f\u4e00\u4e2a\u4f7f\u7528HDF5\u6570\u636e\u96c6\u4ee3\u66ffNumpy\u6570\u7ec4\u7684\u65b9\u6cd5\u3002\n\n\n\u4f8b\u5b50\n\n\nX_data = HDF5Matrix('input/file.hdf5', 'data')\nmodel.predict(X_data)\n\n\n\n\n\u63d0\u4f9bstart\u548cend\u53c2\u6570\u53ef\u4ee5\u4f7f\u7528\u6570\u636e\u96c6\u7684\u5207\u7247\u3002\n\n\n\u53ef\u9009\u7684\uff0c\u53ef\u4ee5\u7ed9\u51fa\u5f52\u4e00\u5316\u51fd\u6570\uff08\u6216lambda\u8868\u8fbe\u5f0f\uff09\u3002 \u8fd9\u5c06\u5728\u6bcf\u4e2a\u68c0\u7d22\u7684\u6570\u636e\u96c6\u7684\u5207\u7247\u4e0a\u8c03\u7528\u3002\n\n\n\u53c2\u6570\n\n\n\n\n\n\ndatapath\uff1a\u5b57\u7b26\u4e32\uff0cHDF5\u6587\u4ef6\u7684\u8def\u5f84\n\n\n\n\n\n\ndataset\uff1a\u5b57\u7b26\u4e32\uff0c\u5728datapath\u4e2d\u6307\u5b9a\u7684\u6587\u4ef6\u4e2d\u7684HDF5\u6570\u636e\u96c6\u7684\u540d\u79f0\n\n\n\n\n\n\nstart\uff1a\u6574\u6570\uff0c\u6307\u5b9a\u6570\u636e\u96c6\u7684\u6240\u9700\u5207\u7247\u7684\u5f00\u59cb\n\n\n\n\n\n\nend\uff1a\u6574\u6570\uff0c\u6307\u5b9a\u6570\u636e\u96c6\u7684\u6240\u9700\u5207\u7247\u7684\u7ed3\u5c3e\n\n\n\n\n\n\nnormalizer\uff1a\u6570\u636e\u96c6\u5728\u88ab\u68c0\u7d22\u65f6\u7684\u8c03\u7528\u51fd\u6570", 
            "title": "\u8f93\u5165\u8f93\u51faI/O"
        }, 
        {
            "location": "/utils/io_utils/#io", 
            "text": "", 
            "title": "I/O\u5de5\u5177"
        }, 
        {
            "location": "/utils/io_utils/#hdf5", 
            "text": "keras.utils.io_utils.HDF5Matrix(datapath, dataset, start=0, end=None, normalizer=None)  \u8fd9\u662f\u4e00\u4e2a\u4f7f\u7528HDF5\u6570\u636e\u96c6\u4ee3\u66ffNumpy\u6570\u7ec4\u7684\u65b9\u6cd5\u3002", 
            "title": "HDF5\u77e9\u9635"
        }, 
        {
            "location": "/utils/io_utils/#_1", 
            "text": "X_data = HDF5Matrix('input/file.hdf5', 'data')\nmodel.predict(X_data)  \u63d0\u4f9bstart\u548cend\u53c2\u6570\u53ef\u4ee5\u4f7f\u7528\u6570\u636e\u96c6\u7684\u5207\u7247\u3002  \u53ef\u9009\u7684\uff0c\u53ef\u4ee5\u7ed9\u51fa\u5f52\u4e00\u5316\u51fd\u6570\uff08\u6216lambda\u8868\u8fbe\u5f0f\uff09\u3002 \u8fd9\u5c06\u5728\u6bcf\u4e2a\u68c0\u7d22\u7684\u6570\u636e\u96c6\u7684\u5207\u7247\u4e0a\u8c03\u7528\u3002", 
            "title": "\u4f8b\u5b50"
        }, 
        {
            "location": "/utils/io_utils/#_2", 
            "text": "datapath\uff1a\u5b57\u7b26\u4e32\uff0cHDF5\u6587\u4ef6\u7684\u8def\u5f84    dataset\uff1a\u5b57\u7b26\u4e32\uff0c\u5728datapath\u4e2d\u6307\u5b9a\u7684\u6587\u4ef6\u4e2d\u7684HDF5\u6570\u636e\u96c6\u7684\u540d\u79f0    start\uff1a\u6574\u6570\uff0c\u6307\u5b9a\u6570\u636e\u96c6\u7684\u6240\u9700\u5207\u7247\u7684\u5f00\u59cb    end\uff1a\u6574\u6570\uff0c\u6307\u5b9a\u6570\u636e\u96c6\u7684\u6240\u9700\u5207\u7247\u7684\u7ed3\u5c3e    normalizer\uff1a\u6570\u636e\u96c6\u5728\u88ab\u68c0\u7d22\u65f6\u7684\u8c03\u7528\u51fd\u6570", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/utils/layer_utils/", 
            "text": "Keras\u5c42\u5de5\u5177\n\n\nlayer_from_config\n\n\nlayer_from_config(config, custom_objects={})\n\n\n\n\n\u4ece\u914d\u7f6e\u751f\u6210Keras\u5c42\u5bf9\u8c61\n\n\n\u53c2\u6570\n\n\n\n\n\n\nconfig:\u5f62\u5982{'class_name':str, 'config':dict}\u7684\u5b57\u5178\n\n\n\n\n\n\ncustom_objects: \u5b57\u5178,\u7528\u4ee5\u5c06\u5b9a\u5236\u7684\u975eKeras\u5bf9\u8c61\u4e4b\u7c7b\u540d/\u51fd\u6570\u540d\u6620\u5c04\u4e3a\u7c7b/\u51fd\u6570\u5bf9\u8c61\n\n\n\n\n\n\n\u8fd4\u56de\u503c\n\n\n\u5c42\u5bf9\u8c61,\u5305\u542bModel,Sequential\u548c\u5176\u4ed6Layer", 
            "title": "Keras\u5c42\u5de5\u5177"
        }, 
        {
            "location": "/utils/layer_utils/#keras", 
            "text": "", 
            "title": "Keras\u5c42\u5de5\u5177"
        }, 
        {
            "location": "/utils/layer_utils/#layer_from_config", 
            "text": "layer_from_config(config, custom_objects={})  \u4ece\u914d\u7f6e\u751f\u6210Keras\u5c42\u5bf9\u8c61", 
            "title": "layer_from_config"
        }, 
        {
            "location": "/utils/layer_utils/#_1", 
            "text": "config:\u5f62\u5982{'class_name':str, 'config':dict}\u7684\u5b57\u5178    custom_objects: \u5b57\u5178,\u7528\u4ee5\u5c06\u5b9a\u5236\u7684\u975eKeras\u5bf9\u8c61\u4e4b\u7c7b\u540d/\u51fd\u6570\u540d\u6620\u5c04\u4e3a\u7c7b/\u51fd\u6570\u5bf9\u8c61", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/utils/layer_utils/#_2", 
            "text": "\u5c42\u5bf9\u8c61,\u5305\u542bModel,Sequential\u548c\u5176\u4ed6Layer", 
            "title": "\u8fd4\u56de\u503c"
        }, 
        {
            "location": "/utils/np_utils/", 
            "text": "numpy\u5de5\u5177\n\n\nto_categorical\n\n\nto_categorical(y, nb_classes=None)\n\n\n\n\n\u5c06\u7c7b\u522b\u5411\u91cf(\u4ece0\u5230nb_classes\u7684\u6574\u6570\u5411\u91cf)\u6620\u5c04\u4e3a\u4e8c\u503c\u7c7b\u522b\u77e9\u9635, \u7528\u4e8e\u5e94\u7528\u5230\u4ee5\ncategorical_crossentropy\n\u4e3a\u76ee\u6807\u51fd\u6570\u7684\u6a21\u578b\u4e2d.\n\n\n\u53c2\u6570\n\n\n\n\ny: \u7c7b\u522b\u5411\u91cf\n\n\nnb_classes:\u603b\u5171\u7c7b\u522b\u6570\n\n\n\n\nconvert_kernel\n\n\nconvert_kernel(kernel, dim_ordering='default')\n\n\n\n\n\u5c06\u5377\u79ef\u6838\u77e9\u9635(numpy\u6570\u7ec4)\u4eceTheano\u5f62\u5f0f\u8f6c\u6362\u4e3aTensorflow\u5f62\u5f0f,\u6216\u8f6c\u6362\u56de\u6765(\u8be5\u8f6c\u5316\u65f6\u81ea\u53ef\u9006\u7684)", 
            "title": "numpy\u5de5\u5177"
        }, 
        {
            "location": "/utils/np_utils/#numpy", 
            "text": "", 
            "title": "numpy\u5de5\u5177"
        }, 
        {
            "location": "/utils/np_utils/#to_categorical", 
            "text": "to_categorical(y, nb_classes=None)  \u5c06\u7c7b\u522b\u5411\u91cf(\u4ece0\u5230nb_classes\u7684\u6574\u6570\u5411\u91cf)\u6620\u5c04\u4e3a\u4e8c\u503c\u7c7b\u522b\u77e9\u9635, \u7528\u4e8e\u5e94\u7528\u5230\u4ee5 categorical_crossentropy \u4e3a\u76ee\u6807\u51fd\u6570\u7684\u6a21\u578b\u4e2d.", 
            "title": "to_categorical"
        }, 
        {
            "location": "/utils/np_utils/#_1", 
            "text": "y: \u7c7b\u522b\u5411\u91cf  nb_classes:\u603b\u5171\u7c7b\u522b\u6570", 
            "title": "\u53c2\u6570"
        }, 
        {
            "location": "/utils/np_utils/#convert_kernel", 
            "text": "convert_kernel(kernel, dim_ordering='default')  \u5c06\u5377\u79ef\u6838\u77e9\u9635(numpy\u6570\u7ec4)\u4eceTheano\u5f62\u5f0f\u8f6c\u6362\u4e3aTensorflow\u5f62\u5f0f,\u6216\u8f6c\u6362\u56de\u6765(\u8be5\u8f6c\u5316\u65f6\u81ea\u53ef\u9006\u7684)", 
            "title": "convert_kernel"
        }, 
        {
            "location": "/blog/cnn_see_world/", 
            "text": "CNN\u773c\u4e2d\u7684\u4e16\u754c\uff1a\u5229\u7528Keras\u89e3\u91caCNN\u7684\u6ee4\u6ce2\u5668\n\n\n\u6587\u7ae0\u4fe1\u606f\n\n\n\u672c\u6587\u5730\u5740\uff1a\nhttp://blog.keras.io/how-convolutional-neural-networks-see-the-world.html\n\n\n\u672c\u6587\u4f5c\u8005\uff1aFrancois Chollet\n\n\n\n\u4f7f\u7528Keras\u63a2\u7d22\u5377\u79ef\u7f51\u7edc\u7684\u6ee4\u6ce2\u5668\n\n\n\u672c\u6587\u4e2d\u6211\u4eec\u5c06\u5229\u7528Keras\u89c2\u5bdfCNN\u5230\u5e95\u5728\u5b66\u4e9b\u4ec0\u4e48\uff0c\u5b83\u662f\u5982\u4f55\u7406\u89e3\u6211\u4eec\u9001\u5165\u7684\u8bad\u7ec3\u56fe\u7247\u7684\u3002\u6211\u4eec\u5c06\u4f7f\u7528Keras\u6765\u5bf9\u6ee4\u6ce2\u5668\u7684\u6fc0\u6d3b\u503c\u8fdb\u884c\u53ef\u89c6\u5316\u3002\u672c\u6587\u4f7f\u7528\u7684\u795e\u7ecf\u7f51\u7edc\u662fVGG-16\uff0c\u6570\u636e\u96c6\u4e3aImageNet\u3002\u672c\u6587\u7684\u4ee3\u7801\u53ef\u4ee5\u5728\ngithub\n\u627e\u5230\n\n\n\n\nVGG-16\u53c8\u79f0\u4e3aOxfordNet\uff0c\u662f\u7531\u725b\u6d25\n\u89c6\u89c9\u51e0\u4f55\u7ec4\uff08Visual Geometry Group\uff09\n\u5f00\u53d1\u7684\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7ed3\u6784\u3002\u8be5\u7f51\u7edc\u8d62\u5f97\u4e86\nILSVR\uff08ImageNet\uff092014\n\u7684\u51a0\u519b\u3002\u65f6\u81f3\u4eca\u65e5\uff0cVGG\u4ecd\u7136\u88ab\u8ba4\u4e3a\u662f\u4e00\u4e2a\u6770\u51fa\u7684\u89c6\u89c9\u6a21\u578b\u2014\u2014\u5c3d\u7ba1\u5b83\u7684\u6027\u80fd\u5b9e\u9645\u4e0a\u5df2\u7ecf\u88ab\u540e\u6765\u7684Inception\u548cResNet\u8d85\u8fc7\u4e86\u3002\n\n\nLorenzo Baraldi\u5c06Caffe\u9884\u8bad\u7ec3\u597d\u7684VGG16\u548cVGG19\u6a21\u578b\u8f6c\u5316\u4e3a\u4e86Keras\u6743\u91cd\u6587\u4ef6\uff0c\u6240\u4ee5\u6211\u4eec\u53ef\u4ee5\u7b80\u5355\u7684\u901a\u8fc7\u8f7d\u5165\u6743\u91cd\u6765\u8fdb\u884c\u5b9e\u9a8c\u3002\u8be5\u6743\u91cd\u6587\u4ef6\u53ef\u4ee5\u5728\n\u8fd9\u91cc\n\u4e0b\u8f7d\u3002\u56fd\u5185\u7684\u540c\u5b66\u9700\u8981\u81ea\u5907\u68af\u5b50\u3002\uff08\u8fd9\u91cc\u662f\u4e00\u4e2a\u7f51\u76d8\u4fdd\u6301\u7684vgg16\uff1a\nhttp://files.heuritech.com/weights/vgg16_weights.h5\n\u8d76\u7d27\u4e0b\u8f7d\uff0c\u7f51\u76d8\u4ec0\u4e48\u7684\u4e0d\u77e5\u9053\u4ec0\u4e48\u65f6\u5019\u5c31\u6302\u4e86\u3002\uff09\n\n\n\u9996\u5148\uff0c\u6211\u4eec\u5728Keras\u4e2d\u5b9a\u4e49VGG\u7f51\u7edc\u7684\u7ed3\u6784\uff1a\n\n\nfrom keras.models import Sequential\nfrom keras.layers import Convolution2D, ZeroPadding2D, MaxPooling2D\n\nimg_width, img_height = 128, 128\n\n# build the VGG16 network\nmodel = Sequential()\nmodel.add(ZeroPadding2D((1, 1), batch_input_shape=(1, 3, img_width, img_height)))\nfirst_layer = model.layers[-1]\n# this is a placeholder tensor that will contain our generated images\ninput_img = first_layer.input\n\n# build the rest of the network\nmodel.add(Convolution2D(64, 3, 3, activation='relu', name='conv1_1'))\nmodel.add(ZeroPadding2D((1, 1)))\nmodel.add(Convolution2D(64, 3, 3, activation='relu', name='conv1_2'))\nmodel.add(MaxPooling2D((2, 2), strides=(2, 2)))\n\nmodel.add(ZeroPadding2D((1, 1)))\nmodel.add(Convolution2D(128, 3, 3, activation='relu', name='conv2_1'))\nmodel.add(ZeroPadding2D((1, 1)))\nmodel.add(Convolution2D(128, 3, 3, activation='relu', name='conv2_2'))\nmodel.add(MaxPooling2D((2, 2), strides=(2, 2)))\n\nmodel.add(ZeroPadding2D((1, 1)))\nmodel.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_1'))\nmodel.add(ZeroPadding2D((1, 1)))\nmodel.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_2'))\nmodel.add(ZeroPadding2D((1, 1)))\nmodel.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_3'))\nmodel.add(MaxPooling2D((2, 2), strides=(2, 2)))\n\nmodel.add(ZeroPadding2D((1, 1)))\nmodel.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_1'))\nmodel.add(ZeroPadding2D((1, 1)))\nmodel.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_2'))\nmodel.add(ZeroPadding2D((1, 1)))\nmodel.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_3'))\nmodel.add(MaxPooling2D((2, 2), strides=(2, 2)))\n\nmodel.add(ZeroPadding2D((1, 1)))\nmodel.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_1'))\nmodel.add(ZeroPadding2D((1, 1)))\nmodel.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_2'))\nmodel.add(ZeroPadding2D((1, 1)))\nmodel.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_3'))\nmodel.add(MaxPooling2D((2, 2), strides=(2, 2)))\n\n# get the symbolic outputs of each \nkey\n layer (we gave them unique names).\nlayer_dict = dict([(layer.name, layer) for layer in model.layers])\n\n\n\n\n\u6ce8\u610f\u6211\u4eec\u4e0d\u9700\u8981\u5168\u8fde\u63a5\u5c42\uff0c\u6240\u4ee5\u7f51\u7edc\u5c31\u5b9a\u4e49\u5230\u6700\u540e\u4e00\u4e2a\u5377\u79ef\u5c42\u4e3a\u6b62\u3002\u4f7f\u7528\u5168\u8fde\u63a5\u5c42\u4f1a\u5c06\u8f93\u5165\u5927\u5c0f\u9650\u5236\u4e3a224\u00d7224\uff0c\u5373ImageNet\u539f\u56fe\u7247\u7684\u5927\u5c0f\u3002\u8fd9\u662f\u56e0\u4e3a\u5982\u679c\u8f93\u5165\u7684\u56fe\u7247\u5927\u5c0f\u4e0d\u662f224\u00d7224\uff0c\u5728\u4ece\u5377\u79ef\u8fc7\u5ea6\u5230\u5168\u94fe\u63a5\u65f6\u5411\u91cf\u7684\u957f\u5ea6\u4e0e\u6a21\u578b\u6307\u5b9a\u7684\u957f\u5ea6\u4e0d\u76f8\u7b26\u3002\n\n\n\u4e0b\u9762\uff0c\u6211\u4eec\u5c06\u9884\u8bad\u7ec3\u597d\u7684\u6743\u91cd\u8f7d\u5165\u6a21\u578b\uff0c\u4e00\u822c\u800c\u8a00\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\nmodel.load_weights()\n\u8f7d\u5165\uff0c\u4f46\u8fd9\u91cc\u6211\u4eec\u53ea\u8f7d\u5165\u4e00\u90e8\u5206\u53c2\u6570\uff0c\u5982\u679c\u4f7f\u7528\u8be5\u65b9\u6cd5\u7684\u8bdd\uff0c\u6a21\u578b\u548c\u53c2\u6570\u5f62\u5f0f\u5c31\u4e0d\u5339\u914d\u4e86\u3002\u6240\u4ee5\u6211\u4eec\u9700\u8981\u624b\u5de5\u8f7d\u5165\uff1a\n\n\nimport h5py\n\nweights_path = 'vgg16_weights.h5'\n\nf = h5py.File(weights_path)\nfor k in range(f.attrs['nb_layers']):\n    if k \n= len(model.layers):\n        # we don't look at the last (fully-connected) layers in the savefile\n        break\n    g = f['layer_{}'.format(k)]\n    weights = [g['param_{}'.format(p)] for p in range(g.attrs['nb_params'])]\n    model.layers[k].set_weights(weights)\nf.close()\nprint('Model loaded.')\n\n\n\n\n\u4e0b\u9762\uff0c\u6211\u4eec\u8981\u5b9a\u4e49\u4e00\u4e2a\u635f\u5931\u51fd\u6570\uff0c\u8fd9\u4e2a\u635f\u5931\u51fd\u6570\u5c06\u7528\u4e8e\u6700\u5927\u5316\u67d0\u4e2a\u6307\u5b9a\u6ee4\u6ce2\u5668\u7684\u6fc0\u6d3b\u503c\u3002\u4ee5\u8be5\u51fd\u6570\u4e3a\u4f18\u5316\u76ee\u6807\u4f18\u5316\u540e\uff0c\u6211\u4eec\u53ef\u4ee5\u771f\u6b63\u770b\u4e00\u4e0b\u4f7f\u5f97\u8fd9\u4e2a\u6ee4\u6ce2\u5668\u6fc0\u6d3b\u7684\u7a76\u7adf\u662f\u4e9b\u4ec0\u4e48\u4e1c\u897f\u3002\n\n\n\u73b0\u5728\u6211\u4eec\u4f7f\u7528Keras\u7684\u540e\u7aef\u6765\u5b8c\u6210\u8fd9\u4e2a\u635f\u5931\u51fd\u6570\uff0c\u8fd9\u6837\u8fd9\u4efd\u4ee3\u7801\u4e0d\u7528\u4fee\u6539\u5c31\u53ef\u4ee5\u5728TensorFlow\u548cTheano\u4e4b\u95f4\u5207\u6362\u4e86\u3002TensorFlow\u5728CPU\u4e0a\u8fdb\u884c\u5377\u79ef\u8981\u5757\u7684\u591a\uff0c\u800c\u76ee\u524d\u4e3a\u6b62Theano\u5728GPU\u4e0a\u8fdb\u884c\u5377\u79ef\u8981\u5feb\u4e00\u4e9b\u3002\n\n\nfrom keras import backend as K\n\nlayer_name = 'conv5_1'\nfilter_index = 0  # can be any integer from 0 to 511, as there are 512 filters in that layer\n\n# build a loss function that maximizes the activation\n# of the nth filter of the layer considered\nlayer_output = layer_dict[layer_name].output\nloss = K.mean(layer_output[:, filter_index, :, :])\n\n# compute the gradient of the input picture wrt this loss\ngrads = K.gradients(loss, input_img)[0]\n\n# normalization trick: we normalize the gradient\ngrads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n\n# this function returns the loss and grads given the input picture\niterate = K.function([input_img], [loss, grads])\n\n\n\n\n\u6ce8\u610f\u8fd9\u91cc\u6709\u4e2a\u5c0ftrick\uff0c\u8ba1\u7b97\u51fa\u6765\u7684\u68af\u5ea6\u8fdb\u884c\u4e86\u6b63\u89c4\u5316\uff0c\u4f7f\u5f97\u68af\u5ea6\u4e0d\u4f1a\u8fc7\u5c0f\u6216\u8fc7\u5927\u3002\u8fd9\u79cd\u6b63\u89c4\u5316\u80fd\u591f\u4f7f\u68af\u5ea6\u4e0a\u5347\u7684\u8fc7\u7a0b\u5e73\u6ed1\u8fdb\u884c\u3002\n\n\n\u6839\u636e\u521a\u521a\u5b9a\u4e49\u7684\u51fd\u6570\uff0c\u73b0\u5728\u53ef\u4ee5\u5bf9\u67d0\u4e2a\u6ee4\u6ce2\u5668\u7684\u6fc0\u6d3b\u503c\u8fdb\u884c\u68af\u5ea6\u4e0a\u5347\u3002\n\n\nimport numpy as np\n\n# we start from a gray image with some noise\ninput_img_data = np.random.random((1, 3, img_width, img_height)) * 20 + 128.\n# run gradient ascent for 20 steps\nfor i in range(20):\n    loss_value, grads_value = iterate([input_img_data])\n    input_img_data += grads_value * step\n\n\n\n\n\u4f7f\u7528TensorFlow\u65f6\uff0c\u8fd9\u4e2a\u64cd\u4f5c\u5927\u6982\u53ea\u8981\u51e0\u79d2\u3002\n\n\n\u7136\u540e\u6211\u4eec\u53ef\u4ee5\u63d0\u53d6\u51fa\u7ed3\u679c\uff0c\u5e76\u53ef\u89c6\u5316\uff1a\n\n\nfrom scipy.misc import imsave\n\n# util function to convert a tensor into a valid image\ndef deprocess_image(x):\n    # normalize tensor: center on 0., ensure std is 0.1\n    x -= x.mean()\n    x /= (x.std() + 1e-5)\n    x *= 0.1\n\n    # clip to [0, 1]\n    x += 0.5\n    x = np.clip(x, 0, 1)\n\n    # convert to RGB array\n    x *= 255\n    x = x.transpose((1, 2, 0))\n    x = np.clip(x, 0, 255).astype('uint8')\n    return x\n\nimg = input_img_data[0]\nimg = deprocess_image(img)\nimsave('%s_filter_%d.png' % (layer_name, filter_index), img)\n\n\n\n\n\u8fd9\u91cc\u662f\u7b2c5\u5377\u57fa\u5c42\u7b2c0\u4e2a\u6ee4\u6ce2\u5668\u7684\u7ed3\u679c\uff1a\n\n\n\n\n\u53ef\u89c6\u5316\u6240\u6709\u7684\u6ee4\u6ce2\u5668\n\n\n\u4e0b\u9762\u6211\u4eec\u7cfb\u7edf\u7684\u53ef\u89c6\u5316\u4e00\u4e0b\u5404\u4e2a\u5c42\u7684\u5404\u4e2a\u6ee4\u6ce2\u5668\u7ed3\u679c\uff0c\u770b\u770bCNN\u662f\u5982\u4f55\u5bf9\u8f93\u5165\u8fdb\u884c\u9010\u5c42\u5206\u89e3\u7684\u3002\n\n\n\u7b2c\u4e00\u5c42\u7684\u6ee4\u6ce2\u5668\u4e3b\u8981\u5b8c\u6210\u65b9\u5411\u3001\u989c\u8272\u7684\u7f16\u7801\uff0c\u8fd9\u4e9b\u989c\u8272\u548c\u65b9\u5411\u4e0e\u57fa\u672c\u7684\u7eb9\u7406\u7ec4\u5408\uff0c\u9010\u6e10\u751f\u6210\u590d\u6742\u7684\u5f62\u72b6\u3002\n\n\n\u53ef\u4ee5\u5c06\u6bcf\u5c42\u7684\u6ee4\u6ce2\u5668\u60f3\u4e3a\u57fa\u5411\u91cf\uff0c\u8fd9\u4e9b\u57fa\u5411\u91cf\u4e00\u822c\u662f\u8fc7\u5b8c\u5907\u7684\u3002\u57fa\u5411\u91cf\u53ef\u4ee5\u5c06\u5c42\u7684\u8f93\u5165\u7d27\u51d1\u7684\u7f16\u7801\u51fa\u6765\u3002\u6ee4\u6ce2\u5668\u968f\u7740\u5176\u5229\u7528\u7684\u7a7a\u57df\u4fe1\u606f\u7684\u62d3\u5bbd\u800c\u66f4\u52a0\u7cbe\u7ec6\u548c\u590d\u6742\uff0c\n\n\n\n\n\u53ef\u4ee5\u89c2\u5bdf\u5230\uff0c\u5f88\u591a\u6ee4\u6ce2\u5668\u7684\u5185\u5bb9\u5176\u5b9e\u662f\u4e00\u6837\u7684\uff0c\u53ea\u4e0d\u8fc7\u65cb\u8f6c\u4e86\u4e00\u4e2a\u968f\u673a\u7684\u7684\u89d2\u5ea6\uff08\u598290\u5ea6\uff09\u800c\u5df2\u3002\u8fd9\u610f\u5473\u7740\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u4f7f\u5f97\u5377\u79ef\u6ee4\u6ce2\u5668\u5177\u6709\u65cb\u8f6c\u4e0d\u53d8\u6027\u800c\u663e\u8457\u51cf\u5c11\u6ee4\u6ce2\u5668\u7684\u6570\u76ee\uff0c\u8fd9\u662f\u4e00\u4e2a\u6709\u8da3\u7684\u7814\u7a76\u65b9\u5411\u3002\n\n\n\u4ee4\u4eba\u9707\u60ca\u7684\u662f\uff0c\u8fd9\u79cd\u65cb\u8f6c\u7684\u6027\u8d28\u5728\u9ad8\u5c42\u7684\u6ee4\u6ce2\u5668\u4e2d\u4ecd\u7136\u53ef\u4ee5\u88ab\u89c2\u5bdf\u5230\u3002\u5982Conv4_1\n\n\nDeep Dream\uff08nightmare\uff09\n\n\n\u53e6\u4e00\u4e2a\u6709\u8da3\u7684\u4e8b\u513f\u662f\uff0c\u5982\u679c\u6211\u4eec\u628a\u521a\u624d\u7684\u968f\u673a\u566a\u58f0\u56fe\u7247\u66ff\u6362\u4e3a\u6709\u610f\u4e49\u7684\u7167\u7247\uff0c\u7ed3\u679c\u5c31\u53d8\u7684\u66f4\u597d\u73a9\u4e86\u3002\u8fd9\u5c31\u662f\u53bb\u5e74\u7531Google\u63d0\u51fa\u7684Deep Dream\u3002\u901a\u8fc7\u9009\u62e9\u7279\u5b9a\u7684\u6ee4\u6ce2\u5668\u7ec4\u5408\uff0c\u6211\u4eec\u53ef\u4ee5\u83b7\u5f97\u4e00\u4e9b\u5f88\u6709\u610f\u601d\u7684\u7ed3\u679c\u3002\u5982\u679c\u4f60\u5bf9\u6b64\u611f\u5174\u8da3\uff0c\u53ef\u4ee5\u53c2\u8003Keras\u7684\u4f8b\u5b50\n\nDeep Dream\n\u548cGoogle\u7684\u535a\u5ba2\nGoogle blog post\n\uff08\u5899\uff09\n\n\n\n\n\u611a\u5f04\u795e\u7ecf\u7f51\u7edc\n\n\n\u5982\u679c\u6211\u4eec\u6dfb\u52a0\u4e0aVGG\u7684\u5168\u8fde\u63a5\u5c42\uff0c\u7136\u540e\u8bd5\u56fe\u6700\u5927\u5316\u67d0\u4e2a\u6307\u5b9a\u7c7b\u522b\u7684\u6fc0\u6d3b\u503c\u5462\uff1f\u4f60\u4f1a\u5f97\u5230\u4e00\u5f20\u5f88\u50cf\u8be5\u7c7b\u522b\u7684\u56fe\u7247\u5417\uff1f\u8ba9\u6211\u4eec\u8bd5\u8bd5\u3002\n\n\n\u8fd9\u79cd\u60c5\u51b5\u4e0b\u6211\u4eec\u7684\u635f\u5931\u51fd\u6570\u957f\u8fd9\u6837\uff1a\n\n\nlayer_output = model.layers[-1].get_output()\nloss = K.mean(layer_output[:, output_index])\n\n\n\n\n\u6bd4\u65b9\u8bf4\u6211\u4eec\u6765\u6700\u5927\u5316\u8f93\u51fa\u4e0b\u6807\u4e3a65\u7684\u90a3\u4e2a\u7c7b\uff0c\u5728ImageNet\u91cc\uff0c\u8fd9\u4e2a\u7c7b\u662f\u86c7\u3002\u5f88\u5feb\uff0c\u6211\u4eec\u7684\u635f\u5931\u8fbe\u5230\u4e860.999\uff0c\u5373\u795e\u7ecf\u7f51\u7edc\u670999.9%\u7684\u6982\u7387\u8ba4\u4e3a\u6211\u4eec\u751f\u6210\u7684\u56fe\u7247\u662f\u4e00\u6761\u6d77\u86c7\uff0c\u5b83\u957f\u8fd9\u6837\uff1a\n\n\n\n\n\u4e0d\u592a\u50cf\u5440\uff0c\u6362\u4e2a\u7c7b\u522b\u8bd5\u8bd5\uff0c\u8fd9\u6b21\u9009\u559c\u9e4a\u7c7b\uff08\u7b2c18\u7c7b\uff09\n\n\n\n\nOK\uff0c\u6211\u4eec\u7684\u7f51\u7edc\u8ba4\u4e3a\u662f\u559c\u9e4a\u7684\u4e1c\u897f\u770b\u8d77\u6765\u5b8c\u5168\u4e0d\u662f\u559c\u9e4a\uff0c\u5f80\u597d\u4e86\u8bf4\uff0c\u8fd9\u4e2a\u56fe\u91cc\u8ddf\u559c\u9e4a\u76f8\u4f3c\u7684\uff0c\u4e5f\u4e0d\u8fc7\u5c31\u662f\u4e00\u4e9b\u5c40\u90e8\u7684\u7eb9\u7406\uff0c\u5982\u7fbd\u6bdb\uff0c\u5634\u5df4\u4e4b\u7c7b\u7684\u3002\u90a3\u4e48\uff0c\u8fd9\u5c31\u610f\u5473\u7740\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u662f\u4e2a\u5f88\u5dee\u7684\u5de5\u5177\u5417\uff1f\u5f53\u7136\u4e0d\u662f\uff0c\u6211\u4eec\u6309\u7167\u4e00\u4e2a\u7279\u5b9a\u4efb\u52a1\u6765\u8bad\u7ec3\u5b83\uff0c\u5b83\u5c31\u4f1a\u5728\u90a3\u4e2a\u4efb\u52a1\u4e0a\u8868\u73b0\u7684\u4e0d\u9519\u3002\u4f46\u6211\u4eec\u4e0d\u80fd\u6709\u7f51\u7edc\u201c\u7406\u89e3\u201d\u67d0\u4e2a\u6982\u5ff5\u7684\u9519\u89c9\u3002\u6211\u4eec\u4e0d\u80fd\u5c06\u7f51\u7edc\u4eba\u683c\u5316\uff0c\u5b83\u53ea\u662f\u5de5\u5177\u800c\u5df2\u3002\u6bd4\u5982\u4e00\u6761\u72d7\uff0c\u5b83\u80fd\u8bc6\u522b\u5176\u4e3a\u72d7\u53ea\u662f\u56e0\u4e3a\u5b83\u80fd\u4ee5\u5f88\u9ad8\u7684\u6982\u7387\u5c06\u5176\u6b63\u786e\u5206\u7c7b\u800c\u5df2\uff0c\u800c\u4e0d\u4ee3\u8868\u5b83\u7406\u89e3\u5173\u4e8e\u201c\u72d7\u201d\u7684\u4efb\u4f55\u5916\u5ef6\u3002\n\n\n\u9769\u547d\u5c1a\u672a\u6210\u529f\uff0c\u540c\u5fd7\u4ecd\u9700\u52aa\u529b\n\n\n\u6240\u4ee5\uff0c\u795e\u7ecf\u7f51\u7edc\u5230\u5e95\u7406\u89e3\u4e86\u4ec0\u4e48\u5462\uff1f\u6211\u8ba4\u4e3a\u6709\u4e24\u4ef6\u4e8b\u662f\u5b83\u4eec\u7406\u89e3\u7684\u3002\n\n\n\u5176\u4e00\uff0c\u795e\u7ecf\u7f51\u7edc\u7406\u89e3\u4e86\u5982\u4f55\u5c06\u8f93\u5165\u7a7a\u95f4\u89e3\u8026\u4e3a\u5206\u5c42\u6b21\u7684\u5377\u79ef\u6ee4\u6ce2\u5668\u7ec4\u3002\u5176\u4e8c\uff0c\u795e\u7ecf\u7f51\u7edc\u7406\u89e3\u4e86\u4ece\u4e00\u7cfb\u5217\u6ee4\u6ce2\u5668\u7684\u7ec4\u5408\u5230\u4e00\u7cfb\u5217\u7279\u5b9a\u6807\u7b7e\u7684\u6982\u7387\u6620\u5c04\u3002\u795e\u7ecf\u7f51\u7edc\u5b66\u4e60\u5230\u7684\u4e1c\u897f\u5b8c\u5168\u8fbe\u4e0d\u5230\u4eba\u7c7b\u7684\u201c\u770b\u89c1\u201d\u7684\u610f\u4e49\uff0c\u4ece\u79d1\u5b66\u7684\u7684\u89d2\u5ea6\u8bb2\uff0c\u8fd9\u5f53\u7136\u4e5f\u4e0d\u610f\u5473\u7740\u6211\u4eec\u5df2\u7ecf\u89e3\u51b3\u4e86\u8ba1\u7b97\u673a\u89c6\u89c9\u7684\u95ee\u9898\u3002\u60f3\u5f97\u522b\u592a\u591a\uff0c\u6211\u4eec\u624d\u521a\u521a\u8e29\u4e0a\u8ba1\u7b97\u673a\u89c6\u89c9\u5929\u68af\u7684\u7b2c\u4e00\u6b65\u3002\n\n\n\u6709\u4e9b\u4eba\u8bf4\uff0c\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u5b66\u4e60\u5230\u7684\u5bf9\u8f93\u5165\u7a7a\u95f4\u7684\u5206\u5c42\u6b21\u89e3\u8026\u6a21\u62df\u4e86\u4eba\u7c7b\u89c6\u89c9\u76ae\u5c42\u7684\u884c\u4e3a\u3002\u8fd9\u79cd\u8bf4\u6cd5\u53ef\u80fd\u5bf9\u4e5f\u53ef\u80fd\u4e0d\u5bf9\uff0c\u4f46\u76ee\u524d\u672a\u77e5\u6211\u4eec\u8fd8\u6ca1\u6709\u6bd4\u8f83\u5f3a\u7684\u8bc1\u636e\u6765\u627f\u8ba4\u6216\u5426\u8ba4\u5b83\u3002\u5f53\u7136\uff0c\u6709\u4e9b\u4eba\u53ef\u4ee5\u671f\u671b\u4eba\u7c7b\u7684\u89c6\u89c9\u76ae\u5c42\u5c31\u662f\u4ee5\u7c7b\u4f3c\u7684\u65b9\u5f0f\u5b66\u4e1c\u897f\u7684\uff0c\u67d0\u79cd\u7a0b\u5ea6\u4e0a\u8bb2\uff0c\u8fd9\u662f\u5bf9\u6211\u4eec\u89c6\u89c9\u4e16\u754c\u7684\u81ea\u7136\u89e3\u8026\uff08\u5c31\u50cf\u5085\u91cc\u53f6\u53d8\u6362\u662f\u5bf9\u5468\u671f\u58f0\u97f3\u4fe1\u53f7\u7684\u4e00\u79cd\u89e3\u8026\u4e00\u6837\u81ea\u7136\uff09\u3010\u8bd1\u6ce8\uff1a\u8fd9\u91cc\u662f\u8bf4\uff0c\u5c31\u50cf\u58f0\u97f3\u4fe1\u53f7\u7684\u5085\u91cc\u53f6\u53d8\u6362\u8868\u8fbe\u4e86\u4e0d\u540c\u9891\u7387\u7684\u58f0\u97f3\u4fe1\u53f7\u8fd9\u79cd\u5f88\u81ea\u7136\u5f88\u7269\u7406\u7684\u7406\u89e3\u4e00\u6837\uff0c\u6211\u4eec\u53ef\u80fd\u4f1a\u8ba4\u4e3a\u6211\u4eec\u5bf9\u89c6\u89c9\u4fe1\u606f\u7684\u8bc6\u522b\u5c31\u662f\u5206\u5c42\u6765\u5b8c\u6210\u7684\uff0c\u5706\u7684\u662f\u8f6e\u5b50\uff0c\u6709\u56db\u4e2a\u8f6e\u5b50\u7684\u662f\u6c7d\u8f66\uff0c\u9020\u578b\u70ab\u9177\u7684\u6c7d\u8f66\u662f\u8dd1\u8f66\uff0c\u50cf\u8fd9\u6837\u3011\u3002\u4f46\u662f\uff0c\u4eba\u7c7b\u5bf9\u89c6\u89c9\u4fe1\u53f7\u7684\u6ee4\u6ce2\u3001\u5206\u5c42\u6b21\u3001\u5904\u7406\u7684\u672c\u8d28\u5f88\u53ef\u80fd\u548c\u6211\u4eec\u5f31\u9e21\u7684\u5377\u79ef\u7f51\u7edc\u5b8c\u5168\u4e0d\u662f\u4e00\u56de\u4e8b\u3002\u89c6\u89c9\u76ae\u5c42\u4e0d\u662f\u5377\u79ef\u7684\uff0c\u5c3d\u7ba1\u5b83\u4eec\u4e5f\u5206\u5c42\uff0c\u4f46\u90a3\u4e9b\u5c42\u5177\u6709\u76ae\u8d28\u5217\u7684\u7ed3\u6784\uff0c\u800c\u8fd9\u4e9b\u7ed3\u6784\u7684\u771f\u6b63\u76ee\u7684\u76ee\u524d\u8fd8\u4e0d\u5f97\u800c\u77e5\uff0c\u8fd9\u79cd\u7ed3\u6784\u5728\u6211\u4eec\u7684\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\u4e2d\u8fd8\u6ca1\u6709\u51fa\u73b0\uff08\u5c3d\u7ba1\u4e54\u5927\u5e1dGeoff Hinton\u6b63\u5728\u5728\u8fd9\u4e2a\u65b9\u9762\u52aa\u529b\uff09\u3002\u6b64\u5916\uff0c\u4eba\u7c7b\u6709\u6bd4\u7ed9\u9759\u6001\u56fe\u50cf\u5206\u7c7b\u7684\u611f\u77e5\u5668\u591a\u5f97\u591a\u7684\u89c6\u89c9\u611f\u77e5\u5668\uff0c\u8fd9\u4e9b\u611f\u77e5\u5668\u662f\u8fde\u7eed\u800c\u4e3b\u52a8\u7684\uff0c\u4e0d\u662f\u9759\u6001\u800c\u88ab\u52a8\u7684\uff0c\u8fd9\u4e9b\u611f\u53d7\u5668\u8fd8\u88ab\u5982\u773c\u52a8\u7b49\u591a\u79cd\u673a\u5236\u590d\u6742\u63a7\u5236\u3002\n\n\n\u4e0b\u6b21\u6709\u98ce\u6295\u6216\u67d0\u77e5\u540dCEO\u8b66\u544a\u4f60\u8981\u8b66\u60d5\u6211\u4eec\u6df1\u5ea6\u5b66\u4e60\u7684\u5a01\u80c1\u65f6\uff0c\u60f3\u60f3\u4e0a\u9762\u8bf4\u7684\u5427\u3002\u4eca\u5929\u6211\u4eec\u662f\u6709\u66f4\u597d\u7684\u5de5\u5177\u6765\u5904\u7406\u590d\u6742\u7684\u4fe1\u606f\u4e86\uff0c\u8fd9\u5f88\u9177\uff0c\u4f46\u5f52\u6839\u7ed3\u5e95\u5b83\u4eec\u53ea\u662f\u5de5\u5177\uff0c\u800c\u4e0d\u662f\u751f\u7269\u3002\u5b83\u4eec\u505a\u7684\u4efb\u4f55\u5de5\u4f5c\u5728\u54ea\u4e2a\u5b87\u5b99\u7684\u6807\u51c6\u4e0b\u90fd\u4e0d\u591f\u683c\u79f0\u4e4b\u4e3a\u201c\u601d\u8003\u201d\u3002\u5728\u4e00\u4e2a\u77f3\u5934\u4e0a\u753b\u4e00\u4e2a\u7b11\u8138\u5e76\u4e0d\u4f1a\u4f7f\u77f3\u5934\u53d8\u5f97\u201c\u5f00\u5fc3\u201d\uff0c\u5c3d\u7ba1\u4f60\u7684\u7075\u957f\u76ee\u76ae\u8d28\u4f1a\u544a\u8bc9\u4f60\u5b83\u5f88\u5f00\u5fc3\u3002\n\n\n\u603b\u800c\u8a00\u4e4b\uff0c\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7684\u53ef\u89c6\u5316\u5de5\u4f5c\u662f\u5f88\u8ba9\u4eba\u7740\u8ff7\u7684\uff0c\u8c01\u80fd\u60f3\u5230\u4ec5\u4ec5\u901a\u8fc7\u7b80\u5355\u7684\u68af\u5ea6\u4e0b\u964d\u6cd5\u548c\u5408\u7406\u7684\u635f\u5931\u51fd\u6570\uff0c\u52a0\u4e0a\u5927\u89c4\u6a21\u7684\u6570\u636e\u5e93\uff0c\u5c31\u80fd\u5b66\u5230\u80fd\u5f88\u597d\u89e3\u91ca\u590d\u6742\u89c6\u89c9\u4fe1\u606f\u7684\u5982\u6b64\u6f02\u4eae\u7684\u5206\u5c42\u6a21\u578b\u5462\u3002\u6df1\u5ea6\u5b66\u4e60\u6216\u8bb8\u5728\u5b9e\u9645\u7684\u610f\u4e49\u4e0a\u5e76\u4e0d\u667a\u80fd\uff0c\u4f46\u5b83\u4ecd\u7136\u80fd\u591f\u8fbe\u5230\u51e0\u5e74\u524d\u4efb\u4f55\u4eba\u90fd\u65e0\u6cd5\u8fbe\u5230\u7684\u6548\u679c\u3002\u73b0\u5728\uff0c\u5982\u679c\u6211\u4eec\u80fd\u7406\u89e3\u4e3a\u4ec0\u4e48\u6df1\u5ea6\u5b66\u4e60\u5982\u6b64\u6709\u6548\uff0c\u90a3\u2026\u2026\u563f\u563f:)\n\n\n@fchollet, 2016\u5e741\u6708", 
            "title": "CNN\u773c\u4e2d\u7684\u4e16\u754c"
        }, 
        {
            "location": "/blog/cnn_see_world/#cnnkerascnn", 
            "text": "", 
            "title": "CNN\u773c\u4e2d\u7684\u4e16\u754c\uff1a\u5229\u7528Keras\u89e3\u91caCNN\u7684\u6ee4\u6ce2\u5668"
        }, 
        {
            "location": "/blog/cnn_see_world/#_1", 
            "text": "\u672c\u6587\u5730\u5740\uff1a http://blog.keras.io/how-convolutional-neural-networks-see-the-world.html  \u672c\u6587\u4f5c\u8005\uff1aFrancois Chollet", 
            "title": "\u6587\u7ae0\u4fe1\u606f"
        }, 
        {
            "location": "/blog/cnn_see_world/#keras", 
            "text": "\u672c\u6587\u4e2d\u6211\u4eec\u5c06\u5229\u7528Keras\u89c2\u5bdfCNN\u5230\u5e95\u5728\u5b66\u4e9b\u4ec0\u4e48\uff0c\u5b83\u662f\u5982\u4f55\u7406\u89e3\u6211\u4eec\u9001\u5165\u7684\u8bad\u7ec3\u56fe\u7247\u7684\u3002\u6211\u4eec\u5c06\u4f7f\u7528Keras\u6765\u5bf9\u6ee4\u6ce2\u5668\u7684\u6fc0\u6d3b\u503c\u8fdb\u884c\u53ef\u89c6\u5316\u3002\u672c\u6587\u4f7f\u7528\u7684\u795e\u7ecf\u7f51\u7edc\u662fVGG-16\uff0c\u6570\u636e\u96c6\u4e3aImageNet\u3002\u672c\u6587\u7684\u4ee3\u7801\u53ef\u4ee5\u5728 github \u627e\u5230   VGG-16\u53c8\u79f0\u4e3aOxfordNet\uff0c\u662f\u7531\u725b\u6d25 \u89c6\u89c9\u51e0\u4f55\u7ec4\uff08Visual Geometry Group\uff09 \u5f00\u53d1\u7684\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7ed3\u6784\u3002\u8be5\u7f51\u7edc\u8d62\u5f97\u4e86 ILSVR\uff08ImageNet\uff092014 \u7684\u51a0\u519b\u3002\u65f6\u81f3\u4eca\u65e5\uff0cVGG\u4ecd\u7136\u88ab\u8ba4\u4e3a\u662f\u4e00\u4e2a\u6770\u51fa\u7684\u89c6\u89c9\u6a21\u578b\u2014\u2014\u5c3d\u7ba1\u5b83\u7684\u6027\u80fd\u5b9e\u9645\u4e0a\u5df2\u7ecf\u88ab\u540e\u6765\u7684Inception\u548cResNet\u8d85\u8fc7\u4e86\u3002  Lorenzo Baraldi\u5c06Caffe\u9884\u8bad\u7ec3\u597d\u7684VGG16\u548cVGG19\u6a21\u578b\u8f6c\u5316\u4e3a\u4e86Keras\u6743\u91cd\u6587\u4ef6\uff0c\u6240\u4ee5\u6211\u4eec\u53ef\u4ee5\u7b80\u5355\u7684\u901a\u8fc7\u8f7d\u5165\u6743\u91cd\u6765\u8fdb\u884c\u5b9e\u9a8c\u3002\u8be5\u6743\u91cd\u6587\u4ef6\u53ef\u4ee5\u5728 \u8fd9\u91cc \u4e0b\u8f7d\u3002\u56fd\u5185\u7684\u540c\u5b66\u9700\u8981\u81ea\u5907\u68af\u5b50\u3002\uff08\u8fd9\u91cc\u662f\u4e00\u4e2a\u7f51\u76d8\u4fdd\u6301\u7684vgg16\uff1a http://files.heuritech.com/weights/vgg16_weights.h5 \u8d76\u7d27\u4e0b\u8f7d\uff0c\u7f51\u76d8\u4ec0\u4e48\u7684\u4e0d\u77e5\u9053\u4ec0\u4e48\u65f6\u5019\u5c31\u6302\u4e86\u3002\uff09  \u9996\u5148\uff0c\u6211\u4eec\u5728Keras\u4e2d\u5b9a\u4e49VGG\u7f51\u7edc\u7684\u7ed3\u6784\uff1a  from keras.models import Sequential\nfrom keras.layers import Convolution2D, ZeroPadding2D, MaxPooling2D\n\nimg_width, img_height = 128, 128\n\n# build the VGG16 network\nmodel = Sequential()\nmodel.add(ZeroPadding2D((1, 1), batch_input_shape=(1, 3, img_width, img_height)))\nfirst_layer = model.layers[-1]\n# this is a placeholder tensor that will contain our generated images\ninput_img = first_layer.input\n\n# build the rest of the network\nmodel.add(Convolution2D(64, 3, 3, activation='relu', name='conv1_1'))\nmodel.add(ZeroPadding2D((1, 1)))\nmodel.add(Convolution2D(64, 3, 3, activation='relu', name='conv1_2'))\nmodel.add(MaxPooling2D((2, 2), strides=(2, 2)))\n\nmodel.add(ZeroPadding2D((1, 1)))\nmodel.add(Convolution2D(128, 3, 3, activation='relu', name='conv2_1'))\nmodel.add(ZeroPadding2D((1, 1)))\nmodel.add(Convolution2D(128, 3, 3, activation='relu', name='conv2_2'))\nmodel.add(MaxPooling2D((2, 2), strides=(2, 2)))\n\nmodel.add(ZeroPadding2D((1, 1)))\nmodel.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_1'))\nmodel.add(ZeroPadding2D((1, 1)))\nmodel.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_2'))\nmodel.add(ZeroPadding2D((1, 1)))\nmodel.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_3'))\nmodel.add(MaxPooling2D((2, 2), strides=(2, 2)))\n\nmodel.add(ZeroPadding2D((1, 1)))\nmodel.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_1'))\nmodel.add(ZeroPadding2D((1, 1)))\nmodel.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_2'))\nmodel.add(ZeroPadding2D((1, 1)))\nmodel.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_3'))\nmodel.add(MaxPooling2D((2, 2), strides=(2, 2)))\n\nmodel.add(ZeroPadding2D((1, 1)))\nmodel.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_1'))\nmodel.add(ZeroPadding2D((1, 1)))\nmodel.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_2'))\nmodel.add(ZeroPadding2D((1, 1)))\nmodel.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_3'))\nmodel.add(MaxPooling2D((2, 2), strides=(2, 2)))\n\n# get the symbolic outputs of each  key  layer (we gave them unique names).\nlayer_dict = dict([(layer.name, layer) for layer in model.layers])  \u6ce8\u610f\u6211\u4eec\u4e0d\u9700\u8981\u5168\u8fde\u63a5\u5c42\uff0c\u6240\u4ee5\u7f51\u7edc\u5c31\u5b9a\u4e49\u5230\u6700\u540e\u4e00\u4e2a\u5377\u79ef\u5c42\u4e3a\u6b62\u3002\u4f7f\u7528\u5168\u8fde\u63a5\u5c42\u4f1a\u5c06\u8f93\u5165\u5927\u5c0f\u9650\u5236\u4e3a224\u00d7224\uff0c\u5373ImageNet\u539f\u56fe\u7247\u7684\u5927\u5c0f\u3002\u8fd9\u662f\u56e0\u4e3a\u5982\u679c\u8f93\u5165\u7684\u56fe\u7247\u5927\u5c0f\u4e0d\u662f224\u00d7224\uff0c\u5728\u4ece\u5377\u79ef\u8fc7\u5ea6\u5230\u5168\u94fe\u63a5\u65f6\u5411\u91cf\u7684\u957f\u5ea6\u4e0e\u6a21\u578b\u6307\u5b9a\u7684\u957f\u5ea6\u4e0d\u76f8\u7b26\u3002  \u4e0b\u9762\uff0c\u6211\u4eec\u5c06\u9884\u8bad\u7ec3\u597d\u7684\u6743\u91cd\u8f7d\u5165\u6a21\u578b\uff0c\u4e00\u822c\u800c\u8a00\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7 model.load_weights() \u8f7d\u5165\uff0c\u4f46\u8fd9\u91cc\u6211\u4eec\u53ea\u8f7d\u5165\u4e00\u90e8\u5206\u53c2\u6570\uff0c\u5982\u679c\u4f7f\u7528\u8be5\u65b9\u6cd5\u7684\u8bdd\uff0c\u6a21\u578b\u548c\u53c2\u6570\u5f62\u5f0f\u5c31\u4e0d\u5339\u914d\u4e86\u3002\u6240\u4ee5\u6211\u4eec\u9700\u8981\u624b\u5de5\u8f7d\u5165\uff1a  import h5py\n\nweights_path = 'vgg16_weights.h5'\n\nf = h5py.File(weights_path)\nfor k in range(f.attrs['nb_layers']):\n    if k  = len(model.layers):\n        # we don't look at the last (fully-connected) layers in the savefile\n        break\n    g = f['layer_{}'.format(k)]\n    weights = [g['param_{}'.format(p)] for p in range(g.attrs['nb_params'])]\n    model.layers[k].set_weights(weights)\nf.close()\nprint('Model loaded.')  \u4e0b\u9762\uff0c\u6211\u4eec\u8981\u5b9a\u4e49\u4e00\u4e2a\u635f\u5931\u51fd\u6570\uff0c\u8fd9\u4e2a\u635f\u5931\u51fd\u6570\u5c06\u7528\u4e8e\u6700\u5927\u5316\u67d0\u4e2a\u6307\u5b9a\u6ee4\u6ce2\u5668\u7684\u6fc0\u6d3b\u503c\u3002\u4ee5\u8be5\u51fd\u6570\u4e3a\u4f18\u5316\u76ee\u6807\u4f18\u5316\u540e\uff0c\u6211\u4eec\u53ef\u4ee5\u771f\u6b63\u770b\u4e00\u4e0b\u4f7f\u5f97\u8fd9\u4e2a\u6ee4\u6ce2\u5668\u6fc0\u6d3b\u7684\u7a76\u7adf\u662f\u4e9b\u4ec0\u4e48\u4e1c\u897f\u3002  \u73b0\u5728\u6211\u4eec\u4f7f\u7528Keras\u7684\u540e\u7aef\u6765\u5b8c\u6210\u8fd9\u4e2a\u635f\u5931\u51fd\u6570\uff0c\u8fd9\u6837\u8fd9\u4efd\u4ee3\u7801\u4e0d\u7528\u4fee\u6539\u5c31\u53ef\u4ee5\u5728TensorFlow\u548cTheano\u4e4b\u95f4\u5207\u6362\u4e86\u3002TensorFlow\u5728CPU\u4e0a\u8fdb\u884c\u5377\u79ef\u8981\u5757\u7684\u591a\uff0c\u800c\u76ee\u524d\u4e3a\u6b62Theano\u5728GPU\u4e0a\u8fdb\u884c\u5377\u79ef\u8981\u5feb\u4e00\u4e9b\u3002  from keras import backend as K\n\nlayer_name = 'conv5_1'\nfilter_index = 0  # can be any integer from 0 to 511, as there are 512 filters in that layer\n\n# build a loss function that maximizes the activation\n# of the nth filter of the layer considered\nlayer_output = layer_dict[layer_name].output\nloss = K.mean(layer_output[:, filter_index, :, :])\n\n# compute the gradient of the input picture wrt this loss\ngrads = K.gradients(loss, input_img)[0]\n\n# normalization trick: we normalize the gradient\ngrads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n\n# this function returns the loss and grads given the input picture\niterate = K.function([input_img], [loss, grads])  \u6ce8\u610f\u8fd9\u91cc\u6709\u4e2a\u5c0ftrick\uff0c\u8ba1\u7b97\u51fa\u6765\u7684\u68af\u5ea6\u8fdb\u884c\u4e86\u6b63\u89c4\u5316\uff0c\u4f7f\u5f97\u68af\u5ea6\u4e0d\u4f1a\u8fc7\u5c0f\u6216\u8fc7\u5927\u3002\u8fd9\u79cd\u6b63\u89c4\u5316\u80fd\u591f\u4f7f\u68af\u5ea6\u4e0a\u5347\u7684\u8fc7\u7a0b\u5e73\u6ed1\u8fdb\u884c\u3002  \u6839\u636e\u521a\u521a\u5b9a\u4e49\u7684\u51fd\u6570\uff0c\u73b0\u5728\u53ef\u4ee5\u5bf9\u67d0\u4e2a\u6ee4\u6ce2\u5668\u7684\u6fc0\u6d3b\u503c\u8fdb\u884c\u68af\u5ea6\u4e0a\u5347\u3002  import numpy as np\n\n# we start from a gray image with some noise\ninput_img_data = np.random.random((1, 3, img_width, img_height)) * 20 + 128.\n# run gradient ascent for 20 steps\nfor i in range(20):\n    loss_value, grads_value = iterate([input_img_data])\n    input_img_data += grads_value * step  \u4f7f\u7528TensorFlow\u65f6\uff0c\u8fd9\u4e2a\u64cd\u4f5c\u5927\u6982\u53ea\u8981\u51e0\u79d2\u3002  \u7136\u540e\u6211\u4eec\u53ef\u4ee5\u63d0\u53d6\u51fa\u7ed3\u679c\uff0c\u5e76\u53ef\u89c6\u5316\uff1a  from scipy.misc import imsave\n\n# util function to convert a tensor into a valid image\ndef deprocess_image(x):\n    # normalize tensor: center on 0., ensure std is 0.1\n    x -= x.mean()\n    x /= (x.std() + 1e-5)\n    x *= 0.1\n\n    # clip to [0, 1]\n    x += 0.5\n    x = np.clip(x, 0, 1)\n\n    # convert to RGB array\n    x *= 255\n    x = x.transpose((1, 2, 0))\n    x = np.clip(x, 0, 255).astype('uint8')\n    return x\n\nimg = input_img_data[0]\nimg = deprocess_image(img)\nimsave('%s_filter_%d.png' % (layer_name, filter_index), img)  \u8fd9\u91cc\u662f\u7b2c5\u5377\u57fa\u5c42\u7b2c0\u4e2a\u6ee4\u6ce2\u5668\u7684\u7ed3\u679c\uff1a", 
            "title": "\u4f7f\u7528Keras\u63a2\u7d22\u5377\u79ef\u7f51\u7edc\u7684\u6ee4\u6ce2\u5668"
        }, 
        {
            "location": "/blog/cnn_see_world/#_2", 
            "text": "\u4e0b\u9762\u6211\u4eec\u7cfb\u7edf\u7684\u53ef\u89c6\u5316\u4e00\u4e0b\u5404\u4e2a\u5c42\u7684\u5404\u4e2a\u6ee4\u6ce2\u5668\u7ed3\u679c\uff0c\u770b\u770bCNN\u662f\u5982\u4f55\u5bf9\u8f93\u5165\u8fdb\u884c\u9010\u5c42\u5206\u89e3\u7684\u3002  \u7b2c\u4e00\u5c42\u7684\u6ee4\u6ce2\u5668\u4e3b\u8981\u5b8c\u6210\u65b9\u5411\u3001\u989c\u8272\u7684\u7f16\u7801\uff0c\u8fd9\u4e9b\u989c\u8272\u548c\u65b9\u5411\u4e0e\u57fa\u672c\u7684\u7eb9\u7406\u7ec4\u5408\uff0c\u9010\u6e10\u751f\u6210\u590d\u6742\u7684\u5f62\u72b6\u3002  \u53ef\u4ee5\u5c06\u6bcf\u5c42\u7684\u6ee4\u6ce2\u5668\u60f3\u4e3a\u57fa\u5411\u91cf\uff0c\u8fd9\u4e9b\u57fa\u5411\u91cf\u4e00\u822c\u662f\u8fc7\u5b8c\u5907\u7684\u3002\u57fa\u5411\u91cf\u53ef\u4ee5\u5c06\u5c42\u7684\u8f93\u5165\u7d27\u51d1\u7684\u7f16\u7801\u51fa\u6765\u3002\u6ee4\u6ce2\u5668\u968f\u7740\u5176\u5229\u7528\u7684\u7a7a\u57df\u4fe1\u606f\u7684\u62d3\u5bbd\u800c\u66f4\u52a0\u7cbe\u7ec6\u548c\u590d\u6742\uff0c   \u53ef\u4ee5\u89c2\u5bdf\u5230\uff0c\u5f88\u591a\u6ee4\u6ce2\u5668\u7684\u5185\u5bb9\u5176\u5b9e\u662f\u4e00\u6837\u7684\uff0c\u53ea\u4e0d\u8fc7\u65cb\u8f6c\u4e86\u4e00\u4e2a\u968f\u673a\u7684\u7684\u89d2\u5ea6\uff08\u598290\u5ea6\uff09\u800c\u5df2\u3002\u8fd9\u610f\u5473\u7740\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u4f7f\u5f97\u5377\u79ef\u6ee4\u6ce2\u5668\u5177\u6709\u65cb\u8f6c\u4e0d\u53d8\u6027\u800c\u663e\u8457\u51cf\u5c11\u6ee4\u6ce2\u5668\u7684\u6570\u76ee\uff0c\u8fd9\u662f\u4e00\u4e2a\u6709\u8da3\u7684\u7814\u7a76\u65b9\u5411\u3002  \u4ee4\u4eba\u9707\u60ca\u7684\u662f\uff0c\u8fd9\u79cd\u65cb\u8f6c\u7684\u6027\u8d28\u5728\u9ad8\u5c42\u7684\u6ee4\u6ce2\u5668\u4e2d\u4ecd\u7136\u53ef\u4ee5\u88ab\u89c2\u5bdf\u5230\u3002\u5982Conv4_1", 
            "title": "\u53ef\u89c6\u5316\u6240\u6709\u7684\u6ee4\u6ce2\u5668"
        }, 
        {
            "location": "/blog/cnn_see_world/#deep-dreamnightmare", 
            "text": "\u53e6\u4e00\u4e2a\u6709\u8da3\u7684\u4e8b\u513f\u662f\uff0c\u5982\u679c\u6211\u4eec\u628a\u521a\u624d\u7684\u968f\u673a\u566a\u58f0\u56fe\u7247\u66ff\u6362\u4e3a\u6709\u610f\u4e49\u7684\u7167\u7247\uff0c\u7ed3\u679c\u5c31\u53d8\u7684\u66f4\u597d\u73a9\u4e86\u3002\u8fd9\u5c31\u662f\u53bb\u5e74\u7531Google\u63d0\u51fa\u7684Deep Dream\u3002\u901a\u8fc7\u9009\u62e9\u7279\u5b9a\u7684\u6ee4\u6ce2\u5668\u7ec4\u5408\uff0c\u6211\u4eec\u53ef\u4ee5\u83b7\u5f97\u4e00\u4e9b\u5f88\u6709\u610f\u601d\u7684\u7ed3\u679c\u3002\u5982\u679c\u4f60\u5bf9\u6b64\u611f\u5174\u8da3\uff0c\u53ef\u4ee5\u53c2\u8003Keras\u7684\u4f8b\u5b50 Deep Dream \u548cGoogle\u7684\u535a\u5ba2 Google blog post \uff08\u5899\uff09", 
            "title": "Deep Dream\uff08nightmare\uff09"
        }, 
        {
            "location": "/blog/cnn_see_world/#_3", 
            "text": "\u5982\u679c\u6211\u4eec\u6dfb\u52a0\u4e0aVGG\u7684\u5168\u8fde\u63a5\u5c42\uff0c\u7136\u540e\u8bd5\u56fe\u6700\u5927\u5316\u67d0\u4e2a\u6307\u5b9a\u7c7b\u522b\u7684\u6fc0\u6d3b\u503c\u5462\uff1f\u4f60\u4f1a\u5f97\u5230\u4e00\u5f20\u5f88\u50cf\u8be5\u7c7b\u522b\u7684\u56fe\u7247\u5417\uff1f\u8ba9\u6211\u4eec\u8bd5\u8bd5\u3002  \u8fd9\u79cd\u60c5\u51b5\u4e0b\u6211\u4eec\u7684\u635f\u5931\u51fd\u6570\u957f\u8fd9\u6837\uff1a  layer_output = model.layers[-1].get_output()\nloss = K.mean(layer_output[:, output_index])  \u6bd4\u65b9\u8bf4\u6211\u4eec\u6765\u6700\u5927\u5316\u8f93\u51fa\u4e0b\u6807\u4e3a65\u7684\u90a3\u4e2a\u7c7b\uff0c\u5728ImageNet\u91cc\uff0c\u8fd9\u4e2a\u7c7b\u662f\u86c7\u3002\u5f88\u5feb\uff0c\u6211\u4eec\u7684\u635f\u5931\u8fbe\u5230\u4e860.999\uff0c\u5373\u795e\u7ecf\u7f51\u7edc\u670999.9%\u7684\u6982\u7387\u8ba4\u4e3a\u6211\u4eec\u751f\u6210\u7684\u56fe\u7247\u662f\u4e00\u6761\u6d77\u86c7\uff0c\u5b83\u957f\u8fd9\u6837\uff1a   \u4e0d\u592a\u50cf\u5440\uff0c\u6362\u4e2a\u7c7b\u522b\u8bd5\u8bd5\uff0c\u8fd9\u6b21\u9009\u559c\u9e4a\u7c7b\uff08\u7b2c18\u7c7b\uff09   OK\uff0c\u6211\u4eec\u7684\u7f51\u7edc\u8ba4\u4e3a\u662f\u559c\u9e4a\u7684\u4e1c\u897f\u770b\u8d77\u6765\u5b8c\u5168\u4e0d\u662f\u559c\u9e4a\uff0c\u5f80\u597d\u4e86\u8bf4\uff0c\u8fd9\u4e2a\u56fe\u91cc\u8ddf\u559c\u9e4a\u76f8\u4f3c\u7684\uff0c\u4e5f\u4e0d\u8fc7\u5c31\u662f\u4e00\u4e9b\u5c40\u90e8\u7684\u7eb9\u7406\uff0c\u5982\u7fbd\u6bdb\uff0c\u5634\u5df4\u4e4b\u7c7b\u7684\u3002\u90a3\u4e48\uff0c\u8fd9\u5c31\u610f\u5473\u7740\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u662f\u4e2a\u5f88\u5dee\u7684\u5de5\u5177\u5417\uff1f\u5f53\u7136\u4e0d\u662f\uff0c\u6211\u4eec\u6309\u7167\u4e00\u4e2a\u7279\u5b9a\u4efb\u52a1\u6765\u8bad\u7ec3\u5b83\uff0c\u5b83\u5c31\u4f1a\u5728\u90a3\u4e2a\u4efb\u52a1\u4e0a\u8868\u73b0\u7684\u4e0d\u9519\u3002\u4f46\u6211\u4eec\u4e0d\u80fd\u6709\u7f51\u7edc\u201c\u7406\u89e3\u201d\u67d0\u4e2a\u6982\u5ff5\u7684\u9519\u89c9\u3002\u6211\u4eec\u4e0d\u80fd\u5c06\u7f51\u7edc\u4eba\u683c\u5316\uff0c\u5b83\u53ea\u662f\u5de5\u5177\u800c\u5df2\u3002\u6bd4\u5982\u4e00\u6761\u72d7\uff0c\u5b83\u80fd\u8bc6\u522b\u5176\u4e3a\u72d7\u53ea\u662f\u56e0\u4e3a\u5b83\u80fd\u4ee5\u5f88\u9ad8\u7684\u6982\u7387\u5c06\u5176\u6b63\u786e\u5206\u7c7b\u800c\u5df2\uff0c\u800c\u4e0d\u4ee3\u8868\u5b83\u7406\u89e3\u5173\u4e8e\u201c\u72d7\u201d\u7684\u4efb\u4f55\u5916\u5ef6\u3002", 
            "title": "\u611a\u5f04\u795e\u7ecf\u7f51\u7edc"
        }, 
        {
            "location": "/blog/cnn_see_world/#_4", 
            "text": "\u6240\u4ee5\uff0c\u795e\u7ecf\u7f51\u7edc\u5230\u5e95\u7406\u89e3\u4e86\u4ec0\u4e48\u5462\uff1f\u6211\u8ba4\u4e3a\u6709\u4e24\u4ef6\u4e8b\u662f\u5b83\u4eec\u7406\u89e3\u7684\u3002  \u5176\u4e00\uff0c\u795e\u7ecf\u7f51\u7edc\u7406\u89e3\u4e86\u5982\u4f55\u5c06\u8f93\u5165\u7a7a\u95f4\u89e3\u8026\u4e3a\u5206\u5c42\u6b21\u7684\u5377\u79ef\u6ee4\u6ce2\u5668\u7ec4\u3002\u5176\u4e8c\uff0c\u795e\u7ecf\u7f51\u7edc\u7406\u89e3\u4e86\u4ece\u4e00\u7cfb\u5217\u6ee4\u6ce2\u5668\u7684\u7ec4\u5408\u5230\u4e00\u7cfb\u5217\u7279\u5b9a\u6807\u7b7e\u7684\u6982\u7387\u6620\u5c04\u3002\u795e\u7ecf\u7f51\u7edc\u5b66\u4e60\u5230\u7684\u4e1c\u897f\u5b8c\u5168\u8fbe\u4e0d\u5230\u4eba\u7c7b\u7684\u201c\u770b\u89c1\u201d\u7684\u610f\u4e49\uff0c\u4ece\u79d1\u5b66\u7684\u7684\u89d2\u5ea6\u8bb2\uff0c\u8fd9\u5f53\u7136\u4e5f\u4e0d\u610f\u5473\u7740\u6211\u4eec\u5df2\u7ecf\u89e3\u51b3\u4e86\u8ba1\u7b97\u673a\u89c6\u89c9\u7684\u95ee\u9898\u3002\u60f3\u5f97\u522b\u592a\u591a\uff0c\u6211\u4eec\u624d\u521a\u521a\u8e29\u4e0a\u8ba1\u7b97\u673a\u89c6\u89c9\u5929\u68af\u7684\u7b2c\u4e00\u6b65\u3002  \u6709\u4e9b\u4eba\u8bf4\uff0c\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u5b66\u4e60\u5230\u7684\u5bf9\u8f93\u5165\u7a7a\u95f4\u7684\u5206\u5c42\u6b21\u89e3\u8026\u6a21\u62df\u4e86\u4eba\u7c7b\u89c6\u89c9\u76ae\u5c42\u7684\u884c\u4e3a\u3002\u8fd9\u79cd\u8bf4\u6cd5\u53ef\u80fd\u5bf9\u4e5f\u53ef\u80fd\u4e0d\u5bf9\uff0c\u4f46\u76ee\u524d\u672a\u77e5\u6211\u4eec\u8fd8\u6ca1\u6709\u6bd4\u8f83\u5f3a\u7684\u8bc1\u636e\u6765\u627f\u8ba4\u6216\u5426\u8ba4\u5b83\u3002\u5f53\u7136\uff0c\u6709\u4e9b\u4eba\u53ef\u4ee5\u671f\u671b\u4eba\u7c7b\u7684\u89c6\u89c9\u76ae\u5c42\u5c31\u662f\u4ee5\u7c7b\u4f3c\u7684\u65b9\u5f0f\u5b66\u4e1c\u897f\u7684\uff0c\u67d0\u79cd\u7a0b\u5ea6\u4e0a\u8bb2\uff0c\u8fd9\u662f\u5bf9\u6211\u4eec\u89c6\u89c9\u4e16\u754c\u7684\u81ea\u7136\u89e3\u8026\uff08\u5c31\u50cf\u5085\u91cc\u53f6\u53d8\u6362\u662f\u5bf9\u5468\u671f\u58f0\u97f3\u4fe1\u53f7\u7684\u4e00\u79cd\u89e3\u8026\u4e00\u6837\u81ea\u7136\uff09\u3010\u8bd1\u6ce8\uff1a\u8fd9\u91cc\u662f\u8bf4\uff0c\u5c31\u50cf\u58f0\u97f3\u4fe1\u53f7\u7684\u5085\u91cc\u53f6\u53d8\u6362\u8868\u8fbe\u4e86\u4e0d\u540c\u9891\u7387\u7684\u58f0\u97f3\u4fe1\u53f7\u8fd9\u79cd\u5f88\u81ea\u7136\u5f88\u7269\u7406\u7684\u7406\u89e3\u4e00\u6837\uff0c\u6211\u4eec\u53ef\u80fd\u4f1a\u8ba4\u4e3a\u6211\u4eec\u5bf9\u89c6\u89c9\u4fe1\u606f\u7684\u8bc6\u522b\u5c31\u662f\u5206\u5c42\u6765\u5b8c\u6210\u7684\uff0c\u5706\u7684\u662f\u8f6e\u5b50\uff0c\u6709\u56db\u4e2a\u8f6e\u5b50\u7684\u662f\u6c7d\u8f66\uff0c\u9020\u578b\u70ab\u9177\u7684\u6c7d\u8f66\u662f\u8dd1\u8f66\uff0c\u50cf\u8fd9\u6837\u3011\u3002\u4f46\u662f\uff0c\u4eba\u7c7b\u5bf9\u89c6\u89c9\u4fe1\u53f7\u7684\u6ee4\u6ce2\u3001\u5206\u5c42\u6b21\u3001\u5904\u7406\u7684\u672c\u8d28\u5f88\u53ef\u80fd\u548c\u6211\u4eec\u5f31\u9e21\u7684\u5377\u79ef\u7f51\u7edc\u5b8c\u5168\u4e0d\u662f\u4e00\u56de\u4e8b\u3002\u89c6\u89c9\u76ae\u5c42\u4e0d\u662f\u5377\u79ef\u7684\uff0c\u5c3d\u7ba1\u5b83\u4eec\u4e5f\u5206\u5c42\uff0c\u4f46\u90a3\u4e9b\u5c42\u5177\u6709\u76ae\u8d28\u5217\u7684\u7ed3\u6784\uff0c\u800c\u8fd9\u4e9b\u7ed3\u6784\u7684\u771f\u6b63\u76ee\u7684\u76ee\u524d\u8fd8\u4e0d\u5f97\u800c\u77e5\uff0c\u8fd9\u79cd\u7ed3\u6784\u5728\u6211\u4eec\u7684\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\u4e2d\u8fd8\u6ca1\u6709\u51fa\u73b0\uff08\u5c3d\u7ba1\u4e54\u5927\u5e1dGeoff Hinton\u6b63\u5728\u5728\u8fd9\u4e2a\u65b9\u9762\u52aa\u529b\uff09\u3002\u6b64\u5916\uff0c\u4eba\u7c7b\u6709\u6bd4\u7ed9\u9759\u6001\u56fe\u50cf\u5206\u7c7b\u7684\u611f\u77e5\u5668\u591a\u5f97\u591a\u7684\u89c6\u89c9\u611f\u77e5\u5668\uff0c\u8fd9\u4e9b\u611f\u77e5\u5668\u662f\u8fde\u7eed\u800c\u4e3b\u52a8\u7684\uff0c\u4e0d\u662f\u9759\u6001\u800c\u88ab\u52a8\u7684\uff0c\u8fd9\u4e9b\u611f\u53d7\u5668\u8fd8\u88ab\u5982\u773c\u52a8\u7b49\u591a\u79cd\u673a\u5236\u590d\u6742\u63a7\u5236\u3002  \u4e0b\u6b21\u6709\u98ce\u6295\u6216\u67d0\u77e5\u540dCEO\u8b66\u544a\u4f60\u8981\u8b66\u60d5\u6211\u4eec\u6df1\u5ea6\u5b66\u4e60\u7684\u5a01\u80c1\u65f6\uff0c\u60f3\u60f3\u4e0a\u9762\u8bf4\u7684\u5427\u3002\u4eca\u5929\u6211\u4eec\u662f\u6709\u66f4\u597d\u7684\u5de5\u5177\u6765\u5904\u7406\u590d\u6742\u7684\u4fe1\u606f\u4e86\uff0c\u8fd9\u5f88\u9177\uff0c\u4f46\u5f52\u6839\u7ed3\u5e95\u5b83\u4eec\u53ea\u662f\u5de5\u5177\uff0c\u800c\u4e0d\u662f\u751f\u7269\u3002\u5b83\u4eec\u505a\u7684\u4efb\u4f55\u5de5\u4f5c\u5728\u54ea\u4e2a\u5b87\u5b99\u7684\u6807\u51c6\u4e0b\u90fd\u4e0d\u591f\u683c\u79f0\u4e4b\u4e3a\u201c\u601d\u8003\u201d\u3002\u5728\u4e00\u4e2a\u77f3\u5934\u4e0a\u753b\u4e00\u4e2a\u7b11\u8138\u5e76\u4e0d\u4f1a\u4f7f\u77f3\u5934\u53d8\u5f97\u201c\u5f00\u5fc3\u201d\uff0c\u5c3d\u7ba1\u4f60\u7684\u7075\u957f\u76ee\u76ae\u8d28\u4f1a\u544a\u8bc9\u4f60\u5b83\u5f88\u5f00\u5fc3\u3002  \u603b\u800c\u8a00\u4e4b\uff0c\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7684\u53ef\u89c6\u5316\u5de5\u4f5c\u662f\u5f88\u8ba9\u4eba\u7740\u8ff7\u7684\uff0c\u8c01\u80fd\u60f3\u5230\u4ec5\u4ec5\u901a\u8fc7\u7b80\u5355\u7684\u68af\u5ea6\u4e0b\u964d\u6cd5\u548c\u5408\u7406\u7684\u635f\u5931\u51fd\u6570\uff0c\u52a0\u4e0a\u5927\u89c4\u6a21\u7684\u6570\u636e\u5e93\uff0c\u5c31\u80fd\u5b66\u5230\u80fd\u5f88\u597d\u89e3\u91ca\u590d\u6742\u89c6\u89c9\u4fe1\u606f\u7684\u5982\u6b64\u6f02\u4eae\u7684\u5206\u5c42\u6a21\u578b\u5462\u3002\u6df1\u5ea6\u5b66\u4e60\u6216\u8bb8\u5728\u5b9e\u9645\u7684\u610f\u4e49\u4e0a\u5e76\u4e0d\u667a\u80fd\uff0c\u4f46\u5b83\u4ecd\u7136\u80fd\u591f\u8fbe\u5230\u51e0\u5e74\u524d\u4efb\u4f55\u4eba\u90fd\u65e0\u6cd5\u8fbe\u5230\u7684\u6548\u679c\u3002\u73b0\u5728\uff0c\u5982\u679c\u6211\u4eec\u80fd\u7406\u89e3\u4e3a\u4ec0\u4e48\u6df1\u5ea6\u5b66\u4e60\u5982\u6b64\u6709\u6548\uff0c\u90a3\u2026\u2026\u563f\u563f:)  @fchollet, 2016\u5e741\u6708", 
            "title": "\u9769\u547d\u5c1a\u672a\u6210\u529f\uff0c\u540c\u5fd7\u4ecd\u9700\u52aa\u529b"
        }, 
        {
            "location": "/blog/autoencoder/", 
            "text": "\u81ea\u52a8\u7f16\u7801\u5668\uff1a\u5404\u79cd\u5404\u6837\u7684\u81ea\u52a8\u7f16\u7801\u5668\n\n\n\u6587\u7ae0\u4fe1\u606f\n\n\n\u672c\u6587\u5730\u5740\uff1a\nhttp://blog.keras.io/building-autoencoders-in-keras.html\n\n\n\u672c\u6587\u4f5c\u8005\uff1aFrancois Chollet\n\n\n\n\u4ec0\u4e48\u662f\u81ea\u52a8\u7f16\u7801\u5668\uff08Autoencoder\uff09\n\n\n\n\n\u81ea\u52a8\u7f16\u7801\u5668\u662f\u4e00\u79cd\u6570\u636e\u7684\u538b\u7f29\u7b97\u6cd5\uff0c\u5176\u4e2d\u6570\u636e\u7684\u538b\u7f29\u548c\u89e3\u538b\u7f29\u51fd\u6570\u662f1\uff09\u6570\u636e\u76f8\u5173\u7684,2\uff09\u6709\u635f\u7684\uff0c3\uff09\u4ece\u6837\u672c\u4e2d\u81ea\u52a8\u5b66\u4e60\u7684\u3002\u5728\u5927\u90e8\u5206\u63d0\u5230\u81ea\u52a8\u7f16\u7801\u5668\u7684\u573a\u5408\uff0c\u538b\u7f29\u548c\u89e3\u538b\u7f29\u7684\u51fd\u6570\u662f\u901a\u8fc7\u795e\u7ecf\u7f51\u7edc\u5b9e\u73b0\u7684\u3002\n\n\n1\uff09\u81ea\u52a8\u7f16\u7801\u5668\u662f\u6570\u636e\u76f8\u5173\u7684\uff08data-specific \u6216 data-dependent\uff09\uff0c\u8fd9\u610f\u5473\u7740\u81ea\u52a8\u7f16\u7801\u5668\u53ea\u80fd\u538b\u7f29\u90a3\u4e9b\u4e0e\u8bad\u7ec3\u6570\u636e\u7c7b\u4f3c\u7684\u6570\u636e\u3002\u81ea\u7f16\u7801\u5668\u4e0e\u4e00\u822c\u7684\u538b\u7f29\u7b97\u6cd5\uff0c\u5982MPEG-2\uff0cMP3\u7b49\u538b\u7f29\u7b97\u6cd5\u4e0d\u540c\uff0c\u4e00\u822c\u7684\u901a\u7528\u7b97\u6cd5\u53ea\u5047\u8bbe\u4e86\u6570\u636e\u662f\u201c\u56fe\u50cf\u201d\u6216\u201c\u58f0\u97f3\u201d\uff0c\u800c\u6ca1\u6709\u6307\u5b9a\u662f\u54ea\u79cd\u56fe\u50cf\u6216\u58f0\u97f3\u3002\u6bd4\u5982\uff0c\u4f7f\u7528\u4eba\u8138\u8bad\u7ec3\u51fa\u6765\u7684\u81ea\u52a8\u7f16\u7801\u5668\u5728\u538b\u7f29\u522b\u7684\u56fe\u7247\uff0c\u6bd4\u5982\u6811\u6728\u65f6\u6027\u80fd\u5f88\u5dee\uff0c\u56e0\u4e3a\u5b83\u5b66\u4e60\u5230\u7684\u7279\u5f81\u662f\u4e0e\u4eba\u8138\u76f8\u5173\u7684\u3002\n\n\n2\uff09\u81ea\u52a8\u7f16\u7801\u5668\u662f\u6709\u635f\u7684\uff0c\u610f\u601d\u662f\u89e3\u538b\u7f29\u7684\u8f93\u51fa\u4e0e\u539f\u6765\u7684\u8f93\u5165\u76f8\u6bd4\u662f\u9000\u5316\u7684\uff0cMP3\uff0cJPEG\u7b49\u538b\u7f29\u7b97\u6cd5\u4e5f\u662f\u5982\u6b64\u3002\u8fd9\u4e0e\u65e0\u635f\u538b\u7f29\u7b97\u6cd5\u4e0d\u540c\u3002\n\n\n3\uff09\u81ea\u52a8\u7f16\u7801\u5668\u662f\u4ece\u6570\u636e\u6837\u672c\u4e2d\u81ea\u52a8\u5b66\u4e60\u7684\uff0c\u8fd9\u610f\u5473\u7740\u5f88\u5bb9\u6613\u5bf9\u6307\u5b9a\u7c7b\u7684\u8f93\u5165\u8bad\u7ec3\u51fa\u4e00\u79cd\u7279\u5b9a\u7684\u7f16\u7801\u5668\uff0c\u800c\u4e0d\u9700\u8981\u5b8c\u6210\u4efb\u4f55\u65b0\u5de5\u4f5c\u3002\n\n\n\u642d\u5efa\u4e00\u4e2a\u81ea\u52a8\u7f16\u7801\u5668\u9700\u8981\u5b8c\u6210\u4e0b\u9762\u4e09\u6837\u5de5\u4f5c\uff1a\u642d\u5efa\u7f16\u7801\u5668\uff0c\u642d\u5efa\u89e3\u7801\u5668\uff0c\u8bbe\u5b9a\u4e00\u4e2a\u635f\u5931\u51fd\u6570\uff0c\u7528\u4ee5\u8861\u91cf\u7531\u4e8e\u538b\u7f29\u800c\u635f\u5931\u6389\u7684\u4fe1\u606f\u3002\u7f16\u7801\u5668\u548c\u89e3\u7801\u5668\u4e00\u822c\u90fd\u662f\u53c2\u6570\u5316\u7684\u65b9\u7a0b\uff0c\u5e76\u5173\u4e8e\u635f\u5931\u51fd\u6570\u53ef\u5bfc\uff0c\u5178\u578b\u60c5\u51b5\u662f\u4f7f\u7528\u795e\u7ecf\u7f51\u7edc\u3002\u7f16\u7801\u5668\u548c\u89e3\u7801\u5668\u7684\u53c2\u6570\u53ef\u4ee5\u901a\u8fc7\u6700\u5c0f\u5316\u635f\u5931\u51fd\u6570\u800c\u4f18\u5316\uff0c\u4f8b\u5982SGD\u3002\n\n\n\u81ea\u7f16\u7801\u5668\u662f\u4e00\u4e2a\u597d\u7684\u6570\u636e\u538b\u7f29\u7b97\u6cd5\u5417\n\n\n\u901a\u5e38\u60c5\u51b5\u4e0b\uff0c\u4f7f\u7528\u81ea\u7f16\u7801\u5668\u505a\u6570\u636e\u538b\u7f29\uff0c\u6027\u80fd\u5e76\u4e0d\u600e\u4e48\u6837\u3002\u4ee5\u56fe\u7247\u538b\u7f29\u4e3a\u4f8b\uff0c\u60f3\u8981\u8bad\u7ec3\u4e00\u4e2a\u80fd\u548cJPEG\u6027\u80fd\u76f8\u63d0\u5e76\u8bba\u7684\u81ea\u7f16\u7801\u5668\u975e\u5e38\u56f0\u96be\uff0c\u5e76\u4e14\u8981\u8fbe\u5230\u8fd9\u4e2a\u6027\u80fd\uff0c\u4f60\u8fd8\u5fc5\u987b\u8981\u628a\u56fe\u7247\u7684\u7c7b\u578b\u9650\u5b9a\u5728\u5f88\u5c0f\u7684\u4e00\u4e2a\u8303\u56f4\u5185\uff08\u4f8b\u5982JPEG\u4e0d\u600e\u4e48\u884c\u7684\u67d0\u7c7b\u56fe\u7247\uff09\u3002\u81ea\u7f16\u7801\u5668\u4f9d\u8d56\u4e8e\u6570\u636e\u7684\u7279\u6027\u4f7f\u5f97\u5b83\u5728\u9762\u5bf9\u771f\u5b9e\u6570\u636e\u7684\u538b\u7f29\u4e0a\u5e76\u4e0d\u53ef\u884c\uff0c\u4f60\u53ea\u80fd\u5728\u6307\u5b9a\u7c7b\u578b\u7684\u6570\u636e\u4e0a\u83b7\u5f97\u8fd8\u53ef\u4ee5\u7684\u6548\u679c\uff0c\u4f46\u8c01\u77e5\u9053\u672a\u6765\u4f1a\u6709\u5565\u65b0\u9700\u6c42\uff1f\n\n\n\u90a3\u4e48\uff0c\u81ea\u7f16\u7801\u5668\u64c5\u957f\u505a\u4ec0\u4e48\uff1f\n\n\n\u81ea\u7f16\u7801\u5668\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7528\u7684\u5f88\u5c11\uff0c2012\u5e74\u4eba\u4eec\u53d1\u73b0\u5728\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u4e2d\u4f7f\u7528\u81ea\u7f16\u7801\u5668\u505a\u9010\u5c42\u9884\u8bad\u7ec3\u53ef\u4ee5\u8bad\u7ec3\u6df1\u5ea6\u7f51\u7edc\uff0c\u4f46\u5f88\u5feb\u4eba\u4eec\u53d1\u73b0\u826f\u597d\u7684\u521d\u59cb\u5316\u7b56\u7565\u5728\u8bad\u7ec3\u6df1\u5ea6\u7f51\u7edc\u4e0a\u8981\u6bd4\u8d39\u52b2\u7684\u9010\u5c42\u9884\u8bad\u7ec3\u6709\u6548\u5f97\u591a\uff0c2014\u5e74\u51fa\u73b0\u7684Batch Normalization\u6280\u672f\u4f7f\u5f97\u66f4\u6df1\u7684\u7f51\u7edc\u4e5f\u53ef\u4ee5\u88ab\u6709\u6548\u8bad\u7ec3\uff0c\u5230\u4e862015\u5e74\u5e95\uff0c\u901a\u8fc7\u4f7f\u7528\u6b8b\u5dee\u5b66\u4e60\uff08ResNet\uff09\u6211\u4eec\u57fa\u672c\u4e0a\u53ef\u4ee5\u8bad\u7ec3\u4efb\u610f\u6df1\u5ea6\u7684\u795e\u7ecf\u7f51\u7edc\u3002\n\n\n\u76ee\u524d\u81ea\u7f16\u7801\u5668\u7684\u5e94\u7528\u4e3b\u8981\u6709\u4e24\u4e2a\u65b9\u9762\uff0c\u7b2c\u4e00\u662f\u6570\u636e\u53bb\u566a\uff0c\u7b2c\u4e8c\u662f\u4e3a\u8fdb\u884c\u53ef\u89c6\u5316\u800c\u964d\u7ef4\u3002\u914d\u5408\u9002\u5f53\u7684\u7ef4\u5ea6\u548c\u7a00\u758f\u7ea6\u675f\uff0c\u81ea\u7f16\u7801\u5668\u53ef\u4ee5\u5b66\u4e60\u5230\u6bd4PCA\u7b49\u6280\u672f\u66f4\u6709\u610f\u601d\u7684\u6570\u636e\u6295\u5f71\u3002\n\n\n\u5bf9\u4e8e2D\u7684\u6570\u636e\u53ef\u89c6\u5316\uff0c\nt-SNE\n\uff08\u8bfb\u4f5ctee-snee\uff09\u6216\u8bb8\u662f\u76ee\u524d\u6700\u597d\u7684\u7b97\u6cd5\uff0c\u4f46\u901a\u5e38\u8fd8\u662f\u9700\u8981\u539f\u6570\u636e\u7684\u7ef4\u5ea6\u76f8\u5bf9\u4f4e\u4e00\u4e9b\u3002\u6240\u4ee5\uff0c\u53ef\u89c6\u5316\u9ad8\u7ef4\u6570\u636e\u7684\u4e00\u4e2a\u597d\u529e\u6cd5\u662f\u9996\u5148\u4f7f\u7528\u81ea\u7f16\u7801\u5668\u5c06\u7ef4\u5ea6\u964d\u4f4e\u5230\u8f83\u4f4e\u7684\u6c34\u5e73\uff08\u598232\u7ef4\uff09\uff0c\u7136\u540e\u518d\u4f7f\u7528t-SNE\u5c06\u5176\u6295\u5f71\u57282D\u5e73\u9762\u4e0a\u3002Keras\u7248\u672c\u7684t-SNE\u7531Kyle McDonald\u5b9e\u73b0\u4e86\u4e00\u4e0b\uff0c\u653e\u5728\u4e86\n\u8fd9\u91cc\n\uff0c\u53e6\u5916\nscikit-learn\n\u4e5f\u6709\u4e00\u4e2a\u7b80\u5355\u5b9e\u7528\u7684\u5b9e\u73b0\u3002\n\n\n\u81ea\u7f16\u7801\u5668\u6709\u4ec0\u4e48\u5375\u7528\n\n\n\u81ea\u7f16\u7801\u5668\u7684\u51fa\u540d\u6765\u81ea\u4e8e\u7f51\u4e0a\u5f88\u591a\u673a\u5668\u5b66\u4e60\u8bfe\u7a0b\u7684\u4ecb\u7ecd\uff0c\u603b\u800c\u8a00\u4e4b\uff0c\u4e00\u5806\u65b0\u624b\u975e\u5e38\u70ed\u7231\u81ea\u7f16\u7801\u5668\u800c\u4e14\u600e\u4e48\u4e5f\u73a9\u4e0d\u591f\uff0c\u8fd9\u5c31\u662f\u8fd9\u7bc7\u6587\u7ae0\u51fa\u73b0\u7684\u610f\u4e49\u3010\u544a\u8bc9\u4f60\u81ea\u7f16\u7801\u5668\u6709\u4ec0\u4e48\u5375\u7528\u3011\u3002\n\n\n\u81ea\u7f16\u7801\u5668\u5438\u5f15\u4e86\u4e00\u5927\u6279\u7814\u7a76\u548c\u5173\u6ce8\u7684\u4e3b\u8981\u539f\u56e0\u4e4b\u4e00\u662f\u5f88\u957f\u65f6\u95f4\u4e00\u6bb5\u4ee5\u6765\u5b83\u88ab\u8ba4\u4e3a\u662f\u89e3\u51b3\u65e0\u76d1\u7763\u5b66\u4e60\u7684\u53ef\u80fd\u65b9\u6848\uff0c\u5373\u5927\u5bb6\u89c9\u5f97\u81ea\u7f16\u7801\u5668\u53ef\u4ee5\u5728\u6ca1\u6709\u6807\u7b7e\u7684\u65f6\u5019\u5b66\u4e60\u5230\u6570\u636e\u7684\u6709\u7528\u8868\u8fbe\u3002\u518d\u8bf4\u4e00\u6b21\uff0c\u81ea\u7f16\u7801\u5668\u5e76\u4e0d\u662f\u4e00\u4e2a\u771f\u6b63\u7684\u65e0\u76d1\u7763\u5b66\u4e60\u7684\u7b97\u6cd5\uff0c\u800c\u662f\u4e00\u4e2a\u81ea\u76d1\u7763\u7684\u7b97\u6cd5\u3002\u81ea\u76d1\u7763\u5b66\u4e60\u662f\u76d1\u7763\u5b66\u4e60\u7684\u4e00\u4e2a\u5b9e\u4f8b\uff0c\u5176\u6807\u7b7e\u4ea7\u751f\u81ea\u8f93\u5165\u6570\u636e\u3002\u8981\u83b7\u5f97\u4e00\u4e2a\u81ea\u76d1\u7763\u7684\u6a21\u578b\uff0c\u4f60\u9700\u8981\u60f3\u51fa\u4e00\u4e2a\u9760\u8c31\u7684\u76ee\u6807\u8ddf\u4e00\u4e2a\u635f\u5931\u51fd\u6570\uff0c\u95ee\u9898\u6765\u4e86\uff0c\u4ec5\u4ec5\u628a\u76ee\u6807\u8bbe\u5b9a\u4e3a\u91cd\u6784\u8f93\u5165\u53ef\u80fd\u4e0d\u662f\u6b63\u786e\u7684\u9009\u9879\u3002\u57fa\u672c\u4e0a\uff0c\u8981\u6c42\u6a21\u578b\u5728\u50cf\u7d20\u7ea7\u4e0a\u7cbe\u786e\u91cd\u6784\u8f93\u5165\u4e0d\u662f\u673a\u5668\u5b66\u4e60\u7684\u5174\u8da3\u6240\u5728\uff0c\u5b66\u4e60\u5230\u9ad8\u7ea7\u7684\u62bd\u8c61\u7279\u5f81\u624d\u662f\u3002\u4e8b\u5b9e\u4e0a\uff0c\u5f53\u4f60\u7684\u4e3b\u8981\u4efb\u52a1\u662f\u5206\u7c7b\u3001\u5b9a\u4f4d\u4e4b\u7c7b\u7684\u4efb\u52a1\u65f6\uff0c\u90a3\u4e9b\u5bf9\u8fd9\u7c7b\u4efb\u52a1\u800c\u8a00\u7684\u6700\u597d\u7684\u7279\u5f81\u57fa\u672c\u4e0a\u90fd\u662f\u91cd\u6784\u8f93\u5165\u65f6\u7684\u6700\u5dee\u7684\u90a3\u79cd\u7279\u5f81\u3002\n\n\n\u5728\u5e94\u7528\u81ea\u76d1\u7763\u5b66\u4e60\u7684\u89c6\u89c9\u95ee\u9898\u4e2d\uff0c\u53ef\u80fd\u5e94\u7528\u81ea\u7f16\u7801\u5668\u7684\u9886\u57df\u6709\u4f8b\u5982\u62fc\u56fe\uff0c\u7ec6\u8282\u7eb9\u7406\u5339\u914d\uff08\u4ece\u4f4e\u5206\u8fa8\u7387\u7684\u56fe\u50cf\u5757\u4e2d\u5339\u914d\u5176\u9ad8\u5206\u8fa8\u7387\u7684\u5bf9\u5e94\u5757\uff09\u3002\u4e0b\u9762\u8fd9\u7bc7\u6587\u7ae0\u7814\u7a76\u4e86\u62fc\u56fe\u95ee\u9898\uff0c\u5176\u5b9e\u5f88\u6709\u610f\u601d\uff0c\u4e0d\u59a8\u4e00\u8bfb\u3002\nUnsupervised Learning of Visual Representations by Solving Jigsaw Puzzles.\n\u3002\u6b64\u7c7b\u95ee\u9898\u7684\u6a21\u578b\u8f93\u5165\u6709\u4e9b\u5185\u7f6e\u7684\u5047\u8bbe\uff0c\u4f8b\u5982\u201c\u89c6\u89c9\u5757\u6bd4\u50cf\u7d20\u7ea7\u7684\u7ec6\u8282\u66f4\u91cd\u8981\u201d\u8fd9\u6837\u7684\uff0c\u8fd9\u79cd\u5047\u8bbe\u662f\u666e\u901a\u7684\u81ea\u7f16\u7801\u5668\u6ca1\u6709\u7684\u3002\n\n\n\n\n\u4f7f\u7528Keras\u5efa\u7acb\u7b80\u5355\u7684\u81ea\u7f16\u7801\u5668\n\n\n\u9996\u5148\uff0c\u5148\u5efa\u7acb\u4e00\u4e2a\u5168\u8fde\u63a5\u7684\u7f16\u7801\u5668\u548c\u89e3\u7801\u5668\n\n\nfrom keras.layers import Input, Dense\nfrom keras.models import Model\n\n# this is the size of our encoded representations\nencoding_dim = 32  # 32 floats -\n compression of factor 24.5, assuming the input is 784 floats\n\n# this is our input placeholder\ninput_img = Input(shape=(784,))\n# \nencoded\n is the encoded representation of the input\nencoded = Dense(encoding_dim, activation='relu')(input_img)\n# \ndecoded\n is the lossy reconstruction of the input\ndecoded = Dense(784, activation='sigmoid')(encoded)\n\n# this model maps an input to its reconstruction\nautoencoder = Model(input=input_img, output=decoded)\n\n\n\n\n\u5f53\u7136\u6211\u4eec\u53ef\u4ee5\u5355\u72ec\u7684\u4f7f\u7528\u7f16\u7801\u5668\u548c\u89e3\u7801\u5668\uff1a\n\n\n# this model maps an input to its encoded representation\nencoder = Model(input=input_img, output=encoded)\n\n\n\n\n# create a placeholder for an encoded (32-dimensional) input\nencoded_input = Input(shape=(encoding_dim,))\n# retrieve the last layer of the autoencoder model\ndecoder_layer = autoencoder.layers[-1]\n# create the decoder model\ndecoder = Model(input=encoded_input, output=decoder_layer(encoded_input))\n\n\n\n\n\u4e0b\u9762\u6211\u4eec\u8bad\u7ec3\u81ea\u7f16\u7801\u5668\uff0c\u6765\u91cd\u6784MNIST\u4e2d\u7684\u6570\u5b57\uff0c\u8fd9\u91cc\u4f7f\u7528\u9010\u50cf\u7d20\u7684\u4ea4\u53c9\u71b5\u4f5c\u4e3a\u635f\u5931\u51fd\u6570\uff0c\u4f18\u5316\u5668\u4e3aadam\n\n\nautoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n\n\n\n\n\u7136\u540e\u51c6\u5907MNIST\u6570\u636e\uff0c\u5c06\u5176\u5f52\u4e00\u5316\u548c\u5411\u91cf\u5316\uff0c\u7136\u540e\u8bad\u7ec3\uff1a\n\n\nfrom keras.datasets import mnist\nimport numpy as np\n(x_train, _), (x_test, _) = mnist.load_data()\n\nx_train = x_train.astype('float32') / 255.\nx_test = x_test.astype('float32') / 255.\nx_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\nx_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\nprint x_train.shape\nprint x_test.shape\n\nautoencoder.fit(x_train, x_train,\n                nb_epoch=50,\n                batch_size=256,\n                shuffle=True,\n                validation_data=(x_test, x_test))\n\n\n\n\n50\u4e2aepoch\u540e\uff0c\u770b\u8d77\u6765\u6211\u4eec\u7684\u81ea\u7f16\u7801\u5668\u4f18\u5316\u7684\u4e0d\u9519\u4e86\uff0c\u635f\u5931\u662f0.10\uff0c\u6211\u4eec\u53ef\u89c6\u5316\u4e00\u4e0b\u91cd\u6784\u51fa\u6765\u7684\u8f93\u51fa\uff1a\n\n\n# encode and decode some digits\n# note that we take them from the *test* set\n# use Matplotlib (don't ask)\nimport matplotlib.pyplot as plt\n\nencoded_imgs = encoder.predict(x_test)\ndecoded_imgs = decoder.predict(encoded_imgs)\n\n\nn = 10  # how many digits we will display\nplt.figure(figsize=(20, 4))\nfor i in range(n):\n    # display original\n    ax = plt.subplot(2, n, i)\n    plt.imshow(x_test[i].reshape(28, 28))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n\n    # display reconstruction\n    ax = plt.subplot(2, n, i + n)\n    plt.imshow(decoded_imgs[i].reshape(28, 28))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\nplt.show()\n\n\n\n\n\u8fd9\u91cc\u662f\u7ed3\u679c\uff1a\n\n\n\n\n\u7a00\u758f\u81ea\u7f16\u7801\u5668\uff1a\u4e3a\u7801\u5b57\u52a0\u4e0a\u7a00\u758f\u6027\u7ea6\u675f\n\n\n\u521a\u521a\u6211\u4eec\u7684\u9690\u5c42\u670932\u4e2a\u795e\u7ecf\u5143\uff0c\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u4e00\u822c\u800c\u8a00\u81ea\u7f16\u7801\u5668\u5b66\u5230\u7684\u662fPCA\u7684\u4e00\u4e2a\u8fd1\u4f3c\uff08PCA\u4e0d\u60f3\u79d1\u666e\u4e86\uff09\u3002\u4f46\u662f\u5982\u679c\u6211\u4eec\u5bf9\u9690\u5c42\u5355\u5143\u65bd\u52a0\u7a00\u758f\u6027\u7ea6\u675f\u7684\u8bdd\uff0c\u4f1a\u5f97\u5230\u66f4\u4e3a\u7d27\u51d1\u7684\u8868\u8fbe\uff0c\u53ea\u6709\u4e00\u5c0f\u90e8\u5206\u795e\u7ecf\u5143\u4f1a\u88ab\u6fc0\u6d3b\u3002\u5728Keras\u4e2d\uff0c\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u6dfb\u52a0\u4e00\u4e2aactivity_regularizer\u8fbe\u5230\u5bf9\u67d0\u5c42\u6fc0\u6d3b\u503c\u8fdb\u884c\u7ea6\u675f\u7684\u76ee\u7684\uff1a\n\n\nfrom keras import regularizers\n\nencoding_dim = 32\n\ninput_img = Input(shape=(784,))\n# add a Dense layer with a L1 activity regularizer\nencoded = Dense(encoding_dim, activation='relu',\n                activity_regularizer=regularizers.activity_l1(10e-5))(input_img)\ndecoded = Dense(784, activation='sigmoid')(encoded)\n\nautoencoder = Model(input=input_img, output=decoded)\n\n\n\n\n\u56e0\u4e3a\u6211\u4eec\u6dfb\u52a0\u4e86\u6b63\u5219\u6027\u7ea6\u675f\uff0c\u6240\u4ee5\u6a21\u578b\u8fc7\u62df\u5408\u7684\u98ce\u9669\u964d\u4f4e\uff0c\u6211\u4eec\u53ef\u4ee5\u8bad\u7ec3\u591a\u51e0\u6b21\uff0c\u8fd9\u6b21\u8bad\u7ec3100\u4e2aepoch\uff0c\u5f97\u5230\u635f\u5931\u4e3a0.11\uff0c\u591a\u51fa\u6765\u76840.01\u57fa\u672c\u4e0a\u662f\u7531\u4e8e\u6b63\u5219\u9879\u9020\u6210\u7684\u3002\u53ef\u89c6\u5316\u7ed3\u679c\u5982\u4e0b\uff1a\n\n\n\n\n\u7ed3\u679c\u4e0a\u6ca1\u6709\u6bdb\u7ebf\u5dee\u522b\uff0c\u533a\u522b\u5728\u4e8e\u7f16\u7801\u51fa\u6765\u7684\u7801\u5b57\u66f4\u52a0\u7a00\u758f\u4e86\u3002\u7a00\u758f\u81ea\u7f16\u7801\u5668\u7684\u572810000\u4e2a\u6d4b\u8bd5\u56fe\u7247\u4e0a\u7684\u7801\u5b57\u5747\u503c\u4e3a3.33\uff0c\u800c\u4e4b\u524d\u7684\u4e3a7.30\n\n\n\u6df1\u5ea6\u81ea\u7f16\u7801\u5668\uff1a\u628a\u81ea\u7f16\u7801\u5668\u53e0\u8d77\u6765\n\n\n\u628a\u591a\u4e2a\u81ea\u7f16\u7801\u5668\u53e0\u8d77\u6765\uff0c\u50cf\u8fd9\u6837\uff1a\n\n\ninput_img = Input(shape=(784,))\nencoded = Dense(128, activation='relu')(input_img)\nencoded = Dense(64, activation='relu')(encoded)\nencoded = Dense(32, activation='relu')(encoded)\n\ndecoded = Dense(64, activation='relu')(encoded)\ndecoded = Dense(128, activation='relu')(decoded)\ndecoded = Dense(784, activation='sigmoid')(decoded)\n\nautoencoder = Model(input=input_img, output=decoded)\nautoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n\nautoencoder.fit(x_train, x_train,\n                nb_epoch=100,\n                batch_size=256,\n                shuffle=True,\n                validation_data=(x_test, x_test))\n\n\n\n\n100\u4e2aepoch\u540e\uff0closs\u5927\u6982\u662f0.097\uff0c\u6bd4\u4e4b\u524d\u7684\u6a21\u578b\u597d\u90a3\u4e48\u4e00\u4e22\u4e22\n\n\n\n\n\u5377\u79ef\u81ea\u7f16\u7801\u5668\uff1a\u7528\u5377\u79ef\u5c42\u642d\u5efa\u81ea\u7f16\u7801\u5668\n\n\n\u5f53\u8f93\u5165\u662f\u56fe\u50cf\u65f6\uff0c\u4f7f\u7528\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u57fa\u672c\u4e0a\u603b\u662f\u6709\u610f\u4e49\u7684\u3002\u5728\u73b0\u5b9e\u4e2d\uff0c\u7528\u4e8e\u5904\u7406\u56fe\u50cf\u7684\u81ea\u52a8\u7f16\u7801\u5668\u51e0\u4e4e\u90fd\u662f\u5377\u79ef\u81ea\u52a8\u7f16\u7801\u5668\u2014\u2014\u53c8\u7b80\u5355\u53c8\u5feb\uff0c\u68d2\u68d2\u54d2\n\n\n\u5377\u79ef\u81ea\u7f16\u7801\u5668\u7684\u7f16\u7801\u5668\u90e8\u5206\u7531\u5377\u79ef\u5c42\u548cMaxPooling\u5c42\u6784\u6210\uff0cMaxPooling\u8d1f\u8d23\u7a7a\u57df\u4e0b\u91c7\u6837\u3002\u800c\u89e3\u7801\u5668\u7531\u5377\u79ef\u5c42\u548c\u4e0a\u91c7\u6837\u5c42\u6784\u6210\u3002\n\n\nfrom keras.layers import Input, Dense, Convolution2D, MaxPooling2D, UpSampling2D\nfrom keras.models import Model\n\ninput_img = Input(shape=(1, 28, 28))\n\nx = Convolution2D(16, 3, 3, activation='relu', border_mode='same')(input_img)\nx = MaxPooling2D((2, 2), border_mode='same')(x)\nx = Convolution2D(8, 3, 3, activation='relu', border_mode='same')(x)\nx = MaxPooling2D((2, 2), border_mode='same')(x)\nx = Convolution2D(8, 3, 3, activation='relu', border_mode='same')(x)\nencoded = MaxPooling2D((2, 2), border_mode='same')(x)\n\n# at this point the representation is (8, 4, 4) i.e. 128-dimensional\n\nx = Convolution2D(8, 3, 3, activation='relu', border_mode='same')(encoded)\nx = UpSampling2D((2, 2))(x)\nx = Convolution2D(8, 3, 3, activation='relu', border_mode='same')(x)\nx = UpSampling2D((2, 2))(x)\nx = Convolution2D(16, 3, 3, activation='relu')(x)\nx = UpSampling2D((2, 2))(x)\ndecoded = Convolution2D(1, 3, 3, activation='sigmoid', border_mode='same')(x)\n\nautoencoder = Model(input_img, decoded)\nautoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n\n\n\n\n\u6211\u4eec\u4f7f\u752828\n28\n3\u7684\u539f\u59cbMNIST\u56fe\u50cf\uff08\u5c3d\u7ba1\u770b\u8d77\u6765\u8fd8\u662f\u7070\u5ea6\u56fe\uff09\u8bad\u7ec3\u7f51\u7edc\uff0c\u56fe\u7247\u7684\u50cf\u7d20\u88ab\u5f52\u4e00\u5316\u52300~1\u4e4b\u95f4\u3002\n\n\nfrom keras.datasets import mnist\nimport numpy as np\n\n(x_train, _), (x_test, _) = mnist.load_data()\n\nx_train = x_train.astype('float32') / 255.\nx_test = x_test.astype('float32') / 255.\nx_train = np.reshape(x_train, (len(x_train), 1, 28, 28))\nx_test = np.reshape(x_test, (len(x_test), 1, 28, 28))\n\n\n\n\n\u4e3a\u4e86\u53ef\u89c6\u5316\u8bad\u7ec3\u8fc7\u7a0b\u7684\u635f\u5931\u60c5\u51b5\uff0c\u6211\u4eec\u4f7f\u7528TensorFlow\u4f5c\u4e3a\u540e\u7aef\uff0c\u8fd9\u6837\u5c31\u53ef\u4ee5\u542f\u7528TensorBoard\u4e86\u3002\u6253\u5f00\u4e00\u4e2a\u7ec8\u7aef\u5e76\u542f\u52a8TensorBoard\uff0cTensorBoard\u5c06\u8bfb\u53d6\u4f4d\u4e8e/tmp/autoencoder\u7684\u65e5\u5fd7\u6587\u4ef6\uff1a\n\n\ntensorboard --logdir=/tmp/autoencoder\n\n\n\n\n\u7136\u540e\u6211\u4eec\u628a\u6a21\u578b\u8bad\u7ec350\u4e2aepoch\uff0c\u5e76\u5728\u56de\u8c03\u51fd\u6570\u5217\u8868\u4e2d\u4f20\u5165TensorBoard\u56de\u8c03\u51fd\u6570\uff0c\u5728\u6bcf\u4e2aepoch\u540e\u56de\u8c03\u51fd\u6570\u5c06\u628a\u8bad\u7ec3\u7684\u4fe1\u606f\u5199\u5165\u521a\u624d\u7684\u90a3\u4e2a\u65e5\u5fd7\u6587\u4ef6\u91cc\uff0c\u5e76\u88abTensorBoard\u8bfb\u53d6\u5230\n\n\nfrom keras.callbacks import TensorBoard\n\nautoencoder.fit(x_train, x_train,\n                nb_epoch=50,\n                batch_size=128,\n                shuffle=True,\n                validation_data=(x_test, x_test),\n                callbacks=[TensorBoard(log_dir='/tmp/autoencoder')])\n\n\n\n\n\u6253\u5f00\u6d4f\u89c8\u5668\u8fdb\u5165http://0.0.0.0:6006\u89c2\u6d4b\u7ed3\u679c\uff1a\n\n\n\n\n\u6a21\u578b\u6700\u540e\u7684loss\u662f0.094\uff0c\u8981\u6bd4\u4e4b\u524d\u7684\u6a21\u578b\u90fd\u8981\u597d\u5f97\u591a\uff0c\u56e0\u4e3a\u73b0\u5728\u6211\u4eec\u7684\u7f16\u7801\u5668\u7684\u8868\u8fbe\u8868\u8fbe\u80fd\u529b\u66f4\u5f3a\u4e86\u3002\n\n\ndecoded_imgs = autoencoder.predict(x_test)\n\nn = 10\nplt.figure(figsize=(20, 4))\nfor i in range(n):\n    # display original\n    ax = plt.subplot(2, n, i)\n    plt.imshow(x_test[i].reshape(28, 28))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n\n    # display reconstruction\n    ax = plt.subplot(2, n, i + n)\n    plt.imshow(decoded_imgs[i].reshape(28, 28))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\nplt.show()\n\n\n\n\n\n\n\u6211\u4eec\u4e5f\u53ef\u4ee5\u770b\u770b\u4e2d\u95f4\u7684\u7801\u5b57\u957f\u4ec0\u4e48\u6837\uff0c\u8fd9\u4e9b\u7801\u5b57\u7684shape\u662f8\n4\n4\uff0c\u6211\u4eec\u53ef\u4ee5\u5c06\u5176reshape\u62104*32\u770b\n\n\nn = 10\nplt.figure(figsize=(20, 8))\nfor i in range(n):\n    ax = plt.subplot(1, n, i)\n    plt.imshow(encoded_imgs[i].reshape(4, 4 * 8).T)\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\nplt.show()\n\n\n\n\n\n\n\u4f7f\u7528\u81ea\u52a8\u7f16\u7801\u5668\u8fdb\u884c\u56fe\u50cf\u53bb\u566a\n\n\n\u6211\u4eec\u628a\u8bad\u7ec3\u6837\u672c\u7528\u566a\u58f0\u6c61\u67d3\uff0c\u7136\u540e\u4f7f\u89e3\u7801\u5668\u89e3\u7801\u51fa\u5e72\u51c0\u7684\u7167\u7247\uff0c\u4ee5\u83b7\u5f97\u53bb\u566a\u81ea\u52a8\u7f16\u7801\u5668\u3002\u9996\u5148\u6211\u4eec\u628a\u539f\u56fe\u7247\u52a0\u5165\u9ad8\u65af\u566a\u58f0\uff0c\u7136\u540e\u628a\u50cf\u7d20\u503cclip\u52300~1\n\n\nfrom keras.datasets import mnist\nimport numpy as np\n\n(x_train, _), (x_test, _) = mnist.load_data()\n\nx_train = x_train.astype('float32') / 255.\nx_test = x_test.astype('float32') / 255.\nx_train = np.reshape(x_train, (len(x_train), 1, 28, 28))\nx_test = np.reshape(x_test, (len(x_test), 1, 28, 28))\n\nnoise_factor = 0.5\nx_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape) \nx_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape) \n\nx_train_noisy = np.clip(x_train_noisy, 0., 1.)\nx_test_noisy = np.clip(x_test_noisy, 0., 1.)\n\n\n\n\n\u6211\u4eec\u53ef\u4ee5\u5148\u770b\u770b\u88ab\u6c61\u67d3\u7684\u7167\u7247\u957f\u5565\u6837\uff1a\n\n\n\n\n\u548c\u4e4b\u524d\u7684\u5377\u79ef\u81ea\u52a8\u7f16\u7801\u5668\u76f8\u6bd4\uff0c\u4e3a\u4e86\u63d0\u9ad8\u91cd\u6784\u56fe\u8d28\u91cf\uff0c\u6211\u4eec\u7684\u6a21\u578b\u7a0d\u6709\u4e0d\u540c\n\n\ninput_img = Input(shape=(1, 28, 28))\n\nx = Convolution2D(32, 3, 3, activation='relu', border_mode='same')(input_img)\nx = MaxPooling2D((2, 2), border_mode='same')(x)\nx = Convolution2D(32, 3, 3, activation='relu', border_mode='same')(x)\nencoded = MaxPooling2D((2, 2), border_mode='same')(x)\n\n# at this point the representation is (32, 7, 7)\n\nx = Convolution2D(32, 3, 3, activation='relu', border_mode='same')(encoded)\nx = UpSampling2D((2, 2))(x)\nx = Convolution2D(32, 3, 3, activation='relu', border_mode='same')(x)\nx = UpSampling2D((2, 2))(x)\ndecoded = Convolution2D(1, 3, 3, activation='sigmoid', border_mode='same')(x)\n\nautoencoder = Model(input_img, decoded)\nautoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n\n\n\n\n\u5148\u6765100\u4e2aepoch\u7684\u8bad\u7ec3\u770b\u770b\u7ed3\u679c\n\n\nautoencoder.fit(x_train_noisy, x_train,\n                nb_epoch=100,\n                batch_size=128,\n                shuffle=True,\n                validation_data=(x_test_noisy, x_test),\n                callbacks=[TensorBoard(log_dir='/tmp/tb', histogram_freq=0, write_graph=False)])\n\n\n\n\n\u7ed3\u679c\u5982\u4e0b\uff0c\u68d2\u68d2\u54d2~\n\n\n\n\n\u5982\u679c\u4f60\u5c06\u8fd9\u4e2a\u8fc7\u7a0b\u6269\u5c55\u5230\u66f4\u5927\u7684\u5377\u79ef\u7f51\u7edc\uff0c\u4f60\u53ef\u4ee5\u5904\u7406\u6587\u6863\u548c\u58f0\u97f3\u7684\u53bb\u566a\uff0cKaggle\u6709\u4e00\u4e2a\u6216\u8bb8\u4f60\u4f1a\u611f\u5174\u8da3\u7684\u6570\u636e\u96c6\u5728\n\u8fd9\u91cc\n\n\n\u5e8f\u5217\u5230\u5e8f\u5217\u7684\u81ea\u52a8\u7f16\u7801\u5668\n\n\n\u5982\u679c\u4f60\u7684\u8f93\u5165\u662f\u5e8f\u5217\u800c\u4e0d\u662f2D\u7684\u56fe\u50cf\uff0c\u90a3\u4e48\u4f60\u53ef\u80fd\u60f3\u8981\u4f7f\u7528\u9488\u5bf9\u5e8f\u5217\u7684\u6a21\u578b\u6784\u9020\u81ea\u7f16\u7801\u5668\uff0c\u5982LSTM\u3002\u8981\u6784\u9020\u57fa\u4e8eLSTM\u7684\u81ea\u7f16\u7801\u5668\uff0c\u9996\u5148\u6211\u4eec\u9700\u8981\u4e00\u4e2aLSTM\u7684\u7f16\u7801\u5668\u6765\u5c06\u8f93\u5165\u5e8f\u5217\u53d8\u4e3a\u4e00\u4e2a\u5411\u91cf\uff0c\u7136\u540e\u5c06\u8fd9\u4e2a\u5411\u91cf\u91cd\u590dN\u6b64\uff0c\u7136\u540e\u7528LSTM\u7684\u89e3\u7801\u5668\u5c06\u8fd9\u4e2aN\u6b65\u7684\u65f6\u95f4\u5e8f\u5217\u53d8\u4e3a\u76ee\u6807\u5e8f\u5217\u3002\n\n\n\u8fd9\u91cc\u6211\u4eec\u4e0d\u9488\u5bf9\u4efb\u4f55\u7279\u5b9a\u7684\u6570\u636e\u5e93\u505a\u8fd9\u4ef6\u4e8b\uff0c\u53ea\u63d0\u4f9b\u4ee3\u7801\u4f9b\u8bfb\u8005\u53c2\u8003\n\n\nfrom keras.layers import Input, LSTM, RepeatVector\nfrom keras.models import Model\n\ninputs = Input(shape=(timesteps, input_dim))\nencoded = LSTM(latent_dim)(inputs)\n\ndecoded = RepeatVector(timesteps)(encoded)\ndecoded = LSTM(input, return_sequences=True)(decoded)\n\nsequence_autoencoder = Model(inputs, decoded)\nencoder = Model(inputs, encoded)\n\n\n\n\n\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff08Variational autoencoder\uff0cVAE\uff09\uff1a\u7f16\u7801\u6570\u636e\u7684\u5206\u5e03\n\n\n\u7f16\u7801\u81ea\u7f16\u7801\u5668\u662f\u66f4\u73b0\u4ee3\u548c\u6709\u8da3\u7684\u4e00\u79cd\u81ea\u52a8\u7f16\u7801\u5668\uff0c\u5b83\u4e3a\u7801\u5b57\u65bd\u52a0\u7ea6\u675f\uff0c\u4f7f\u5f97\u7f16\u7801\u5668\u5b66\u4e60\u5230\u8f93\u5165\u6570\u636e\u7684\u9690\u53d8\u91cf\u6a21\u578b\u3002\u9690\u53d8\u91cf\u6a21\u578b\u662f\u8fde\u63a5\u663e\u53d8\u91cf\u96c6\u548c\u9690\u53d8\u91cf\u96c6\u7684\u7edf\u8ba1\u6a21\u578b\uff0c\u9690\u53d8\u91cf\u6a21\u578b\u7684\u5047\u8bbe\u662f\u663e\u53d8\u91cf\u662f\u7531\u9690\u53d8\u91cf\u7684\u72b6\u6001\u63a7\u5236\u7684\uff0c\u5404\u4e2a\u663e\u53d8\u91cf\u4e4b\u95f4\u6761\u4ef6\u72ec\u7acb\u3002\u4e5f\u5c31\u662f\u8bf4\uff0c\u53d8\u5206\u7f16\u7801\u5668\u4e0d\u518d\u5b66\u4e60\u4e00\u4e2a\u4efb\u610f\u7684\u51fd\u6570\uff0c\u800c\u662f\u5b66\u4e60\u4f60\u7684\u6570\u636e\u6982\u7387\u5206\u5e03\u7684\u4e00\u7ec4\u53c2\u6570\u3002\u901a\u8fc7\u5728\u8fd9\u4e2a\u6982\u7387\u5206\u5e03\u4e2d\u91c7\u6837\uff0c\u4f60\u53ef\u4ee5\u751f\u6210\u65b0\u7684\u8f93\u5165\u6570\u636e\uff0c\u5373\u53d8\u5206\u7f16\u7801\u5668\u662f\u4e00\u4e2a\u751f\u6210\u6a21\u578b\u3002\n\n\n\u4e0b\u9762\u662f\u53d8\u5206\u7f16\u7801\u5668\u7684\u5de5\u4f5c\u539f\u7406\uff1a\n\n\n\u9996\u5148\uff0c\u7f16\u7801\u5668\u7f51\u7edc\u5c06\u8f93\u5165\u6837\u672cx\u8f6c\u6362\u4e3a\u9690\u7a7a\u95f4\u7684\u4e24\u4e2a\u53c2\u6570\uff0c\u8bb0\u4f5cz_mean\u548cz_log_sigma\u3002\u7136\u540e\uff0c\u6211\u4eec\u968f\u673a\u4ece\u9690\u85cf\u7684\u6b63\u6001\u5206\u5e03\u4e2d\u91c7\u6837\u5f97\u5230\u6570\u636e\u70b9z\uff0c\u8fd9\u4e2a\u9690\u85cf\u5206\u5e03\u6211\u4eec\u5047\u8bbe\u5c31\u662f\u4ea7\u751f\u8f93\u5165\u6570\u636e\u7684\u90a3\u4e2a\u5206\u5e03\u3002z = z_mean + exp(z_log_sigma)*epsilon\uff0cepsilon\u662f\u4e00\u4e2a\u670d\u4ece\u6b63\u6001\u5206\u5e03\u7684\u5f20\u91cf\u3002\u6700\u540e\uff0c\u4f7f\u7528\u89e3\u7801\u5668\u7f51\u7edc\u5c06\u9690\u7a7a\u95f4\u6620\u5c04\u5230\u663e\u7a7a\u95f4\uff0c\u5373\u5c06z\u8f6c\u6362\u56de\u539f\u6765\u7684\u8f93\u5165\u6570\u636e\u7a7a\u95f4\u3002\n\n\n\u53c2\u6570\u85c9\u7531\u4e24\u4e2a\u635f\u5931\u51fd\u6570\u6765\u8bad\u7ec3\uff0c\u4e00\u4e2a\u662f\u91cd\u6784\u635f\u5931\u51fd\u6570\uff0c\u8be5\u51fd\u6570\u8981\u6c42\u89e3\u7801\u51fa\u6765\u7684\u6837\u672c\u4e0e\u8f93\u5165\u7684\u6837\u672c\u76f8\u4f3c\uff08\u4e0e\u4e4b\u524d\u7684\u81ea\u7f16\u7801\u5668\u76f8\u540c\uff09\uff0c\u7b2c\u4e8c\u9879\u635f\u5931\u51fd\u6570\u662f\u5b66\u4e60\u5230\u7684\u9690\u5206\u5e03\u4e0e\u5148\u9a8c\u5206\u5e03\u7684KL\u8ddd\u79bb\uff0c\u4f5c\u4e3a\u4e00\u4e2a\u6b63\u5219\u3002\u5b9e\u9645\u4e0a\u628a\u540e\u9762\u8fd9\u9879\u635f\u5931\u51fd\u6570\u53bb\u6389\u4e5f\u53ef\u4ee5\uff0c\u5c3d\u7ba1\u5b83\u5bf9\u5b66\u4e60\u7b26\u5408\u8981\u6c42\u7684\u9690\u7a7a\u95f4\u548c\u9632\u6b62\u8fc7\u62df\u5408\u6709\u5e2e\u52a9\u3002\n\n\n\u56e0\u4e3aVAE\u662f\u4e00\u4e2a\u5f88\u590d\u6742\u7684\u4f8b\u5b50\uff0c\u6211\u4eec\u628aVAE\u7684\u4ee3\u7801\u653e\u5728\u4e86github\u4e0a\uff0c\u5728\n\u8fd9\u91cc\n\u3002\u5728\u8fd9\u91cc\u6211\u4eec\u6765\u4e00\u6b65\u6b65\u56de\u987e\u4e00\u4e0b\u8fd9\u4e2a\u6a21\u578b\u662f\u5982\u4f55\u642d\u5efa\u7684\n\n\n\u9996\u5148\uff0c\u5efa\u7acb\u7f16\u7801\u7f51\u7edc\uff0c\u5c06\u8f93\u5165\u5f71\u5c04\u4e3a\u9690\u5206\u5e03\u7684\u53c2\u6570\uff1a\n\n\nx = Input(batch_shape=(batch_size, original_dim))\nh = Dense(intermediate_dim, activation='relu')(x)\nz_mean = Dense(latent_dim)(h)\nz_log_sigma = Dense(latent_dim)(h)\n\n\n\n\n\u7136\u540e\u4ece\u8fd9\u4e9b\u53c2\u6570\u786e\u5b9a\u7684\u5206\u5e03\u4e2d\u91c7\u6837\uff0c\u8fd9\u4e2a\u6837\u672c\u76f8\u5f53\u4e8e\u4e4b\u524d\u7684\u9690\u5c42\u503c\n\n\ndef sampling(args):\n    z_mean, z_log_sigma = args\n    epsilon = K.random_normal(shape=(batch_size, latent_dim),\n                              mean=0., std=epsilon_std)\n    return z_mean + K.exp(z_log_sigma) * epsilon\n\n# note that \noutput_shape\n isn't necessary with the TensorFlow backend\n# so you could write `Lambda(sampling)([z_mean, z_log_sigma])`\nz = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_sigma])\n\n\n\n\n\u6700\u540e\uff0c\u5c06\u91c7\u6837\u5f97\u5230\u7684\u70b9\u6620\u5c04\u56de\u53bb\u91cd\u6784\u539f\u8f93\u5165\uff1a\n\n\ndecoder_h = Dense(intermediate_dim, activation='relu')\ndecoder_mean = Dense(original_dim, activation='sigmoid')\nh_decoded = decoder_h(z)\nx_decoded_mean = decoder_mean(h_decoded)\n\n\n\n\n\u5230\u76ee\u524d\u4e3a\u6b62\u6211\u4eec\u505a\u7684\u5de5\u4f5c\u9700\u8981\u5b9e\u4f8b\u5316\u4e09\u4e2a\u6a21\u578b\uff1a\n\n\n\n\n\n\n\u4e00\u4e2a\u7aef\u5230\u7aef\u7684\u81ea\u52a8\u7f16\u7801\u5668\uff0c\u7528\u4e8e\u5b8c\u6210\u8f93\u5165\u4fe1\u53f7\u7684\u91cd\u6784\n\n\n\n\n\n\n\u4e00\u4e2a\u7528\u4e8e\u5c06\u8f93\u5165\u7a7a\u95f4\u6620\u5c04\u4e3a\u9690\u7a7a\u95f4\u7684\u7f16\u7801\u5668\n\n\n\n\n\n\n\u4e00\u4e2a\u5229\u7528\u9690\u7a7a\u95f4\u7684\u5206\u5e03\u4ea7\u751f\u7684\u6837\u672c\u70b9\u751f\u6210\u5bf9\u5e94\u7684\u91cd\u6784\u6837\u672c\u7684\u751f\u6210\u5668\n\n\n\n\n\n\n# end-to-end autoencoder\nvae = Model(x, x_decoded_mean)\n\n# encoder, from inputs to latent space\nencoder = Model(x, z_mean)\n\n# generator, from latent space to reconstructed inputs\ndecoder_input = Input(shape=(latent_dim,))\n_h_decoded = decoder_h(decoder_input)\n_x_decoded_mean = decoder_mean(_h_decoded)\ngenerator = Model(decoder_input, _x_decoded_mean)\n\n\n\n\n\u6211\u4eec\u4f7f\u7528\u7aef\u5230\u7aef\u7684\u6a21\u578b\u8bad\u7ec3\uff0c\u635f\u5931\u51fd\u6570\u662f\u4e00\u9879\u91cd\u6784\u8bef\u5dee\uff0c\u548c\u4e00\u9879KL\u8ddd\u79bb\n\n\ndef vae_loss(x, x_decoded_mean):\n    xent_loss = objectives.binary_crossentropy(x, x_decoded_mean)\n    kl_loss = - 0.5 * K.mean(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma), axis=-1)\n    return xent_loss + kl_loss\n\nvae.compile(optimizer='rmsprop', loss=vae_loss)\n\n\n\n\n\u73b0\u5728\u4f7f\u7528MNIST\u5e93\u6765\u8bad\u7ec3\u53d8\u5206\u7f16\u7801\u5668\uff1a\n\n\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\nx_train = x_train.astype('float32') / 255.\nx_test = x_test.astype('float32') / 255.\nx_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\nx_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n\nvae.fit(x_train, x_train,\n        shuffle=True,\n        nb_epoch=nb_epoch,\n        batch_size=batch_size,\n        validation_data=(x_test, x_test))\n\n\n\n\n\u56e0\u4e3a\u6211\u4eec\u7684\u9690\u7a7a\u95f4\u53ea\u6709\u4e24\u7ef4\uff0c\u6240\u4ee5\u6211\u4eec\u53ef\u4ee5\u53ef\u89c6\u5316\u4e00\u4e0b\u3002\u6211\u4eec\u6765\u770b\u770b2D\u5e73\u9762\u4e2d\u4e0d\u540c\u7c7b\u7684\u8fd1\u90bb\u5206\u5e03\uff1a\n\n\nx_test_encoded = encoder.predict(x_test, batch_size=batch_size)\nplt.figure(figsize=(6, 6))\nplt.scatter(x_test_encoded[:, 0], x_test_encoded[:, 1], c=y_test)\nplt.colorbar()\nplt.show()\n\n\n\n\n\n\n\u4e0a\u56fe\u6bcf\u79cd\u989c\u8272\u4ee3\u8868\u4e00\u4e2a\u6570\u5b57\uff0c\u76f8\u8fd1\u805a\u7c7b\u7684\u6570\u5b57\u4ee3\u8868\u4ed6\u4eec\u5728\u7ed3\u6784\u4e0a\u76f8\u4f3c\u3002\n\n\n\u56e0\u4e3a\u53d8\u5206\u7f16\u7801\u5668\u662f\u4e00\u4e2a\u751f\u6210\u6a21\u578b\uff0c\u6211\u4eec\u53ef\u4ee5\u7528\u5b83\u6765\u751f\u6210\u65b0\u6570\u5b57\u3002\u6211\u4eec\u53ef\u4ee5\u4ece\u9690\u5e73\u9762\u4e0a\u91c7\u6837\u4e00\u4e9b\u70b9\uff0c\u7136\u540e\u751f\u6210\u5bf9\u5e94\u7684\u663e\u53d8\u91cf\uff0c\u5373MNIST\u7684\u6570\u5b57\uff1a\n\n\n# display a 2D manifold of the digits\nn = 15  # figure with 15x15 digits\ndigit_size = 28\nfigure = np.zeros((digit_size * n, digit_size * n))\n# we will sample n points within [-15, 15] standard deviations\ngrid_x = np.linspace(-15, 15, n)\ngrid_y = np.linspace(-15, 15, n)\n\nfor i, yi in enumerate(grid_x):\n    for j, xi in enumerate(grid_y):\n        z_sample = np.array([[xi, yi]]) * epsilon_std\n        x_decoded = generator.predict(z_sample)\n        digit = x_decoded[0].reshape(digit_size, digit_size)\n        figure[i * digit_size: (i + 1) * digit_size,\n               j * digit_size: (j + 1) * digit_size] = digit\n\nplt.figure(figsize=(10, 10))\nplt.imshow(figure)\nplt.show()\n\n\n\n\n\n\nOK\u8fd9\u5c31\u662f\u672c\u6587\u7684\u5168\u90e8\uff0c\u5982\u679c\u4f60\u89c9\u5f97\u672c\u6587\u8fd8\u53ef\u4ee5\u589e\u52a0\u70b9\u522b\u7684\u4e3b\u9898\uff0c\u53ef\u4ee5\u5728Twitter\u4e0a@fchollet\n\n\n\u53c2\u8003\u6587\u732e\n\n\n\n\n\n\n[1] Why does unsupervised pre-training help deep learning?\n\n\n\n\n\n\n[2] Batch normalization: Accelerating deep network training by reducing internal covariate shift.\n\n\n\n\n\n\n[3] Deep Residual Learning for Image Recognition\n\n\n\n\n\n\n[4] Auto-Encoding Variational Bayes", 
            "title": "\u82b1\u5f0f\u81ea\u52a8\u7f16\u7801\u5668"
        }, 
        {
            "location": "/blog/autoencoder/#_1", 
            "text": "", 
            "title": "\u81ea\u52a8\u7f16\u7801\u5668\uff1a\u5404\u79cd\u5404\u6837\u7684\u81ea\u52a8\u7f16\u7801\u5668"
        }, 
        {
            "location": "/blog/autoencoder/#_2", 
            "text": "\u672c\u6587\u5730\u5740\uff1a http://blog.keras.io/building-autoencoders-in-keras.html  \u672c\u6587\u4f5c\u8005\uff1aFrancois Chollet", 
            "title": "\u6587\u7ae0\u4fe1\u606f"
        }, 
        {
            "location": "/blog/autoencoder/#autoencoder", 
            "text": "\u81ea\u52a8\u7f16\u7801\u5668\u662f\u4e00\u79cd\u6570\u636e\u7684\u538b\u7f29\u7b97\u6cd5\uff0c\u5176\u4e2d\u6570\u636e\u7684\u538b\u7f29\u548c\u89e3\u538b\u7f29\u51fd\u6570\u662f1\uff09\u6570\u636e\u76f8\u5173\u7684,2\uff09\u6709\u635f\u7684\uff0c3\uff09\u4ece\u6837\u672c\u4e2d\u81ea\u52a8\u5b66\u4e60\u7684\u3002\u5728\u5927\u90e8\u5206\u63d0\u5230\u81ea\u52a8\u7f16\u7801\u5668\u7684\u573a\u5408\uff0c\u538b\u7f29\u548c\u89e3\u538b\u7f29\u7684\u51fd\u6570\u662f\u901a\u8fc7\u795e\u7ecf\u7f51\u7edc\u5b9e\u73b0\u7684\u3002  1\uff09\u81ea\u52a8\u7f16\u7801\u5668\u662f\u6570\u636e\u76f8\u5173\u7684\uff08data-specific \u6216 data-dependent\uff09\uff0c\u8fd9\u610f\u5473\u7740\u81ea\u52a8\u7f16\u7801\u5668\u53ea\u80fd\u538b\u7f29\u90a3\u4e9b\u4e0e\u8bad\u7ec3\u6570\u636e\u7c7b\u4f3c\u7684\u6570\u636e\u3002\u81ea\u7f16\u7801\u5668\u4e0e\u4e00\u822c\u7684\u538b\u7f29\u7b97\u6cd5\uff0c\u5982MPEG-2\uff0cMP3\u7b49\u538b\u7f29\u7b97\u6cd5\u4e0d\u540c\uff0c\u4e00\u822c\u7684\u901a\u7528\u7b97\u6cd5\u53ea\u5047\u8bbe\u4e86\u6570\u636e\u662f\u201c\u56fe\u50cf\u201d\u6216\u201c\u58f0\u97f3\u201d\uff0c\u800c\u6ca1\u6709\u6307\u5b9a\u662f\u54ea\u79cd\u56fe\u50cf\u6216\u58f0\u97f3\u3002\u6bd4\u5982\uff0c\u4f7f\u7528\u4eba\u8138\u8bad\u7ec3\u51fa\u6765\u7684\u81ea\u52a8\u7f16\u7801\u5668\u5728\u538b\u7f29\u522b\u7684\u56fe\u7247\uff0c\u6bd4\u5982\u6811\u6728\u65f6\u6027\u80fd\u5f88\u5dee\uff0c\u56e0\u4e3a\u5b83\u5b66\u4e60\u5230\u7684\u7279\u5f81\u662f\u4e0e\u4eba\u8138\u76f8\u5173\u7684\u3002  2\uff09\u81ea\u52a8\u7f16\u7801\u5668\u662f\u6709\u635f\u7684\uff0c\u610f\u601d\u662f\u89e3\u538b\u7f29\u7684\u8f93\u51fa\u4e0e\u539f\u6765\u7684\u8f93\u5165\u76f8\u6bd4\u662f\u9000\u5316\u7684\uff0cMP3\uff0cJPEG\u7b49\u538b\u7f29\u7b97\u6cd5\u4e5f\u662f\u5982\u6b64\u3002\u8fd9\u4e0e\u65e0\u635f\u538b\u7f29\u7b97\u6cd5\u4e0d\u540c\u3002  3\uff09\u81ea\u52a8\u7f16\u7801\u5668\u662f\u4ece\u6570\u636e\u6837\u672c\u4e2d\u81ea\u52a8\u5b66\u4e60\u7684\uff0c\u8fd9\u610f\u5473\u7740\u5f88\u5bb9\u6613\u5bf9\u6307\u5b9a\u7c7b\u7684\u8f93\u5165\u8bad\u7ec3\u51fa\u4e00\u79cd\u7279\u5b9a\u7684\u7f16\u7801\u5668\uff0c\u800c\u4e0d\u9700\u8981\u5b8c\u6210\u4efb\u4f55\u65b0\u5de5\u4f5c\u3002  \u642d\u5efa\u4e00\u4e2a\u81ea\u52a8\u7f16\u7801\u5668\u9700\u8981\u5b8c\u6210\u4e0b\u9762\u4e09\u6837\u5de5\u4f5c\uff1a\u642d\u5efa\u7f16\u7801\u5668\uff0c\u642d\u5efa\u89e3\u7801\u5668\uff0c\u8bbe\u5b9a\u4e00\u4e2a\u635f\u5931\u51fd\u6570\uff0c\u7528\u4ee5\u8861\u91cf\u7531\u4e8e\u538b\u7f29\u800c\u635f\u5931\u6389\u7684\u4fe1\u606f\u3002\u7f16\u7801\u5668\u548c\u89e3\u7801\u5668\u4e00\u822c\u90fd\u662f\u53c2\u6570\u5316\u7684\u65b9\u7a0b\uff0c\u5e76\u5173\u4e8e\u635f\u5931\u51fd\u6570\u53ef\u5bfc\uff0c\u5178\u578b\u60c5\u51b5\u662f\u4f7f\u7528\u795e\u7ecf\u7f51\u7edc\u3002\u7f16\u7801\u5668\u548c\u89e3\u7801\u5668\u7684\u53c2\u6570\u53ef\u4ee5\u901a\u8fc7\u6700\u5c0f\u5316\u635f\u5931\u51fd\u6570\u800c\u4f18\u5316\uff0c\u4f8b\u5982SGD\u3002", 
            "title": "\u4ec0\u4e48\u662f\u81ea\u52a8\u7f16\u7801\u5668\uff08Autoencoder\uff09"
        }, 
        {
            "location": "/blog/autoencoder/#_3", 
            "text": "\u901a\u5e38\u60c5\u51b5\u4e0b\uff0c\u4f7f\u7528\u81ea\u7f16\u7801\u5668\u505a\u6570\u636e\u538b\u7f29\uff0c\u6027\u80fd\u5e76\u4e0d\u600e\u4e48\u6837\u3002\u4ee5\u56fe\u7247\u538b\u7f29\u4e3a\u4f8b\uff0c\u60f3\u8981\u8bad\u7ec3\u4e00\u4e2a\u80fd\u548cJPEG\u6027\u80fd\u76f8\u63d0\u5e76\u8bba\u7684\u81ea\u7f16\u7801\u5668\u975e\u5e38\u56f0\u96be\uff0c\u5e76\u4e14\u8981\u8fbe\u5230\u8fd9\u4e2a\u6027\u80fd\uff0c\u4f60\u8fd8\u5fc5\u987b\u8981\u628a\u56fe\u7247\u7684\u7c7b\u578b\u9650\u5b9a\u5728\u5f88\u5c0f\u7684\u4e00\u4e2a\u8303\u56f4\u5185\uff08\u4f8b\u5982JPEG\u4e0d\u600e\u4e48\u884c\u7684\u67d0\u7c7b\u56fe\u7247\uff09\u3002\u81ea\u7f16\u7801\u5668\u4f9d\u8d56\u4e8e\u6570\u636e\u7684\u7279\u6027\u4f7f\u5f97\u5b83\u5728\u9762\u5bf9\u771f\u5b9e\u6570\u636e\u7684\u538b\u7f29\u4e0a\u5e76\u4e0d\u53ef\u884c\uff0c\u4f60\u53ea\u80fd\u5728\u6307\u5b9a\u7c7b\u578b\u7684\u6570\u636e\u4e0a\u83b7\u5f97\u8fd8\u53ef\u4ee5\u7684\u6548\u679c\uff0c\u4f46\u8c01\u77e5\u9053\u672a\u6765\u4f1a\u6709\u5565\u65b0\u9700\u6c42\uff1f", 
            "title": "\u81ea\u7f16\u7801\u5668\u662f\u4e00\u4e2a\u597d\u7684\u6570\u636e\u538b\u7f29\u7b97\u6cd5\u5417"
        }, 
        {
            "location": "/blog/autoencoder/#_4", 
            "text": "\u81ea\u7f16\u7801\u5668\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7528\u7684\u5f88\u5c11\uff0c2012\u5e74\u4eba\u4eec\u53d1\u73b0\u5728\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u4e2d\u4f7f\u7528\u81ea\u7f16\u7801\u5668\u505a\u9010\u5c42\u9884\u8bad\u7ec3\u53ef\u4ee5\u8bad\u7ec3\u6df1\u5ea6\u7f51\u7edc\uff0c\u4f46\u5f88\u5feb\u4eba\u4eec\u53d1\u73b0\u826f\u597d\u7684\u521d\u59cb\u5316\u7b56\u7565\u5728\u8bad\u7ec3\u6df1\u5ea6\u7f51\u7edc\u4e0a\u8981\u6bd4\u8d39\u52b2\u7684\u9010\u5c42\u9884\u8bad\u7ec3\u6709\u6548\u5f97\u591a\uff0c2014\u5e74\u51fa\u73b0\u7684Batch Normalization\u6280\u672f\u4f7f\u5f97\u66f4\u6df1\u7684\u7f51\u7edc\u4e5f\u53ef\u4ee5\u88ab\u6709\u6548\u8bad\u7ec3\uff0c\u5230\u4e862015\u5e74\u5e95\uff0c\u901a\u8fc7\u4f7f\u7528\u6b8b\u5dee\u5b66\u4e60\uff08ResNet\uff09\u6211\u4eec\u57fa\u672c\u4e0a\u53ef\u4ee5\u8bad\u7ec3\u4efb\u610f\u6df1\u5ea6\u7684\u795e\u7ecf\u7f51\u7edc\u3002  \u76ee\u524d\u81ea\u7f16\u7801\u5668\u7684\u5e94\u7528\u4e3b\u8981\u6709\u4e24\u4e2a\u65b9\u9762\uff0c\u7b2c\u4e00\u662f\u6570\u636e\u53bb\u566a\uff0c\u7b2c\u4e8c\u662f\u4e3a\u8fdb\u884c\u53ef\u89c6\u5316\u800c\u964d\u7ef4\u3002\u914d\u5408\u9002\u5f53\u7684\u7ef4\u5ea6\u548c\u7a00\u758f\u7ea6\u675f\uff0c\u81ea\u7f16\u7801\u5668\u53ef\u4ee5\u5b66\u4e60\u5230\u6bd4PCA\u7b49\u6280\u672f\u66f4\u6709\u610f\u601d\u7684\u6570\u636e\u6295\u5f71\u3002  \u5bf9\u4e8e2D\u7684\u6570\u636e\u53ef\u89c6\u5316\uff0c t-SNE \uff08\u8bfb\u4f5ctee-snee\uff09\u6216\u8bb8\u662f\u76ee\u524d\u6700\u597d\u7684\u7b97\u6cd5\uff0c\u4f46\u901a\u5e38\u8fd8\u662f\u9700\u8981\u539f\u6570\u636e\u7684\u7ef4\u5ea6\u76f8\u5bf9\u4f4e\u4e00\u4e9b\u3002\u6240\u4ee5\uff0c\u53ef\u89c6\u5316\u9ad8\u7ef4\u6570\u636e\u7684\u4e00\u4e2a\u597d\u529e\u6cd5\u662f\u9996\u5148\u4f7f\u7528\u81ea\u7f16\u7801\u5668\u5c06\u7ef4\u5ea6\u964d\u4f4e\u5230\u8f83\u4f4e\u7684\u6c34\u5e73\uff08\u598232\u7ef4\uff09\uff0c\u7136\u540e\u518d\u4f7f\u7528t-SNE\u5c06\u5176\u6295\u5f71\u57282D\u5e73\u9762\u4e0a\u3002Keras\u7248\u672c\u7684t-SNE\u7531Kyle McDonald\u5b9e\u73b0\u4e86\u4e00\u4e0b\uff0c\u653e\u5728\u4e86 \u8fd9\u91cc \uff0c\u53e6\u5916 scikit-learn \u4e5f\u6709\u4e00\u4e2a\u7b80\u5355\u5b9e\u7528\u7684\u5b9e\u73b0\u3002", 
            "title": "\u90a3\u4e48\uff0c\u81ea\u7f16\u7801\u5668\u64c5\u957f\u505a\u4ec0\u4e48\uff1f"
        }, 
        {
            "location": "/blog/autoencoder/#_5", 
            "text": "\u81ea\u7f16\u7801\u5668\u7684\u51fa\u540d\u6765\u81ea\u4e8e\u7f51\u4e0a\u5f88\u591a\u673a\u5668\u5b66\u4e60\u8bfe\u7a0b\u7684\u4ecb\u7ecd\uff0c\u603b\u800c\u8a00\u4e4b\uff0c\u4e00\u5806\u65b0\u624b\u975e\u5e38\u70ed\u7231\u81ea\u7f16\u7801\u5668\u800c\u4e14\u600e\u4e48\u4e5f\u73a9\u4e0d\u591f\uff0c\u8fd9\u5c31\u662f\u8fd9\u7bc7\u6587\u7ae0\u51fa\u73b0\u7684\u610f\u4e49\u3010\u544a\u8bc9\u4f60\u81ea\u7f16\u7801\u5668\u6709\u4ec0\u4e48\u5375\u7528\u3011\u3002  \u81ea\u7f16\u7801\u5668\u5438\u5f15\u4e86\u4e00\u5927\u6279\u7814\u7a76\u548c\u5173\u6ce8\u7684\u4e3b\u8981\u539f\u56e0\u4e4b\u4e00\u662f\u5f88\u957f\u65f6\u95f4\u4e00\u6bb5\u4ee5\u6765\u5b83\u88ab\u8ba4\u4e3a\u662f\u89e3\u51b3\u65e0\u76d1\u7763\u5b66\u4e60\u7684\u53ef\u80fd\u65b9\u6848\uff0c\u5373\u5927\u5bb6\u89c9\u5f97\u81ea\u7f16\u7801\u5668\u53ef\u4ee5\u5728\u6ca1\u6709\u6807\u7b7e\u7684\u65f6\u5019\u5b66\u4e60\u5230\u6570\u636e\u7684\u6709\u7528\u8868\u8fbe\u3002\u518d\u8bf4\u4e00\u6b21\uff0c\u81ea\u7f16\u7801\u5668\u5e76\u4e0d\u662f\u4e00\u4e2a\u771f\u6b63\u7684\u65e0\u76d1\u7763\u5b66\u4e60\u7684\u7b97\u6cd5\uff0c\u800c\u662f\u4e00\u4e2a\u81ea\u76d1\u7763\u7684\u7b97\u6cd5\u3002\u81ea\u76d1\u7763\u5b66\u4e60\u662f\u76d1\u7763\u5b66\u4e60\u7684\u4e00\u4e2a\u5b9e\u4f8b\uff0c\u5176\u6807\u7b7e\u4ea7\u751f\u81ea\u8f93\u5165\u6570\u636e\u3002\u8981\u83b7\u5f97\u4e00\u4e2a\u81ea\u76d1\u7763\u7684\u6a21\u578b\uff0c\u4f60\u9700\u8981\u60f3\u51fa\u4e00\u4e2a\u9760\u8c31\u7684\u76ee\u6807\u8ddf\u4e00\u4e2a\u635f\u5931\u51fd\u6570\uff0c\u95ee\u9898\u6765\u4e86\uff0c\u4ec5\u4ec5\u628a\u76ee\u6807\u8bbe\u5b9a\u4e3a\u91cd\u6784\u8f93\u5165\u53ef\u80fd\u4e0d\u662f\u6b63\u786e\u7684\u9009\u9879\u3002\u57fa\u672c\u4e0a\uff0c\u8981\u6c42\u6a21\u578b\u5728\u50cf\u7d20\u7ea7\u4e0a\u7cbe\u786e\u91cd\u6784\u8f93\u5165\u4e0d\u662f\u673a\u5668\u5b66\u4e60\u7684\u5174\u8da3\u6240\u5728\uff0c\u5b66\u4e60\u5230\u9ad8\u7ea7\u7684\u62bd\u8c61\u7279\u5f81\u624d\u662f\u3002\u4e8b\u5b9e\u4e0a\uff0c\u5f53\u4f60\u7684\u4e3b\u8981\u4efb\u52a1\u662f\u5206\u7c7b\u3001\u5b9a\u4f4d\u4e4b\u7c7b\u7684\u4efb\u52a1\u65f6\uff0c\u90a3\u4e9b\u5bf9\u8fd9\u7c7b\u4efb\u52a1\u800c\u8a00\u7684\u6700\u597d\u7684\u7279\u5f81\u57fa\u672c\u4e0a\u90fd\u662f\u91cd\u6784\u8f93\u5165\u65f6\u7684\u6700\u5dee\u7684\u90a3\u79cd\u7279\u5f81\u3002  \u5728\u5e94\u7528\u81ea\u76d1\u7763\u5b66\u4e60\u7684\u89c6\u89c9\u95ee\u9898\u4e2d\uff0c\u53ef\u80fd\u5e94\u7528\u81ea\u7f16\u7801\u5668\u7684\u9886\u57df\u6709\u4f8b\u5982\u62fc\u56fe\uff0c\u7ec6\u8282\u7eb9\u7406\u5339\u914d\uff08\u4ece\u4f4e\u5206\u8fa8\u7387\u7684\u56fe\u50cf\u5757\u4e2d\u5339\u914d\u5176\u9ad8\u5206\u8fa8\u7387\u7684\u5bf9\u5e94\u5757\uff09\u3002\u4e0b\u9762\u8fd9\u7bc7\u6587\u7ae0\u7814\u7a76\u4e86\u62fc\u56fe\u95ee\u9898\uff0c\u5176\u5b9e\u5f88\u6709\u610f\u601d\uff0c\u4e0d\u59a8\u4e00\u8bfb\u3002 Unsupervised Learning of Visual Representations by Solving Jigsaw Puzzles. \u3002\u6b64\u7c7b\u95ee\u9898\u7684\u6a21\u578b\u8f93\u5165\u6709\u4e9b\u5185\u7f6e\u7684\u5047\u8bbe\uff0c\u4f8b\u5982\u201c\u89c6\u89c9\u5757\u6bd4\u50cf\u7d20\u7ea7\u7684\u7ec6\u8282\u66f4\u91cd\u8981\u201d\u8fd9\u6837\u7684\uff0c\u8fd9\u79cd\u5047\u8bbe\u662f\u666e\u901a\u7684\u81ea\u7f16\u7801\u5668\u6ca1\u6709\u7684\u3002", 
            "title": "\u81ea\u7f16\u7801\u5668\u6709\u4ec0\u4e48\u5375\u7528"
        }, 
        {
            "location": "/blog/autoencoder/#keras", 
            "text": "\u9996\u5148\uff0c\u5148\u5efa\u7acb\u4e00\u4e2a\u5168\u8fde\u63a5\u7684\u7f16\u7801\u5668\u548c\u89e3\u7801\u5668  from keras.layers import Input, Dense\nfrom keras.models import Model\n\n# this is the size of our encoded representations\nencoding_dim = 32  # 32 floats -  compression of factor 24.5, assuming the input is 784 floats\n\n# this is our input placeholder\ninput_img = Input(shape=(784,))\n#  encoded  is the encoded representation of the input\nencoded = Dense(encoding_dim, activation='relu')(input_img)\n#  decoded  is the lossy reconstruction of the input\ndecoded = Dense(784, activation='sigmoid')(encoded)\n\n# this model maps an input to its reconstruction\nautoencoder = Model(input=input_img, output=decoded)  \u5f53\u7136\u6211\u4eec\u53ef\u4ee5\u5355\u72ec\u7684\u4f7f\u7528\u7f16\u7801\u5668\u548c\u89e3\u7801\u5668\uff1a  # this model maps an input to its encoded representation\nencoder = Model(input=input_img, output=encoded)  # create a placeholder for an encoded (32-dimensional) input\nencoded_input = Input(shape=(encoding_dim,))\n# retrieve the last layer of the autoencoder model\ndecoder_layer = autoencoder.layers[-1]\n# create the decoder model\ndecoder = Model(input=encoded_input, output=decoder_layer(encoded_input))  \u4e0b\u9762\u6211\u4eec\u8bad\u7ec3\u81ea\u7f16\u7801\u5668\uff0c\u6765\u91cd\u6784MNIST\u4e2d\u7684\u6570\u5b57\uff0c\u8fd9\u91cc\u4f7f\u7528\u9010\u50cf\u7d20\u7684\u4ea4\u53c9\u71b5\u4f5c\u4e3a\u635f\u5931\u51fd\u6570\uff0c\u4f18\u5316\u5668\u4e3aadam  autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')  \u7136\u540e\u51c6\u5907MNIST\u6570\u636e\uff0c\u5c06\u5176\u5f52\u4e00\u5316\u548c\u5411\u91cf\u5316\uff0c\u7136\u540e\u8bad\u7ec3\uff1a  from keras.datasets import mnist\nimport numpy as np\n(x_train, _), (x_test, _) = mnist.load_data()\n\nx_train = x_train.astype('float32') / 255.\nx_test = x_test.astype('float32') / 255.\nx_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\nx_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\nprint x_train.shape\nprint x_test.shape\n\nautoencoder.fit(x_train, x_train,\n                nb_epoch=50,\n                batch_size=256,\n                shuffle=True,\n                validation_data=(x_test, x_test))  50\u4e2aepoch\u540e\uff0c\u770b\u8d77\u6765\u6211\u4eec\u7684\u81ea\u7f16\u7801\u5668\u4f18\u5316\u7684\u4e0d\u9519\u4e86\uff0c\u635f\u5931\u662f0.10\uff0c\u6211\u4eec\u53ef\u89c6\u5316\u4e00\u4e0b\u91cd\u6784\u51fa\u6765\u7684\u8f93\u51fa\uff1a  # encode and decode some digits\n# note that we take them from the *test* set\n# use Matplotlib (don't ask)\nimport matplotlib.pyplot as plt\n\nencoded_imgs = encoder.predict(x_test)\ndecoded_imgs = decoder.predict(encoded_imgs)\n\n\nn = 10  # how many digits we will display\nplt.figure(figsize=(20, 4))\nfor i in range(n):\n    # display original\n    ax = plt.subplot(2, n, i)\n    plt.imshow(x_test[i].reshape(28, 28))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n\n    # display reconstruction\n    ax = plt.subplot(2, n, i + n)\n    plt.imshow(decoded_imgs[i].reshape(28, 28))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\nplt.show()  \u8fd9\u91cc\u662f\u7ed3\u679c\uff1a", 
            "title": "\u4f7f\u7528Keras\u5efa\u7acb\u7b80\u5355\u7684\u81ea\u7f16\u7801\u5668"
        }, 
        {
            "location": "/blog/autoencoder/#_6", 
            "text": "\u521a\u521a\u6211\u4eec\u7684\u9690\u5c42\u670932\u4e2a\u795e\u7ecf\u5143\uff0c\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u4e00\u822c\u800c\u8a00\u81ea\u7f16\u7801\u5668\u5b66\u5230\u7684\u662fPCA\u7684\u4e00\u4e2a\u8fd1\u4f3c\uff08PCA\u4e0d\u60f3\u79d1\u666e\u4e86\uff09\u3002\u4f46\u662f\u5982\u679c\u6211\u4eec\u5bf9\u9690\u5c42\u5355\u5143\u65bd\u52a0\u7a00\u758f\u6027\u7ea6\u675f\u7684\u8bdd\uff0c\u4f1a\u5f97\u5230\u66f4\u4e3a\u7d27\u51d1\u7684\u8868\u8fbe\uff0c\u53ea\u6709\u4e00\u5c0f\u90e8\u5206\u795e\u7ecf\u5143\u4f1a\u88ab\u6fc0\u6d3b\u3002\u5728Keras\u4e2d\uff0c\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u6dfb\u52a0\u4e00\u4e2aactivity_regularizer\u8fbe\u5230\u5bf9\u67d0\u5c42\u6fc0\u6d3b\u503c\u8fdb\u884c\u7ea6\u675f\u7684\u76ee\u7684\uff1a  from keras import regularizers\n\nencoding_dim = 32\n\ninput_img = Input(shape=(784,))\n# add a Dense layer with a L1 activity regularizer\nencoded = Dense(encoding_dim, activation='relu',\n                activity_regularizer=regularizers.activity_l1(10e-5))(input_img)\ndecoded = Dense(784, activation='sigmoid')(encoded)\n\nautoencoder = Model(input=input_img, output=decoded)  \u56e0\u4e3a\u6211\u4eec\u6dfb\u52a0\u4e86\u6b63\u5219\u6027\u7ea6\u675f\uff0c\u6240\u4ee5\u6a21\u578b\u8fc7\u62df\u5408\u7684\u98ce\u9669\u964d\u4f4e\uff0c\u6211\u4eec\u53ef\u4ee5\u8bad\u7ec3\u591a\u51e0\u6b21\uff0c\u8fd9\u6b21\u8bad\u7ec3100\u4e2aepoch\uff0c\u5f97\u5230\u635f\u5931\u4e3a0.11\uff0c\u591a\u51fa\u6765\u76840.01\u57fa\u672c\u4e0a\u662f\u7531\u4e8e\u6b63\u5219\u9879\u9020\u6210\u7684\u3002\u53ef\u89c6\u5316\u7ed3\u679c\u5982\u4e0b\uff1a   \u7ed3\u679c\u4e0a\u6ca1\u6709\u6bdb\u7ebf\u5dee\u522b\uff0c\u533a\u522b\u5728\u4e8e\u7f16\u7801\u51fa\u6765\u7684\u7801\u5b57\u66f4\u52a0\u7a00\u758f\u4e86\u3002\u7a00\u758f\u81ea\u7f16\u7801\u5668\u7684\u572810000\u4e2a\u6d4b\u8bd5\u56fe\u7247\u4e0a\u7684\u7801\u5b57\u5747\u503c\u4e3a3.33\uff0c\u800c\u4e4b\u524d\u7684\u4e3a7.30", 
            "title": "\u7a00\u758f\u81ea\u7f16\u7801\u5668\uff1a\u4e3a\u7801\u5b57\u52a0\u4e0a\u7a00\u758f\u6027\u7ea6\u675f"
        }, 
        {
            "location": "/blog/autoencoder/#_7", 
            "text": "\u628a\u591a\u4e2a\u81ea\u7f16\u7801\u5668\u53e0\u8d77\u6765\uff0c\u50cf\u8fd9\u6837\uff1a  input_img = Input(shape=(784,))\nencoded = Dense(128, activation='relu')(input_img)\nencoded = Dense(64, activation='relu')(encoded)\nencoded = Dense(32, activation='relu')(encoded)\n\ndecoded = Dense(64, activation='relu')(encoded)\ndecoded = Dense(128, activation='relu')(decoded)\ndecoded = Dense(784, activation='sigmoid')(decoded)\n\nautoencoder = Model(input=input_img, output=decoded)\nautoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n\nautoencoder.fit(x_train, x_train,\n                nb_epoch=100,\n                batch_size=256,\n                shuffle=True,\n                validation_data=(x_test, x_test))  100\u4e2aepoch\u540e\uff0closs\u5927\u6982\u662f0.097\uff0c\u6bd4\u4e4b\u524d\u7684\u6a21\u578b\u597d\u90a3\u4e48\u4e00\u4e22\u4e22", 
            "title": "\u6df1\u5ea6\u81ea\u7f16\u7801\u5668\uff1a\u628a\u81ea\u7f16\u7801\u5668\u53e0\u8d77\u6765"
        }, 
        {
            "location": "/blog/autoencoder/#_8", 
            "text": "\u5f53\u8f93\u5165\u662f\u56fe\u50cf\u65f6\uff0c\u4f7f\u7528\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u57fa\u672c\u4e0a\u603b\u662f\u6709\u610f\u4e49\u7684\u3002\u5728\u73b0\u5b9e\u4e2d\uff0c\u7528\u4e8e\u5904\u7406\u56fe\u50cf\u7684\u81ea\u52a8\u7f16\u7801\u5668\u51e0\u4e4e\u90fd\u662f\u5377\u79ef\u81ea\u52a8\u7f16\u7801\u5668\u2014\u2014\u53c8\u7b80\u5355\u53c8\u5feb\uff0c\u68d2\u68d2\u54d2  \u5377\u79ef\u81ea\u7f16\u7801\u5668\u7684\u7f16\u7801\u5668\u90e8\u5206\u7531\u5377\u79ef\u5c42\u548cMaxPooling\u5c42\u6784\u6210\uff0cMaxPooling\u8d1f\u8d23\u7a7a\u57df\u4e0b\u91c7\u6837\u3002\u800c\u89e3\u7801\u5668\u7531\u5377\u79ef\u5c42\u548c\u4e0a\u91c7\u6837\u5c42\u6784\u6210\u3002  from keras.layers import Input, Dense, Convolution2D, MaxPooling2D, UpSampling2D\nfrom keras.models import Model\n\ninput_img = Input(shape=(1, 28, 28))\n\nx = Convolution2D(16, 3, 3, activation='relu', border_mode='same')(input_img)\nx = MaxPooling2D((2, 2), border_mode='same')(x)\nx = Convolution2D(8, 3, 3, activation='relu', border_mode='same')(x)\nx = MaxPooling2D((2, 2), border_mode='same')(x)\nx = Convolution2D(8, 3, 3, activation='relu', border_mode='same')(x)\nencoded = MaxPooling2D((2, 2), border_mode='same')(x)\n\n# at this point the representation is (8, 4, 4) i.e. 128-dimensional\n\nx = Convolution2D(8, 3, 3, activation='relu', border_mode='same')(encoded)\nx = UpSampling2D((2, 2))(x)\nx = Convolution2D(8, 3, 3, activation='relu', border_mode='same')(x)\nx = UpSampling2D((2, 2))(x)\nx = Convolution2D(16, 3, 3, activation='relu')(x)\nx = UpSampling2D((2, 2))(x)\ndecoded = Convolution2D(1, 3, 3, activation='sigmoid', border_mode='same')(x)\n\nautoencoder = Model(input_img, decoded)\nautoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')  \u6211\u4eec\u4f7f\u752828 28 3\u7684\u539f\u59cbMNIST\u56fe\u50cf\uff08\u5c3d\u7ba1\u770b\u8d77\u6765\u8fd8\u662f\u7070\u5ea6\u56fe\uff09\u8bad\u7ec3\u7f51\u7edc\uff0c\u56fe\u7247\u7684\u50cf\u7d20\u88ab\u5f52\u4e00\u5316\u52300~1\u4e4b\u95f4\u3002  from keras.datasets import mnist\nimport numpy as np\n\n(x_train, _), (x_test, _) = mnist.load_data()\n\nx_train = x_train.astype('float32') / 255.\nx_test = x_test.astype('float32') / 255.\nx_train = np.reshape(x_train, (len(x_train), 1, 28, 28))\nx_test = np.reshape(x_test, (len(x_test), 1, 28, 28))  \u4e3a\u4e86\u53ef\u89c6\u5316\u8bad\u7ec3\u8fc7\u7a0b\u7684\u635f\u5931\u60c5\u51b5\uff0c\u6211\u4eec\u4f7f\u7528TensorFlow\u4f5c\u4e3a\u540e\u7aef\uff0c\u8fd9\u6837\u5c31\u53ef\u4ee5\u542f\u7528TensorBoard\u4e86\u3002\u6253\u5f00\u4e00\u4e2a\u7ec8\u7aef\u5e76\u542f\u52a8TensorBoard\uff0cTensorBoard\u5c06\u8bfb\u53d6\u4f4d\u4e8e/tmp/autoencoder\u7684\u65e5\u5fd7\u6587\u4ef6\uff1a  tensorboard --logdir=/tmp/autoencoder  \u7136\u540e\u6211\u4eec\u628a\u6a21\u578b\u8bad\u7ec350\u4e2aepoch\uff0c\u5e76\u5728\u56de\u8c03\u51fd\u6570\u5217\u8868\u4e2d\u4f20\u5165TensorBoard\u56de\u8c03\u51fd\u6570\uff0c\u5728\u6bcf\u4e2aepoch\u540e\u56de\u8c03\u51fd\u6570\u5c06\u628a\u8bad\u7ec3\u7684\u4fe1\u606f\u5199\u5165\u521a\u624d\u7684\u90a3\u4e2a\u65e5\u5fd7\u6587\u4ef6\u91cc\uff0c\u5e76\u88abTensorBoard\u8bfb\u53d6\u5230  from keras.callbacks import TensorBoard\n\nautoencoder.fit(x_train, x_train,\n                nb_epoch=50,\n                batch_size=128,\n                shuffle=True,\n                validation_data=(x_test, x_test),\n                callbacks=[TensorBoard(log_dir='/tmp/autoencoder')])  \u6253\u5f00\u6d4f\u89c8\u5668\u8fdb\u5165http://0.0.0.0:6006\u89c2\u6d4b\u7ed3\u679c\uff1a   \u6a21\u578b\u6700\u540e\u7684loss\u662f0.094\uff0c\u8981\u6bd4\u4e4b\u524d\u7684\u6a21\u578b\u90fd\u8981\u597d\u5f97\u591a\uff0c\u56e0\u4e3a\u73b0\u5728\u6211\u4eec\u7684\u7f16\u7801\u5668\u7684\u8868\u8fbe\u8868\u8fbe\u80fd\u529b\u66f4\u5f3a\u4e86\u3002  decoded_imgs = autoencoder.predict(x_test)\n\nn = 10\nplt.figure(figsize=(20, 4))\nfor i in range(n):\n    # display original\n    ax = plt.subplot(2, n, i)\n    plt.imshow(x_test[i].reshape(28, 28))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n\n    # display reconstruction\n    ax = plt.subplot(2, n, i + n)\n    plt.imshow(decoded_imgs[i].reshape(28, 28))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\nplt.show()   \u6211\u4eec\u4e5f\u53ef\u4ee5\u770b\u770b\u4e2d\u95f4\u7684\u7801\u5b57\u957f\u4ec0\u4e48\u6837\uff0c\u8fd9\u4e9b\u7801\u5b57\u7684shape\u662f8 4 4\uff0c\u6211\u4eec\u53ef\u4ee5\u5c06\u5176reshape\u62104*32\u770b  n = 10\nplt.figure(figsize=(20, 8))\nfor i in range(n):\n    ax = plt.subplot(1, n, i)\n    plt.imshow(encoded_imgs[i].reshape(4, 4 * 8).T)\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\nplt.show()", 
            "title": "\u5377\u79ef\u81ea\u7f16\u7801\u5668\uff1a\u7528\u5377\u79ef\u5c42\u642d\u5efa\u81ea\u7f16\u7801\u5668"
        }, 
        {
            "location": "/blog/autoencoder/#_9", 
            "text": "\u6211\u4eec\u628a\u8bad\u7ec3\u6837\u672c\u7528\u566a\u58f0\u6c61\u67d3\uff0c\u7136\u540e\u4f7f\u89e3\u7801\u5668\u89e3\u7801\u51fa\u5e72\u51c0\u7684\u7167\u7247\uff0c\u4ee5\u83b7\u5f97\u53bb\u566a\u81ea\u52a8\u7f16\u7801\u5668\u3002\u9996\u5148\u6211\u4eec\u628a\u539f\u56fe\u7247\u52a0\u5165\u9ad8\u65af\u566a\u58f0\uff0c\u7136\u540e\u628a\u50cf\u7d20\u503cclip\u52300~1  from keras.datasets import mnist\nimport numpy as np\n\n(x_train, _), (x_test, _) = mnist.load_data()\n\nx_train = x_train.astype('float32') / 255.\nx_test = x_test.astype('float32') / 255.\nx_train = np.reshape(x_train, (len(x_train), 1, 28, 28))\nx_test = np.reshape(x_test, (len(x_test), 1, 28, 28))\n\nnoise_factor = 0.5\nx_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape) \nx_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape) \n\nx_train_noisy = np.clip(x_train_noisy, 0., 1.)\nx_test_noisy = np.clip(x_test_noisy, 0., 1.)  \u6211\u4eec\u53ef\u4ee5\u5148\u770b\u770b\u88ab\u6c61\u67d3\u7684\u7167\u7247\u957f\u5565\u6837\uff1a   \u548c\u4e4b\u524d\u7684\u5377\u79ef\u81ea\u52a8\u7f16\u7801\u5668\u76f8\u6bd4\uff0c\u4e3a\u4e86\u63d0\u9ad8\u91cd\u6784\u56fe\u8d28\u91cf\uff0c\u6211\u4eec\u7684\u6a21\u578b\u7a0d\u6709\u4e0d\u540c  input_img = Input(shape=(1, 28, 28))\n\nx = Convolution2D(32, 3, 3, activation='relu', border_mode='same')(input_img)\nx = MaxPooling2D((2, 2), border_mode='same')(x)\nx = Convolution2D(32, 3, 3, activation='relu', border_mode='same')(x)\nencoded = MaxPooling2D((2, 2), border_mode='same')(x)\n\n# at this point the representation is (32, 7, 7)\n\nx = Convolution2D(32, 3, 3, activation='relu', border_mode='same')(encoded)\nx = UpSampling2D((2, 2))(x)\nx = Convolution2D(32, 3, 3, activation='relu', border_mode='same')(x)\nx = UpSampling2D((2, 2))(x)\ndecoded = Convolution2D(1, 3, 3, activation='sigmoid', border_mode='same')(x)\n\nautoencoder = Model(input_img, decoded)\nautoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')  \u5148\u6765100\u4e2aepoch\u7684\u8bad\u7ec3\u770b\u770b\u7ed3\u679c  autoencoder.fit(x_train_noisy, x_train,\n                nb_epoch=100,\n                batch_size=128,\n                shuffle=True,\n                validation_data=(x_test_noisy, x_test),\n                callbacks=[TensorBoard(log_dir='/tmp/tb', histogram_freq=0, write_graph=False)])  \u7ed3\u679c\u5982\u4e0b\uff0c\u68d2\u68d2\u54d2~   \u5982\u679c\u4f60\u5c06\u8fd9\u4e2a\u8fc7\u7a0b\u6269\u5c55\u5230\u66f4\u5927\u7684\u5377\u79ef\u7f51\u7edc\uff0c\u4f60\u53ef\u4ee5\u5904\u7406\u6587\u6863\u548c\u58f0\u97f3\u7684\u53bb\u566a\uff0cKaggle\u6709\u4e00\u4e2a\u6216\u8bb8\u4f60\u4f1a\u611f\u5174\u8da3\u7684\u6570\u636e\u96c6\u5728 \u8fd9\u91cc", 
            "title": "\u4f7f\u7528\u81ea\u52a8\u7f16\u7801\u5668\u8fdb\u884c\u56fe\u50cf\u53bb\u566a"
        }, 
        {
            "location": "/blog/autoencoder/#_10", 
            "text": "\u5982\u679c\u4f60\u7684\u8f93\u5165\u662f\u5e8f\u5217\u800c\u4e0d\u662f2D\u7684\u56fe\u50cf\uff0c\u90a3\u4e48\u4f60\u53ef\u80fd\u60f3\u8981\u4f7f\u7528\u9488\u5bf9\u5e8f\u5217\u7684\u6a21\u578b\u6784\u9020\u81ea\u7f16\u7801\u5668\uff0c\u5982LSTM\u3002\u8981\u6784\u9020\u57fa\u4e8eLSTM\u7684\u81ea\u7f16\u7801\u5668\uff0c\u9996\u5148\u6211\u4eec\u9700\u8981\u4e00\u4e2aLSTM\u7684\u7f16\u7801\u5668\u6765\u5c06\u8f93\u5165\u5e8f\u5217\u53d8\u4e3a\u4e00\u4e2a\u5411\u91cf\uff0c\u7136\u540e\u5c06\u8fd9\u4e2a\u5411\u91cf\u91cd\u590dN\u6b64\uff0c\u7136\u540e\u7528LSTM\u7684\u89e3\u7801\u5668\u5c06\u8fd9\u4e2aN\u6b65\u7684\u65f6\u95f4\u5e8f\u5217\u53d8\u4e3a\u76ee\u6807\u5e8f\u5217\u3002  \u8fd9\u91cc\u6211\u4eec\u4e0d\u9488\u5bf9\u4efb\u4f55\u7279\u5b9a\u7684\u6570\u636e\u5e93\u505a\u8fd9\u4ef6\u4e8b\uff0c\u53ea\u63d0\u4f9b\u4ee3\u7801\u4f9b\u8bfb\u8005\u53c2\u8003  from keras.layers import Input, LSTM, RepeatVector\nfrom keras.models import Model\n\ninputs = Input(shape=(timesteps, input_dim))\nencoded = LSTM(latent_dim)(inputs)\n\ndecoded = RepeatVector(timesteps)(encoded)\ndecoded = LSTM(input, return_sequences=True)(decoded)\n\nsequence_autoencoder = Model(inputs, decoded)\nencoder = Model(inputs, encoded)", 
            "title": "\u5e8f\u5217\u5230\u5e8f\u5217\u7684\u81ea\u52a8\u7f16\u7801\u5668"
        }, 
        {
            "location": "/blog/autoencoder/#variational-autoencodervae", 
            "text": "\u7f16\u7801\u81ea\u7f16\u7801\u5668\u662f\u66f4\u73b0\u4ee3\u548c\u6709\u8da3\u7684\u4e00\u79cd\u81ea\u52a8\u7f16\u7801\u5668\uff0c\u5b83\u4e3a\u7801\u5b57\u65bd\u52a0\u7ea6\u675f\uff0c\u4f7f\u5f97\u7f16\u7801\u5668\u5b66\u4e60\u5230\u8f93\u5165\u6570\u636e\u7684\u9690\u53d8\u91cf\u6a21\u578b\u3002\u9690\u53d8\u91cf\u6a21\u578b\u662f\u8fde\u63a5\u663e\u53d8\u91cf\u96c6\u548c\u9690\u53d8\u91cf\u96c6\u7684\u7edf\u8ba1\u6a21\u578b\uff0c\u9690\u53d8\u91cf\u6a21\u578b\u7684\u5047\u8bbe\u662f\u663e\u53d8\u91cf\u662f\u7531\u9690\u53d8\u91cf\u7684\u72b6\u6001\u63a7\u5236\u7684\uff0c\u5404\u4e2a\u663e\u53d8\u91cf\u4e4b\u95f4\u6761\u4ef6\u72ec\u7acb\u3002\u4e5f\u5c31\u662f\u8bf4\uff0c\u53d8\u5206\u7f16\u7801\u5668\u4e0d\u518d\u5b66\u4e60\u4e00\u4e2a\u4efb\u610f\u7684\u51fd\u6570\uff0c\u800c\u662f\u5b66\u4e60\u4f60\u7684\u6570\u636e\u6982\u7387\u5206\u5e03\u7684\u4e00\u7ec4\u53c2\u6570\u3002\u901a\u8fc7\u5728\u8fd9\u4e2a\u6982\u7387\u5206\u5e03\u4e2d\u91c7\u6837\uff0c\u4f60\u53ef\u4ee5\u751f\u6210\u65b0\u7684\u8f93\u5165\u6570\u636e\uff0c\u5373\u53d8\u5206\u7f16\u7801\u5668\u662f\u4e00\u4e2a\u751f\u6210\u6a21\u578b\u3002  \u4e0b\u9762\u662f\u53d8\u5206\u7f16\u7801\u5668\u7684\u5de5\u4f5c\u539f\u7406\uff1a  \u9996\u5148\uff0c\u7f16\u7801\u5668\u7f51\u7edc\u5c06\u8f93\u5165\u6837\u672cx\u8f6c\u6362\u4e3a\u9690\u7a7a\u95f4\u7684\u4e24\u4e2a\u53c2\u6570\uff0c\u8bb0\u4f5cz_mean\u548cz_log_sigma\u3002\u7136\u540e\uff0c\u6211\u4eec\u968f\u673a\u4ece\u9690\u85cf\u7684\u6b63\u6001\u5206\u5e03\u4e2d\u91c7\u6837\u5f97\u5230\u6570\u636e\u70b9z\uff0c\u8fd9\u4e2a\u9690\u85cf\u5206\u5e03\u6211\u4eec\u5047\u8bbe\u5c31\u662f\u4ea7\u751f\u8f93\u5165\u6570\u636e\u7684\u90a3\u4e2a\u5206\u5e03\u3002z = z_mean + exp(z_log_sigma)*epsilon\uff0cepsilon\u662f\u4e00\u4e2a\u670d\u4ece\u6b63\u6001\u5206\u5e03\u7684\u5f20\u91cf\u3002\u6700\u540e\uff0c\u4f7f\u7528\u89e3\u7801\u5668\u7f51\u7edc\u5c06\u9690\u7a7a\u95f4\u6620\u5c04\u5230\u663e\u7a7a\u95f4\uff0c\u5373\u5c06z\u8f6c\u6362\u56de\u539f\u6765\u7684\u8f93\u5165\u6570\u636e\u7a7a\u95f4\u3002  \u53c2\u6570\u85c9\u7531\u4e24\u4e2a\u635f\u5931\u51fd\u6570\u6765\u8bad\u7ec3\uff0c\u4e00\u4e2a\u662f\u91cd\u6784\u635f\u5931\u51fd\u6570\uff0c\u8be5\u51fd\u6570\u8981\u6c42\u89e3\u7801\u51fa\u6765\u7684\u6837\u672c\u4e0e\u8f93\u5165\u7684\u6837\u672c\u76f8\u4f3c\uff08\u4e0e\u4e4b\u524d\u7684\u81ea\u7f16\u7801\u5668\u76f8\u540c\uff09\uff0c\u7b2c\u4e8c\u9879\u635f\u5931\u51fd\u6570\u662f\u5b66\u4e60\u5230\u7684\u9690\u5206\u5e03\u4e0e\u5148\u9a8c\u5206\u5e03\u7684KL\u8ddd\u79bb\uff0c\u4f5c\u4e3a\u4e00\u4e2a\u6b63\u5219\u3002\u5b9e\u9645\u4e0a\u628a\u540e\u9762\u8fd9\u9879\u635f\u5931\u51fd\u6570\u53bb\u6389\u4e5f\u53ef\u4ee5\uff0c\u5c3d\u7ba1\u5b83\u5bf9\u5b66\u4e60\u7b26\u5408\u8981\u6c42\u7684\u9690\u7a7a\u95f4\u548c\u9632\u6b62\u8fc7\u62df\u5408\u6709\u5e2e\u52a9\u3002  \u56e0\u4e3aVAE\u662f\u4e00\u4e2a\u5f88\u590d\u6742\u7684\u4f8b\u5b50\uff0c\u6211\u4eec\u628aVAE\u7684\u4ee3\u7801\u653e\u5728\u4e86github\u4e0a\uff0c\u5728 \u8fd9\u91cc \u3002\u5728\u8fd9\u91cc\u6211\u4eec\u6765\u4e00\u6b65\u6b65\u56de\u987e\u4e00\u4e0b\u8fd9\u4e2a\u6a21\u578b\u662f\u5982\u4f55\u642d\u5efa\u7684  \u9996\u5148\uff0c\u5efa\u7acb\u7f16\u7801\u7f51\u7edc\uff0c\u5c06\u8f93\u5165\u5f71\u5c04\u4e3a\u9690\u5206\u5e03\u7684\u53c2\u6570\uff1a  x = Input(batch_shape=(batch_size, original_dim))\nh = Dense(intermediate_dim, activation='relu')(x)\nz_mean = Dense(latent_dim)(h)\nz_log_sigma = Dense(latent_dim)(h)  \u7136\u540e\u4ece\u8fd9\u4e9b\u53c2\u6570\u786e\u5b9a\u7684\u5206\u5e03\u4e2d\u91c7\u6837\uff0c\u8fd9\u4e2a\u6837\u672c\u76f8\u5f53\u4e8e\u4e4b\u524d\u7684\u9690\u5c42\u503c  def sampling(args):\n    z_mean, z_log_sigma = args\n    epsilon = K.random_normal(shape=(batch_size, latent_dim),\n                              mean=0., std=epsilon_std)\n    return z_mean + K.exp(z_log_sigma) * epsilon\n\n# note that  output_shape  isn't necessary with the TensorFlow backend\n# so you could write `Lambda(sampling)([z_mean, z_log_sigma])`\nz = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_sigma])  \u6700\u540e\uff0c\u5c06\u91c7\u6837\u5f97\u5230\u7684\u70b9\u6620\u5c04\u56de\u53bb\u91cd\u6784\u539f\u8f93\u5165\uff1a  decoder_h = Dense(intermediate_dim, activation='relu')\ndecoder_mean = Dense(original_dim, activation='sigmoid')\nh_decoded = decoder_h(z)\nx_decoded_mean = decoder_mean(h_decoded)  \u5230\u76ee\u524d\u4e3a\u6b62\u6211\u4eec\u505a\u7684\u5de5\u4f5c\u9700\u8981\u5b9e\u4f8b\u5316\u4e09\u4e2a\u6a21\u578b\uff1a    \u4e00\u4e2a\u7aef\u5230\u7aef\u7684\u81ea\u52a8\u7f16\u7801\u5668\uff0c\u7528\u4e8e\u5b8c\u6210\u8f93\u5165\u4fe1\u53f7\u7684\u91cd\u6784    \u4e00\u4e2a\u7528\u4e8e\u5c06\u8f93\u5165\u7a7a\u95f4\u6620\u5c04\u4e3a\u9690\u7a7a\u95f4\u7684\u7f16\u7801\u5668    \u4e00\u4e2a\u5229\u7528\u9690\u7a7a\u95f4\u7684\u5206\u5e03\u4ea7\u751f\u7684\u6837\u672c\u70b9\u751f\u6210\u5bf9\u5e94\u7684\u91cd\u6784\u6837\u672c\u7684\u751f\u6210\u5668    # end-to-end autoencoder\nvae = Model(x, x_decoded_mean)\n\n# encoder, from inputs to latent space\nencoder = Model(x, z_mean)\n\n# generator, from latent space to reconstructed inputs\ndecoder_input = Input(shape=(latent_dim,))\n_h_decoded = decoder_h(decoder_input)\n_x_decoded_mean = decoder_mean(_h_decoded)\ngenerator = Model(decoder_input, _x_decoded_mean)  \u6211\u4eec\u4f7f\u7528\u7aef\u5230\u7aef\u7684\u6a21\u578b\u8bad\u7ec3\uff0c\u635f\u5931\u51fd\u6570\u662f\u4e00\u9879\u91cd\u6784\u8bef\u5dee\uff0c\u548c\u4e00\u9879KL\u8ddd\u79bb  def vae_loss(x, x_decoded_mean):\n    xent_loss = objectives.binary_crossentropy(x, x_decoded_mean)\n    kl_loss = - 0.5 * K.mean(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma), axis=-1)\n    return xent_loss + kl_loss\n\nvae.compile(optimizer='rmsprop', loss=vae_loss)  \u73b0\u5728\u4f7f\u7528MNIST\u5e93\u6765\u8bad\u7ec3\u53d8\u5206\u7f16\u7801\u5668\uff1a  (x_train, y_train), (x_test, y_test) = mnist.load_data()\n\nx_train = x_train.astype('float32') / 255.\nx_test = x_test.astype('float32') / 255.\nx_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\nx_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n\nvae.fit(x_train, x_train,\n        shuffle=True,\n        nb_epoch=nb_epoch,\n        batch_size=batch_size,\n        validation_data=(x_test, x_test))  \u56e0\u4e3a\u6211\u4eec\u7684\u9690\u7a7a\u95f4\u53ea\u6709\u4e24\u7ef4\uff0c\u6240\u4ee5\u6211\u4eec\u53ef\u4ee5\u53ef\u89c6\u5316\u4e00\u4e0b\u3002\u6211\u4eec\u6765\u770b\u770b2D\u5e73\u9762\u4e2d\u4e0d\u540c\u7c7b\u7684\u8fd1\u90bb\u5206\u5e03\uff1a  x_test_encoded = encoder.predict(x_test, batch_size=batch_size)\nplt.figure(figsize=(6, 6))\nplt.scatter(x_test_encoded[:, 0], x_test_encoded[:, 1], c=y_test)\nplt.colorbar()\nplt.show()   \u4e0a\u56fe\u6bcf\u79cd\u989c\u8272\u4ee3\u8868\u4e00\u4e2a\u6570\u5b57\uff0c\u76f8\u8fd1\u805a\u7c7b\u7684\u6570\u5b57\u4ee3\u8868\u4ed6\u4eec\u5728\u7ed3\u6784\u4e0a\u76f8\u4f3c\u3002  \u56e0\u4e3a\u53d8\u5206\u7f16\u7801\u5668\u662f\u4e00\u4e2a\u751f\u6210\u6a21\u578b\uff0c\u6211\u4eec\u53ef\u4ee5\u7528\u5b83\u6765\u751f\u6210\u65b0\u6570\u5b57\u3002\u6211\u4eec\u53ef\u4ee5\u4ece\u9690\u5e73\u9762\u4e0a\u91c7\u6837\u4e00\u4e9b\u70b9\uff0c\u7136\u540e\u751f\u6210\u5bf9\u5e94\u7684\u663e\u53d8\u91cf\uff0c\u5373MNIST\u7684\u6570\u5b57\uff1a  # display a 2D manifold of the digits\nn = 15  # figure with 15x15 digits\ndigit_size = 28\nfigure = np.zeros((digit_size * n, digit_size * n))\n# we will sample n points within [-15, 15] standard deviations\ngrid_x = np.linspace(-15, 15, n)\ngrid_y = np.linspace(-15, 15, n)\n\nfor i, yi in enumerate(grid_x):\n    for j, xi in enumerate(grid_y):\n        z_sample = np.array([[xi, yi]]) * epsilon_std\n        x_decoded = generator.predict(z_sample)\n        digit = x_decoded[0].reshape(digit_size, digit_size)\n        figure[i * digit_size: (i + 1) * digit_size,\n               j * digit_size: (j + 1) * digit_size] = digit\n\nplt.figure(figsize=(10, 10))\nplt.imshow(figure)\nplt.show()   OK\u8fd9\u5c31\u662f\u672c\u6587\u7684\u5168\u90e8\uff0c\u5982\u679c\u4f60\u89c9\u5f97\u672c\u6587\u8fd8\u53ef\u4ee5\u589e\u52a0\u70b9\u522b\u7684\u4e3b\u9898\uff0c\u53ef\u4ee5\u5728Twitter\u4e0a@fchollet", 
            "title": "\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff08Variational autoencoder\uff0cVAE\uff09\uff1a\u7f16\u7801\u6570\u636e\u7684\u5206\u5e03"
        }, 
        {
            "location": "/blog/autoencoder/#_11", 
            "text": "[1] Why does unsupervised pre-training help deep learning?    [2] Batch normalization: Accelerating deep network training by reducing internal covariate shift.    [3] Deep Residual Learning for Image Recognition    [4] Auto-Encoding Variational Bayes", 
            "title": "\u53c2\u8003\u6587\u732e"
        }, 
        {
            "location": "/blog/image_classification_using_very_little_data/", 
            "text": "\u9762\u5411\u5c0f\u6570\u636e\u96c6\u6784\u5efa\u56fe\u50cf\u5206\u7c7b\u6a21\u578b\n\n\n\u6587\u7ae0\u4fe1\u606f\n\n\n\u672c\u6587\u5730\u5740\uff1a\nhttp://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html\n\n\n\u672c\u6587\u4f5c\u8005\uff1aFrancois Chollet\n\n\n\u6982\u8ff0\n\n\n\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u5c06\u63d0\u4f9b\u4e00\u4e9b\u9762\u5411\u5c0f\u6570\u636e\u96c6\uff08\u51e0\u767e\u5f20\u5230\u51e0\u5343\u5f20\u56fe\u7247\uff09\u6784\u9020\u9ad8\u6548\u3001\u5b9e\u7528\u7684\u56fe\u50cf\u5206\u7c7b\u5668\u7684\u65b9\u6cd5\u3002\n\n\n\u672c\u6587\u5c06\u63a2\u8ba8\u5982\u4e0b\u51e0\u79cd\u65b9\u6cd5\uff1a\n\n\n\n\n\n\n\u4ece\u56fe\u7247\u4e2d\u76f4\u63a5\u8bad\u7ec3\u4e00\u4e2a\u5c0f\u7f51\u7edc\uff08\u4f5c\u4e3a\u57fa\u51c6\u65b9\u6cd5\uff09\n\n\n\n\n\n\n\u5229\u7528\u9884\u8bad\u7ec3\u7f51\u7edc\u7684bottleneck\uff08\u74f6\u9888\uff09\u7279\u5f81\n\n\n\n\n\n\nfine-tune\u9884\u8bad\u7ec3\u7f51\u7edc\u7684\u9ad8\u5c42\n\n\n\n\n\n\n\u672c\u6587\u9700\u8981\u4f7f\u7528\u7684Keras\u6a21\u5757\u6709\uff1a\n\n\n\n\n\n\nfit_generator\n\uff1a\u7528\u4e8e\u4ecePython\u751f\u6210\u5668\u4e2d\u8bad\u7ec3\u7f51\u7edc\n\n\n\n\n\n\nImageDataGenerator\n\uff1a\u7528\u4e8e\u5b9e\u65f6\u6570\u636e\u63d0\u5347\n\n\n\n\n\n\n\u5c42\u53c2\u6570\u51bb\u7ed3\u548c\u6a21\u578bfine-tune\n\n\n\n\n\n\n\n\n\u914d\u7f6e\u60c5\u51b5\n\n\n\u6211\u4eec\u7684\u5b9e\u9a8c\u57fa\u4e8e\u4e0b\u9762\u7684\u914d\u7f6e\n\n\n\n\n\n\n2000\u5f20\u8bad\u7ec3\u56fe\u7247\u6784\u6210\u7684\u6570\u636e\u96c6\uff0c\u4e00\u5171\u4e24\u4e2a\u7c7b\u522b\uff0c\u6bcf\u7c7b1000\u5f20\n\n\n\n\n\n\n\u5b89\u88c5\u6709Keras\uff0cSciPy\uff0cPIL\u7684\u673a\u5668\uff0c\u5982\u679c\u6709NVIDIA GPU\u90a3\u5c31\u66f4\u597d\u4e86\uff0c\u4f46\u56e0\u4e3a\u6211\u4eec\u9762\u5bf9\u7684\u662f\u5c0f\u6570\u636e\u96c6\uff0c\u6ca1\u6709\u4e5f\u53ef\u4ee5\u3002\n\n\n\n\n\n\n\u6570\u636e\u96c6\u6309\u7167\u4e0b\u9762\u7684\u5f62\u5f0f\u5b58\u653e\n\n\n\n\n\n\ndata/\n    train/\n        dogs/\n            dog001.jpg\n            dog002.jpg\n            ...\n        cats/\n            cat001/jpg\n            cat002.jpg\n            ...\n    validation/\n        dogs/\n            dog001.jpg\n            dog002.jpg\n            ...\n        cats/\n            cat001/jpg\n            cat002.jpg\n            ...\n\n\n\n\n\u8fd9\u4efd\u6570\u636e\u96c6\u6765\u6e90\u4e8e\nKaggle\n\uff0c\u539f\u6570\u636e\u96c6\u670912500\u53ea\u732b\u548c12500\u53ea\u72d7\uff0c\u6211\u4eec\u53ea\u53d6\u4e86\u5404\u4e2a\u7c7b\u7684\u524d1000\u5f20\u56fe\u7247\u3002\u53e6\u5916\u6211\u4eec\u8fd8\u4ece\u5404\u4e2a\u7c7b\u4e2d\u53d6\u4e86400\u5f20\u989d\u5916\u56fe\u7247\u7528\u4e8e\u6d4b\u8bd5\u3002\n\n\n\u4e0b\u9762\u662f\u6570\u636e\u96c6\u7684\u4e00\u4e9b\u793a\u4f8b\u56fe\u7247\uff0c\u56fe\u7247\u7684\u6570\u91cf\u975e\u5e38\u5c11\uff0c\u8fd9\u5bf9\u4e8e\u56fe\u50cf\u5206\u7c7b\u6765\u8bf4\u662f\u4e2a\u5927\u9ebb\u70e6\u3002\u4f46\u73b0\u5b9e\u662f\uff0c\u5f88\u591a\u771f\u5b9e\u4e16\u754c\u56fe\u7247\u83b7\u53d6\u662f\u5f88\u56f0\u96be\u7684\uff0c\u6211\u4eec\u80fd\u5f97\u5230\u7684\u6837\u672c\u6570\u76ee\u786e\u5b9e\u5f88\u6709\u9650\uff08\u6bd4\u5982\u533b\u5b66\u56fe\u50cf\uff0c\u6bcf\u5f20\u6b63\u6837\u672c\u90fd\u610f\u5473\u7740\u4e00\u4e2a\u627f\u53d7\u75db\u82e6\u7684\u75c5\u4eba:(\uff09\u3002\u5bf9\u6570\u636e\u79d1\u5b66\u5bb6\u800c\u8a00\uff0c\u6211\u4eec\u5e94\u8be5\u6709\u80fd\u591f\u69a8\u53d6\u5c11\u91cf\u6570\u636e\u7684\u5168\u90e8\u4ef7\u503c\u7684\u80fd\u529b\uff0c\u800c\u4e0d\u662f\u7b80\u5355\u7684\u4f38\u624b\u8981\u66f4\u591a\u7684\u6570\u636e\u3002\n\n\n\n\n\u5728Kaggle\u7684\u732b\u72d7\u5927\u6218\u7ade\u8d5b\u79cd\uff0c\u53c2\u8d5b\u8005\u901a\u8fc7\u4f7f\u7528\u73b0\u4ee3\u7684\u6df1\u5ea6\u5b66\u4e60\u6280\u672f\u8fbe\u5230\u4e8698%\u7684\u6b63\u786e\u7387\uff0c\u6211\u4eec\u53ea\u4f7f\u7528\u4e86\u5168\u90e8\u6570\u636e\u76848%\uff0c\u56e0\u6b64\u8fd9\u4e2a\u95ee\u9898\u5bf9\u6211\u4eec\u6765\u8bf4\u66f4\u96be\u3002\n\n\n\n\n\u9488\u5bf9\u5c0f\u6570\u636e\u96c6\u7684\u6df1\u5ea6\u5b66\u4e60\n\n\n\u6211\u7ecf\u5e38\u542c\u5230\u7684\u4e00\u79cd\u8bf4\u6cd5\u662f\uff0c\u6df1\u5ea6\u5b66\u4e60\u53ea\u6709\u5728\u4f60\u62e5\u6709\u6d77\u91cf\u6570\u636e\u65f6\u624d\u6709\u610f\u4e49\u3002\u867d\u7136\u8fd9\u79cd\u8bf4\u6cd5\u5e76\u4e0d\u662f\u5b8c\u5168\u4e0d\u5bf9\uff0c\u4f46\u5374\u5177\u6709\u8f83\u5f3a\u7684\u8bef\u5bfc\u6027\u3002\u5f53\u7136\uff0c\u6df1\u5ea6\u5b66\u4e60\u5f3a\u8c03\u4ece\u6570\u636e\u4e2d\u81ea\u52a8\u5b66\u4e60\u7279\u5f81\u7684\u80fd\u529b\uff0c\u6ca1\u6709\u8db3\u591f\u7684\u8bad\u7ec3\u6837\u672c\uff0c\u8fd9\u51e0\u4e4e\u662f\u4e0d\u53ef\u80fd\u7684\u3002\u5c24\u5176\u662f\u5f53\u8f93\u5165\u7684\u6570\u636e\u7ef4\u5ea6\u5f88\u9ad8\uff08\u5982\u56fe\u7247\uff09\u65f6\u3002\u7136\u800c\uff0c\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u4f5c\u4e3a\u6df1\u5ea6\u5b66\u4e60\u7684\u652f\u67f1\uff0c\u88ab\u8bbe\u8ba1\u4e3a\u9488\u5bf9\u201c\u611f\u77e5\u201d\u95ee\u9898\u6700\u597d\u7684\u6a21\u578b\u4e4b\u4e00\uff08\u5982\u56fe\u50cf\u5206\u7c7b\u95ee\u9898\uff09\uff0c\u5373\u4f7f\u53ea\u6709\u5f88\u5c11\u7684\u6570\u636e\uff0c\u7f51\u7edc\u4e5f\u80fd\u628a\u7279\u5f81\u5b66\u7684\u4e0d\u9519\u3002\u9488\u5bf9\u5c0f\u6570\u636e\u96c6\u7684\u795e\u7ecf\u7f51\u7edc\u4f9d\u7136\u80fd\u591f\u5f97\u5230\u5408\u7406\u7684\u7ed3\u679c\uff0c\u5e76\u4e0d\u9700\u8981\u4efb\u4f55\u624b\u5de5\u7684\u7279\u5f81\u5de5\u7a0b\u3002\u4e00\u8a00\u4ee5\u853d\u4e4b\uff0c\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u5927\u6cd5\u597d\uff01\n\n\n\u53e6\u4e00\u65b9\u9762\uff0c\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5929\u7136\u5c31\u5177\u6709\u53ef\u91cd\u7528\u7684\u7279\u6027\uff1a\u6bd4\u65b9\u8bf4\uff0c\u4f60\u53ef\u4ee5\u628a\u4e00\u4e2a\u5728\u5927\u89c4\u6a21\u6570\u636e\u4e0a\u8bad\u7ec3\u597d\u7684\u56fe\u50cf\u5206\u7c7b\u6216\u8bed\u97f3\u8bc6\u522b\u7684\u6a21\u578b\u91cd\u7528\u5728\u53e6\u4e00\u4e2a\u5f88\u4e0d\u4e00\u6837\u7684\u95ee\u9898\u4e0a\uff0c\u800c\u53ea\u9700\u8981\u505a\u6709\u9650\u7684\u4e00\u70b9\u6539\u52a8\u3002\u5c24\u5176\u5728\u8ba1\u7b97\u673a\u89c6\u89c9\u9886\u57df\uff0c\u8bb8\u591a\u9884\u8bad\u7ec3\u7684\u6a21\u578b\u73b0\u5728\u90fd\u88ab\u516c\u5f00\u4e0b\u8f7d\uff0c\u5e76\u88ab\u91cd\u7528\u5728\u5176\u4ed6\u95ee\u9898\u4e0a\u4ee5\u63d0\u5347\u5728\u5c0f\u6570\u636e\u96c6\u4e0a\u7684\u6027\u80fd\u3002\n\n\n\n\n\u6570\u636e\u9884\u5904\u7406\u4e0e\u6570\u636e\u63d0\u5347\n\n\n\u4e3a\u4e86\u5c3d\u91cf\u5229\u7528\u6211\u4eec\u6709\u9650\u7684\u8bad\u7ec3\u6570\u636e\uff0c\u6211\u4eec\u5c06\u901a\u8fc7\u4e00\u7cfb\u5217\u968f\u673a\u53d8\u6362\u5806\u6570\u636e\u8fdb\u884c\u63d0\u5347\uff0c\u8fd9\u6837\u6211\u4eec\u7684\u6a21\u578b\u5c06\u770b\u4e0d\u5230\u4efb\u4f55\u4e24\u5f20\u5b8c\u5168\u76f8\u540c\u7684\u56fe\u7247\uff0c\u8fd9\u6709\u5229\u4e8e\u6211\u4eec\u6291\u5236\u8fc7\u62df\u5408\uff0c\u4f7f\u5f97\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u66f4\u597d\u3002\n\n\n\u5728Keras\u4e2d\uff0c\u8fd9\u4e2a\u6b65\u9aa4\u53ef\u4ee5\u901a\u8fc7\nkeras.preprocessing.image.ImageGenerator\n\u6765\u5b9e\u73b0\uff0c\u8fd9\u4e2a\u7c7b\u4f7f\u4f60\u53ef\u4ee5\uff1a\n\n\n\n\n\n\n\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u8bbe\u7f6e\u8981\u65bd\u884c\u7684\u968f\u673a\u53d8\u6362\n\n\n\n\n\n\n\u901a\u8fc7\n.flow\n\u6216\n.flow_from_directory(directory)\n\u65b9\u6cd5\u5b9e\u4f8b\u5316\u4e00\u4e2a\u9488\u5bf9\u56fe\u50cfbatch\u7684\u751f\u6210\u5668\uff0c\u8fd9\u4e9b\u751f\u6210\u5668\u53ef\u4ee5\u88ab\u7528\u4f5ckeras\u6a21\u578b\u76f8\u5173\u65b9\u6cd5\u7684\u8f93\u5165\uff0c\u5982\nfit_generator\n\uff0c\nevaluate_generator\n\u548c\npredict_generator\n\n\n\n\n\n\n\u73b0\u5728\u8ba9\u6211\u4eec\u770b\u4e2a\u4f8b\u5b50\uff1a\n\n\nfrom keras.preprocessing.image import ImageDataGenerator\n\ndatagen = ImageDataGenerator(\n        rotation_range=40,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        rescale=1./255,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True,\n        fill_mode='nearest')\n\n\n\n\n\u4e0a\u9762\u663e\u793a\u7684\u53ea\u662f\u4e00\u90e8\u5206\u9009\u9879\uff0c\u8bf7\u9605\u8bfb\u6587\u6863\u7684\u76f8\u5173\u90e8\u5206\u6765\u67e5\u770b\u5168\u90e8\u53ef\u7528\u7684\u9009\u9879\u3002\u6211\u4eec\u6765\u5feb\u901f\u7684\u6d4f\u89c8\u4e00\u4e0b\u8fd9\u4e9b\u9009\u9879\u7684\u542b\u4e49\uff1a\n\n\n\n\n\n\nrotation_range\n\u662f\u4e00\u4e2a0~180\u7684\u5ea6\u6570\uff0c\u7528\u6765\u6307\u5b9a\u968f\u673a\u9009\u62e9\u56fe\u7247\u7684\u89d2\u5ea6\u3002\n\n\n\n\n\n\nwidth_shift\n\u548c\nheight_shift\n\u7528\u6765\u6307\u5b9a\u6c34\u5e73\u548c\u7ad6\u76f4\u65b9\u5411\u968f\u673a\u79fb\u52a8\u7684\u7a0b\u5ea6\uff0c\u8fd9\u662f\u4e24\u4e2a0~1\u4e4b\u95f4\u7684\u6bd4\u4f8b\u3002\n\n\n\n\n\n\nrescale\n\u503c\u5c06\u5728\u6267\u884c\u5176\u4ed6\u5904\u7406\u524d\u4e58\u5230\u6574\u4e2a\u56fe\u50cf\u4e0a\uff0c\u6211\u4eec\u7684\u56fe\u50cf\u5728RGB\u901a\u9053\u90fd\u662f0~255\u7684\u6574\u6570\uff0c\u8fd9\u6837\u7684\u64cd\u4f5c\u53ef\u80fd\u4f7f\u56fe\u50cf\u7684\u503c\u8fc7\u9ad8\u6216\u8fc7\u4f4e\uff0c\u6240\u4ee5\u6211\u4eec\u5c06\u8fd9\u4e2a\u503c\u5b9a\u4e3a0~1\u4e4b\u95f4\u7684\u6570\u3002\n\n\n\n\n\n\nshear_range\n\u662f\u7528\u6765\u8fdb\u884c\u526a\u5207\u53d8\u6362\u7684\u7a0b\u5ea6\uff0c\u53c2\u8003\n\u526a\u5207\u53d8\u6362\n\n\n\n\n\n\nzoom_range\n\u7528\u6765\u8fdb\u884c\u968f\u673a\u7684\u653e\u5927\n\n\n\n\n\n\nhorizontal_flip\n\u968f\u673a\u7684\u5bf9\u56fe\u7247\u8fdb\u884c\u6c34\u5e73\u7ffb\u8f6c\uff0c\u8fd9\u4e2a\u53c2\u6570\u9002\u7528\u4e8e\u6c34\u5e73\u7ffb\u8f6c\u4e0d\u5f71\u54cd\u56fe\u7247\u8bed\u4e49\u7684\u65f6\u5019\n\n\n\n\n\n\nfill_mode\n\u7528\u6765\u6307\u5b9a\u5f53\u9700\u8981\u8fdb\u884c\u50cf\u7d20\u586b\u5145\uff0c\u5982\u65cb\u8f6c\uff0c\u6c34\u5e73\u548c\u7ad6\u76f4\u4f4d\u79fb\u65f6\uff0c\u5982\u4f55\u586b\u5145\u65b0\u51fa\u73b0\u7684\u50cf\u7d20\n\n\n\n\n\n\n\u4e0b\u9762\u6211\u4eec\u4f7f\u7528\u8fd9\u4e2a\u5de5\u5177\u6765\u751f\u6210\u56fe\u7247\uff0c\u5e76\u5c06\u5b83\u4eec\u4fdd\u5b58\u5728\u4e00\u4e2a\u4e34\u65f6\u6587\u4ef6\u5939\u4e2d\uff0c\u8fd9\u6837\u6211\u4eec\u53ef\u4ee5\u611f\u89c9\u4e00\u4e0b\u6570\u636e\u63d0\u5347\u7a76\u7adf\u505a\u4e86\u4ec0\u4e48\u4e8b\u3002\u4e3a\u4e86\u4f7f\u56fe\u7247\u80fd\u591f\u5c55\u793a\u51fa\u6765\uff0c\u8fd9\u91cc\u6ca1\u6709\u4f7f\u7528\nrescaling\n\n\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n\ndatagen = ImageDataGenerator(\n        rotation_range=40,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True,\n        fill_mode='nearest')\n\nimg = load_img('data/train/cats/cat.0.jpg')  # this is a PIL image\nx = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)\nx = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)\n\n# the .flow() command below generates batches of randomly transformed images\n# and saves the results to the `preview/` directory\ni = 0\nfor batch in datagen.flow(x, batch_size=1,\n                          save_to_dir='preview', save_prefix='cat', save_format='jpeg'):\n    i += 1\n    if i \n 20:\n        break  # otherwise the generator would loop indefinitely\n\n\n\n\n\u4e0b\u9762\u662f\u4e00\u5f20\u56fe\u7247\u88ab\u63d0\u5347\u4ee5\u540e\u5f97\u5230\u7684\u591a\u4e2a\u7ed3\u679c\uff1a\n\n\n\n\n\n\n\u5728\u5c0f\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\uff1a40\u884c\u4ee3\u7801\u8fbe\u523080%\u7684\u51c6\u786e\u7387\n\n\n\u8fdb\u884c\u56fe\u50cf\u5206\u7c7b\u7684\u6b63\u786e\u5de5\u5177\u662f\u5377\u79ef\u7f51\u7edc\uff0c\u6240\u4ee5\u6211\u4eec\u6765\u8bd5\u8bd5\u7528\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u642d\u5efa\u4e00\u4e2a\u521d\u7ea7\u7684\u6a21\u578b\u3002\u56e0\u4e3a\u6211\u4eec\u7684\u6837\u672c\u6570\u5f88\u5c11\uff0c\u6240\u4ee5\u6211\u4eec\u5e94\u8be5\u5bf9\u8fc7\u62df\u5408\u7684\u95ee\u9898\u591a\u52a0\u6ce8\u610f\u3002\u5f53\u4e00\u4e2a\u6a21\u578b\u4ece\u5f88\u5c11\u7684\u6837\u672c\u4e2d\u5b66\u4e60\u5230\u4e0d\u80fd\u63a8\u5e7f\u5230\u65b0\u6570\u636e\u7684\u6a21\u5f0f\u65f6\uff0c\u6211\u4eec\u79f0\u4e3a\u51fa\u73b0\u4e86\u8fc7\u62df\u5408\u7684\u95ee\u9898\u3002\u8fc7\u62df\u5408\u53d1\u751f\u65f6\uff0c\u6a21\u578b\u8bd5\u56fe\u4f7f\u7528\u4e0d\u76f8\u5173\u7684\u7279\u5f81\u6765\u8fdb\u884c\u9884\u6d4b\u3002\u4f8b\u5982\uff0c\u4f60\u6709\u4e09\u5f20\u4f10\u6728\u5de5\u4eba\u7684\u7167\u7247\uff0c\u6709\u4e09\u5f20\u6c34\u624b\u7684\u7167\u7247\u3002\u516d\u5f20\u7167\u7247\u4e2d\u53ea\u6709\u4e00\u4e2a\u4f10\u6728\u5de5\u4eba\u6234\u4e86\u5e3d\u5b50\uff0c\u5982\u679c\u4f60\u8ba4\u4e3a\u6234\u5e3d\u5b50\u662f\u80fd\u5c06\u4f10\u6728\u5de5\u4eba\u4e0e\u6c34\u624b\u533a\u522b\u5f00\u7684\u7279\u5f81\uff0c\u90a3\u4e48\u6b64\u65f6\u4f60\u5c31\u662f\u4e00\u4e2a\u5dee\u52b2\u7684\u5206\u7c7b\u5668\u3002\n\n\n\u6570\u636e\u63d0\u5347\u662f\u5bf9\u6297\u8fc7\u62df\u5408\u95ee\u9898\u7684\u4e00\u4e2a\u6b66\u5668\uff0c\u4f46\u8fd8\u4e0d\u591f\uff0c\u56e0\u4e3a\u63d0\u5347\u8fc7\u7684\u6570\u636e\u4ecd\u7136\u662f\u9ad8\u5ea6\u76f8\u5173\u7684\u3002\u5bf9\u6297\u8fc7\u62df\u5408\u7684\u4f60\u5e94\u8be5\u4e3b\u8981\u5173\u6ce8\u7684\u662f\u6a21\u578b\u7684\u201c\u71b5\u5bb9\u91cf\u201d\u2014\u2014\u6a21\u578b\u5141\u8bb8\u5b58\u50a8\u7684\u4fe1\u606f\u91cf\u3002\u80fd\u591f\u5b58\u50a8\u66f4\u591a\u4fe1\u606f\u7684\u6a21\u578b\u80fd\u591f\u5229\u7528\u66f4\u591a\u7684\u7279\u5f81\u53d6\u5f97\u66f4\u597d\u7684\u6027\u80fd\uff0c\u4f46\u4e5f\u6709\u5b58\u50a8\u4e0d\u76f8\u5173\u7279\u5f81\u7684\u98ce\u9669\u3002\u53e6\u4e00\u65b9\u9762\uff0c\u53ea\u80fd\u5b58\u50a8\u5c11\u91cf\u4fe1\u606f\u7684\u6a21\u578b\u4f1a\u5c06\u5b58\u50a8\u7684\u7279\u5f81\u4e3b\u8981\u96c6\u4e2d\u5728\u771f\u6b63\u76f8\u5173\u7684\u7279\u5f81\u4e0a\uff0c\u5e76\u6709\u66f4\u597d\u7684\u6cdb\u5316\u6027\u80fd\u3002\n\n\n\u6709\u5f88\u591a\u4e0d\u540c\u7684\u65b9\u6cd5\u6765\u8c03\u6574\u6a21\u578b\u7684\u201c\u71b5\u5bb9\u91cf\u201d\uff0c\u5e38\u89c1\u7684\u4e00\u79cd\u9009\u62e9\u662f\u8c03\u6574\u6a21\u578b\u7684\u53c2\u6570\u6570\u76ee\uff0c\u5373\u6a21\u578b\u7684\u5c42\u6570\u548c\u6bcf\u5c42\u7684\u89c4\u6a21\u3002\u53e6\u4e00\u79cd\u65b9\u6cd5\u662f\u5bf9\u6743\u91cd\u8fdb\u884c\u6b63\u5219\u5316\u7ea6\u675f\uff0c\u5982L1\u6216L2.\u8fd9\u79cd\u7ea6\u675f\u4f1a\u4f7f\u6a21\u578b\u7684\u6743\u91cd\u504f\u5411\u8f83\u5c0f\u7684\u503c\u3002\n\n\n\u5728\u6211\u4eec\u7684\u6a21\u578b\u91cc\uff0c\u6211\u4eec\u4f7f\u7528\u4e86\u5f88\u5c0f\u7684\u5377\u79ef\u7f51\u7edc\uff0c\u53ea\u6709\u5f88\u5c11\u7684\u51e0\u5c42\uff0c\u6bcf\u5c42\u7684\u6ee4\u6ce2\u5668\u6570\u76ee\u4e5f\u4e0d\u591a\u3002\u518d\u52a0\u4e0a\u6570\u636e\u63d0\u5347\u548cDropout\uff0c\u5c31\u5dee\u4e0d\u591a\u4e86\u3002Dropout\u901a\u8fc7\u9632\u6b62\u4e00\u5c42\u770b\u5230\u4e24\u6b21\u5b8c\u5168\u4e00\u6837\u7684\u6a21\u5f0f\u6765\u9632\u6b62\u8fc7\u62df\u5408\uff0c\u76f8\u5f53\u4e8e\u4e5f\u662f\u4e00\u79cd\u6570\u636e\u63d0\u5347\u7684\u65b9\u6cd5\u3002\uff08\u4f60\u53ef\u4ee5\u8bf4dropout\u548c\u6570\u636e\u63d0\u5347\u90fd\u5728\u968f\u673a\u6270\u4e71\u6570\u636e\u7684\u76f8\u5173\u6027\uff09\n\n\n\u4e0b\u9762\u5c55\u793a\u7684\u4ee3\u7801\u662f\u6211\u4eec\u7684\u7b2c\u4e00\u4e2a\u6a21\u578b\uff0c\u4e00\u4e2a\u5f88\u7b80\u5355\u76843\u5c42\u5377\u79ef\u52a0\u4e0aReLU\u6fc0\u6d3b\u51fd\u6570\uff0c\u518d\u63a5max-pooling\u5c42\u3002\u8fd9\u4e2a\u7ed3\u6784\u548cYann LeCun\u57281990\u5e74\u53d1\u5e03\u7684\u56fe\u50cf\u5206\u7c7b\u5668\u5f88\u76f8\u4f3c\uff08\u9664\u4e86ReLU\uff09\n\n\n\u8fd9\u4e2a\u5b9e\u9a8c\u7684\u5168\u90e8\u4ee3\u7801\u5728\n\u8fd9\u91cc\n\n\nfrom keras.models import Sequential\nfrom keras.layers import Convolution2D, MaxPooling2D\nfrom keras.layers import Activation, Dropout, Flatten, Dense\n\nmodel = Sequential()\nmodel.add(Convolution2D(32, 3, 3, input_shape=(3, 150, 150)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Convolution2D(32, 3, 3))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Convolution2D(64, 3, 3))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n# the model so far outputs 3D feature maps (height, width, features)\n\n\n\n\n\u7136\u540e\u6211\u4eec\u63a5\u4e86\u4e24\u4e2a\u5168\u8fde\u63a5\u7f51\u7edc\uff0c\u5e76\u4ee5\u5355\u4e2a\u795e\u7ecf\u5143\u548csigmoid\u6fc0\u6d3b\u7ed3\u675f\u6a21\u578b\u3002\u8fd9\u79cd\u9009\u62e9\u4f1a\u4ea7\u751f\u4e8c\u5206\u7c7b\u7684\u7ed3\u679c\uff0c\u4e0e\u8fd9\u79cd\u914d\u7f6e\u76f8\u9002\u5e94\uff0c\u6211\u4eec\u4f7f\u7528\nbinary_crossentropy\n\u4f5c\u4e3a\u635f\u5931\u51fd\u6570\u3002\n\n\nmodel.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\nmodel.add(Dense(64))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1))\nmodel.add(Activation('sigmoid'))\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer='rmsprop',\n              metrics=['accuracy'])\n\n\n\n\n\u7136\u540e\u6211\u4eec\u5f00\u59cb\u51c6\u5907\u6570\u636e\uff0c\u4f7f\u7528\n.flow_from_directory()\n\u6765\u4ece\u6211\u4eec\u7684jpgs\u56fe\u7247\u4e2d\u76f4\u63a5\u4ea7\u751f\u6570\u636e\u548c\u6807\u7b7e\u3002\n\n\n# this is the augmentation configuration we will use for training\ntrain_datagen = ImageDataGenerator(\n        rescale=1./255,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True)\n\n# this is the augmentation configuration we will use for testing:\n# only rescaling\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\n# this is a generator that will read pictures found in\n# subfolers of 'data/train', and indefinitely generate\n# batches of augmented image data\ntrain_generator = train_datagen.flow_from_directory(\n        'data/train',  # this is the target directory\n        target_size=(150, 150),  # all images will be resized to 150x150\n        batch_size=32,\n        class_mode='binary')  # since we use binary_crossentropy loss, we need binary labels\n\n# this is a similar generator, for validation data\nvalidation_generator = test_datagen.flow_from_directory(\n        'data/validation',\n        target_size=(150, 150),\n        batch_size=32,\n        class_mode='binary')\n\n\n\n\n\u7136\u540e\u6211\u4eec\u53ef\u4ee5\u7528\u8fd9\u4e2a\u751f\u6210\u5668\u6765\u8bad\u7ec3\u7f51\u7edc\u4e86\uff0c\u5728GPU\u4e0a\u6bcf\u4e2aepoch\u8017\u65f620~30\u79d2\uff0c\u5728CPU\u4e0a\u8017\u65f6300~400\u79d2\uff0c\u6240\u4ee5\u5982\u679c\u4f60\u4e0d\u662f\u5f88\u7740\u6025\uff0c\u5728CPU\u4e0a\u8dd1\u8fd9\u4e2a\u6a21\u578b\u4e5f\u662f\u5b8c\u5168\u53ef\u4ee5\u7684\u3002\n\n\nmodel.fit_generator(\n        train_generator,\n        samples_per_epoch=2000,\n        nb_epoch=50,\n        validation_data=validation_generator,\n        nb_val_samples=800)\nmodel.save_weights('first_try.h5')  # always save your weights after training or during training\n\n\n\n\n\n\u8fd9\u4e2a\u6a21\u578b\u572850\u4e2aepoch\u540e\u7684\u51c6\u786e\u7387\u4e3a79%~81%\uff0c\u522b\u5fd8\u4e86\u6211\u4eec\u53ea\u7528\u4e868%\u7684\u6570\u636e\uff0c\u4e5f\u6ca1\u6709\u82b1\u65f6\u95f4\u6765\u505a\u6a21\u578b\u548c\u8d85\u53c2\u6570\u7684\u4f18\u5316\u3002\u5728Kaggle\u4e2d\uff0c\u8fd9\u4e2a\u6a21\u578b\u5df2\u7ecf\u53ef\u4ee5\u8fdb\u524d100\u540d\u4e86\uff08\u4e00\u5171215\u961f\u53c2\u4e0e\uff09\uff0c\u4f30\u8ba1\u5269\u4e0b\u7684115\u961f\u90fd\u6ca1\u6709\u7528\u6df1\u5ea6\u5b66\u4e60:)\n\n\n\u6ce8\u610f\u8fd9\u4e2a\u51c6\u786e\u7387\u7684\u53d8\u5316\u53ef\u80fd\u4f1a\u6bd4\u8f83\u5927\uff0c\u56e0\u4e3a\u51c6\u786e\u7387\u672c\u6765\u5c31\u662f\u4e00\u4e2a\u53d8\u5316\u8f83\u9ad8\u7684\u8bc4\u4f30\u53c2\u6570\uff0c\u800c\u4e14\u6211\u4eec\u53ea\u6709800\u4e2a\u6837\u672c\u7528\u6765\u6d4b\u8bd5\u3002\u6bd4\u8f83\u597d\u7684\u9a8c\u8bc1\u65b9\u6cd5\u662f\u4f7f\u7528K\u6298\u4ea4\u53c9\u9a8c\u8bc1\uff0c\u4f46\u6bcf\u8f6e\u9a8c\u8bc1\u4e2d\u6211\u4eec\u90fd\u8981\u8bad\u7ec3\u4e00\u4e2a\u6a21\u578b\u3002\n\n\n\n\n\u4f7f\u7528\u9884\u8bad\u7ec3\u7f51\u7edc\u7684bottleneck\u7279\u5f81\uff1a\u4e00\u5206\u949f\u8fbe\u523090%\u7684\u6b63\u786e\u7387\n\n\n\u4e00\u4e2a\u7a0d\u5fae\u8bb2\u7a76\u4e00\u70b9\u7684\u529e\u6cd5\u662f\uff0c\u5229\u7528\u5728\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u9884\u8bad\u7ec3\u597d\u7684\u7f51\u7edc\u3002\u8fd9\u6837\u7684\u7f51\u7edc\u5728\u591a\u6570\u7684\u8ba1\u7b97\u673a\u89c6\u89c9\u95ee\u9898\u4e0a\u90fd\u80fd\u53d6\u5f97\u4e0d\u9519\u7684\u7279\u5f81\uff0c\u5229\u7528\u8fd9\u6837\u7684\u7279\u5f81\u53ef\u4ee5\u8ba9\u6211\u4eec\u83b7\u5f97\u66f4\u9ad8\u7684\u51c6\u786e\u7387\u3002\n\n\n\u6211\u4eec\u5c06\u4f7f\u7528vgg-16\u7f51\u7edc\uff0c\u8be5\u7f51\u7edc\u5728ImageNet\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bad\u7ec3\uff0c\u8fd9\u4e2a\u6a21\u578b\u6211\u4eec\u4e4b\u524d\u63d0\u5230\u8fc7\u4e86\u3002\u56e0\u4e3aImageNet\u6570\u636e\u96c6\u5305\u542b\u591a\u79cd\u201c\u732b\u201d\u7c7b\u548c\u591a\u79cd\u201c\u72d7\u201d\u7c7b\uff0c\u8fd9\u4e2a\u6a21\u578b\u5df2\u7ecf\u80fd\u591f\u5b66\u4e60\u4e0e\u6211\u4eec\u8fd9\u4e2a\u6570\u636e\u96c6\u76f8\u5173\u7684\u7279\u5f81\u4e86\u3002\u4e8b\u5b9e\u4e0a\uff0c\u7b80\u5355\u7684\u8bb0\u5f55\u539f\u6765\u7f51\u7edc\u7684\u8f93\u51fa\u800c\u4e0d\u7528bottleneck\u7279\u5f81\u5c31\u5df2\u7ecf\u8db3\u591f\u628a\u6211\u4eec\u7684\u95ee\u9898\u89e3\u51b3\u7684\u4e0d\u9519\u4e86\u3002\u4e0d\u8fc7\u6211\u4eec\u8fd9\u91cc\u8bb2\u7684\u65b9\u6cd5\u5bf9\u5176\u4ed6\u7684\u7c7b\u4f3c\u95ee\u9898\u6709\u66f4\u597d\u7684\u63a8\u5e7f\u6027\uff0c\u5305\u62ec\u5728ImageNet\u4e2d\u6ca1\u6709\u51fa\u73b0\u7684\u7c7b\u522b\u7684\u5206\u7c7b\u95ee\u9898\u3002\n\n\nVGG-16\u7684\u7f51\u7edc\u7ed3\u6784\u5982\u4e0b\uff1a\n\n\n\n\n\u6211\u4eec\u7684\u65b9\u6cd5\u662f\u8fd9\u6837\u7684\uff0c\u6211\u4eec\u5c06\u5229\u7528\u7f51\u7edc\u7684\u5377\u79ef\u5c42\u90e8\u5206\uff0c\u628a\u5168\u8fde\u63a5\u4ee5\u4e0a\u7684\u90e8\u5206\u629b\u6389\u3002\u7136\u540e\u5728\u6211\u4eec\u7684\u8bad\u7ec3\u96c6\u548c\u6d4b\u8bd5\u96c6\u4e0a\u8dd1\u4e00\u904d\uff0c\u5c06\u5f97\u5230\u7684\u8f93\u51fa\uff08\u5373\u201cbottleneck feature\u201d\uff0c\u7f51\u7edc\u5728\u5168\u8fde\u63a5\u4e4b\u524d\u7684\u6700\u540e\u4e00\u5c42\u6fc0\u6d3b\u7684feature map\uff09\u8bb0\u5f55\u5728\u4e24\u4e2anumpy array\u91cc\u3002\u7136\u540e\u6211\u4eec\u57fa\u4e8e\u8bb0\u5f55\u4e0b\u6765\u7684\u7279\u5f81\u8bad\u7ec3\u4e00\u4e2a\u5168\u8fde\u63a5\u7f51\u7edc\u3002\n\n\n\u6211\u4eec\u5c06\u8fd9\u4e9b\u7279\u5f81\u4fdd\u5b58\u4e3a\u79bb\u7ebf\u5f62\u5f0f\uff0c\u800c\u4e0d\u662f\u5c06\u6211\u4eec\u7684\u5168\u8fde\u63a5\u6a21\u578b\u76f4\u63a5\u52a0\u5230\u7f51\u7edc\u4e0a\u5e76\u51bb\u7ed3\u4e4b\u524d\u7684\u5c42\u53c2\u6570\u8fdb\u884c\u8bad\u7ec3\u7684\u539f\u56e0\u662f\u5904\u4e8e\u8ba1\u7b97\u6548\u7387\u7684\u8003\u8651\u3002\u8fd0\u884cVGG\u7f51\u7edc\u7684\u4ee3\u4ef7\u662f\u975e\u5e38\u9ad8\u6602\u7684\uff0c\u5c24\u5176\u662f\u5728CPU\u4e0a\u8fd0\u884c\uff0c\u6240\u4ee5\u6211\u4eec\u53ea\u60f3\u8fd0\u884c\u4e00\u6b21\u3002\u8fd9\u4e5f\u662f\u6211\u4eec\u4e0d\u8fdb\u884c\u6570\u636e\u63d0\u5347\u7684\u539f\u56e0\u3002\n\n\n\u6211\u4eec\u4e0d\u518d\u8d58\u8ff0\u5982\u4f55\u642d\u5efavgg-16\u7f51\u7edc\u4e86\uff0c\u8fd9\u4ef6\u4e8b\u4e4b\u524d\u5df2\u7ecf\u8bf4\u8fc7\uff0c\u5728keras\u7684example\u91cc\u4e5f\u53ef\u4ee5\u627e\u5230\u3002\u4f46\u8ba9\u6211\u4eec\u770b\u770b\u5982\u4f55\u8bb0\u5f55bottleneck\u7279\u5f81\u3002\n\n\ngenerator = datagen.flow_from_directory(\n        'data/train',\n        target_size=(150, 150),\n        batch_size=32,\n        class_mode=None,  # this means our generator will only yield batches of data, no labels\n        shuffle=False)  # our data will be in order, so all first 1000 images will be cats, then 1000 dogs\n# the predict_generator method returns the output of a model, given\n# a generator that yields batches of numpy data\nbottleneck_features_train = model.predict_generator(generator, 2000)\n# save the output as a Numpy array\nnp.save(open('bottleneck_features_train.npy', 'w'), bottleneck_features_train)\n\ngenerator = datagen.flow_from_directory(\n        'data/validation',\n        target_size=(150, 150),\n        batch_size=32,\n        class_mode=None,\n        shuffle=False)\nbottleneck_features_validation = model.predict_generator(generator, 800)\nnp.save(open('bottleneck_features_validation.npy', 'w'), bottleneck_features_validation)\n\n\n\n\n\u8bb0\u5f55\u5b8c\u6bd5\u540e\u6211\u4eec\u53ef\u4ee5\u5c06\u6570\u636e\u8f7d\u5165\uff0c\u7528\u4e8e\u8bad\u7ec3\u6211\u4eec\u7684\u5168\u8fde\u63a5\u7f51\u7edc\uff1a\n\n\ntrain_data = np.load(open('bottleneck_features_train.npy'))\n# the features were saved in order, so recreating the labels is easy\ntrain_labels = np.array([0] * 1000 + [1] * 1000)\n\nvalidation_data = np.load(open('bottleneck_features_validation.npy'))\nvalidation_labels = np.array([0] * 400 + [1] * 400)\n\nmodel = Sequential()\nmodel.add(Flatten(input_shape=train_data.shape[1:]))\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(optimizer='rmsprop',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\nmodel.fit(train_data, train_labels,\n          nb_epoch=50, batch_size=32,\n          validation_data=(validation_data, validation_labels))\nmodel.save_weights('bottleneck_fc_model.h5')\n\n\n\n\n\u56e0\u4e3a\u7279\u5f81\u7684size\u5f88\u5c0f\uff0c\u6a21\u578b\u5728CPU\u4e0a\u8dd1\u7684\u4e5f\u4f1a\u5f88\u5feb\uff0c\u5927\u69821s\u4e00\u4e2aepoch\uff0c\u6700\u540e\u6211\u4eec\u7684\u51c6\u786e\u7387\u662f90%~91%\uff0c\u8fd9\u4e48\u597d\u7684\u7ed3\u679c\u591a\u534a\u5f52\u529f\u4e8e\u9884\u8bad\u7ec3\u7684vgg\u7f51\u7edc\u5e2e\u52a9\u6211\u4eec\u63d0\u53d6\u7279\u5f81\u3002\n\n\n\n\n\u5728\u9884\u8bad\u7ec3\u7684\u7f51\u7edc\u4e0afine-tune\n\n\n\u4e3a\u4e86\u8fdb\u4e00\u6b65\u63d0\u9ad8\u4e4b\u524d\u7684\u7ed3\u679c\uff0c\u6211\u4eec\u53ef\u4ee5\u8bd5\u7740fine-tune\u7f51\u7edc\u7684\u540e\u9762\u51e0\u5c42\u3002Fine-tune\u4ee5\u4e00\u4e2a\u9884\u8bad\u7ec3\u597d\u7684\u7f51\u7edc\u4e3a\u57fa\u7840\uff0c\u5728\u65b0\u7684\u6570\u636e\u96c6\u4e0a\u91cd\u65b0\u8bad\u7ec3\u4e00\u5c0f\u90e8\u5206\u6743\u91cd\u3002\u5728\u8fd9\u4e2a\u5b9e\u9a8c\u4e2d\uff0cfine-tune\u5206\u4e09\u4e2a\u6b65\u9aa4\n\n\n\n\n\n\n\u642d\u5efavgg-16\u5e76\u8f7d\u5165\u6743\u91cd\n\n\n\n\n\n\n\u5c06\u4e4b\u524d\u5b9a\u4e49\u7684\u5168\u8fde\u63a5\u7f51\u7edc\u52a0\u5728\u6a21\u578b\u7684\u9876\u90e8\uff0c\u5e76\u8f7d\u5165\u6743\u91cd\n\n\n\n\n\n\n\u51bb\u7ed3vgg16\u7f51\u7edc\u7684\u4e00\u90e8\u5206\u53c2\u6570\n\n\n\n\n\n\n\n\n\u6ce8\u610f\uff1a\n\n\n\n\n\n\n\u4e3a\u4e86\u8fdb\u884cfine-tune,\u6240\u6709\u7684\u5c42\u90fd\u5e94\u8be5\u4ee5\u8bad\u7ec3\u597d\u7684\u6743\u91cd\u4e3a\u521d\u59cb\u503c\uff0c\u4f8b\u5982\uff0c\u4f60\u4e0d\u80fd\u5c06\u968f\u673a\u521d\u59cb\u7684\u5168\u8fde\u63a5\u653e\u5728\u9884\u8bad\u7ec3\u7684\u5377\u79ef\u5c42\u4e4b\u4e0a\uff0c\u8fd9\u662f\u56e0\u4e3a\u7531\u968f\u673a\u6743\u91cd\u4ea7\u751f\u7684\u5927\u68af\u5ea6\u5c06\u4f1a\u7834\u574f\u5377\u79ef\u5c42\u9884\u8bad\u7ec3\u7684\u6743\u91cd\u3002\u5728\u6211\u4eec\u7684\u60c5\u5f62\u4e2d\uff0c\u8fd9\u5c31\u662f\u4e3a\u4ec0\u4e48\u6211\u4eec\u9996\u5148\u8bad\u7ec3\u9876\u5c42\u5206\u7c7b\u5668\uff0c\u7136\u540e\u518d\u57fa\u4e8e\u5b83\u8fdb\u884cfine-tune\u7684\u539f\u56e0\n\n\n\n\n\n\n\u6211\u4eec\u9009\u62e9\u53eafine-tune\u6700\u540e\u7684\u5377\u79ef\u5757\uff0c\u800c\u4e0d\u662f\u6574\u4e2a\u7f51\u7edc\uff0c\u8fd9\u662f\u4e3a\u4e86\u9632\u6b62\u8fc7\u62df\u5408\u3002\u6574\u4e2a\u7f51\u7edc\u5177\u6709\u5de8\u5927\u7684\u71b5\u5bb9\u91cf\uff0c\u56e0\u6b64\u5177\u6709\u5f88\u9ad8\u7684\u8fc7\u62df\u5408\u503e\u5411\u3002\u7531\u5e95\u5c42\u5377\u79ef\u6a21\u5757\u5b66\u4e60\u5230\u7684\u7279\u5f81\u66f4\u52a0\u4e00\u822c\uff0c\u66f4\u52a0\u4e0d\u5177\u6709\u62bd\u8c61\u6027\uff0c\u56e0\u6b64\u6211\u4eec\u8981\u4fdd\u6301\u524d\u4e24\u4e2a\u5377\u79ef\u5757\uff08\u5b66\u4e60\u4e00\u822c\u7279\u5f81\uff09\u4e0d\u52a8\uff0c\u53eafine-tune\u540e\u9762\u7684\u5377\u79ef\u5757\uff08\u5b66\u4e60\u7279\u522b\u7684\u7279\u5f81\uff09\u3002\n\n\n\n\n\n\nfine-tune\u5e94\u8be5\u5728\u5f88\u4f4e\u7684\u5b66\u4e60\u7387\u4e0b\u8fdb\u884c\uff0c\u901a\u5e38\u4f7f\u7528SGD\u4f18\u5316\u800c\u4e0d\u662f\u5176\u4ed6\u81ea\u9002\u5e94\u5b66\u4e60\u7387\u7684\u4f18\u5316\u7b97\u6cd5\uff0c\u5982RMSProp\u3002\u8fd9\u662f\u4e3a\u4e86\u4fdd\u8bc1\u66f4\u65b0\u7684\u5e45\u5ea6\u4fdd\u6301\u5728\u8f83\u4f4e\u7684\u7a0b\u5ea6\uff0c\u4ee5\u514d\u6bc1\u574f\u9884\u8bad\u7ec3\u7684\u7279\u5f81\u3002\n\n\n\n\n\n\n\u4ee3\u7801\u5982\u4e0b\uff0c\u9996\u5148\u5728\u521d\u59cb\u5316\u597d\u7684vgg\u7f51\u7edc\u4e0a\u6dfb\u52a0\u6211\u4eec\u9884\u8bad\u7ec3\u597d\u7684\u6a21\u578b\uff1a\n\n\n# build a classifier model to put on top of the convolutional model\ntop_model = Sequential()\ntop_model.add(Flatten(input_shape=model.output_shape[1:]))\ntop_model.add(Dense(256, activation='relu'))\ntop_model.add(Dropout(0.5))\ntop_model.add(Dense(1, activation='sigmoid'))\n\n# note that it is necessary to start with a fully-trained\n# classifier, including the top classifier,\n# in order to successfully do fine-tuning\ntop_model.load_weights(top_model_weights_path)\n\n# add the model on top of the convolutional base\nmodel.add(top_model)\n\n\n\n\n\u7136\u540e\u5c06\u6700\u540e\u4e00\u4e2a\u5377\u79ef\u5757\u524d\u7684\u5377\u79ef\u5c42\u53c2\u6570\u51bb\u7ed3\uff1a\n\n\n# set the first 25 layers (up to the last conv block)\n# to non-trainable (weights will not be updated)\nfor layer in model.layers[:25]:\n    layer.trainable = False\n\n# compile the model with a SGD/momentum optimizer\n# and a very slow learning rate.\nmodel.compile(loss='binary_crossentropy',\n              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n              metrics=['accuracy'])\n\n\n\n\n\u7136\u540e\u4ee5\u5f88\u4f4e\u7684\u5b66\u4e60\u7387\u8fdb\u884c\u8bad\u7ec3\uff1a\n\n\n# prepare data augmentation configuration\ntrain_datagen = ImageDataGenerator(\n        rescale=1./255,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True)\n\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_generator = train_datagen.flow_from_directory(\n        train_data_dir,\n        target_size=(img_height, img_width),\n        batch_size=32,\n        class_mode='binary')\n\nvalidation_generator = test_datagen.flow_from_directory(\n        validation_data_dir,\n        target_size=(img_height, img_width),\n        batch_size=32,\n        class_mode='binary')\n\n# fine-tune the model\nmodel.fit_generator(\n        train_generator,\n        samples_per_epoch=nb_train_samples,\n        nb_epoch=nb_epoch,\n        validation_data=validation_generator,\n        nb_val_samples=nb_validation_samples)\n\n\n\n\n\u572850\u4e2aepoch\u4e4b\u540e\u8be5\u65b9\u6cd5\u7684\u51c6\u786e\u7387\u4e3a94%\uff0c\u975e\u5e38\u6210\u529f\n\n\n\u901a\u8fc7\u4e0b\u9762\u7684\u65b9\u6cd5\u4f60\u53ef\u4ee5\u8fbe\u523095%\u4ee5\u4e0a\u7684\u6b63\u786e\u7387\uff1a\n\n\n\n\n\n\n\u66f4\u52a0\u5f3a\u70c8\u7684\u6570\u636e\u63d0\u5347\n\n\n\n\n\n\n\u66f4\u52a0\u5f3a\u70c8\u7684dropout\n\n\n\n\n\n\n\u4f7f\u7528L1\u548cL2\u6b63\u5219\u9879\uff08\u4e5f\u79f0\u4e3a\u6743\u91cd\u8870\u51cf\uff09\n\n\n\n\n\n\nfine-tune\u66f4\u591a\u7684\u5377\u79ef\u5757\uff08\u914d\u5408\u66f4\u5927\u7684\u6b63\u5219\uff09", 
            "title": "\u9762\u5411\u5c0f\u6570\u636e\u96c6\u6784\u5efa\u56fe\u50cf\u5206\u7c7b\u6a21\u578b"
        }, 
        {
            "location": "/blog/image_classification_using_very_little_data/#_1", 
            "text": "", 
            "title": "\u9762\u5411\u5c0f\u6570\u636e\u96c6\u6784\u5efa\u56fe\u50cf\u5206\u7c7b\u6a21\u578b"
        }, 
        {
            "location": "/blog/image_classification_using_very_little_data/#_2", 
            "text": "\u672c\u6587\u5730\u5740\uff1a http://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html  \u672c\u6587\u4f5c\u8005\uff1aFrancois Chollet", 
            "title": "\u6587\u7ae0\u4fe1\u606f"
        }, 
        {
            "location": "/blog/image_classification_using_very_little_data/#_3", 
            "text": "\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u5c06\u63d0\u4f9b\u4e00\u4e9b\u9762\u5411\u5c0f\u6570\u636e\u96c6\uff08\u51e0\u767e\u5f20\u5230\u51e0\u5343\u5f20\u56fe\u7247\uff09\u6784\u9020\u9ad8\u6548\u3001\u5b9e\u7528\u7684\u56fe\u50cf\u5206\u7c7b\u5668\u7684\u65b9\u6cd5\u3002  \u672c\u6587\u5c06\u63a2\u8ba8\u5982\u4e0b\u51e0\u79cd\u65b9\u6cd5\uff1a    \u4ece\u56fe\u7247\u4e2d\u76f4\u63a5\u8bad\u7ec3\u4e00\u4e2a\u5c0f\u7f51\u7edc\uff08\u4f5c\u4e3a\u57fa\u51c6\u65b9\u6cd5\uff09    \u5229\u7528\u9884\u8bad\u7ec3\u7f51\u7edc\u7684bottleneck\uff08\u74f6\u9888\uff09\u7279\u5f81    fine-tune\u9884\u8bad\u7ec3\u7f51\u7edc\u7684\u9ad8\u5c42    \u672c\u6587\u9700\u8981\u4f7f\u7528\u7684Keras\u6a21\u5757\u6709\uff1a    fit_generator \uff1a\u7528\u4e8e\u4ecePython\u751f\u6210\u5668\u4e2d\u8bad\u7ec3\u7f51\u7edc    ImageDataGenerator \uff1a\u7528\u4e8e\u5b9e\u65f6\u6570\u636e\u63d0\u5347    \u5c42\u53c2\u6570\u51bb\u7ed3\u548c\u6a21\u578bfine-tune", 
            "title": "\u6982\u8ff0"
        }, 
        {
            "location": "/blog/image_classification_using_very_little_data/#_4", 
            "text": "\u6211\u4eec\u7684\u5b9e\u9a8c\u57fa\u4e8e\u4e0b\u9762\u7684\u914d\u7f6e    2000\u5f20\u8bad\u7ec3\u56fe\u7247\u6784\u6210\u7684\u6570\u636e\u96c6\uff0c\u4e00\u5171\u4e24\u4e2a\u7c7b\u522b\uff0c\u6bcf\u7c7b1000\u5f20    \u5b89\u88c5\u6709Keras\uff0cSciPy\uff0cPIL\u7684\u673a\u5668\uff0c\u5982\u679c\u6709NVIDIA GPU\u90a3\u5c31\u66f4\u597d\u4e86\uff0c\u4f46\u56e0\u4e3a\u6211\u4eec\u9762\u5bf9\u7684\u662f\u5c0f\u6570\u636e\u96c6\uff0c\u6ca1\u6709\u4e5f\u53ef\u4ee5\u3002    \u6570\u636e\u96c6\u6309\u7167\u4e0b\u9762\u7684\u5f62\u5f0f\u5b58\u653e    data/\n    train/\n        dogs/\n            dog001.jpg\n            dog002.jpg\n            ...\n        cats/\n            cat001/jpg\n            cat002.jpg\n            ...\n    validation/\n        dogs/\n            dog001.jpg\n            dog002.jpg\n            ...\n        cats/\n            cat001/jpg\n            cat002.jpg\n            ...  \u8fd9\u4efd\u6570\u636e\u96c6\u6765\u6e90\u4e8e Kaggle \uff0c\u539f\u6570\u636e\u96c6\u670912500\u53ea\u732b\u548c12500\u53ea\u72d7\uff0c\u6211\u4eec\u53ea\u53d6\u4e86\u5404\u4e2a\u7c7b\u7684\u524d1000\u5f20\u56fe\u7247\u3002\u53e6\u5916\u6211\u4eec\u8fd8\u4ece\u5404\u4e2a\u7c7b\u4e2d\u53d6\u4e86400\u5f20\u989d\u5916\u56fe\u7247\u7528\u4e8e\u6d4b\u8bd5\u3002  \u4e0b\u9762\u662f\u6570\u636e\u96c6\u7684\u4e00\u4e9b\u793a\u4f8b\u56fe\u7247\uff0c\u56fe\u7247\u7684\u6570\u91cf\u975e\u5e38\u5c11\uff0c\u8fd9\u5bf9\u4e8e\u56fe\u50cf\u5206\u7c7b\u6765\u8bf4\u662f\u4e2a\u5927\u9ebb\u70e6\u3002\u4f46\u73b0\u5b9e\u662f\uff0c\u5f88\u591a\u771f\u5b9e\u4e16\u754c\u56fe\u7247\u83b7\u53d6\u662f\u5f88\u56f0\u96be\u7684\uff0c\u6211\u4eec\u80fd\u5f97\u5230\u7684\u6837\u672c\u6570\u76ee\u786e\u5b9e\u5f88\u6709\u9650\uff08\u6bd4\u5982\u533b\u5b66\u56fe\u50cf\uff0c\u6bcf\u5f20\u6b63\u6837\u672c\u90fd\u610f\u5473\u7740\u4e00\u4e2a\u627f\u53d7\u75db\u82e6\u7684\u75c5\u4eba:(\uff09\u3002\u5bf9\u6570\u636e\u79d1\u5b66\u5bb6\u800c\u8a00\uff0c\u6211\u4eec\u5e94\u8be5\u6709\u80fd\u591f\u69a8\u53d6\u5c11\u91cf\u6570\u636e\u7684\u5168\u90e8\u4ef7\u503c\u7684\u80fd\u529b\uff0c\u800c\u4e0d\u662f\u7b80\u5355\u7684\u4f38\u624b\u8981\u66f4\u591a\u7684\u6570\u636e\u3002   \u5728Kaggle\u7684\u732b\u72d7\u5927\u6218\u7ade\u8d5b\u79cd\uff0c\u53c2\u8d5b\u8005\u901a\u8fc7\u4f7f\u7528\u73b0\u4ee3\u7684\u6df1\u5ea6\u5b66\u4e60\u6280\u672f\u8fbe\u5230\u4e8698%\u7684\u6b63\u786e\u7387\uff0c\u6211\u4eec\u53ea\u4f7f\u7528\u4e86\u5168\u90e8\u6570\u636e\u76848%\uff0c\u56e0\u6b64\u8fd9\u4e2a\u95ee\u9898\u5bf9\u6211\u4eec\u6765\u8bf4\u66f4\u96be\u3002", 
            "title": "\u914d\u7f6e\u60c5\u51b5"
        }, 
        {
            "location": "/blog/image_classification_using_very_little_data/#_5", 
            "text": "\u6211\u7ecf\u5e38\u542c\u5230\u7684\u4e00\u79cd\u8bf4\u6cd5\u662f\uff0c\u6df1\u5ea6\u5b66\u4e60\u53ea\u6709\u5728\u4f60\u62e5\u6709\u6d77\u91cf\u6570\u636e\u65f6\u624d\u6709\u610f\u4e49\u3002\u867d\u7136\u8fd9\u79cd\u8bf4\u6cd5\u5e76\u4e0d\u662f\u5b8c\u5168\u4e0d\u5bf9\uff0c\u4f46\u5374\u5177\u6709\u8f83\u5f3a\u7684\u8bef\u5bfc\u6027\u3002\u5f53\u7136\uff0c\u6df1\u5ea6\u5b66\u4e60\u5f3a\u8c03\u4ece\u6570\u636e\u4e2d\u81ea\u52a8\u5b66\u4e60\u7279\u5f81\u7684\u80fd\u529b\uff0c\u6ca1\u6709\u8db3\u591f\u7684\u8bad\u7ec3\u6837\u672c\uff0c\u8fd9\u51e0\u4e4e\u662f\u4e0d\u53ef\u80fd\u7684\u3002\u5c24\u5176\u662f\u5f53\u8f93\u5165\u7684\u6570\u636e\u7ef4\u5ea6\u5f88\u9ad8\uff08\u5982\u56fe\u7247\uff09\u65f6\u3002\u7136\u800c\uff0c\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u4f5c\u4e3a\u6df1\u5ea6\u5b66\u4e60\u7684\u652f\u67f1\uff0c\u88ab\u8bbe\u8ba1\u4e3a\u9488\u5bf9\u201c\u611f\u77e5\u201d\u95ee\u9898\u6700\u597d\u7684\u6a21\u578b\u4e4b\u4e00\uff08\u5982\u56fe\u50cf\u5206\u7c7b\u95ee\u9898\uff09\uff0c\u5373\u4f7f\u53ea\u6709\u5f88\u5c11\u7684\u6570\u636e\uff0c\u7f51\u7edc\u4e5f\u80fd\u628a\u7279\u5f81\u5b66\u7684\u4e0d\u9519\u3002\u9488\u5bf9\u5c0f\u6570\u636e\u96c6\u7684\u795e\u7ecf\u7f51\u7edc\u4f9d\u7136\u80fd\u591f\u5f97\u5230\u5408\u7406\u7684\u7ed3\u679c\uff0c\u5e76\u4e0d\u9700\u8981\u4efb\u4f55\u624b\u5de5\u7684\u7279\u5f81\u5de5\u7a0b\u3002\u4e00\u8a00\u4ee5\u853d\u4e4b\uff0c\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u5927\u6cd5\u597d\uff01  \u53e6\u4e00\u65b9\u9762\uff0c\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5929\u7136\u5c31\u5177\u6709\u53ef\u91cd\u7528\u7684\u7279\u6027\uff1a\u6bd4\u65b9\u8bf4\uff0c\u4f60\u53ef\u4ee5\u628a\u4e00\u4e2a\u5728\u5927\u89c4\u6a21\u6570\u636e\u4e0a\u8bad\u7ec3\u597d\u7684\u56fe\u50cf\u5206\u7c7b\u6216\u8bed\u97f3\u8bc6\u522b\u7684\u6a21\u578b\u91cd\u7528\u5728\u53e6\u4e00\u4e2a\u5f88\u4e0d\u4e00\u6837\u7684\u95ee\u9898\u4e0a\uff0c\u800c\u53ea\u9700\u8981\u505a\u6709\u9650\u7684\u4e00\u70b9\u6539\u52a8\u3002\u5c24\u5176\u5728\u8ba1\u7b97\u673a\u89c6\u89c9\u9886\u57df\uff0c\u8bb8\u591a\u9884\u8bad\u7ec3\u7684\u6a21\u578b\u73b0\u5728\u90fd\u88ab\u516c\u5f00\u4e0b\u8f7d\uff0c\u5e76\u88ab\u91cd\u7528\u5728\u5176\u4ed6\u95ee\u9898\u4e0a\u4ee5\u63d0\u5347\u5728\u5c0f\u6570\u636e\u96c6\u4e0a\u7684\u6027\u80fd\u3002", 
            "title": "\u9488\u5bf9\u5c0f\u6570\u636e\u96c6\u7684\u6df1\u5ea6\u5b66\u4e60"
        }, 
        {
            "location": "/blog/image_classification_using_very_little_data/#_6", 
            "text": "\u4e3a\u4e86\u5c3d\u91cf\u5229\u7528\u6211\u4eec\u6709\u9650\u7684\u8bad\u7ec3\u6570\u636e\uff0c\u6211\u4eec\u5c06\u901a\u8fc7\u4e00\u7cfb\u5217\u968f\u673a\u53d8\u6362\u5806\u6570\u636e\u8fdb\u884c\u63d0\u5347\uff0c\u8fd9\u6837\u6211\u4eec\u7684\u6a21\u578b\u5c06\u770b\u4e0d\u5230\u4efb\u4f55\u4e24\u5f20\u5b8c\u5168\u76f8\u540c\u7684\u56fe\u7247\uff0c\u8fd9\u6709\u5229\u4e8e\u6211\u4eec\u6291\u5236\u8fc7\u62df\u5408\uff0c\u4f7f\u5f97\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u66f4\u597d\u3002  \u5728Keras\u4e2d\uff0c\u8fd9\u4e2a\u6b65\u9aa4\u53ef\u4ee5\u901a\u8fc7 keras.preprocessing.image.ImageGenerator \u6765\u5b9e\u73b0\uff0c\u8fd9\u4e2a\u7c7b\u4f7f\u4f60\u53ef\u4ee5\uff1a    \u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u8bbe\u7f6e\u8981\u65bd\u884c\u7684\u968f\u673a\u53d8\u6362    \u901a\u8fc7 .flow \u6216 .flow_from_directory(directory) \u65b9\u6cd5\u5b9e\u4f8b\u5316\u4e00\u4e2a\u9488\u5bf9\u56fe\u50cfbatch\u7684\u751f\u6210\u5668\uff0c\u8fd9\u4e9b\u751f\u6210\u5668\u53ef\u4ee5\u88ab\u7528\u4f5ckeras\u6a21\u578b\u76f8\u5173\u65b9\u6cd5\u7684\u8f93\u5165\uff0c\u5982 fit_generator \uff0c evaluate_generator \u548c predict_generator    \u73b0\u5728\u8ba9\u6211\u4eec\u770b\u4e2a\u4f8b\u5b50\uff1a  from keras.preprocessing.image import ImageDataGenerator\n\ndatagen = ImageDataGenerator(\n        rotation_range=40,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        rescale=1./255,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True,\n        fill_mode='nearest')  \u4e0a\u9762\u663e\u793a\u7684\u53ea\u662f\u4e00\u90e8\u5206\u9009\u9879\uff0c\u8bf7\u9605\u8bfb\u6587\u6863\u7684\u76f8\u5173\u90e8\u5206\u6765\u67e5\u770b\u5168\u90e8\u53ef\u7528\u7684\u9009\u9879\u3002\u6211\u4eec\u6765\u5feb\u901f\u7684\u6d4f\u89c8\u4e00\u4e0b\u8fd9\u4e9b\u9009\u9879\u7684\u542b\u4e49\uff1a    rotation_range \u662f\u4e00\u4e2a0~180\u7684\u5ea6\u6570\uff0c\u7528\u6765\u6307\u5b9a\u968f\u673a\u9009\u62e9\u56fe\u7247\u7684\u89d2\u5ea6\u3002    width_shift \u548c height_shift \u7528\u6765\u6307\u5b9a\u6c34\u5e73\u548c\u7ad6\u76f4\u65b9\u5411\u968f\u673a\u79fb\u52a8\u7684\u7a0b\u5ea6\uff0c\u8fd9\u662f\u4e24\u4e2a0~1\u4e4b\u95f4\u7684\u6bd4\u4f8b\u3002    rescale \u503c\u5c06\u5728\u6267\u884c\u5176\u4ed6\u5904\u7406\u524d\u4e58\u5230\u6574\u4e2a\u56fe\u50cf\u4e0a\uff0c\u6211\u4eec\u7684\u56fe\u50cf\u5728RGB\u901a\u9053\u90fd\u662f0~255\u7684\u6574\u6570\uff0c\u8fd9\u6837\u7684\u64cd\u4f5c\u53ef\u80fd\u4f7f\u56fe\u50cf\u7684\u503c\u8fc7\u9ad8\u6216\u8fc7\u4f4e\uff0c\u6240\u4ee5\u6211\u4eec\u5c06\u8fd9\u4e2a\u503c\u5b9a\u4e3a0~1\u4e4b\u95f4\u7684\u6570\u3002    shear_range \u662f\u7528\u6765\u8fdb\u884c\u526a\u5207\u53d8\u6362\u7684\u7a0b\u5ea6\uff0c\u53c2\u8003 \u526a\u5207\u53d8\u6362    zoom_range \u7528\u6765\u8fdb\u884c\u968f\u673a\u7684\u653e\u5927    horizontal_flip \u968f\u673a\u7684\u5bf9\u56fe\u7247\u8fdb\u884c\u6c34\u5e73\u7ffb\u8f6c\uff0c\u8fd9\u4e2a\u53c2\u6570\u9002\u7528\u4e8e\u6c34\u5e73\u7ffb\u8f6c\u4e0d\u5f71\u54cd\u56fe\u7247\u8bed\u4e49\u7684\u65f6\u5019    fill_mode \u7528\u6765\u6307\u5b9a\u5f53\u9700\u8981\u8fdb\u884c\u50cf\u7d20\u586b\u5145\uff0c\u5982\u65cb\u8f6c\uff0c\u6c34\u5e73\u548c\u7ad6\u76f4\u4f4d\u79fb\u65f6\uff0c\u5982\u4f55\u586b\u5145\u65b0\u51fa\u73b0\u7684\u50cf\u7d20    \u4e0b\u9762\u6211\u4eec\u4f7f\u7528\u8fd9\u4e2a\u5de5\u5177\u6765\u751f\u6210\u56fe\u7247\uff0c\u5e76\u5c06\u5b83\u4eec\u4fdd\u5b58\u5728\u4e00\u4e2a\u4e34\u65f6\u6587\u4ef6\u5939\u4e2d\uff0c\u8fd9\u6837\u6211\u4eec\u53ef\u4ee5\u611f\u89c9\u4e00\u4e0b\u6570\u636e\u63d0\u5347\u7a76\u7adf\u505a\u4e86\u4ec0\u4e48\u4e8b\u3002\u4e3a\u4e86\u4f7f\u56fe\u7247\u80fd\u591f\u5c55\u793a\u51fa\u6765\uff0c\u8fd9\u91cc\u6ca1\u6709\u4f7f\u7528 rescaling  from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n\ndatagen = ImageDataGenerator(\n        rotation_range=40,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True,\n        fill_mode='nearest')\n\nimg = load_img('data/train/cats/cat.0.jpg')  # this is a PIL image\nx = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)\nx = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)\n\n# the .flow() command below generates batches of randomly transformed images\n# and saves the results to the `preview/` directory\ni = 0\nfor batch in datagen.flow(x, batch_size=1,\n                          save_to_dir='preview', save_prefix='cat', save_format='jpeg'):\n    i += 1\n    if i   20:\n        break  # otherwise the generator would loop indefinitely  \u4e0b\u9762\u662f\u4e00\u5f20\u56fe\u7247\u88ab\u63d0\u5347\u4ee5\u540e\u5f97\u5230\u7684\u591a\u4e2a\u7ed3\u679c\uff1a", 
            "title": "\u6570\u636e\u9884\u5904\u7406\u4e0e\u6570\u636e\u63d0\u5347"
        }, 
        {
            "location": "/blog/image_classification_using_very_little_data/#4080", 
            "text": "\u8fdb\u884c\u56fe\u50cf\u5206\u7c7b\u7684\u6b63\u786e\u5de5\u5177\u662f\u5377\u79ef\u7f51\u7edc\uff0c\u6240\u4ee5\u6211\u4eec\u6765\u8bd5\u8bd5\u7528\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u642d\u5efa\u4e00\u4e2a\u521d\u7ea7\u7684\u6a21\u578b\u3002\u56e0\u4e3a\u6211\u4eec\u7684\u6837\u672c\u6570\u5f88\u5c11\uff0c\u6240\u4ee5\u6211\u4eec\u5e94\u8be5\u5bf9\u8fc7\u62df\u5408\u7684\u95ee\u9898\u591a\u52a0\u6ce8\u610f\u3002\u5f53\u4e00\u4e2a\u6a21\u578b\u4ece\u5f88\u5c11\u7684\u6837\u672c\u4e2d\u5b66\u4e60\u5230\u4e0d\u80fd\u63a8\u5e7f\u5230\u65b0\u6570\u636e\u7684\u6a21\u5f0f\u65f6\uff0c\u6211\u4eec\u79f0\u4e3a\u51fa\u73b0\u4e86\u8fc7\u62df\u5408\u7684\u95ee\u9898\u3002\u8fc7\u62df\u5408\u53d1\u751f\u65f6\uff0c\u6a21\u578b\u8bd5\u56fe\u4f7f\u7528\u4e0d\u76f8\u5173\u7684\u7279\u5f81\u6765\u8fdb\u884c\u9884\u6d4b\u3002\u4f8b\u5982\uff0c\u4f60\u6709\u4e09\u5f20\u4f10\u6728\u5de5\u4eba\u7684\u7167\u7247\uff0c\u6709\u4e09\u5f20\u6c34\u624b\u7684\u7167\u7247\u3002\u516d\u5f20\u7167\u7247\u4e2d\u53ea\u6709\u4e00\u4e2a\u4f10\u6728\u5de5\u4eba\u6234\u4e86\u5e3d\u5b50\uff0c\u5982\u679c\u4f60\u8ba4\u4e3a\u6234\u5e3d\u5b50\u662f\u80fd\u5c06\u4f10\u6728\u5de5\u4eba\u4e0e\u6c34\u624b\u533a\u522b\u5f00\u7684\u7279\u5f81\uff0c\u90a3\u4e48\u6b64\u65f6\u4f60\u5c31\u662f\u4e00\u4e2a\u5dee\u52b2\u7684\u5206\u7c7b\u5668\u3002  \u6570\u636e\u63d0\u5347\u662f\u5bf9\u6297\u8fc7\u62df\u5408\u95ee\u9898\u7684\u4e00\u4e2a\u6b66\u5668\uff0c\u4f46\u8fd8\u4e0d\u591f\uff0c\u56e0\u4e3a\u63d0\u5347\u8fc7\u7684\u6570\u636e\u4ecd\u7136\u662f\u9ad8\u5ea6\u76f8\u5173\u7684\u3002\u5bf9\u6297\u8fc7\u62df\u5408\u7684\u4f60\u5e94\u8be5\u4e3b\u8981\u5173\u6ce8\u7684\u662f\u6a21\u578b\u7684\u201c\u71b5\u5bb9\u91cf\u201d\u2014\u2014\u6a21\u578b\u5141\u8bb8\u5b58\u50a8\u7684\u4fe1\u606f\u91cf\u3002\u80fd\u591f\u5b58\u50a8\u66f4\u591a\u4fe1\u606f\u7684\u6a21\u578b\u80fd\u591f\u5229\u7528\u66f4\u591a\u7684\u7279\u5f81\u53d6\u5f97\u66f4\u597d\u7684\u6027\u80fd\uff0c\u4f46\u4e5f\u6709\u5b58\u50a8\u4e0d\u76f8\u5173\u7279\u5f81\u7684\u98ce\u9669\u3002\u53e6\u4e00\u65b9\u9762\uff0c\u53ea\u80fd\u5b58\u50a8\u5c11\u91cf\u4fe1\u606f\u7684\u6a21\u578b\u4f1a\u5c06\u5b58\u50a8\u7684\u7279\u5f81\u4e3b\u8981\u96c6\u4e2d\u5728\u771f\u6b63\u76f8\u5173\u7684\u7279\u5f81\u4e0a\uff0c\u5e76\u6709\u66f4\u597d\u7684\u6cdb\u5316\u6027\u80fd\u3002  \u6709\u5f88\u591a\u4e0d\u540c\u7684\u65b9\u6cd5\u6765\u8c03\u6574\u6a21\u578b\u7684\u201c\u71b5\u5bb9\u91cf\u201d\uff0c\u5e38\u89c1\u7684\u4e00\u79cd\u9009\u62e9\u662f\u8c03\u6574\u6a21\u578b\u7684\u53c2\u6570\u6570\u76ee\uff0c\u5373\u6a21\u578b\u7684\u5c42\u6570\u548c\u6bcf\u5c42\u7684\u89c4\u6a21\u3002\u53e6\u4e00\u79cd\u65b9\u6cd5\u662f\u5bf9\u6743\u91cd\u8fdb\u884c\u6b63\u5219\u5316\u7ea6\u675f\uff0c\u5982L1\u6216L2.\u8fd9\u79cd\u7ea6\u675f\u4f1a\u4f7f\u6a21\u578b\u7684\u6743\u91cd\u504f\u5411\u8f83\u5c0f\u7684\u503c\u3002  \u5728\u6211\u4eec\u7684\u6a21\u578b\u91cc\uff0c\u6211\u4eec\u4f7f\u7528\u4e86\u5f88\u5c0f\u7684\u5377\u79ef\u7f51\u7edc\uff0c\u53ea\u6709\u5f88\u5c11\u7684\u51e0\u5c42\uff0c\u6bcf\u5c42\u7684\u6ee4\u6ce2\u5668\u6570\u76ee\u4e5f\u4e0d\u591a\u3002\u518d\u52a0\u4e0a\u6570\u636e\u63d0\u5347\u548cDropout\uff0c\u5c31\u5dee\u4e0d\u591a\u4e86\u3002Dropout\u901a\u8fc7\u9632\u6b62\u4e00\u5c42\u770b\u5230\u4e24\u6b21\u5b8c\u5168\u4e00\u6837\u7684\u6a21\u5f0f\u6765\u9632\u6b62\u8fc7\u62df\u5408\uff0c\u76f8\u5f53\u4e8e\u4e5f\u662f\u4e00\u79cd\u6570\u636e\u63d0\u5347\u7684\u65b9\u6cd5\u3002\uff08\u4f60\u53ef\u4ee5\u8bf4dropout\u548c\u6570\u636e\u63d0\u5347\u90fd\u5728\u968f\u673a\u6270\u4e71\u6570\u636e\u7684\u76f8\u5173\u6027\uff09  \u4e0b\u9762\u5c55\u793a\u7684\u4ee3\u7801\u662f\u6211\u4eec\u7684\u7b2c\u4e00\u4e2a\u6a21\u578b\uff0c\u4e00\u4e2a\u5f88\u7b80\u5355\u76843\u5c42\u5377\u79ef\u52a0\u4e0aReLU\u6fc0\u6d3b\u51fd\u6570\uff0c\u518d\u63a5max-pooling\u5c42\u3002\u8fd9\u4e2a\u7ed3\u6784\u548cYann LeCun\u57281990\u5e74\u53d1\u5e03\u7684\u56fe\u50cf\u5206\u7c7b\u5668\u5f88\u76f8\u4f3c\uff08\u9664\u4e86ReLU\uff09  \u8fd9\u4e2a\u5b9e\u9a8c\u7684\u5168\u90e8\u4ee3\u7801\u5728 \u8fd9\u91cc  from keras.models import Sequential\nfrom keras.layers import Convolution2D, MaxPooling2D\nfrom keras.layers import Activation, Dropout, Flatten, Dense\n\nmodel = Sequential()\nmodel.add(Convolution2D(32, 3, 3, input_shape=(3, 150, 150)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Convolution2D(32, 3, 3))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Convolution2D(64, 3, 3))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n# the model so far outputs 3D feature maps (height, width, features)  \u7136\u540e\u6211\u4eec\u63a5\u4e86\u4e24\u4e2a\u5168\u8fde\u63a5\u7f51\u7edc\uff0c\u5e76\u4ee5\u5355\u4e2a\u795e\u7ecf\u5143\u548csigmoid\u6fc0\u6d3b\u7ed3\u675f\u6a21\u578b\u3002\u8fd9\u79cd\u9009\u62e9\u4f1a\u4ea7\u751f\u4e8c\u5206\u7c7b\u7684\u7ed3\u679c\uff0c\u4e0e\u8fd9\u79cd\u914d\u7f6e\u76f8\u9002\u5e94\uff0c\u6211\u4eec\u4f7f\u7528 binary_crossentropy \u4f5c\u4e3a\u635f\u5931\u51fd\u6570\u3002  model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\nmodel.add(Dense(64))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1))\nmodel.add(Activation('sigmoid'))\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer='rmsprop',\n              metrics=['accuracy'])  \u7136\u540e\u6211\u4eec\u5f00\u59cb\u51c6\u5907\u6570\u636e\uff0c\u4f7f\u7528 .flow_from_directory() \u6765\u4ece\u6211\u4eec\u7684jpgs\u56fe\u7247\u4e2d\u76f4\u63a5\u4ea7\u751f\u6570\u636e\u548c\u6807\u7b7e\u3002  # this is the augmentation configuration we will use for training\ntrain_datagen = ImageDataGenerator(\n        rescale=1./255,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True)\n\n# this is the augmentation configuration we will use for testing:\n# only rescaling\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\n# this is a generator that will read pictures found in\n# subfolers of 'data/train', and indefinitely generate\n# batches of augmented image data\ntrain_generator = train_datagen.flow_from_directory(\n        'data/train',  # this is the target directory\n        target_size=(150, 150),  # all images will be resized to 150x150\n        batch_size=32,\n        class_mode='binary')  # since we use binary_crossentropy loss, we need binary labels\n\n# this is a similar generator, for validation data\nvalidation_generator = test_datagen.flow_from_directory(\n        'data/validation',\n        target_size=(150, 150),\n        batch_size=32,\n        class_mode='binary')  \u7136\u540e\u6211\u4eec\u53ef\u4ee5\u7528\u8fd9\u4e2a\u751f\u6210\u5668\u6765\u8bad\u7ec3\u7f51\u7edc\u4e86\uff0c\u5728GPU\u4e0a\u6bcf\u4e2aepoch\u8017\u65f620~30\u79d2\uff0c\u5728CPU\u4e0a\u8017\u65f6300~400\u79d2\uff0c\u6240\u4ee5\u5982\u679c\u4f60\u4e0d\u662f\u5f88\u7740\u6025\uff0c\u5728CPU\u4e0a\u8dd1\u8fd9\u4e2a\u6a21\u578b\u4e5f\u662f\u5b8c\u5168\u53ef\u4ee5\u7684\u3002  model.fit_generator(\n        train_generator,\n        samples_per_epoch=2000,\n        nb_epoch=50,\n        validation_data=validation_generator,\n        nb_val_samples=800)\nmodel.save_weights('first_try.h5')  # always save your weights after training or during training  \u8fd9\u4e2a\u6a21\u578b\u572850\u4e2aepoch\u540e\u7684\u51c6\u786e\u7387\u4e3a79%~81%\uff0c\u522b\u5fd8\u4e86\u6211\u4eec\u53ea\u7528\u4e868%\u7684\u6570\u636e\uff0c\u4e5f\u6ca1\u6709\u82b1\u65f6\u95f4\u6765\u505a\u6a21\u578b\u548c\u8d85\u53c2\u6570\u7684\u4f18\u5316\u3002\u5728Kaggle\u4e2d\uff0c\u8fd9\u4e2a\u6a21\u578b\u5df2\u7ecf\u53ef\u4ee5\u8fdb\u524d100\u540d\u4e86\uff08\u4e00\u5171215\u961f\u53c2\u4e0e\uff09\uff0c\u4f30\u8ba1\u5269\u4e0b\u7684115\u961f\u90fd\u6ca1\u6709\u7528\u6df1\u5ea6\u5b66\u4e60:)  \u6ce8\u610f\u8fd9\u4e2a\u51c6\u786e\u7387\u7684\u53d8\u5316\u53ef\u80fd\u4f1a\u6bd4\u8f83\u5927\uff0c\u56e0\u4e3a\u51c6\u786e\u7387\u672c\u6765\u5c31\u662f\u4e00\u4e2a\u53d8\u5316\u8f83\u9ad8\u7684\u8bc4\u4f30\u53c2\u6570\uff0c\u800c\u4e14\u6211\u4eec\u53ea\u6709800\u4e2a\u6837\u672c\u7528\u6765\u6d4b\u8bd5\u3002\u6bd4\u8f83\u597d\u7684\u9a8c\u8bc1\u65b9\u6cd5\u662f\u4f7f\u7528K\u6298\u4ea4\u53c9\u9a8c\u8bc1\uff0c\u4f46\u6bcf\u8f6e\u9a8c\u8bc1\u4e2d\u6211\u4eec\u90fd\u8981\u8bad\u7ec3\u4e00\u4e2a\u6a21\u578b\u3002", 
            "title": "\u5728\u5c0f\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\uff1a40\u884c\u4ee3\u7801\u8fbe\u523080%\u7684\u51c6\u786e\u7387"
        }, 
        {
            "location": "/blog/image_classification_using_very_little_data/#bottleneck90", 
            "text": "\u4e00\u4e2a\u7a0d\u5fae\u8bb2\u7a76\u4e00\u70b9\u7684\u529e\u6cd5\u662f\uff0c\u5229\u7528\u5728\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u9884\u8bad\u7ec3\u597d\u7684\u7f51\u7edc\u3002\u8fd9\u6837\u7684\u7f51\u7edc\u5728\u591a\u6570\u7684\u8ba1\u7b97\u673a\u89c6\u89c9\u95ee\u9898\u4e0a\u90fd\u80fd\u53d6\u5f97\u4e0d\u9519\u7684\u7279\u5f81\uff0c\u5229\u7528\u8fd9\u6837\u7684\u7279\u5f81\u53ef\u4ee5\u8ba9\u6211\u4eec\u83b7\u5f97\u66f4\u9ad8\u7684\u51c6\u786e\u7387\u3002  \u6211\u4eec\u5c06\u4f7f\u7528vgg-16\u7f51\u7edc\uff0c\u8be5\u7f51\u7edc\u5728ImageNet\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bad\u7ec3\uff0c\u8fd9\u4e2a\u6a21\u578b\u6211\u4eec\u4e4b\u524d\u63d0\u5230\u8fc7\u4e86\u3002\u56e0\u4e3aImageNet\u6570\u636e\u96c6\u5305\u542b\u591a\u79cd\u201c\u732b\u201d\u7c7b\u548c\u591a\u79cd\u201c\u72d7\u201d\u7c7b\uff0c\u8fd9\u4e2a\u6a21\u578b\u5df2\u7ecf\u80fd\u591f\u5b66\u4e60\u4e0e\u6211\u4eec\u8fd9\u4e2a\u6570\u636e\u96c6\u76f8\u5173\u7684\u7279\u5f81\u4e86\u3002\u4e8b\u5b9e\u4e0a\uff0c\u7b80\u5355\u7684\u8bb0\u5f55\u539f\u6765\u7f51\u7edc\u7684\u8f93\u51fa\u800c\u4e0d\u7528bottleneck\u7279\u5f81\u5c31\u5df2\u7ecf\u8db3\u591f\u628a\u6211\u4eec\u7684\u95ee\u9898\u89e3\u51b3\u7684\u4e0d\u9519\u4e86\u3002\u4e0d\u8fc7\u6211\u4eec\u8fd9\u91cc\u8bb2\u7684\u65b9\u6cd5\u5bf9\u5176\u4ed6\u7684\u7c7b\u4f3c\u95ee\u9898\u6709\u66f4\u597d\u7684\u63a8\u5e7f\u6027\uff0c\u5305\u62ec\u5728ImageNet\u4e2d\u6ca1\u6709\u51fa\u73b0\u7684\u7c7b\u522b\u7684\u5206\u7c7b\u95ee\u9898\u3002  VGG-16\u7684\u7f51\u7edc\u7ed3\u6784\u5982\u4e0b\uff1a   \u6211\u4eec\u7684\u65b9\u6cd5\u662f\u8fd9\u6837\u7684\uff0c\u6211\u4eec\u5c06\u5229\u7528\u7f51\u7edc\u7684\u5377\u79ef\u5c42\u90e8\u5206\uff0c\u628a\u5168\u8fde\u63a5\u4ee5\u4e0a\u7684\u90e8\u5206\u629b\u6389\u3002\u7136\u540e\u5728\u6211\u4eec\u7684\u8bad\u7ec3\u96c6\u548c\u6d4b\u8bd5\u96c6\u4e0a\u8dd1\u4e00\u904d\uff0c\u5c06\u5f97\u5230\u7684\u8f93\u51fa\uff08\u5373\u201cbottleneck feature\u201d\uff0c\u7f51\u7edc\u5728\u5168\u8fde\u63a5\u4e4b\u524d\u7684\u6700\u540e\u4e00\u5c42\u6fc0\u6d3b\u7684feature map\uff09\u8bb0\u5f55\u5728\u4e24\u4e2anumpy array\u91cc\u3002\u7136\u540e\u6211\u4eec\u57fa\u4e8e\u8bb0\u5f55\u4e0b\u6765\u7684\u7279\u5f81\u8bad\u7ec3\u4e00\u4e2a\u5168\u8fde\u63a5\u7f51\u7edc\u3002  \u6211\u4eec\u5c06\u8fd9\u4e9b\u7279\u5f81\u4fdd\u5b58\u4e3a\u79bb\u7ebf\u5f62\u5f0f\uff0c\u800c\u4e0d\u662f\u5c06\u6211\u4eec\u7684\u5168\u8fde\u63a5\u6a21\u578b\u76f4\u63a5\u52a0\u5230\u7f51\u7edc\u4e0a\u5e76\u51bb\u7ed3\u4e4b\u524d\u7684\u5c42\u53c2\u6570\u8fdb\u884c\u8bad\u7ec3\u7684\u539f\u56e0\u662f\u5904\u4e8e\u8ba1\u7b97\u6548\u7387\u7684\u8003\u8651\u3002\u8fd0\u884cVGG\u7f51\u7edc\u7684\u4ee3\u4ef7\u662f\u975e\u5e38\u9ad8\u6602\u7684\uff0c\u5c24\u5176\u662f\u5728CPU\u4e0a\u8fd0\u884c\uff0c\u6240\u4ee5\u6211\u4eec\u53ea\u60f3\u8fd0\u884c\u4e00\u6b21\u3002\u8fd9\u4e5f\u662f\u6211\u4eec\u4e0d\u8fdb\u884c\u6570\u636e\u63d0\u5347\u7684\u539f\u56e0\u3002  \u6211\u4eec\u4e0d\u518d\u8d58\u8ff0\u5982\u4f55\u642d\u5efavgg-16\u7f51\u7edc\u4e86\uff0c\u8fd9\u4ef6\u4e8b\u4e4b\u524d\u5df2\u7ecf\u8bf4\u8fc7\uff0c\u5728keras\u7684example\u91cc\u4e5f\u53ef\u4ee5\u627e\u5230\u3002\u4f46\u8ba9\u6211\u4eec\u770b\u770b\u5982\u4f55\u8bb0\u5f55bottleneck\u7279\u5f81\u3002  generator = datagen.flow_from_directory(\n        'data/train',\n        target_size=(150, 150),\n        batch_size=32,\n        class_mode=None,  # this means our generator will only yield batches of data, no labels\n        shuffle=False)  # our data will be in order, so all first 1000 images will be cats, then 1000 dogs\n# the predict_generator method returns the output of a model, given\n# a generator that yields batches of numpy data\nbottleneck_features_train = model.predict_generator(generator, 2000)\n# save the output as a Numpy array\nnp.save(open('bottleneck_features_train.npy', 'w'), bottleneck_features_train)\n\ngenerator = datagen.flow_from_directory(\n        'data/validation',\n        target_size=(150, 150),\n        batch_size=32,\n        class_mode=None,\n        shuffle=False)\nbottleneck_features_validation = model.predict_generator(generator, 800)\nnp.save(open('bottleneck_features_validation.npy', 'w'), bottleneck_features_validation)  \u8bb0\u5f55\u5b8c\u6bd5\u540e\u6211\u4eec\u53ef\u4ee5\u5c06\u6570\u636e\u8f7d\u5165\uff0c\u7528\u4e8e\u8bad\u7ec3\u6211\u4eec\u7684\u5168\u8fde\u63a5\u7f51\u7edc\uff1a  train_data = np.load(open('bottleneck_features_train.npy'))\n# the features were saved in order, so recreating the labels is easy\ntrain_labels = np.array([0] * 1000 + [1] * 1000)\n\nvalidation_data = np.load(open('bottleneck_features_validation.npy'))\nvalidation_labels = np.array([0] * 400 + [1] * 400)\n\nmodel = Sequential()\nmodel.add(Flatten(input_shape=train_data.shape[1:]))\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(optimizer='rmsprop',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\nmodel.fit(train_data, train_labels,\n          nb_epoch=50, batch_size=32,\n          validation_data=(validation_data, validation_labels))\nmodel.save_weights('bottleneck_fc_model.h5')  \u56e0\u4e3a\u7279\u5f81\u7684size\u5f88\u5c0f\uff0c\u6a21\u578b\u5728CPU\u4e0a\u8dd1\u7684\u4e5f\u4f1a\u5f88\u5feb\uff0c\u5927\u69821s\u4e00\u4e2aepoch\uff0c\u6700\u540e\u6211\u4eec\u7684\u51c6\u786e\u7387\u662f90%~91%\uff0c\u8fd9\u4e48\u597d\u7684\u7ed3\u679c\u591a\u534a\u5f52\u529f\u4e8e\u9884\u8bad\u7ec3\u7684vgg\u7f51\u7edc\u5e2e\u52a9\u6211\u4eec\u63d0\u53d6\u7279\u5f81\u3002", 
            "title": "\u4f7f\u7528\u9884\u8bad\u7ec3\u7f51\u7edc\u7684bottleneck\u7279\u5f81\uff1a\u4e00\u5206\u949f\u8fbe\u523090%\u7684\u6b63\u786e\u7387"
        }, 
        {
            "location": "/blog/image_classification_using_very_little_data/#fine-tune", 
            "text": "\u4e3a\u4e86\u8fdb\u4e00\u6b65\u63d0\u9ad8\u4e4b\u524d\u7684\u7ed3\u679c\uff0c\u6211\u4eec\u53ef\u4ee5\u8bd5\u7740fine-tune\u7f51\u7edc\u7684\u540e\u9762\u51e0\u5c42\u3002Fine-tune\u4ee5\u4e00\u4e2a\u9884\u8bad\u7ec3\u597d\u7684\u7f51\u7edc\u4e3a\u57fa\u7840\uff0c\u5728\u65b0\u7684\u6570\u636e\u96c6\u4e0a\u91cd\u65b0\u8bad\u7ec3\u4e00\u5c0f\u90e8\u5206\u6743\u91cd\u3002\u5728\u8fd9\u4e2a\u5b9e\u9a8c\u4e2d\uff0cfine-tune\u5206\u4e09\u4e2a\u6b65\u9aa4    \u642d\u5efavgg-16\u5e76\u8f7d\u5165\u6743\u91cd    \u5c06\u4e4b\u524d\u5b9a\u4e49\u7684\u5168\u8fde\u63a5\u7f51\u7edc\u52a0\u5728\u6a21\u578b\u7684\u9876\u90e8\uff0c\u5e76\u8f7d\u5165\u6743\u91cd    \u51bb\u7ed3vgg16\u7f51\u7edc\u7684\u4e00\u90e8\u5206\u53c2\u6570     \u6ce8\u610f\uff1a    \u4e3a\u4e86\u8fdb\u884cfine-tune,\u6240\u6709\u7684\u5c42\u90fd\u5e94\u8be5\u4ee5\u8bad\u7ec3\u597d\u7684\u6743\u91cd\u4e3a\u521d\u59cb\u503c\uff0c\u4f8b\u5982\uff0c\u4f60\u4e0d\u80fd\u5c06\u968f\u673a\u521d\u59cb\u7684\u5168\u8fde\u63a5\u653e\u5728\u9884\u8bad\u7ec3\u7684\u5377\u79ef\u5c42\u4e4b\u4e0a\uff0c\u8fd9\u662f\u56e0\u4e3a\u7531\u968f\u673a\u6743\u91cd\u4ea7\u751f\u7684\u5927\u68af\u5ea6\u5c06\u4f1a\u7834\u574f\u5377\u79ef\u5c42\u9884\u8bad\u7ec3\u7684\u6743\u91cd\u3002\u5728\u6211\u4eec\u7684\u60c5\u5f62\u4e2d\uff0c\u8fd9\u5c31\u662f\u4e3a\u4ec0\u4e48\u6211\u4eec\u9996\u5148\u8bad\u7ec3\u9876\u5c42\u5206\u7c7b\u5668\uff0c\u7136\u540e\u518d\u57fa\u4e8e\u5b83\u8fdb\u884cfine-tune\u7684\u539f\u56e0    \u6211\u4eec\u9009\u62e9\u53eafine-tune\u6700\u540e\u7684\u5377\u79ef\u5757\uff0c\u800c\u4e0d\u662f\u6574\u4e2a\u7f51\u7edc\uff0c\u8fd9\u662f\u4e3a\u4e86\u9632\u6b62\u8fc7\u62df\u5408\u3002\u6574\u4e2a\u7f51\u7edc\u5177\u6709\u5de8\u5927\u7684\u71b5\u5bb9\u91cf\uff0c\u56e0\u6b64\u5177\u6709\u5f88\u9ad8\u7684\u8fc7\u62df\u5408\u503e\u5411\u3002\u7531\u5e95\u5c42\u5377\u79ef\u6a21\u5757\u5b66\u4e60\u5230\u7684\u7279\u5f81\u66f4\u52a0\u4e00\u822c\uff0c\u66f4\u52a0\u4e0d\u5177\u6709\u62bd\u8c61\u6027\uff0c\u56e0\u6b64\u6211\u4eec\u8981\u4fdd\u6301\u524d\u4e24\u4e2a\u5377\u79ef\u5757\uff08\u5b66\u4e60\u4e00\u822c\u7279\u5f81\uff09\u4e0d\u52a8\uff0c\u53eafine-tune\u540e\u9762\u7684\u5377\u79ef\u5757\uff08\u5b66\u4e60\u7279\u522b\u7684\u7279\u5f81\uff09\u3002    fine-tune\u5e94\u8be5\u5728\u5f88\u4f4e\u7684\u5b66\u4e60\u7387\u4e0b\u8fdb\u884c\uff0c\u901a\u5e38\u4f7f\u7528SGD\u4f18\u5316\u800c\u4e0d\u662f\u5176\u4ed6\u81ea\u9002\u5e94\u5b66\u4e60\u7387\u7684\u4f18\u5316\u7b97\u6cd5\uff0c\u5982RMSProp\u3002\u8fd9\u662f\u4e3a\u4e86\u4fdd\u8bc1\u66f4\u65b0\u7684\u5e45\u5ea6\u4fdd\u6301\u5728\u8f83\u4f4e\u7684\u7a0b\u5ea6\uff0c\u4ee5\u514d\u6bc1\u574f\u9884\u8bad\u7ec3\u7684\u7279\u5f81\u3002    \u4ee3\u7801\u5982\u4e0b\uff0c\u9996\u5148\u5728\u521d\u59cb\u5316\u597d\u7684vgg\u7f51\u7edc\u4e0a\u6dfb\u52a0\u6211\u4eec\u9884\u8bad\u7ec3\u597d\u7684\u6a21\u578b\uff1a  # build a classifier model to put on top of the convolutional model\ntop_model = Sequential()\ntop_model.add(Flatten(input_shape=model.output_shape[1:]))\ntop_model.add(Dense(256, activation='relu'))\ntop_model.add(Dropout(0.5))\ntop_model.add(Dense(1, activation='sigmoid'))\n\n# note that it is necessary to start with a fully-trained\n# classifier, including the top classifier,\n# in order to successfully do fine-tuning\ntop_model.load_weights(top_model_weights_path)\n\n# add the model on top of the convolutional base\nmodel.add(top_model)  \u7136\u540e\u5c06\u6700\u540e\u4e00\u4e2a\u5377\u79ef\u5757\u524d\u7684\u5377\u79ef\u5c42\u53c2\u6570\u51bb\u7ed3\uff1a  # set the first 25 layers (up to the last conv block)\n# to non-trainable (weights will not be updated)\nfor layer in model.layers[:25]:\n    layer.trainable = False\n\n# compile the model with a SGD/momentum optimizer\n# and a very slow learning rate.\nmodel.compile(loss='binary_crossentropy',\n              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n              metrics=['accuracy'])  \u7136\u540e\u4ee5\u5f88\u4f4e\u7684\u5b66\u4e60\u7387\u8fdb\u884c\u8bad\u7ec3\uff1a  # prepare data augmentation configuration\ntrain_datagen = ImageDataGenerator(\n        rescale=1./255,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True)\n\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_generator = train_datagen.flow_from_directory(\n        train_data_dir,\n        target_size=(img_height, img_width),\n        batch_size=32,\n        class_mode='binary')\n\nvalidation_generator = test_datagen.flow_from_directory(\n        validation_data_dir,\n        target_size=(img_height, img_width),\n        batch_size=32,\n        class_mode='binary')\n\n# fine-tune the model\nmodel.fit_generator(\n        train_generator,\n        samples_per_epoch=nb_train_samples,\n        nb_epoch=nb_epoch,\n        validation_data=validation_generator,\n        nb_val_samples=nb_validation_samples)  \u572850\u4e2aepoch\u4e4b\u540e\u8be5\u65b9\u6cd5\u7684\u51c6\u786e\u7387\u4e3a94%\uff0c\u975e\u5e38\u6210\u529f  \u901a\u8fc7\u4e0b\u9762\u7684\u65b9\u6cd5\u4f60\u53ef\u4ee5\u8fbe\u523095%\u4ee5\u4e0a\u7684\u6b63\u786e\u7387\uff1a    \u66f4\u52a0\u5f3a\u70c8\u7684\u6570\u636e\u63d0\u5347    \u66f4\u52a0\u5f3a\u70c8\u7684dropout    \u4f7f\u7528L1\u548cL2\u6b63\u5219\u9879\uff08\u4e5f\u79f0\u4e3a\u6743\u91cd\u8870\u51cf\uff09    fine-tune\u66f4\u591a\u7684\u5377\u79ef\u5757\uff08\u914d\u5408\u66f4\u5927\u7684\u6b63\u5219\uff09", 
            "title": "\u5728\u9884\u8bad\u7ec3\u7684\u7f51\u7edc\u4e0afine-tune"
        }, 
        {
            "location": "/blog/word_embedding/", 
            "text": "\u5728Keras\u6a21\u578b\u4e2d\u4f7f\u7528\u9884\u8bad\u7ec3\u7684\u8bcd\u5411\u91cf\n\n\n\u6587\u7ae0\u4fe1\u606f\n\n\n\u901a\u8fc7\u672c\u6559\u7a0b\uff0c\u4f60\u53ef\u4ee5\u638c\u63e1\u6280\u80fd\uff1a\u4f7f\u7528\u9884\u5148\u8bad\u7ec3\u7684\u8bcd\u5411\u91cf\u548c\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u89e3\u51b3\u4e00\u4e2a\u6587\u672c\u5206\u7c7b\u95ee\u9898\n\u672c\u6587\u4ee3\u7801\u5df2\u4e0a\u4f20\u5230\nGithub\n\n\n\u672c\u6587\u5730\u5740\uff1a\nhttp://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html\n\n\n\u672c\u6587\u4f5c\u8005\uff1aFrancois Chollet\n\n\n\n\n\u4ec0\u4e48\u662f\u8bcd\u5411\u91cf?\n\n\n\u201d\u8bcd\u5411\u91cf\u201d\uff08\u8bcd\u5d4c\u5165\uff09\u662f\u5c06\u4e00\u7c7b\u5c06\u8bcd\u7684\u8bed\u4e49\u6620\u5c04\u5230\u5411\u91cf\u7a7a\u95f4\u4e2d\u53bb\u7684\u81ea\u7136\u8bed\u8a00\u5904\u7406\u6280\u672f\u3002\u5373\u5c06\u4e00\u4e2a\u8bcd\u7528\u7279\u5b9a\u7684\u5411\u91cf\u6765\u8868\u793a\uff0c\u5411\u91cf\u4e4b\u95f4\u7684\u8ddd\u79bb\uff08\u4f8b\u5982\uff0c\u4efb\u610f\u4e24\u4e2a\u5411\u91cf\u4e4b\u95f4\u7684L2\u8303\u5f0f\u8ddd\u79bb\u6216\u66f4\u5e38\u7528\u7684\u4f59\u5f26\u8ddd\u79bb\uff09\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u8868\u5f81\u4e86\u7684\u8bcd\u4e4b\u95f4\u7684\u8bed\u4e49\u5173\u7cfb\u3002\u7531\u8fd9\u4e9b\u5411\u91cf\u5f62\u6210\u7684\u51e0\u4f55\u7a7a\u95f4\u88ab\u79f0\u4e3a\u4e00\u4e2a\u5d4c\u5165\u7a7a\u95f4\u3002\n\n\n\u4f8b\u5982\uff0c\u201c\u6930\u5b50\u201d\u548c\u201c\u5317\u6781\u718a\u201d\u662f\u8bed\u4e49\u4e0a\u5b8c\u5168\u4e0d\u540c\u7684\u8bcd\uff0c\u6240\u4ee5\u5b83\u4eec\u7684\u8bcd\u5411\u91cf\u5728\u4e00\u4e2a\u5408\u7406\u7684\u5d4c\u5165\u7a7a\u95f4\u7684\u8ddd\u79bb\u5c06\u4f1a\u975e\u5e38\u9065\u8fdc\u3002\u4f46\u201c\u53a8\u623f\u201d\u548c\u201c\u665a\u9910\u201d\u662f\u76f8\u5173\u7684\u8bdd\uff0c\u6240\u4ee5\u5b83\u4eec\u7684\u8bcd\u5411\u91cf\u4e4b\u95f4\u7684\u8ddd\u79bb\u4f1a\u76f8\u5bf9\u5c0f\u3002\n\n\n\u7406\u60f3\u7684\u60c5\u51b5\u4e0b\uff0c\u5728\u4e00\u4e2a\u826f\u597d\u7684\u5d4c\u5165\u7a7a\u95f4\u91cc\uff0c\u4ece\u201c\u53a8\u623f\u201d\u5411\u91cf\u5230\u201c\u665a\u9910\u201d\u5411\u91cf\u7684\u201c\u8def\u5f84\u201d\u5411\u91cf\u4f1a\u7cbe\u786e\u5730\u6355\u6349\u8fd9\u4e24\u4e2a\u6982\u5ff5\u4e4b\u95f4\u7684\u8bed\u4e49\u5173\u7cfb\u3002\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u201c\u8def\u5f84\u201d\u5411\u91cf\u8868\u793a\u7684\u662f\u201c\u53d1\u751f\u7684\u5730\u70b9\u201d\uff0c\u6240\u4ee5\u4f60\u4f1a\u671f\u671b\u201c\u53a8\u623f\u201d\u5411\u91cf - \u201c\u665a\u9910\"\u5411\u91cf\uff08\u4e24\u4e2a\u8bcd\u5411\u91cf\u7684\u5dee\u5f02\uff09\u6355\u6349\u5230\u201c\u53d1\u751f\u7684\u5730\u70b9\u201d\u8fd9\u6837\u7684\u8bed\u4e49\u5173\u7cfb\u3002\u57fa\u672c\u4e0a\uff0c\u6211\u4eec\u5e94\u8be5\u6709\u5411\u91cf\u7b49\u5f0f\uff1a\u665a\u9910 + \u53d1\u751f\u7684\u5730\u70b9 = \u53a8\u623f\uff08\u81f3\u5c11\u63a5\u8fd1\uff09\u3002\u5982\u679c\u771f\u7684\u662f\u8fd9\u6837\u7684\u8bdd\uff0c\u90a3\u4e48\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u8fd9\u6837\u7684\u5173\u7cfb\u5411\u91cf\u6765\u56de\u7b54\u67d0\u4e9b\u95ee\u9898\u3002\u4f8b\u5982\uff0c\u5e94\u7528\u8fd9\u79cd\u8bed\u4e49\u5173\u7cfb\u5230\u4e00\u4e2a\u65b0\u7684\u5411\u91cf\uff0c\u6bd4\u5982\u201c\u5de5\u4f5c\u201d\uff0c\u6211\u4eec\u5e94\u8be5\u5f97\u5230\u4e00\u4e2a\u6709\u610f\u4e49\u7684\u7b49\u5f0f\uff0c\u5de5\u4f5c+ \u53d1\u751f\u7684\u5730\u70b9 = \u529e\u516c\u5ba4\uff0c\u6765\u56de\u7b54\u201c\u5de5\u4f5c\u53d1\u751f\u5728\u54ea\u91cc\uff1f\u201d\u3002\n\n\n\u8bcd\u5411\u91cf\u901a\u8fc7\u964d\u7ef4\u6280\u672f\u8868\u5f81\u6587\u672c\u6570\u636e\u96c6\u4e2d\u7684\u8bcd\u7684\u5171\u73b0\u4fe1\u606f\u3002\u65b9\u6cd5\u5305\u62ec\u795e\u7ecf\u7f51\u7edc(\u201cWord2vec\u201d\u6280\u672f)\uff0c\u6216\u77e9\u9635\u5206\u89e3\u3002\n\n\n\n\nGloVe \u8bcd\u5411\u91cf\n\n\n\u672c\u6587\u4f7f\u7528\nGloVe\u8bcd\u5411\u91cf\n\u3002GloVe \u662f \"Global Vectors for Word Representation\"\u7684\u7f29\u5199\uff0c\u4e00\u79cd\u57fa\u4e8e\u5171\u73b0\u77e9\u9635\u5206\u89e3\u7684\u8bcd\u5411\u91cf\u3002\u672c\u6587\u6240\u4f7f\u7528\u7684GloVe\u8bcd\u5411\u91cf\u662f\u57282014\u5e74\u7684\u82f1\u6587\u7ef4\u57fa\u767e\u79d1\u4e0a\u8bad\u7ec3\u7684\uff0c\u6709400k\u4e2a\u4e0d\u540c\u7684\u8bcd\uff0c\u6bcf\u4e2a\u8bcd\u7528100\u7ef4\u5411\u91cf\u8868\u793a\u3002\n\u70b9\u6b64\u4e0b\u8f7d\n (\u53cb\u60c5\u63d0\u793a\uff0c\u8bcd\u5411\u91cf\u6587\u4ef6\u5927\u5c0f\u7ea6\u4e3a822M)\n\n\n\n\n20 Newsgroup dataset\n\n\n\u672c\u6587\u4f7f\u7528\u7684\u6570\u636e\u96c6\u662f\u8457\u540d\u7684\"20 Newsgroup dataset\"\u3002\u8be5\u6570\u636e\u96c6\u5171\u670920\u79cd\u65b0\u95fb\u6587\u672c\u6570\u636e\uff0c\u6211\u4eec\u5c06\u5b9e\u73b0\u5bf9\u8be5\u6570\u636e\u96c6\u7684\u6587\u672c\u5206\u7c7b\u4efb\u52a1\u3002\u6570\u636e\u96c6\u7684\u8bf4\u660e\u548c\u4e0b\u8f7d\u8bf7\u53c2\u8003\n\u8fd9\u91cc\n\u3002\n\n\n\u4e0d\u540c\u7c7b\u522b\u7684\u65b0\u95fb\u5305\u542b\u5927\u91cf\u4e0d\u540c\u7684\u5355\u8bcd\uff0c\u5728\u8bed\u4e49\u4e0a\u5b58\u5728\u6781\u5927\u7684\u5dee\u522b\uff0c\u3002\u4e00\u4e9b\u65b0\u95fb\u7c7b\u522b\u5982\u4e0b\u6240\u793a\n\n\n\n\ncomp.sys.ibm.pc.hardware\n\n\ncomp.graphics\n\n\ncomp.os.ms-windows.misc\n\n\ncomp.sys.mac.hardware\n\n\ncomp.windows.x\n\n\nrec.autos\n\n\nrec.motorcycles\n\n\nrec.sport.baseball\n\n\nrec.sport.hockey\n\n\n\n\n\n\n\u5b9e\u9a8c\u65b9\u6cd5\n\n\n\u4ee5\u4e0b\u662f\u6211\u4eec\u5982\u4f55\u89e3\u51b3\u5206\u7c7b\u95ee\u9898\u7684\u6b65\u9aa4\n\n\n\n\n\u5c06\u6240\u6709\u7684\u65b0\u95fb\u6837\u672c\u8f6c\u5316\u4e3a\u8bcd\u7d22\u5f15\u5e8f\u5217\u3002\u6240\u8c13\u8bcd\u7d22\u5f15\u5c31\u662f\u4e3a\u6bcf\u4e00\u4e2a\u8bcd\u4f9d\u6b21\u5206\u914d\u4e00\u4e2a\u6574\u6570ID\u3002\u904d\u5386\u6240\u6709\u7684\u65b0\u95fb\u6587\u672c\uff0c\u6211\u4eec\u53ea\u4fdd\u7559\u6700\u53c2\u89c1\u768420,000\u4e2a\u8bcd\uff0c\u800c\u4e14 \u6bcf\u4e2a\u65b0\u95fb\u6587\u672c\u6700\u591a\u4fdd\u75591000\u4e2a\u8bcd\u3002\n\n\n\u751f\u6210\u4e00\u4e2a\u8bcd\u5411\u91cf\u77e9\u9635\u3002\u7b2ci\u5217\u8868\u793a\u8bcd\u7d22\u5f15\u4e3ai\u7684\u8bcd\u7684\u8bcd\u5411\u91cf\u3002\n\n\n\u5c06\u8bcd\u5411\u91cf\u77e9\u9635\u8f7d\u5165Keras Embedding\u5c42\uff0c\u8bbe\u7f6e\u8be5\u5c42\u7684\u6743\u91cd\u4e0d\u53ef\u518d\u8bad\u7ec3\uff08\u4e5f\u5c31\u662f\u8bf4\u5728\u4e4b\u540e\u7684\u7f51\u7edc\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u8bcd\u5411\u91cf\u4e0d\u518d\u6539\u53d8\uff09\u3002\n\n\nKeras Embedding\u5c42\u4e4b\u540e\u8fde\u63a5\u4e00\u4e2a1D\u7684\u5377\u79ef\u5c42\uff0c\u5e76\u7528\u4e00\u4e2asoftmax\u5168\u8fde\u63a5\u8f93\u51fa\u65b0\u95fb\u7c7b\u522b\n\n\n\n\n\u6570\u636e\u9884\u5904\u7406\n\n\n\u6211\u4eec\u9996\u5148\u904d\u5386\u4e0b\u8bed\u6599\u6587\u4ef6\u4e0b\u7684\u6240\u6709\u6587\u4ef6\u5939\uff0c\u83b7\u5f97\u4e0d\u540c\u7c7b\u522b\u7684\u65b0\u95fb\u4ee5\u53ca\u5bf9\u5e94\u7684\u7c7b\u522b\u6807\u7b7e\uff0c\u4ee3\u7801\u5982\u4e0b\u6240\u793a\n\n\ntexts = []  # list of text samples\nlabels_index = {}  # dictionary mapping label name to numeric id\nlabels = []  # list of label ids\nfor name in sorted(os.listdir(TEXT_DATA_DIR)):\n    path = os.path.join(TEXT_DATA_DIR, name)\n    if os.path.isdir(path):\n        label_id = len(labels_index)\n        labels_index[name] = label_id\n        for fname in sorted(os.listdir(path)):\n            if fname.isdigit():\n                fpath = os.path.join(path, fname)\n                f = open(fpath)\n                texts.append(f.read())\n                f.close()\n                labels.append(label_id)\n\nprint('Found %s texts.' % len(texts))\n\n\n\n\n\u4e4b\u540e\uff0c\u6211\u4eec\u53ef\u4ee5\u65b0\u95fb\u6837\u672c\u8f6c\u5316\u4e3a\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u6240\u7528\u7684\u5f20\u91cf\u3002\u6240\u7528\u5230\u7684Keras\u5e93\u662fkeras.preprocessing.text.Tokenizer\u548ckeras.preprocessing.sequence.pad_sequences\u3002\u4ee3\u7801\u5982\u4e0b\u6240\u793a\n\n\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\n\ntokenizer = Tokenizer(nb_words=MAX_NB_WORDS)\ntokenizer.fit_on_texts(texts)\nsequences = tokenizer.texts_to_sequences(texts)\n\nword_index = tokenizer.word_index\nprint('Found %s unique tokens.' % len(word_index))\n\ndata = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n\nlabels = to_categorical(np.asarray(labels))\nprint('Shape of data tensor:', data.shape)\nprint('Shape of label tensor:', labels.shape)\n\n# split the data into a training set and a validation set\nindices = np.arange(data.shape[0])\nnp.random.shuffle(indices)\ndata = data[indices]\nlabels = labels[indices]\nnb_validation_samples = int(VALIDATION_SPLIT * data.shape[0])\n\nx_train = data[:-nb_validation_samples]\ny_train = labels[:-nb_validation_samples]\nx_val = data[-nb_validation_samples:]\ny_val = labels[-nb_validation_samples:]\n\n\n\n\nEmbedding layer\u8bbe\u7f6e\n\n\n\u63a5\u4e0b\u6765\uff0c\u6211\u4eec\u4eceGloVe\u6587\u4ef6\u4e2d\u89e3\u6790\u51fa\u6bcf\u4e2a\u8bcd\u548c\u5b83\u6240\u5bf9\u5e94\u7684\u8bcd\u5411\u91cf\uff0c\u5e76\u7528\u5b57\u5178\u7684\u65b9\u5f0f\u5b58\u50a8\n\n\nembeddings_index = {}\nf = open(os.path.join(GLOVE_DIR, 'glove.6B.100d.txt'))\nfor line in f:\n    values = line.split()\n    word = values[0]\n    coefs = np.asarray(values[1:], dtype='float32')\n    embeddings_index[word] = coefs\nf.close()\n\nprint('Found %s word vectors.' % len(embeddings_index))\n\n\n\n\n\u6b64\u65f6\uff0c\u6211\u4eec\u53ef\u4ee5\u6839\u636e\u5f97\u5230\u7684\u5b57\u5178\u751f\u6210\u4e0a\u6587\u6240\u5b9a\u4e49\u7684\u8bcd\u5411\u91cf\u77e9\u9635\n\n\nembedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\nfor word, i in word_index.items():\n    embedding_vector = embeddings_index.get(word)\n    if embedding_vector is not None:\n        # words not found in embedding index will be all-zeros.\n        embedding_matrix[i] = embedding_vector\n\n\n\n\n\u73b0\u5728\u6211\u4eec\u5c06\u8fd9\u4e2a\u8bcd\u5411\u91cf\u77e9\u9635\u52a0\u8f7d\u5230Embedding\u5c42\u4e2d\uff0c\u6ce8\u610f\uff0c\u6211\u4eec\u8bbe\u7f6etrainable=False\u4f7f\u5f97\u8fd9\u4e2a\u7f16\u7801\u5c42\u4e0d\u53ef\u518d\u8bad\u7ec3\u3002\n\n\nfrom keras.layers import Embedding\n\nembedding_layer = Embedding(len(word_index) + 1,\n                            EMBEDDING_DIM,\n                            weights=[embedding_matrix],\n                            input_length=MAX_SEQUENCE_LENGTH,\n                            trainable=False)\n\n\n\n\n\n\u4e00\u4e2aEmbedding\u5c42\u7684\u8f93\u5165\u5e94\u8be5\u662f\u4e00\u7cfb\u5217\u7684\u6574\u6570\u5e8f\u5217\uff0c\u6bd4\u5982\u4e00\u4e2a2D\u7684\u8f93\u5165\uff0c\u5b83\u7684shape\u503c\u4e3a(samples, indices)\uff0c\u4e5f\u5c31\u662f\u4e00\u4e2asamples\u884c\uff0cindeces\u5217\u7684\u77e9\u9635\u3002\u6bcf\u4e00\u6b21\u7684batch\u8bad\u7ec3\u7684\u8f93\u5165\u5e94\u8be5\u88abpadded\u6210\u76f8\u540c\u5927\u5c0f\uff08\u5c3d\u7ba1Embedding\u5c42\u6709\u80fd\u529b\u5904\u7406\u4e0d\u5b9a\u957f\u5e8f\u5217\uff0c\u5982\u679c\u4f60\u4e0d\u6307\u5b9a\u6570\u5217\u957f\u5ea6\u8fd9\u4e00\u53c2\u6570\uff09\ndim).\n\u6240\u6709\u7684\u5e8f\u5217\u4e2d\u7684\u6574\u6570\u90fd\u5c06\u88ab\u5bf9\u5e94\u7684\u8bcd\u5411\u91cf\u77e9\u9635\u4e2d\u5bf9\u5e94\u7684\u5217\uff08\u4e5f\u5c31\u662f\u5b83\u7684\u8bcd\u5411\u91cf\uff09\u4ee3\u66ff,\u6bd4\u5982\u5e8f\u5217[1,2]\u5c06\u88ab\u5e8f\u5217[\u8bcd\u5411\u91cf[1],\u8bcd\u5411\u91cf[2]]\u4ee3\u66ff\u3002\u8fd9\u6837\uff0c\u8f93\u5165\u4e00\u4e2a2D\u5f20\u91cf\u540e\uff0c\u6211\u4eec\u53ef\u4ee5\u5f97\u5230\u4e00\u4e2a3D\u5f20\u91cf\u3002\n\n\n\u8bad\u7ec31D\u5377\u79ef\n\n\n\u6700\u540e\uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u4e00\u4e2a\u5c0f\u578b\u76841D\u5377\u79ef\u89e3\u51b3\u8fd9\u4e2a\u65b0\u95fb\u5206\u7c7b\u95ee\u9898\u3002\n\n\nsequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\nembedded_sequences = embedding_layer(sequence_input)\nx = Conv1D(128, 5, activation='relu')(embedded_sequences)\nx = MaxPooling1D(5)(x)\nx = Conv1D(128, 5, activation='relu')(x)\nx = MaxPooling1D(5)(x)\nx = Conv1D(128, 5, activation='relu')(x)\nx = MaxPooling1D(35)(x)  # global max pooling\nx = Flatten()(x)\nx = Dense(128, activation='relu')(x)\npreds = Dense(len(labels_index), activation='softmax')(x)\n\nmodel = Model(sequence_input, preds)\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='rmsprop',\n              metrics=['acc'])\n\n# happy learning!\nmodel.fit(x_train, y_train, validation_data=(x_val, y_val),\n          nb_epoch=2, batch_size=128)\n\n\n\n\n\u5728\u4e24\u6b21\u8fed\u4ee3\u4e4b\u540e\uff0c\u8fd9\u4e2a\u6a21\u578b\u6700\u540e\u53ef\u4ee5\u8fbe\u52300.95\u7684\u5206\u7c7b\u51c6\u786e\u7387\uff084:1\u5206\u5272\u8bad\u7ec3\u548c\u6d4b\u8bd5\u96c6\u5408\uff09\u3002\u4f60\u53ef\u4ee5\u5229\u7528\u6b63\u5219\u65b9\u6cd5\uff08\u4f8b\u5982dropout\uff09\u6216\u5728Embedding\u5c42\u4e0a\u8fdb\u884cfine-tuning\u83b7\u5f97\u66f4\u9ad8\u7684\u51c6\u786e\u7387\u3002\n\n\n\u6211\u4eec\u53ef\u4ee5\u505a\u4e00\u4e2a\u5bf9\u6bd4\u5b9e\u9a8c\uff0c\u76f4\u63a5\u4f7f\u7528Keras\u81ea\u5e26\u7684Embedding\u5c42\u8bad\u7ec3\u8bcd\u5411\u91cf\u800c\u4e0d\u7528GloVe\u5411\u91cf\u3002\u4ee3\u7801\u5982\u4e0b\u6240\u793a\n\n\nembedding_layer = Embedding(len(word_index) + 1,\n                            EMBEDDING_DIM,\n                            input_length=MAX_SEQUENCE_LENGTH)\n\n\n\n\n\u4e24\u6b21\u8fed\u4ee3\u4e4b\u540e\uff0c\u6211\u4eec\u53ef\u4ee5\u5f97\u52300.9\u7684\u51c6\u786e\u7387\u3002\u6240\u4ee5\u4f7f\u7528\u9884\u8bad\u7ec3\u7684\u8bcd\u5411\u91cf\u4f5c\u4e3a\u7279\u5f81\u662f\u975e\u5e38\u6709\u6548\u7684\u3002\u4e00\u822c\u6765\u8bf4\uff0c\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4efb\u52a1\u4e2d\uff0c\u5f53\u6837\u672c\u6570\u91cf\u975e\u5e38\u5c11\u65f6\uff0c\u4f7f\u7528\u9884\u8bad\u7ec3\u7684\u8bcd\u5411\u91cf\u662f\u53ef\u884c\u7684\uff08\u5b9e\u9645\u4e0a\uff0c\u9884\u8bad\u7ec3\u7684\u8bcd\u5411\u91cf\u5f15\u5165\u4e86\u5916\u90e8\u8bed\u4e49\u4fe1\u606f\uff0c\u5f80\u5f80\u5bf9\u6a21\u578b\u5f88\u6709\u5e2e\u52a9\uff09\u3002\n\n\n\u4ee5\u4e0b\u90e8\u5206\u4e3a\u8bd1\u8005\u6dfb\u52a0\n\n\n\u56fd\u5185\u7684Rachel-Zhang\u7528sklearn\u5bf9\u540c\u6837\u7684\u6570\u636e\u96c6\u505a\u8fc7\u57fa\u4e8e\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u7684\u5b9e\u9a8c\uff0c\u8bf7\u70b9\u51fb\n\u8fd9\u91cc\n\u3002\n\u540c\u65f6Richard Socher\u7b49\u5728\u63d0\u51faGloVe\u8bcd\u5411\u91cf\u7684\u90a3\u7bc7\u8bba\u6587\u4e2d\u6307\u51faGloVe\u8bcd\u5411\u91cf\u6bd4word2vec\u7684\u6027\u80fd\u66f4\u597d[1]\u3002\u4e4b\u540e\u7684\u7814\u7a76\u8868\u793aword2vec\u548cGloVe\u5176\u5b9e\u5404\u6709\u5343\u79cb\uff0c\u4f8b\u5982Schnabel\u7b49\u63d0\u51fa\u4e86\u7528\u4e8e\u6d4b\u8bc4\u8bcd\u5411\u91cf\u7684\u5404\u9879\u6307\u6807\uff0c\u6d4b\u8bc4\u663e\u793a word2vec\u5728\u5927\u90e8\u5206\u6d4b\u8bc4\u6307\u6807\u4f18\u4e8eGloVe\u548cC\nW\u8bcd\u5411\u91cf[2]\u3002\u672c\u6587\u5b9e\u73b0\u5176\u5b9e\u53ef\u4ee5\u5229\u7528\u8c37\u6b4c\u65b0\u95fb\u7684\nword2vec\u8bcd\u5411\u91cf\n\u518d\u505a\u4e00\u7ec4\u6d4b\u8bc4\u5b9e\u9a8c\u3002\n\n\n\u53c2\u8003\u6587\u732e\n\n\n[1]: Pennington J, Socher R, Manning C D. Glove: Global Vectors for Word Representation[C]//EMNLP. 2014, 14: 1532-1543\n\n\n[2]: Schnabel T, Labutov I, Mimno D, et al. Evaluation methods for unsupervised word embeddings[C]//Proc. of EMNLP. 2015", 
            "title": "\u5728Keras\u6a21\u578b\u4e2d\u4f7f\u7528\u9884\u8bad\u7ec3\u7684\u8bcd\u5411\u91cf"
        }, 
        {
            "location": "/blog/word_embedding/#keras", 
            "text": "", 
            "title": "\u5728Keras\u6a21\u578b\u4e2d\u4f7f\u7528\u9884\u8bad\u7ec3\u7684\u8bcd\u5411\u91cf"
        }, 
        {
            "location": "/blog/word_embedding/#_1", 
            "text": "\u901a\u8fc7\u672c\u6559\u7a0b\uff0c\u4f60\u53ef\u4ee5\u638c\u63e1\u6280\u80fd\uff1a\u4f7f\u7528\u9884\u5148\u8bad\u7ec3\u7684\u8bcd\u5411\u91cf\u548c\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u89e3\u51b3\u4e00\u4e2a\u6587\u672c\u5206\u7c7b\u95ee\u9898\n\u672c\u6587\u4ee3\u7801\u5df2\u4e0a\u4f20\u5230 Github  \u672c\u6587\u5730\u5740\uff1a http://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html  \u672c\u6587\u4f5c\u8005\uff1aFrancois Chollet", 
            "title": "\u6587\u7ae0\u4fe1\u606f"
        }, 
        {
            "location": "/blog/word_embedding/#_2", 
            "text": "\u201d\u8bcd\u5411\u91cf\u201d\uff08\u8bcd\u5d4c\u5165\uff09\u662f\u5c06\u4e00\u7c7b\u5c06\u8bcd\u7684\u8bed\u4e49\u6620\u5c04\u5230\u5411\u91cf\u7a7a\u95f4\u4e2d\u53bb\u7684\u81ea\u7136\u8bed\u8a00\u5904\u7406\u6280\u672f\u3002\u5373\u5c06\u4e00\u4e2a\u8bcd\u7528\u7279\u5b9a\u7684\u5411\u91cf\u6765\u8868\u793a\uff0c\u5411\u91cf\u4e4b\u95f4\u7684\u8ddd\u79bb\uff08\u4f8b\u5982\uff0c\u4efb\u610f\u4e24\u4e2a\u5411\u91cf\u4e4b\u95f4\u7684L2\u8303\u5f0f\u8ddd\u79bb\u6216\u66f4\u5e38\u7528\u7684\u4f59\u5f26\u8ddd\u79bb\uff09\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u8868\u5f81\u4e86\u7684\u8bcd\u4e4b\u95f4\u7684\u8bed\u4e49\u5173\u7cfb\u3002\u7531\u8fd9\u4e9b\u5411\u91cf\u5f62\u6210\u7684\u51e0\u4f55\u7a7a\u95f4\u88ab\u79f0\u4e3a\u4e00\u4e2a\u5d4c\u5165\u7a7a\u95f4\u3002  \u4f8b\u5982\uff0c\u201c\u6930\u5b50\u201d\u548c\u201c\u5317\u6781\u718a\u201d\u662f\u8bed\u4e49\u4e0a\u5b8c\u5168\u4e0d\u540c\u7684\u8bcd\uff0c\u6240\u4ee5\u5b83\u4eec\u7684\u8bcd\u5411\u91cf\u5728\u4e00\u4e2a\u5408\u7406\u7684\u5d4c\u5165\u7a7a\u95f4\u7684\u8ddd\u79bb\u5c06\u4f1a\u975e\u5e38\u9065\u8fdc\u3002\u4f46\u201c\u53a8\u623f\u201d\u548c\u201c\u665a\u9910\u201d\u662f\u76f8\u5173\u7684\u8bdd\uff0c\u6240\u4ee5\u5b83\u4eec\u7684\u8bcd\u5411\u91cf\u4e4b\u95f4\u7684\u8ddd\u79bb\u4f1a\u76f8\u5bf9\u5c0f\u3002  \u7406\u60f3\u7684\u60c5\u51b5\u4e0b\uff0c\u5728\u4e00\u4e2a\u826f\u597d\u7684\u5d4c\u5165\u7a7a\u95f4\u91cc\uff0c\u4ece\u201c\u53a8\u623f\u201d\u5411\u91cf\u5230\u201c\u665a\u9910\u201d\u5411\u91cf\u7684\u201c\u8def\u5f84\u201d\u5411\u91cf\u4f1a\u7cbe\u786e\u5730\u6355\u6349\u8fd9\u4e24\u4e2a\u6982\u5ff5\u4e4b\u95f4\u7684\u8bed\u4e49\u5173\u7cfb\u3002\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u201c\u8def\u5f84\u201d\u5411\u91cf\u8868\u793a\u7684\u662f\u201c\u53d1\u751f\u7684\u5730\u70b9\u201d\uff0c\u6240\u4ee5\u4f60\u4f1a\u671f\u671b\u201c\u53a8\u623f\u201d\u5411\u91cf - \u201c\u665a\u9910\"\u5411\u91cf\uff08\u4e24\u4e2a\u8bcd\u5411\u91cf\u7684\u5dee\u5f02\uff09\u6355\u6349\u5230\u201c\u53d1\u751f\u7684\u5730\u70b9\u201d\u8fd9\u6837\u7684\u8bed\u4e49\u5173\u7cfb\u3002\u57fa\u672c\u4e0a\uff0c\u6211\u4eec\u5e94\u8be5\u6709\u5411\u91cf\u7b49\u5f0f\uff1a\u665a\u9910 + \u53d1\u751f\u7684\u5730\u70b9 = \u53a8\u623f\uff08\u81f3\u5c11\u63a5\u8fd1\uff09\u3002\u5982\u679c\u771f\u7684\u662f\u8fd9\u6837\u7684\u8bdd\uff0c\u90a3\u4e48\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u8fd9\u6837\u7684\u5173\u7cfb\u5411\u91cf\u6765\u56de\u7b54\u67d0\u4e9b\u95ee\u9898\u3002\u4f8b\u5982\uff0c\u5e94\u7528\u8fd9\u79cd\u8bed\u4e49\u5173\u7cfb\u5230\u4e00\u4e2a\u65b0\u7684\u5411\u91cf\uff0c\u6bd4\u5982\u201c\u5de5\u4f5c\u201d\uff0c\u6211\u4eec\u5e94\u8be5\u5f97\u5230\u4e00\u4e2a\u6709\u610f\u4e49\u7684\u7b49\u5f0f\uff0c\u5de5\u4f5c+ \u53d1\u751f\u7684\u5730\u70b9 = \u529e\u516c\u5ba4\uff0c\u6765\u56de\u7b54\u201c\u5de5\u4f5c\u53d1\u751f\u5728\u54ea\u91cc\uff1f\u201d\u3002  \u8bcd\u5411\u91cf\u901a\u8fc7\u964d\u7ef4\u6280\u672f\u8868\u5f81\u6587\u672c\u6570\u636e\u96c6\u4e2d\u7684\u8bcd\u7684\u5171\u73b0\u4fe1\u606f\u3002\u65b9\u6cd5\u5305\u62ec\u795e\u7ecf\u7f51\u7edc(\u201cWord2vec\u201d\u6280\u672f)\uff0c\u6216\u77e9\u9635\u5206\u89e3\u3002", 
            "title": "\u4ec0\u4e48\u662f\u8bcd\u5411\u91cf?"
        }, 
        {
            "location": "/blog/word_embedding/#glove", 
            "text": "\u672c\u6587\u4f7f\u7528 GloVe\u8bcd\u5411\u91cf \u3002GloVe \u662f \"Global Vectors for Word Representation\"\u7684\u7f29\u5199\uff0c\u4e00\u79cd\u57fa\u4e8e\u5171\u73b0\u77e9\u9635\u5206\u89e3\u7684\u8bcd\u5411\u91cf\u3002\u672c\u6587\u6240\u4f7f\u7528\u7684GloVe\u8bcd\u5411\u91cf\u662f\u57282014\u5e74\u7684\u82f1\u6587\u7ef4\u57fa\u767e\u79d1\u4e0a\u8bad\u7ec3\u7684\uff0c\u6709400k\u4e2a\u4e0d\u540c\u7684\u8bcd\uff0c\u6bcf\u4e2a\u8bcd\u7528100\u7ef4\u5411\u91cf\u8868\u793a\u3002 \u70b9\u6b64\u4e0b\u8f7d  (\u53cb\u60c5\u63d0\u793a\uff0c\u8bcd\u5411\u91cf\u6587\u4ef6\u5927\u5c0f\u7ea6\u4e3a822M)", 
            "title": "GloVe \u8bcd\u5411\u91cf"
        }, 
        {
            "location": "/blog/word_embedding/#20-newsgroup-dataset", 
            "text": "\u672c\u6587\u4f7f\u7528\u7684\u6570\u636e\u96c6\u662f\u8457\u540d\u7684\"20 Newsgroup dataset\"\u3002\u8be5\u6570\u636e\u96c6\u5171\u670920\u79cd\u65b0\u95fb\u6587\u672c\u6570\u636e\uff0c\u6211\u4eec\u5c06\u5b9e\u73b0\u5bf9\u8be5\u6570\u636e\u96c6\u7684\u6587\u672c\u5206\u7c7b\u4efb\u52a1\u3002\u6570\u636e\u96c6\u7684\u8bf4\u660e\u548c\u4e0b\u8f7d\u8bf7\u53c2\u8003 \u8fd9\u91cc \u3002  \u4e0d\u540c\u7c7b\u522b\u7684\u65b0\u95fb\u5305\u542b\u5927\u91cf\u4e0d\u540c\u7684\u5355\u8bcd\uff0c\u5728\u8bed\u4e49\u4e0a\u5b58\u5728\u6781\u5927\u7684\u5dee\u522b\uff0c\u3002\u4e00\u4e9b\u65b0\u95fb\u7c7b\u522b\u5982\u4e0b\u6240\u793a   comp.sys.ibm.pc.hardware  comp.graphics  comp.os.ms-windows.misc  comp.sys.mac.hardware  comp.windows.x  rec.autos  rec.motorcycles  rec.sport.baseball  rec.sport.hockey", 
            "title": "20 Newsgroup dataset"
        }, 
        {
            "location": "/blog/word_embedding/#_3", 
            "text": "\u4ee5\u4e0b\u662f\u6211\u4eec\u5982\u4f55\u89e3\u51b3\u5206\u7c7b\u95ee\u9898\u7684\u6b65\u9aa4   \u5c06\u6240\u6709\u7684\u65b0\u95fb\u6837\u672c\u8f6c\u5316\u4e3a\u8bcd\u7d22\u5f15\u5e8f\u5217\u3002\u6240\u8c13\u8bcd\u7d22\u5f15\u5c31\u662f\u4e3a\u6bcf\u4e00\u4e2a\u8bcd\u4f9d\u6b21\u5206\u914d\u4e00\u4e2a\u6574\u6570ID\u3002\u904d\u5386\u6240\u6709\u7684\u65b0\u95fb\u6587\u672c\uff0c\u6211\u4eec\u53ea\u4fdd\u7559\u6700\u53c2\u89c1\u768420,000\u4e2a\u8bcd\uff0c\u800c\u4e14 \u6bcf\u4e2a\u65b0\u95fb\u6587\u672c\u6700\u591a\u4fdd\u75591000\u4e2a\u8bcd\u3002  \u751f\u6210\u4e00\u4e2a\u8bcd\u5411\u91cf\u77e9\u9635\u3002\u7b2ci\u5217\u8868\u793a\u8bcd\u7d22\u5f15\u4e3ai\u7684\u8bcd\u7684\u8bcd\u5411\u91cf\u3002  \u5c06\u8bcd\u5411\u91cf\u77e9\u9635\u8f7d\u5165Keras Embedding\u5c42\uff0c\u8bbe\u7f6e\u8be5\u5c42\u7684\u6743\u91cd\u4e0d\u53ef\u518d\u8bad\u7ec3\uff08\u4e5f\u5c31\u662f\u8bf4\u5728\u4e4b\u540e\u7684\u7f51\u7edc\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u8bcd\u5411\u91cf\u4e0d\u518d\u6539\u53d8\uff09\u3002  Keras Embedding\u5c42\u4e4b\u540e\u8fde\u63a5\u4e00\u4e2a1D\u7684\u5377\u79ef\u5c42\uff0c\u5e76\u7528\u4e00\u4e2asoftmax\u5168\u8fde\u63a5\u8f93\u51fa\u65b0\u95fb\u7c7b\u522b", 
            "title": "\u5b9e\u9a8c\u65b9\u6cd5"
        }, 
        {
            "location": "/blog/word_embedding/#_4", 
            "text": "\u6211\u4eec\u9996\u5148\u904d\u5386\u4e0b\u8bed\u6599\u6587\u4ef6\u4e0b\u7684\u6240\u6709\u6587\u4ef6\u5939\uff0c\u83b7\u5f97\u4e0d\u540c\u7c7b\u522b\u7684\u65b0\u95fb\u4ee5\u53ca\u5bf9\u5e94\u7684\u7c7b\u522b\u6807\u7b7e\uff0c\u4ee3\u7801\u5982\u4e0b\u6240\u793a  texts = []  # list of text samples\nlabels_index = {}  # dictionary mapping label name to numeric id\nlabels = []  # list of label ids\nfor name in sorted(os.listdir(TEXT_DATA_DIR)):\n    path = os.path.join(TEXT_DATA_DIR, name)\n    if os.path.isdir(path):\n        label_id = len(labels_index)\n        labels_index[name] = label_id\n        for fname in sorted(os.listdir(path)):\n            if fname.isdigit():\n                fpath = os.path.join(path, fname)\n                f = open(fpath)\n                texts.append(f.read())\n                f.close()\n                labels.append(label_id)\n\nprint('Found %s texts.' % len(texts))  \u4e4b\u540e\uff0c\u6211\u4eec\u53ef\u4ee5\u65b0\u95fb\u6837\u672c\u8f6c\u5316\u4e3a\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u6240\u7528\u7684\u5f20\u91cf\u3002\u6240\u7528\u5230\u7684Keras\u5e93\u662fkeras.preprocessing.text.Tokenizer\u548ckeras.preprocessing.sequence.pad_sequences\u3002\u4ee3\u7801\u5982\u4e0b\u6240\u793a  from keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\n\ntokenizer = Tokenizer(nb_words=MAX_NB_WORDS)\ntokenizer.fit_on_texts(texts)\nsequences = tokenizer.texts_to_sequences(texts)\n\nword_index = tokenizer.word_index\nprint('Found %s unique tokens.' % len(word_index))\n\ndata = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n\nlabels = to_categorical(np.asarray(labels))\nprint('Shape of data tensor:', data.shape)\nprint('Shape of label tensor:', labels.shape)\n\n# split the data into a training set and a validation set\nindices = np.arange(data.shape[0])\nnp.random.shuffle(indices)\ndata = data[indices]\nlabels = labels[indices]\nnb_validation_samples = int(VALIDATION_SPLIT * data.shape[0])\n\nx_train = data[:-nb_validation_samples]\ny_train = labels[:-nb_validation_samples]\nx_val = data[-nb_validation_samples:]\ny_val = labels[-nb_validation_samples:]", 
            "title": "\u6570\u636e\u9884\u5904\u7406"
        }, 
        {
            "location": "/blog/word_embedding/#embedding-layer", 
            "text": "\u63a5\u4e0b\u6765\uff0c\u6211\u4eec\u4eceGloVe\u6587\u4ef6\u4e2d\u89e3\u6790\u51fa\u6bcf\u4e2a\u8bcd\u548c\u5b83\u6240\u5bf9\u5e94\u7684\u8bcd\u5411\u91cf\uff0c\u5e76\u7528\u5b57\u5178\u7684\u65b9\u5f0f\u5b58\u50a8  embeddings_index = {}\nf = open(os.path.join(GLOVE_DIR, 'glove.6B.100d.txt'))\nfor line in f:\n    values = line.split()\n    word = values[0]\n    coefs = np.asarray(values[1:], dtype='float32')\n    embeddings_index[word] = coefs\nf.close()\n\nprint('Found %s word vectors.' % len(embeddings_index))  \u6b64\u65f6\uff0c\u6211\u4eec\u53ef\u4ee5\u6839\u636e\u5f97\u5230\u7684\u5b57\u5178\u751f\u6210\u4e0a\u6587\u6240\u5b9a\u4e49\u7684\u8bcd\u5411\u91cf\u77e9\u9635  embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\nfor word, i in word_index.items():\n    embedding_vector = embeddings_index.get(word)\n    if embedding_vector is not None:\n        # words not found in embedding index will be all-zeros.\n        embedding_matrix[i] = embedding_vector  \u73b0\u5728\u6211\u4eec\u5c06\u8fd9\u4e2a\u8bcd\u5411\u91cf\u77e9\u9635\u52a0\u8f7d\u5230Embedding\u5c42\u4e2d\uff0c\u6ce8\u610f\uff0c\u6211\u4eec\u8bbe\u7f6etrainable=False\u4f7f\u5f97\u8fd9\u4e2a\u7f16\u7801\u5c42\u4e0d\u53ef\u518d\u8bad\u7ec3\u3002  from keras.layers import Embedding\n\nembedding_layer = Embedding(len(word_index) + 1,\n                            EMBEDDING_DIM,\n                            weights=[embedding_matrix],\n                            input_length=MAX_SEQUENCE_LENGTH,\n                            trainable=False)  \u4e00\u4e2aEmbedding\u5c42\u7684\u8f93\u5165\u5e94\u8be5\u662f\u4e00\u7cfb\u5217\u7684\u6574\u6570\u5e8f\u5217\uff0c\u6bd4\u5982\u4e00\u4e2a2D\u7684\u8f93\u5165\uff0c\u5b83\u7684shape\u503c\u4e3a(samples, indices)\uff0c\u4e5f\u5c31\u662f\u4e00\u4e2asamples\u884c\uff0cindeces\u5217\u7684\u77e9\u9635\u3002\u6bcf\u4e00\u6b21\u7684batch\u8bad\u7ec3\u7684\u8f93\u5165\u5e94\u8be5\u88abpadded\u6210\u76f8\u540c\u5927\u5c0f\uff08\u5c3d\u7ba1Embedding\u5c42\u6709\u80fd\u529b\u5904\u7406\u4e0d\u5b9a\u957f\u5e8f\u5217\uff0c\u5982\u679c\u4f60\u4e0d\u6307\u5b9a\u6570\u5217\u957f\u5ea6\u8fd9\u4e00\u53c2\u6570\uff09\ndim).\n\u6240\u6709\u7684\u5e8f\u5217\u4e2d\u7684\u6574\u6570\u90fd\u5c06\u88ab\u5bf9\u5e94\u7684\u8bcd\u5411\u91cf\u77e9\u9635\u4e2d\u5bf9\u5e94\u7684\u5217\uff08\u4e5f\u5c31\u662f\u5b83\u7684\u8bcd\u5411\u91cf\uff09\u4ee3\u66ff,\u6bd4\u5982\u5e8f\u5217[1,2]\u5c06\u88ab\u5e8f\u5217[\u8bcd\u5411\u91cf[1],\u8bcd\u5411\u91cf[2]]\u4ee3\u66ff\u3002\u8fd9\u6837\uff0c\u8f93\u5165\u4e00\u4e2a2D\u5f20\u91cf\u540e\uff0c\u6211\u4eec\u53ef\u4ee5\u5f97\u5230\u4e00\u4e2a3D\u5f20\u91cf\u3002", 
            "title": "Embedding layer\u8bbe\u7f6e"
        }, 
        {
            "location": "/blog/word_embedding/#1d", 
            "text": "\u6700\u540e\uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u4e00\u4e2a\u5c0f\u578b\u76841D\u5377\u79ef\u89e3\u51b3\u8fd9\u4e2a\u65b0\u95fb\u5206\u7c7b\u95ee\u9898\u3002  sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\nembedded_sequences = embedding_layer(sequence_input)\nx = Conv1D(128, 5, activation='relu')(embedded_sequences)\nx = MaxPooling1D(5)(x)\nx = Conv1D(128, 5, activation='relu')(x)\nx = MaxPooling1D(5)(x)\nx = Conv1D(128, 5, activation='relu')(x)\nx = MaxPooling1D(35)(x)  # global max pooling\nx = Flatten()(x)\nx = Dense(128, activation='relu')(x)\npreds = Dense(len(labels_index), activation='softmax')(x)\n\nmodel = Model(sequence_input, preds)\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='rmsprop',\n              metrics=['acc'])\n\n# happy learning!\nmodel.fit(x_train, y_train, validation_data=(x_val, y_val),\n          nb_epoch=2, batch_size=128)  \u5728\u4e24\u6b21\u8fed\u4ee3\u4e4b\u540e\uff0c\u8fd9\u4e2a\u6a21\u578b\u6700\u540e\u53ef\u4ee5\u8fbe\u52300.95\u7684\u5206\u7c7b\u51c6\u786e\u7387\uff084:1\u5206\u5272\u8bad\u7ec3\u548c\u6d4b\u8bd5\u96c6\u5408\uff09\u3002\u4f60\u53ef\u4ee5\u5229\u7528\u6b63\u5219\u65b9\u6cd5\uff08\u4f8b\u5982dropout\uff09\u6216\u5728Embedding\u5c42\u4e0a\u8fdb\u884cfine-tuning\u83b7\u5f97\u66f4\u9ad8\u7684\u51c6\u786e\u7387\u3002  \u6211\u4eec\u53ef\u4ee5\u505a\u4e00\u4e2a\u5bf9\u6bd4\u5b9e\u9a8c\uff0c\u76f4\u63a5\u4f7f\u7528Keras\u81ea\u5e26\u7684Embedding\u5c42\u8bad\u7ec3\u8bcd\u5411\u91cf\u800c\u4e0d\u7528GloVe\u5411\u91cf\u3002\u4ee3\u7801\u5982\u4e0b\u6240\u793a  embedding_layer = Embedding(len(word_index) + 1,\n                            EMBEDDING_DIM,\n                            input_length=MAX_SEQUENCE_LENGTH)  \u4e24\u6b21\u8fed\u4ee3\u4e4b\u540e\uff0c\u6211\u4eec\u53ef\u4ee5\u5f97\u52300.9\u7684\u51c6\u786e\u7387\u3002\u6240\u4ee5\u4f7f\u7528\u9884\u8bad\u7ec3\u7684\u8bcd\u5411\u91cf\u4f5c\u4e3a\u7279\u5f81\u662f\u975e\u5e38\u6709\u6548\u7684\u3002\u4e00\u822c\u6765\u8bf4\uff0c\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4efb\u52a1\u4e2d\uff0c\u5f53\u6837\u672c\u6570\u91cf\u975e\u5e38\u5c11\u65f6\uff0c\u4f7f\u7528\u9884\u8bad\u7ec3\u7684\u8bcd\u5411\u91cf\u662f\u53ef\u884c\u7684\uff08\u5b9e\u9645\u4e0a\uff0c\u9884\u8bad\u7ec3\u7684\u8bcd\u5411\u91cf\u5f15\u5165\u4e86\u5916\u90e8\u8bed\u4e49\u4fe1\u606f\uff0c\u5f80\u5f80\u5bf9\u6a21\u578b\u5f88\u6709\u5e2e\u52a9\uff09\u3002", 
            "title": "\u8bad\u7ec31D\u5377\u79ef"
        }, 
        {
            "location": "/blog/word_embedding/#_5", 
            "text": "\u56fd\u5185\u7684Rachel-Zhang\u7528sklearn\u5bf9\u540c\u6837\u7684\u6570\u636e\u96c6\u505a\u8fc7\u57fa\u4e8e\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u7684\u5b9e\u9a8c\uff0c\u8bf7\u70b9\u51fb \u8fd9\u91cc \u3002\n\u540c\u65f6Richard Socher\u7b49\u5728\u63d0\u51faGloVe\u8bcd\u5411\u91cf\u7684\u90a3\u7bc7\u8bba\u6587\u4e2d\u6307\u51faGloVe\u8bcd\u5411\u91cf\u6bd4word2vec\u7684\u6027\u80fd\u66f4\u597d[1]\u3002\u4e4b\u540e\u7684\u7814\u7a76\u8868\u793aword2vec\u548cGloVe\u5176\u5b9e\u5404\u6709\u5343\u79cb\uff0c\u4f8b\u5982Schnabel\u7b49\u63d0\u51fa\u4e86\u7528\u4e8e\u6d4b\u8bc4\u8bcd\u5411\u91cf\u7684\u5404\u9879\u6307\u6807\uff0c\u6d4b\u8bc4\u663e\u793a word2vec\u5728\u5927\u90e8\u5206\u6d4b\u8bc4\u6307\u6807\u4f18\u4e8eGloVe\u548cC W\u8bcd\u5411\u91cf[2]\u3002\u672c\u6587\u5b9e\u73b0\u5176\u5b9e\u53ef\u4ee5\u5229\u7528\u8c37\u6b4c\u65b0\u95fb\u7684 word2vec\u8bcd\u5411\u91cf \u518d\u505a\u4e00\u7ec4\u6d4b\u8bc4\u5b9e\u9a8c\u3002", 
            "title": "\u4ee5\u4e0b\u90e8\u5206\u4e3a\u8bd1\u8005\u6dfb\u52a0"
        }, 
        {
            "location": "/blog/word_embedding/#_6", 
            "text": "[1]: Pennington J, Socher R, Manning C D. Glove: Global Vectors for Word Representation[C]//EMNLP. 2014, 14: 1532-1543  [2]: Schnabel T, Labutov I, Mimno D, et al. Evaluation methods for unsupervised word embeddings[C]//Proc. of EMNLP. 2015", 
            "title": "\u53c2\u8003\u6587\u732e"
        }, 
        {
            "location": "/blog/keras_and_tensorflow/", 
            "text": "\u5c06Keras\u4f5c\u4e3atensorflow\u7684\u7cbe\u7b80\u63a5\u53e3\n\n\n\u6587\u7ae0\u4fe1\u606f\n\n\n\u672c\u6587\u5730\u5740\uff1a\nhttps://blog.keras.io/keras-as-a-simplified-interface-to-tensorflow-tutorial.html\n\n\n\u672c\u6587\u4f5c\u8005\uff1aFrancois Chollet\n\n\n\n\u4f7f\u7528Keras\u4f5c\u4e3aTensorFlow\u5de5\u4f5c\u6d41\u7684\u4e00\u90e8\u5206\n\n\n\u5982\u679cTensorflow\u662f\u4f60\u7684\u9996\u9009\u6846\u67b6\uff0c\u5e76\u4e14\u4f60\u60f3\u627e\u4e00\u4e2a\u7b80\u5316\u7684\u3001\u9ad8\u5c42\u7684\u6a21\u578b\u5b9a\u4e49\u63a5\u53e3\u6765\u8ba9\u81ea\u5df1\u6d3b\u7684\u4e0d\u90a3\u4e48\u7d2f\uff0c\u90a3\u4e48\u8fd9\u7bc7\u6587\u7ae0\u5c31\u662f\u7ed9\u4f60\u770b\u7684\n\n\nKeras\u7684\u5c42\u548c\u6a21\u578b\u4e0e\u7eafTensorFlow\u7684tensor\u5b8c\u5168\u517c\u5bb9\uff0c\u56e0\u6b64\uff0cKeras\u53ef\u4ee5\u4f5c\u4e3aTensorFlow\u7684\u6a21\u578b\u5b9a\u4e49\uff0c\u751a\u81f3\u53ef\u4ee5\u4e0e\u5176\u4ed6TensoFlow\u5e93\u534f\u540c\u5de5\u4f5c\u3002\n\n\n\u6ce8\u610f\uff0c\u672c\u6587\u5047\u5b9a\u4f60\u5df2\u7ecf\u628aKeras\u914d\u7f6e\u4e3atensorflow\u540e\u7aef\uff0c\u5982\u679c\u4f60\u4e0d\u61c2\u600e\u4e48\u914d\u7f6e\uff0c\u8bf7\u67e5\u770b\n\u8fd9\u91cc\n\n\n\n\n\u5728tensorflow\u4e2d\u8c03\u7528Keras\u5c42\n\n\n\u8ba9\u6211\u4eec\u4ee5\u4e00\u4e2a\u7b80\u5355\u7684\u4f8b\u5b50\u5f00\u59cb\uff1aMNIST\u6570\u5b57\u5206\u7c7b\u3002\u6211\u4eec\u5c06\u4ee5Keras\u7684\u5168\u8fde\u63a5\u5c42\u5806\u53e0\u6784\u9020\u4e00\u4e2aTensorFlow\u7684\u5206\u7c7b\u5668\uff0c\n\n\nimport tensorflow as tf\nsess = tf.Session()\n\nfrom keras import backend as K\nK.set_session(sess)\n\n\n\n\n\u7136\u540e\uff0c\u6211\u4eec\u5f00\u59cb\u7528tensorflow\u6784\u5efa\u6a21\u578b\uff1a\n\n\n# this placeholder will contain our input digits, as flat vectors\nimg = tf.placeholder(tf.float32, shape=(None, 784))\n\n\n\n\n\n\u7528Keras\u53ef\u4ee5\u52a0\u901f\u6a21\u578b\u7684\u5b9a\u4e49\u8fc7\u7a0b\uff1a\n\n\nfrom keras.layers import Dense\n\n# Keras layers can be called on TensorFlow tensors:\nx = Dense(128, activation='relu')(img)  # fully-connected layer with 128 units and ReLU activation\nx = Dense(128, activation='relu')(x)\npreds = Dense(10, activation='softmax')(x)  # output layer with 10 units and a softmax activation\n\n\n\n\n\u5b9a\u4e49\u6807\u7b7e\u7684\u5360\u4f4d\u7b26\u548c\u635f\u5931\u51fd\u6570\uff1a\n\n\nlabels = tf.placeholder(tf.float32, shape=(None, 10))\n\nfrom keras.objectives import categorical_crossentropy\nloss = tf.reduce_mean(categorical_crossentropy(labels, preds))\n\n\n\n\n\u7136\u540e\uff0c\u6211\u4eec\u53ef\u4ee5\u7528tensorflow\u7684\u4f18\u5316\u5668\u6765\u8bad\u7ec3\u6a21\u578b\uff1a\n\n\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist_data = input_data.read_data_sets('MNIST_data', one_hot=True)\n\ntrain_step = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\nwith sess.as_default():\n    for i in range(100):\n        batch = mnist_data.train.next_batch(50)\n        train_step.run(feed_dict={img: batch[0],\n                                  labels: batch[1]})\n\n\n\n\n\u6700\u540e\u6211\u4eec\u6765\u8bc4\u4f30\u4e00\u4e0b\u6a21\u578b\u6027\u80fd\uff1a\n\n\nfrom keras.metrics import categorical_accuracy as accuracy\n\nacc_value = accuracy(labels, preds)\nwith sess.as_default():\n    print acc_value.eval(feed_dict={img: mnist_data.test.images,\n                                    labels: mnist_data.test.labels})\n\n\n\n\n\u6211\u4eec\u53ea\u662f\u5c06Keras\u4f5c\u4e3a\u751f\u6210\u4ecetensor\u5230tensor\u7684\u51fd\u6570\uff08op\uff09\u7684\u5feb\u6377\u65b9\u6cd5\u800c\u5df2\uff0c\u4f18\u5316\u8fc7\u7a0b\u5b8c\u5168\u91c7\u7528\u7684\u539f\u751ftensorflow\u7684\u4f18\u5316\u5668\uff0c\u800c\u4e0d\u662fKeras\u4f18\u5316\u5668\uff0c\u6211\u4eec\u538b\u6839\u4e0d\u9700\u8981Keras\u7684Model\n\n\n\u5173\u4e8e\u539f\u751fTensorFlow\u548cKeras\u7684\u4f18\u5316\u5668\u7684\u4e00\u70b9\u6ce8\u8bb0\uff1a\u867d\u7136\u6709\u70b9\u53cd\u76f4\u89c9\uff0c\u4f46Keras\u7684\u4f18\u5316\u5668\u8981\u6bd4TensorFlow\u7684\u4f18\u5316\u5668\u5feb\u5927\u69825-10%\u3002\u867d\u7136\u8fd9\u79cd\u901f\u5ea6\u7684\u5dee\u5f02\u57fa\u672c\u4e0a\u6ca1\u4ec0\u4e48\u5dee\u522b\u3002\n\n\n\u8bad\u7ec3\u548c\u6d4b\u8bd5\u884c\u4e3a\u4e0d\u540c\n\n\n\u6709\u4e9bKeras\u5c42\uff0c\u5982BN\uff0cDropout\uff0c\u5728\u8bad\u7ec3\u548c\u6d4b\u8bd5\u8fc7\u7a0b\u4e2d\u7684\u884c\u4e3a\u4e0d\u4e00\u81f4\uff0c\u4f60\u53ef\u4ee5\u901a\u8fc7\u6253\u5370layer.uses_learning_phase\u6765\u786e\u5b9a\u5f53\u524d\u5c42\u5de5\u4f5c\u5728\u8bad\u7ec3\u6a21\u5f0f\u8fd8\u662f\u6d4b\u8bd5\u6a21\u5f0f\u3002\n\n\n\u5982\u679c\u4f60\u7684\u6a21\u578b\u5305\u542b\u8fd9\u6837\u7684\u5c42\uff0c\u4f60\u9700\u8981\u6307\u5b9a\u4f60\u5e0c\u671b\u6a21\u578b\u5de5\u4f5c\u5728\u4ec0\u4e48\u6a21\u5f0f\u4e0b\uff0c\u901a\u8fc7Keras\u7684backend\u4f60\u53ef\u4ee5\u4e86\u89e3\u5f53\u524d\u7684\u5de5\u4f5c\u6a21\u5f0f\uff1a\n\n\nfrom keras import backend as K\nprint K.learning_phase()\n\n\n\n\n\u5411feed_dict\u4e2d\u4f20\u90121\uff08\u8bad\u7ec3\u6a21\u5f0f\uff09\u62160\uff08\u6d4b\u8bd5\u6a21\u5f0f\uff09\u5373\u53ef\u6307\u5b9a\u5f53\u524d\u5de5\u4f5c\u6a21\u5f0f\uff1a\n\n\n# train mode\ntrain_step.run(feed_dict={x: batch[0], labels: batch[1], K.learning_phase(): 1})\n\n\n\n\n\u4f8b\u5982\uff0c\u4e0b\u9762\u4ee3\u7801\u793a\u8303\u4e86\u5982\u4f55\u5c06Dropout\u5c42\u52a0\u5165\u521a\u624d\u7684\u6a21\u578b\u4e2d\uff1a\n\n\nfrom keras.layers import Dropout\nfrom keras import backend as K\n\nimg = tf.placeholder(tf.float32, shape=(None, 784))\nlabels = tf.placeholder(tf.float32, shape=(None, 10))\n\nx = Dense(128, activation='relu')(img)\nx = Dropout(0.5)(x)\nx = Dense(128, activation='relu')(x)\nx = Dropout(0.5)(x)\npreds = Dense(10, activation='softmax')(x)\n\nloss = tf.reduce_mean(categorical_crossentropy(labels, preds))\n\ntrain_step = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\nwith sess.as_default():\n    for i in range(100):\n        batch = mnist_data.train.next_batch(50)\n        train_step.run(feed_dict={img: batch[0],\n                                  labels: batch[1],\n                                  K.learning_phase(): 1})\n\nacc_value = accuracy(labels, preds)\nwith sess.as_default():\n    print acc_value.eval(feed_dict={img: mnist_data.test.images,\n                                    labels: mnist_data.test.labels,\n                                    K.learning_phase(): 0})\n\n\n\n\n\u4e0e\u53d8\u91cf\u540d\u4f5c\u7528\u57df\u548c\u8bbe\u5907\u4f5c\u7528\u57df\u7684\u517c\u5bb9\n\n\nKeras\u7684\u5c42\u4e0e\u6a21\u578b\u548ctensorflow\u7684\u547d\u540d\u5b8c\u5168\u517c\u5bb9\uff0c\u4f8b\u5982\uff1a\n\n\nx = tf.placeholder(tf.float32, shape=(None, 20, 64))\nwith tf.name_scope('block1'):\n    y = LSTM(32, name='mylstm')(x)\n\n\n\n\n\u6211\u4eecLSTM\u5c42\u7684\u6743\u91cd\u5c06\u4f1a\u88ab\u547d\u540d\u4e3ablock1/mylstm_W_i, block1/mylstm_U, \u7b49..\n\u7c7b\u4f3c\u7684\uff0c\u8bbe\u5907\u7684\u547d\u540d\u4e5f\u4f1a\u50cf\u4f60\u671f\u671b\u7684\u4e00\u6837\u5de5\u4f5c\uff1a\n\n\nwith tf.device('/gpu:0'):\n    x = tf.placeholder(tf.float32, shape=(None, 20, 64))\n    y = LSTM(32)(x)  # all ops / variables in the LSTM layer will live on GPU:0\n\n\n\n\n\u4e0eGraph\u7684\u4f5c\u7528\u57df\u517c\u5bb9\n\n\n\u4efb\u4f55\u5728tensorflow\u7684Graph\u4f5c\u7528\u57df\u5b9a\u4e49\u7684Keras\u5c42\u6216\u6a21\u578b\u7684\u6240\u6709\u53d8\u91cf\u548c\u64cd\u4f5c\u5c06\u88ab\u751f\u6210\u4e3a\u8be5Graph\u7684\u4e00\u4e2a\u90e8\u5206\uff0c\u4f8b\u5982\uff0c\u4e0b\u9762\u7684\u4ee3\u7801\u5c06\u4f1a\u4ee5\u4f60\u6240\u671f\u671b\u7684\u5f62\u5f0f\u5de5\u4f5c\n\n\nfrom keras.layers import LSTM\nimport tensorflow as tf\n\nmy_graph = tf.Graph()\nwith my_graph.as_default():\n    x = tf.placeholder(tf.float32, shape=(None, 20, 64))\n    y = LSTM(32)(x)  # all ops / variables in the LSTM layer are created as part of our graph\n\n\n\n\n\u4e0e\u53d8\u91cf\u4f5c\u7528\u57df\u517c\u5bb9\n\n\n\u53d8\u91cf\u5171\u4eab\u5e94\u901a\u8fc7\u591a\u6b21\u8c03\u7528\u540c\u6837\u7684Keras\u5c42\u6216\u6a21\u578b\u6765\u5b9e\u73b0\uff0c\u800c\u4e0d\u662f\u901a\u8fc7TensorFlow\u7684\u53d8\u91cf\u4f5c\u7528\u57df\u5b9e\u73b0\u3002TensorFlow\u53d8\u91cf\u4f5c\u7528\u57df\u5c06\u5bf9Keras\u5c42\u6216\u6a21\u578b\u6ca1\u6709\u4efb\u4f55\u5f71\u54cd\u3002\u66f4\u591aKeras\u6743\u91cd\u5171\u4eab\u7684\u4fe1\u606f\u8bf7\u53c2\u8003\n\u8fd9\u91cc\n\n\nKeras\u901a\u8fc7\u91cd\u7528\u76f8\u540c\u5c42\u6216\u6a21\u578b\u7684\u5bf9\u8c61\u6765\u5b8c\u6210\u6743\u503c\u5171\u4eab\uff0c\u8fd9\u662f\u4e00\u4e2a\u4f8b\u5b50\uff1a\n\n\n# instantiate a Keras layer\nlstm = LSTM(32)\n\n# instantiate two TF placeholders\nx = tf.placeholder(tf.float32, shape=(None, 20, 64))\ny = tf.placeholder(tf.float32, shape=(None, 20, 64))\n\n# encode the two tensors with the *same* LSTM weights\nx_encoded = lstm(x)\ny_encoded = lstm(y)\n\n\n\n\n\u6536\u96c6\u53ef\u8bad\u7ec3\u6743\u91cd\u4e0e\u72b6\u6001\u66f4\u65b0\n\n\n\u67d0\u4e9bKeras\u5c42\uff0c\u5982\u72b6\u6001RNN\u548cBN\u5c42\uff0c\u5176\u5185\u90e8\u7684\u66f4\u65b0\u9700\u8981\u4f5c\u4e3a\u8bad\u7ec3\u8fc7\u7a0b\u7684\u4e00\u6b65\u6765\u8fdb\u884c\uff0c\u8fd9\u4e9b\u66f4\u65b0\u88ab\u5b58\u50a8\u5728\u4e00\u4e2atensor tuple\u91cc\uff1alayer.updates\uff0c\u4f60\u5e94\u8be5\u751f\u6210assign\u64cd\u4f5c\u6765\u4f7f\u5728\u8bad\u7ec3\u7684\u6bcf\u4e00\u6b65\u8fd9\u4e9b\u66f4\u65b0\u80fd\u591f\u88ab\u8fd0\u884c\uff0c\u8fd9\u91cc\u662f\u4f8b\u5b50\uff1a\n\n\nfrom keras.layers import BatchNormalization\n\nlayer = BatchNormalization()(x)\n\nupdate_ops = []\nfor old_value, new_value in layer.updates:\n    update_ops.append(tf.assign(old_value, new_value))\n\n\n\n\n\u6ce8\u610f\u5982\u679c\u4f60\u4f7f\u7528Keras\u6a21\u578b\uff0cmodel.updates\u5c06\u4e0e\u4e0a\u9762\u7684\u4ee3\u7801\u4f5c\u7528\u76f8\u540c\uff08\u6536\u96c6\u6a21\u578b\u4e2d\u6240\u6709\u66f4\u65b0\uff09\n\n\n\u53e6\u5916\uff0c\u5982\u679c\u4f60\u9700\u8981\u663e\u5f0f\u7684\u6536\u96c6\u4e00\u4e2a\u5c42\u7684\u53ef\u8bad\u7ec3\u6743\u91cd\uff0c\u4f60\u53ef\u4ee5\u901a\u8fc7layer.trainable_weights\u6765\u5b9e\u73b0\uff0c\u5bf9\u6a21\u578b\u800c\u8a00\u662fmodel.trainable_weights\uff0c\u5b83\u662f\u4e00\u4e2atensorflow\u53d8\u91cf\u5bf9\u8c61\u7684\u5217\u8868\uff1a\n\n\nfrom keras.layers import Dense\n\nlayer = Dense(32)(x)  # instantiate and call a layer\nprint layer.trainable_weights  # list of TensorFlow Variables\n\n\n\n\n\u8fd9\u4e9b\u4e1c\u897f\u5141\u8bb8\u4f60\u5b9e\u73b0\u4f60\u57fa\u4e8eTensorFlow\u4f18\u5316\u5668\u5b9e\u73b0\u81ea\u5df1\u7684\u8bad\u7ec3\u7a0b\u5e8f\n\n\n\u4f7f\u7528Keras\u6a21\u578b\u4e0eTensorFlow\u534f\u4f5c\n\n\n\u5c06Keras Sequential\u6a21\u578b\u8f6c\u6362\u5230TensorFlow\u4e2d\n\n\n\u5047\u5982\u4f60\u5df2\u7ecf\u6709\u4e00\u4e2a\u8bad\u7ec3\u597d\u7684Keras\u6a21\u578b\uff0c\u5982VGG-16\uff0c\u73b0\u5728\u4f60\u60f3\u5c06\u5b83\u5e94\u7528\u5728\u4f60\u7684TensorFlow\u5de5\u4f5c\u4e2d\uff0c\u5e94\u8be5\u600e\u4e48\u529e\uff1f\n\n\n\u9996\u5148\uff0c\u6ce8\u610f\u5982\u679c\u4f60\u7684\u9884\u8bad\u7ec3\u6743\u91cd\u542b\u6709\u4f7f\u7528Theano\u8bad\u7ec3\u7684\u5377\u79ef\u5c42\u7684\u8bdd\uff0c\u4f60\u9700\u8981\u5bf9\u8fd9\u4e9b\u6743\u91cd\u7684\u5377\u79ef\u6838\u8fdb\u884c\u8f6c\u6362\uff0c\u8fd9\u662f\u56e0\u4e3aTheano\u548cTensorFlow\u5bf9\u5377\u79ef\u7684\u5b9e\u73b0\u4e0d\u540c\uff0cTensorFlow\u548cCaffe\u5b9e\u9645\u4e0a\u5b9e\u73b0\u7684\u662f\u76f8\u5173\u6027\u8ba1\u7b97\u3002\u70b9\u51fb\n\u8fd9\u91cc\n\u67e5\u770b\u8be6\u7ec6\u793a\u4f8b\u3002\n\n\n\u5047\u8bbe\u4f60\u4ece\u4e0b\u9762\u7684Keras\u6a21\u578b\u5f00\u59cb\uff0c\u5e76\u5e0c\u671b\u5bf9\u5176\u8fdb\u884c\u4fee\u6539\u4ee5\u4f7f\u5f97\u5b83\u53ef\u4ee5\u4ee5\u4e00\u4e2a\u7279\u5b9a\u7684tensorflow\u5f20\u91cfmy_input_tensor\u4e3a\u8f93\u5165\uff0c\u8fd9\u4e2atensor\u53ef\u80fd\u662f\u4e00\u4e2a\u6570\u636efeeder\u6216\u522b\u7684tensorflow\u6a21\u578b\u7684\u8f93\u51fa\n\n\n# this is our initial Keras model\nmodel = Sequential()\nfirst_layer = Dense(32, activation='relu', input_dim=784)\nmodel.add(Dense(10, activation='softmax'))\n\n\n\n\n\u4f60\u53ea\u9700\u8981\u5728\u5b9e\u4f8b\u5316\u8be5\u6a21\u578b\u540e\uff0c\u4f7f\u7528set_input\u6765\u4fee\u6539\u9996\u5c42\u7684\u8f93\u5165\uff0c\u7136\u540e\u5c06\u5269\u4e0b\u6a21\u578b\u642d\u5efa\u4e8e\u5176\u4e0a\uff1a\n\n\n# this is our modified Keras model\nmodel = Sequential()\nfirst_layer = Dense(32, activation='relu', input_dim=784)\nfirst_layer.set_input(my_input_tensor)\n\n# build the rest of the model as before\nmodel.add(first_layer)\nmodel.add(Dense(10, activation='softmax'))\n\n\n\n\n\u5728\u8fd9\u4e2a\u9636\u6bb5\uff0c\u4f60\u53ef\u4ee5\u8c03\u7528model.load_weights(weights_file)\u6765\u52a0\u8f7d\u9884\u8bad\u7ec3\u7684\u6743\u91cd\n\n\n\u7136\u540e\uff0c\u4f60\u6216\u8bb8\u4f1a\u6536\u96c6\u8be5\u6a21\u578b\u7684\u8f93\u51fa\u5f20\u91cf\uff1a\n\n\noutput_tensor = model.output\n\n\n\n\n\u5bf9TensorFlow\u5f20\u91cf\u4e2d\u8c03\u7528Keras\u6a21\u578b\n\n\nKeras\u6a21\u578b\u4e0eKeras\u5c42\u7684\u884c\u4e3a\u4e00\u81f4\uff0c\u56e0\u6b64\u53ef\u4ee5\u88ab\u8c03\u7528\u4e8eTensorFlow\u5f20\u91cf\u4e0a\uff1a\n\n\nfrom keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(Dense(32, activation='relu', input_dim=784))\nmodel.add(Dense(10, activation='softmax'))\n\n# this works! \nx = tf.placeholder(tf.float32, shape=(None, 784))\ny = model(x)\n\n\n\n\n\u6ce8\u610f\uff0c\u8c03\u7528\u6a21\u578b\u65f6\u4f60\u540c\u65f6\u4f7f\u7528\u4e86\u6a21\u578b\u7684\u7ed3\u6784\u4e0e\u6743\u91cd\uff0c\u5f53\u4f60\u5728\u4e00\u4e2atensor\u4e0a\u8c03\u7528\u6a21\u578b\u65f6\uff0c\u4f60\u5c31\u5728\u8be5tensor\u4e0a\u521b\u9020\u4e86\u4e00\u4e9b\u64cd\u4f5c\uff0c\u8fd9\u4e9b\u64cd\u4f5c\u91cd\u7528\u4e86\u5df2\u7ecf\u5728\u6a21\u578b\u4e2d\u51fa\u73b0\u7684TensorFlow\u53d8\u91cf\u7684\u5bf9\u8c61\n\n\n\u591aGPU\u548c\u5206\u5e03\u5f0f\u8bad\u7ec3\n\n\n\u5c06Keras\u6a21\u578b\u5206\u6563\u5728\u591a\u4e2aGPU\u4e2d\u8bad\u7ec3\n\n\nTensorFlow\u7684\u8bbe\u5907\u4f5c\u7528\u57df\u5b8c\u5168\u4e0eKeras\u7684\u5c42\u548c\u6a21\u578b\u517c\u5bb9\uff0c\u56e0\u6b64\u4f60\u53ef\u4ee5\u4f7f\u7528\u5b83\u4eec\u6765\u5c06\u4e00\u4e2a\u56fe\u7684\u7279\u5b9a\u90e8\u5206\u653e\u5728\u4e0d\u540c\u7684GPU\u4e2d\u8bad\u7ec3\uff0c\u8fd9\u91cc\u662f\u4e00\u4e2a\u7b80\u5355\u7684\u4f8b\u5b50\uff1a\n\n\nwith tf.device('/gpu:0'):\n    x = tf.placeholder(tf.float32, shape=(None, 20, 64))\n    y = LSTM(32)(x)  # all ops in the LSTM layer will live on GPU:0\n\nwith tf.device('/gpu:1'):\n    x = tf.placeholder(tf.float32, shape=(None, 20, 64))\n    y = LSTM(32)(x)  # all ops in the LSTM layer will live on GPU:1\n\n\n\n\n\u6ce8\u610f\uff0c\u7531LSTM\u5c42\u521b\u5efa\u7684\u53d8\u91cf\u5c06\u4e0d\u4f1a\u751f\u5b58\u5728GPU\u4e0a\uff0c\u4e0d\u7ba1TensorFlow\u53d8\u91cf\u5728\u54ea\u91cc\u521b\u5efa\uff0c\u5b83\u4eec\u603b\u662f\u751f\u5b58\u5728CPU\u4e0a\uff0cTensorFlow\u5c06\u9690\u542b\u7684\u5904\u7406\u8bbe\u5907\u4e4b\u95f4\u7684\u8f6c\u6362\n\n\n\u5982\u679c\u4f60\u60f3\u5728\u591a\u4e2aGPU\u4e0a\u8bad\u7ec3\u540c\u4e00\u4e2a\u6a21\u578b\u7684\u591a\u4e2a\u526f\u672c\uff0c\u5e76\u5728\u591a\u4e2a\u526f\u672c\u4e2d\u8fdb\u884c\u6743\u91cd\u5171\u4eab\uff0c\u9996\u5148\u4f60\u5e94\u8be5\u5728\u4e00\u4e2a\u8bbe\u5907\u4f5c\u7528\u57df\u4e0b\u5b9e\u4f8b\u5316\u4f60\u7684\u6a21\u578b\u6216\u5c42\uff0c\u7136\u540e\u5728\u4e0d\u540cGPU\u8bbe\u5907\u7684\u4f5c\u7528\u57df\u4e0b\u591a\u6b21\u8c03\u7528\u8be5\u6a21\u578b\u5b9e\u4f8b\uff0c\u5982\uff1a\n\n\nwith tf.device('/cpu:0'):\n    x = tf.placeholder(tf.float32, shape=(None, 784))\n\n    # shared model living on CPU:0\n    # it won't actually be run during training; it acts as an op template\n    # and as a repository for shared variables\n    model = Sequential()\n    model.add(Dense(32, activation='relu', input_dim=784))\n    model.add(Dense(10, activation='softmax'))\n\n# replica 0\nwith tf.device('/gpu:0'):\n    output_0 = model(x)  # all ops in the replica will live on GPU:0\n\n# replica 1\nwith tf.device('/gpu:1'):\n    output_1 = model(x)  # all ops in the replica will live on GPU:1\n\n# merge outputs on CPU\nwith tf.device('/cpu:0'):\n    preds = 0.5 * (output_0 + output_1)\n\n# we only run the `preds` tensor, so that only the two\n# replicas on GPU get run (plus the merge op on CPU)\noutput_value = sess.run([preds], feed_dict={x: data})\n\n\n\n\n\u5206\u5e03\u5f0f\u8bad\u7ec3\n\n\n\u901a\u8fc7\u6ce8\u518cKeras\u4f1a\u8bdd\u5230\u4e00\u4e2a\u96c6\u7fa4\u4e0a\uff0c\u4f60\u53ef\u4ee5\u7b80\u5355\u7684\u5b9e\u73b0\u5206\u5e03\u5f0f\u8bad\u7ec3\uff1a\n\n\nserver = tf.train.Server.create_local_server()\nsess = tf.Session(server.target)\n\nfrom keras import backend as K\nK.set_session(sess)\n\n\n\n\n\u5173\u4e8eTensorFlow\u8fdb\u884c\u5206\u5e03\u5f0f\u8bad\u7ec3\u7684\u914d\u7f6e\u4fe1\u606f\uff0c\u8bf7\u53c2\u8003\n\u8fd9\u91cc\n\n\n\u4f7f\u7528TensorFlow-serving\u5bfc\u51fa\u6a21\u578b\n\n\nTensorFlow-Serving\n\u662f\u7531Google\u5f00\u53d1\u7684\u7528\u4e8e\u5c06TensoFlow\u6a21\u578b\u90e8\u7f72\u4e8e\u751f\u4ea7\u73af\u5883\u7684\u5de5\u5177\n\n\n\u4efb\u4f55Keras\u6a21\u578b\u90fd\u53ef\u4ee5\u88abTensorFlow-serving\u6240\u5bfc\u51fa\uff08\u53ea\u8981\u5b83\u53ea\u542b\u6709\u4e00\u4e2a\u8f93\u5165\u548c\u4e00\u4e2a\u8f93\u51fa\uff0c\u8fd9\u662fTF-serving\u7684\u9650\u5236\uff09\uff0c\u4e0d\u7ba1\u5b83\u662f\u5426\u4f5c\u4e3aTensroFlow\u5de5\u4f5c\u6d41\u7684\u4e00\u90e8\u5206\u3002\u4e8b\u5b9e\u4e0a\u4f60\u751a\u81f3\u53ef\u4ee5\u4f7f\u7528Theano\u8bad\u7ec3\u4f60\u7684Keras\u6a21\u578b\uff0c\u7136\u540e\u5c06\u5176\u5207\u6362\u5230tensorflow\u540e\u7aef\uff0c\u7136\u540e\u5bfc\u51fa\u6a21\u578b\n\n\n\u5982\u679c\u4f60\u7684graph\u4f7f\u7528\u4e86Keras\u7684learning phase\uff08\u5728\u8bad\u7ec3\u548c\u6d4b\u8bd5\u4e2d\u884c\u4e3a\u4e0d\u540c\uff09\uff0c\u4f60\u9996\u5148\u8981\u505a\u7684\u4e8b\u5c31\u662f\u5728graph\u4e2d\u786c\u7f16\u7801\u4f60\u7684\u5de5\u4f5c\u6a21\u5f0f\uff08\u8bbe\u4e3a0\uff0c\u5373\u6d4b\u8bd5\u6a21\u5f0f\uff09\uff0c\u8be5\u5de5\u4f5c\u901a\u8fc71\uff09\u4f7f\u7528Keras\u7684\u540e\u7aef\u6ce8\u518c\u4e00\u4e2alearning phase\u5e38\u91cf\uff0c2\uff09\u91cd\u65b0\u6784\u5efa\u6a21\u578b\uff0c\u6765\u5b8c\u6210\u3002\n\n\n\u8fd9\u91cc\u662f\u5b9e\u8df5\u4e2d\u7684\u793a\u8303\uff1a\n\n\nfrom keras import backend as K\n\nK.set_learning_phase(0)  # all new operations will be in test mode from now on\n\n# serialize the model and get its weights, for quick re-building\nconfig = previous_model.get_config()\nweights = previous_model.get_weights()\n\n# re-build a model where the learning phase is now hard-coded to 0\nfrom keras.models import model_from_config\nnew_model = model_from_config(config)\nnew_model.set_weights(weights)\n\n\n\n\n\u73b0\u5728\uff0c\u6211\u4eec\u53ef\u4f7f\u7528Tensorflow-serving\u6765\u5bfc\u51fa\u6a21\u578b\uff0c\u6309\u7167\u5b98\u65b9\u6559\u7a0b\u7684\u6307\u5bfc\uff1a\n\n\nfrom tensorflow_serving.session_bundle import exporter\n\nexport_path = ... # where to save the exported graph\nexport_version = ... # version number (integer)\n\nsaver = tf.train.Saver(sharded=True)\nmodel_exporter = exporter.Exporter(saver)\nsignature = exporter.classification_signature(input_tensor=model.input,\n                                              scores_tensor=model.output)\nmodel_exporter.init(sess.graph.as_graph_def(),\n                    default_graph_signature=signature)\nmodel_exporter.export(export_path, tf.constant(export_version), sess)\n\n\n\n\n\u5982\u60f3\u770b\u5230\u5305\u542b\u672c\u6559\u7a0b\u7684\u65b0\u4e3b\u9898\uff0c\u8bf7\u770b\n\u6211\u7684Twitter", 
            "title": "\u5c06Keras\u4f5c\u4e3atensorflow\u7684\u7cbe\u7b80\u63a5\u53e3"
        }, 
        {
            "location": "/blog/keras_and_tensorflow/#kerastensorflow", 
            "text": "", 
            "title": "\u5c06Keras\u4f5c\u4e3atensorflow\u7684\u7cbe\u7b80\u63a5\u53e3"
        }, 
        {
            "location": "/blog/keras_and_tensorflow/#_1", 
            "text": "\u672c\u6587\u5730\u5740\uff1a https://blog.keras.io/keras-as-a-simplified-interface-to-tensorflow-tutorial.html  \u672c\u6587\u4f5c\u8005\uff1aFrancois Chollet", 
            "title": "\u6587\u7ae0\u4fe1\u606f"
        }, 
        {
            "location": "/blog/keras_and_tensorflow/#kerastensorflow_1", 
            "text": "\u5982\u679cTensorflow\u662f\u4f60\u7684\u9996\u9009\u6846\u67b6\uff0c\u5e76\u4e14\u4f60\u60f3\u627e\u4e00\u4e2a\u7b80\u5316\u7684\u3001\u9ad8\u5c42\u7684\u6a21\u578b\u5b9a\u4e49\u63a5\u53e3\u6765\u8ba9\u81ea\u5df1\u6d3b\u7684\u4e0d\u90a3\u4e48\u7d2f\uff0c\u90a3\u4e48\u8fd9\u7bc7\u6587\u7ae0\u5c31\u662f\u7ed9\u4f60\u770b\u7684  Keras\u7684\u5c42\u548c\u6a21\u578b\u4e0e\u7eafTensorFlow\u7684tensor\u5b8c\u5168\u517c\u5bb9\uff0c\u56e0\u6b64\uff0cKeras\u53ef\u4ee5\u4f5c\u4e3aTensorFlow\u7684\u6a21\u578b\u5b9a\u4e49\uff0c\u751a\u81f3\u53ef\u4ee5\u4e0e\u5176\u4ed6TensoFlow\u5e93\u534f\u540c\u5de5\u4f5c\u3002  \u6ce8\u610f\uff0c\u672c\u6587\u5047\u5b9a\u4f60\u5df2\u7ecf\u628aKeras\u914d\u7f6e\u4e3atensorflow\u540e\u7aef\uff0c\u5982\u679c\u4f60\u4e0d\u61c2\u600e\u4e48\u914d\u7f6e\uff0c\u8bf7\u67e5\u770b \u8fd9\u91cc", 
            "title": "\u4f7f\u7528Keras\u4f5c\u4e3aTensorFlow\u5de5\u4f5c\u6d41\u7684\u4e00\u90e8\u5206"
        }, 
        {
            "location": "/blog/keras_and_tensorflow/#tensorflowkeras", 
            "text": "\u8ba9\u6211\u4eec\u4ee5\u4e00\u4e2a\u7b80\u5355\u7684\u4f8b\u5b50\u5f00\u59cb\uff1aMNIST\u6570\u5b57\u5206\u7c7b\u3002\u6211\u4eec\u5c06\u4ee5Keras\u7684\u5168\u8fde\u63a5\u5c42\u5806\u53e0\u6784\u9020\u4e00\u4e2aTensorFlow\u7684\u5206\u7c7b\u5668\uff0c  import tensorflow as tf\nsess = tf.Session()\n\nfrom keras import backend as K\nK.set_session(sess)  \u7136\u540e\uff0c\u6211\u4eec\u5f00\u59cb\u7528tensorflow\u6784\u5efa\u6a21\u578b\uff1a  # this placeholder will contain our input digits, as flat vectors\nimg = tf.placeholder(tf.float32, shape=(None, 784))  \u7528Keras\u53ef\u4ee5\u52a0\u901f\u6a21\u578b\u7684\u5b9a\u4e49\u8fc7\u7a0b\uff1a  from keras.layers import Dense\n\n# Keras layers can be called on TensorFlow tensors:\nx = Dense(128, activation='relu')(img)  # fully-connected layer with 128 units and ReLU activation\nx = Dense(128, activation='relu')(x)\npreds = Dense(10, activation='softmax')(x)  # output layer with 10 units and a softmax activation  \u5b9a\u4e49\u6807\u7b7e\u7684\u5360\u4f4d\u7b26\u548c\u635f\u5931\u51fd\u6570\uff1a  labels = tf.placeholder(tf.float32, shape=(None, 10))\n\nfrom keras.objectives import categorical_crossentropy\nloss = tf.reduce_mean(categorical_crossentropy(labels, preds))  \u7136\u540e\uff0c\u6211\u4eec\u53ef\u4ee5\u7528tensorflow\u7684\u4f18\u5316\u5668\u6765\u8bad\u7ec3\u6a21\u578b\uff1a  from tensorflow.examples.tutorials.mnist import input_data\nmnist_data = input_data.read_data_sets('MNIST_data', one_hot=True)\n\ntrain_step = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\nwith sess.as_default():\n    for i in range(100):\n        batch = mnist_data.train.next_batch(50)\n        train_step.run(feed_dict={img: batch[0],\n                                  labels: batch[1]})  \u6700\u540e\u6211\u4eec\u6765\u8bc4\u4f30\u4e00\u4e0b\u6a21\u578b\u6027\u80fd\uff1a  from keras.metrics import categorical_accuracy as accuracy\n\nacc_value = accuracy(labels, preds)\nwith sess.as_default():\n    print acc_value.eval(feed_dict={img: mnist_data.test.images,\n                                    labels: mnist_data.test.labels})  \u6211\u4eec\u53ea\u662f\u5c06Keras\u4f5c\u4e3a\u751f\u6210\u4ecetensor\u5230tensor\u7684\u51fd\u6570\uff08op\uff09\u7684\u5feb\u6377\u65b9\u6cd5\u800c\u5df2\uff0c\u4f18\u5316\u8fc7\u7a0b\u5b8c\u5168\u91c7\u7528\u7684\u539f\u751ftensorflow\u7684\u4f18\u5316\u5668\uff0c\u800c\u4e0d\u662fKeras\u4f18\u5316\u5668\uff0c\u6211\u4eec\u538b\u6839\u4e0d\u9700\u8981Keras\u7684Model  \u5173\u4e8e\u539f\u751fTensorFlow\u548cKeras\u7684\u4f18\u5316\u5668\u7684\u4e00\u70b9\u6ce8\u8bb0\uff1a\u867d\u7136\u6709\u70b9\u53cd\u76f4\u89c9\uff0c\u4f46Keras\u7684\u4f18\u5316\u5668\u8981\u6bd4TensorFlow\u7684\u4f18\u5316\u5668\u5feb\u5927\u69825-10%\u3002\u867d\u7136\u8fd9\u79cd\u901f\u5ea6\u7684\u5dee\u5f02\u57fa\u672c\u4e0a\u6ca1\u4ec0\u4e48\u5dee\u522b\u3002", 
            "title": "\u5728tensorflow\u4e2d\u8c03\u7528Keras\u5c42"
        }, 
        {
            "location": "/blog/keras_and_tensorflow/#_2", 
            "text": "\u6709\u4e9bKeras\u5c42\uff0c\u5982BN\uff0cDropout\uff0c\u5728\u8bad\u7ec3\u548c\u6d4b\u8bd5\u8fc7\u7a0b\u4e2d\u7684\u884c\u4e3a\u4e0d\u4e00\u81f4\uff0c\u4f60\u53ef\u4ee5\u901a\u8fc7\u6253\u5370layer.uses_learning_phase\u6765\u786e\u5b9a\u5f53\u524d\u5c42\u5de5\u4f5c\u5728\u8bad\u7ec3\u6a21\u5f0f\u8fd8\u662f\u6d4b\u8bd5\u6a21\u5f0f\u3002  \u5982\u679c\u4f60\u7684\u6a21\u578b\u5305\u542b\u8fd9\u6837\u7684\u5c42\uff0c\u4f60\u9700\u8981\u6307\u5b9a\u4f60\u5e0c\u671b\u6a21\u578b\u5de5\u4f5c\u5728\u4ec0\u4e48\u6a21\u5f0f\u4e0b\uff0c\u901a\u8fc7Keras\u7684backend\u4f60\u53ef\u4ee5\u4e86\u89e3\u5f53\u524d\u7684\u5de5\u4f5c\u6a21\u5f0f\uff1a  from keras import backend as K\nprint K.learning_phase()  \u5411feed_dict\u4e2d\u4f20\u90121\uff08\u8bad\u7ec3\u6a21\u5f0f\uff09\u62160\uff08\u6d4b\u8bd5\u6a21\u5f0f\uff09\u5373\u53ef\u6307\u5b9a\u5f53\u524d\u5de5\u4f5c\u6a21\u5f0f\uff1a  # train mode\ntrain_step.run(feed_dict={x: batch[0], labels: batch[1], K.learning_phase(): 1})  \u4f8b\u5982\uff0c\u4e0b\u9762\u4ee3\u7801\u793a\u8303\u4e86\u5982\u4f55\u5c06Dropout\u5c42\u52a0\u5165\u521a\u624d\u7684\u6a21\u578b\u4e2d\uff1a  from keras.layers import Dropout\nfrom keras import backend as K\n\nimg = tf.placeholder(tf.float32, shape=(None, 784))\nlabels = tf.placeholder(tf.float32, shape=(None, 10))\n\nx = Dense(128, activation='relu')(img)\nx = Dropout(0.5)(x)\nx = Dense(128, activation='relu')(x)\nx = Dropout(0.5)(x)\npreds = Dense(10, activation='softmax')(x)\n\nloss = tf.reduce_mean(categorical_crossentropy(labels, preds))\n\ntrain_step = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\nwith sess.as_default():\n    for i in range(100):\n        batch = mnist_data.train.next_batch(50)\n        train_step.run(feed_dict={img: batch[0],\n                                  labels: batch[1],\n                                  K.learning_phase(): 1})\n\nacc_value = accuracy(labels, preds)\nwith sess.as_default():\n    print acc_value.eval(feed_dict={img: mnist_data.test.images,\n                                    labels: mnist_data.test.labels,\n                                    K.learning_phase(): 0})", 
            "title": "\u8bad\u7ec3\u548c\u6d4b\u8bd5\u884c\u4e3a\u4e0d\u540c"
        }, 
        {
            "location": "/blog/keras_and_tensorflow/#_3", 
            "text": "Keras\u7684\u5c42\u4e0e\u6a21\u578b\u548ctensorflow\u7684\u547d\u540d\u5b8c\u5168\u517c\u5bb9\uff0c\u4f8b\u5982\uff1a  x = tf.placeholder(tf.float32, shape=(None, 20, 64))\nwith tf.name_scope('block1'):\n    y = LSTM(32, name='mylstm')(x)  \u6211\u4eecLSTM\u5c42\u7684\u6743\u91cd\u5c06\u4f1a\u88ab\u547d\u540d\u4e3ablock1/mylstm_W_i, block1/mylstm_U, \u7b49..\n\u7c7b\u4f3c\u7684\uff0c\u8bbe\u5907\u7684\u547d\u540d\u4e5f\u4f1a\u50cf\u4f60\u671f\u671b\u7684\u4e00\u6837\u5de5\u4f5c\uff1a  with tf.device('/gpu:0'):\n    x = tf.placeholder(tf.float32, shape=(None, 20, 64))\n    y = LSTM(32)(x)  # all ops / variables in the LSTM layer will live on GPU:0", 
            "title": "\u4e0e\u53d8\u91cf\u540d\u4f5c\u7528\u57df\u548c\u8bbe\u5907\u4f5c\u7528\u57df\u7684\u517c\u5bb9"
        }, 
        {
            "location": "/blog/keras_and_tensorflow/#graph", 
            "text": "\u4efb\u4f55\u5728tensorflow\u7684Graph\u4f5c\u7528\u57df\u5b9a\u4e49\u7684Keras\u5c42\u6216\u6a21\u578b\u7684\u6240\u6709\u53d8\u91cf\u548c\u64cd\u4f5c\u5c06\u88ab\u751f\u6210\u4e3a\u8be5Graph\u7684\u4e00\u4e2a\u90e8\u5206\uff0c\u4f8b\u5982\uff0c\u4e0b\u9762\u7684\u4ee3\u7801\u5c06\u4f1a\u4ee5\u4f60\u6240\u671f\u671b\u7684\u5f62\u5f0f\u5de5\u4f5c  from keras.layers import LSTM\nimport tensorflow as tf\n\nmy_graph = tf.Graph()\nwith my_graph.as_default():\n    x = tf.placeholder(tf.float32, shape=(None, 20, 64))\n    y = LSTM(32)(x)  # all ops / variables in the LSTM layer are created as part of our graph", 
            "title": "\u4e0eGraph\u7684\u4f5c\u7528\u57df\u517c\u5bb9"
        }, 
        {
            "location": "/blog/keras_and_tensorflow/#_4", 
            "text": "\u53d8\u91cf\u5171\u4eab\u5e94\u901a\u8fc7\u591a\u6b21\u8c03\u7528\u540c\u6837\u7684Keras\u5c42\u6216\u6a21\u578b\u6765\u5b9e\u73b0\uff0c\u800c\u4e0d\u662f\u901a\u8fc7TensorFlow\u7684\u53d8\u91cf\u4f5c\u7528\u57df\u5b9e\u73b0\u3002TensorFlow\u53d8\u91cf\u4f5c\u7528\u57df\u5c06\u5bf9Keras\u5c42\u6216\u6a21\u578b\u6ca1\u6709\u4efb\u4f55\u5f71\u54cd\u3002\u66f4\u591aKeras\u6743\u91cd\u5171\u4eab\u7684\u4fe1\u606f\u8bf7\u53c2\u8003 \u8fd9\u91cc  Keras\u901a\u8fc7\u91cd\u7528\u76f8\u540c\u5c42\u6216\u6a21\u578b\u7684\u5bf9\u8c61\u6765\u5b8c\u6210\u6743\u503c\u5171\u4eab\uff0c\u8fd9\u662f\u4e00\u4e2a\u4f8b\u5b50\uff1a  # instantiate a Keras layer\nlstm = LSTM(32)\n\n# instantiate two TF placeholders\nx = tf.placeholder(tf.float32, shape=(None, 20, 64))\ny = tf.placeholder(tf.float32, shape=(None, 20, 64))\n\n# encode the two tensors with the *same* LSTM weights\nx_encoded = lstm(x)\ny_encoded = lstm(y)", 
            "title": "\u4e0e\u53d8\u91cf\u4f5c\u7528\u57df\u517c\u5bb9"
        }, 
        {
            "location": "/blog/keras_and_tensorflow/#_5", 
            "text": "\u67d0\u4e9bKeras\u5c42\uff0c\u5982\u72b6\u6001RNN\u548cBN\u5c42\uff0c\u5176\u5185\u90e8\u7684\u66f4\u65b0\u9700\u8981\u4f5c\u4e3a\u8bad\u7ec3\u8fc7\u7a0b\u7684\u4e00\u6b65\u6765\u8fdb\u884c\uff0c\u8fd9\u4e9b\u66f4\u65b0\u88ab\u5b58\u50a8\u5728\u4e00\u4e2atensor tuple\u91cc\uff1alayer.updates\uff0c\u4f60\u5e94\u8be5\u751f\u6210assign\u64cd\u4f5c\u6765\u4f7f\u5728\u8bad\u7ec3\u7684\u6bcf\u4e00\u6b65\u8fd9\u4e9b\u66f4\u65b0\u80fd\u591f\u88ab\u8fd0\u884c\uff0c\u8fd9\u91cc\u662f\u4f8b\u5b50\uff1a  from keras.layers import BatchNormalization\n\nlayer = BatchNormalization()(x)\n\nupdate_ops = []\nfor old_value, new_value in layer.updates:\n    update_ops.append(tf.assign(old_value, new_value))  \u6ce8\u610f\u5982\u679c\u4f60\u4f7f\u7528Keras\u6a21\u578b\uff0cmodel.updates\u5c06\u4e0e\u4e0a\u9762\u7684\u4ee3\u7801\u4f5c\u7528\u76f8\u540c\uff08\u6536\u96c6\u6a21\u578b\u4e2d\u6240\u6709\u66f4\u65b0\uff09  \u53e6\u5916\uff0c\u5982\u679c\u4f60\u9700\u8981\u663e\u5f0f\u7684\u6536\u96c6\u4e00\u4e2a\u5c42\u7684\u53ef\u8bad\u7ec3\u6743\u91cd\uff0c\u4f60\u53ef\u4ee5\u901a\u8fc7layer.trainable_weights\u6765\u5b9e\u73b0\uff0c\u5bf9\u6a21\u578b\u800c\u8a00\u662fmodel.trainable_weights\uff0c\u5b83\u662f\u4e00\u4e2atensorflow\u53d8\u91cf\u5bf9\u8c61\u7684\u5217\u8868\uff1a  from keras.layers import Dense\n\nlayer = Dense(32)(x)  # instantiate and call a layer\nprint layer.trainable_weights  # list of TensorFlow Variables  \u8fd9\u4e9b\u4e1c\u897f\u5141\u8bb8\u4f60\u5b9e\u73b0\u4f60\u57fa\u4e8eTensorFlow\u4f18\u5316\u5668\u5b9e\u73b0\u81ea\u5df1\u7684\u8bad\u7ec3\u7a0b\u5e8f", 
            "title": "\u6536\u96c6\u53ef\u8bad\u7ec3\u6743\u91cd\u4e0e\u72b6\u6001\u66f4\u65b0"
        }, 
        {
            "location": "/blog/keras_and_tensorflow/#kerastensorflow_2", 
            "text": "", 
            "title": "\u4f7f\u7528Keras\u6a21\u578b\u4e0eTensorFlow\u534f\u4f5c"
        }, 
        {
            "location": "/blog/keras_and_tensorflow/#keras-sequentialtensorflow", 
            "text": "\u5047\u5982\u4f60\u5df2\u7ecf\u6709\u4e00\u4e2a\u8bad\u7ec3\u597d\u7684Keras\u6a21\u578b\uff0c\u5982VGG-16\uff0c\u73b0\u5728\u4f60\u60f3\u5c06\u5b83\u5e94\u7528\u5728\u4f60\u7684TensorFlow\u5de5\u4f5c\u4e2d\uff0c\u5e94\u8be5\u600e\u4e48\u529e\uff1f  \u9996\u5148\uff0c\u6ce8\u610f\u5982\u679c\u4f60\u7684\u9884\u8bad\u7ec3\u6743\u91cd\u542b\u6709\u4f7f\u7528Theano\u8bad\u7ec3\u7684\u5377\u79ef\u5c42\u7684\u8bdd\uff0c\u4f60\u9700\u8981\u5bf9\u8fd9\u4e9b\u6743\u91cd\u7684\u5377\u79ef\u6838\u8fdb\u884c\u8f6c\u6362\uff0c\u8fd9\u662f\u56e0\u4e3aTheano\u548cTensorFlow\u5bf9\u5377\u79ef\u7684\u5b9e\u73b0\u4e0d\u540c\uff0cTensorFlow\u548cCaffe\u5b9e\u9645\u4e0a\u5b9e\u73b0\u7684\u662f\u76f8\u5173\u6027\u8ba1\u7b97\u3002\u70b9\u51fb \u8fd9\u91cc \u67e5\u770b\u8be6\u7ec6\u793a\u4f8b\u3002  \u5047\u8bbe\u4f60\u4ece\u4e0b\u9762\u7684Keras\u6a21\u578b\u5f00\u59cb\uff0c\u5e76\u5e0c\u671b\u5bf9\u5176\u8fdb\u884c\u4fee\u6539\u4ee5\u4f7f\u5f97\u5b83\u53ef\u4ee5\u4ee5\u4e00\u4e2a\u7279\u5b9a\u7684tensorflow\u5f20\u91cfmy_input_tensor\u4e3a\u8f93\u5165\uff0c\u8fd9\u4e2atensor\u53ef\u80fd\u662f\u4e00\u4e2a\u6570\u636efeeder\u6216\u522b\u7684tensorflow\u6a21\u578b\u7684\u8f93\u51fa  # this is our initial Keras model\nmodel = Sequential()\nfirst_layer = Dense(32, activation='relu', input_dim=784)\nmodel.add(Dense(10, activation='softmax'))  \u4f60\u53ea\u9700\u8981\u5728\u5b9e\u4f8b\u5316\u8be5\u6a21\u578b\u540e\uff0c\u4f7f\u7528set_input\u6765\u4fee\u6539\u9996\u5c42\u7684\u8f93\u5165\uff0c\u7136\u540e\u5c06\u5269\u4e0b\u6a21\u578b\u642d\u5efa\u4e8e\u5176\u4e0a\uff1a  # this is our modified Keras model\nmodel = Sequential()\nfirst_layer = Dense(32, activation='relu', input_dim=784)\nfirst_layer.set_input(my_input_tensor)\n\n# build the rest of the model as before\nmodel.add(first_layer)\nmodel.add(Dense(10, activation='softmax'))  \u5728\u8fd9\u4e2a\u9636\u6bb5\uff0c\u4f60\u53ef\u4ee5\u8c03\u7528model.load_weights(weights_file)\u6765\u52a0\u8f7d\u9884\u8bad\u7ec3\u7684\u6743\u91cd  \u7136\u540e\uff0c\u4f60\u6216\u8bb8\u4f1a\u6536\u96c6\u8be5\u6a21\u578b\u7684\u8f93\u51fa\u5f20\u91cf\uff1a  output_tensor = model.output", 
            "title": "\u5c06Keras Sequential\u6a21\u578b\u8f6c\u6362\u5230TensorFlow\u4e2d"
        }, 
        {
            "location": "/blog/keras_and_tensorflow/#tensorflowkeras_1", 
            "text": "Keras\u6a21\u578b\u4e0eKeras\u5c42\u7684\u884c\u4e3a\u4e00\u81f4\uff0c\u56e0\u6b64\u53ef\u4ee5\u88ab\u8c03\u7528\u4e8eTensorFlow\u5f20\u91cf\u4e0a\uff1a  from keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(Dense(32, activation='relu', input_dim=784))\nmodel.add(Dense(10, activation='softmax'))\n\n# this works! \nx = tf.placeholder(tf.float32, shape=(None, 784))\ny = model(x)  \u6ce8\u610f\uff0c\u8c03\u7528\u6a21\u578b\u65f6\u4f60\u540c\u65f6\u4f7f\u7528\u4e86\u6a21\u578b\u7684\u7ed3\u6784\u4e0e\u6743\u91cd\uff0c\u5f53\u4f60\u5728\u4e00\u4e2atensor\u4e0a\u8c03\u7528\u6a21\u578b\u65f6\uff0c\u4f60\u5c31\u5728\u8be5tensor\u4e0a\u521b\u9020\u4e86\u4e00\u4e9b\u64cd\u4f5c\uff0c\u8fd9\u4e9b\u64cd\u4f5c\u91cd\u7528\u4e86\u5df2\u7ecf\u5728\u6a21\u578b\u4e2d\u51fa\u73b0\u7684TensorFlow\u53d8\u91cf\u7684\u5bf9\u8c61", 
            "title": "\u5bf9TensorFlow\u5f20\u91cf\u4e2d\u8c03\u7528Keras\u6a21\u578b"
        }, 
        {
            "location": "/blog/keras_and_tensorflow/#gpu", 
            "text": "", 
            "title": "\u591aGPU\u548c\u5206\u5e03\u5f0f\u8bad\u7ec3"
        }, 
        {
            "location": "/blog/keras_and_tensorflow/#kerasgpu", 
            "text": "TensorFlow\u7684\u8bbe\u5907\u4f5c\u7528\u57df\u5b8c\u5168\u4e0eKeras\u7684\u5c42\u548c\u6a21\u578b\u517c\u5bb9\uff0c\u56e0\u6b64\u4f60\u53ef\u4ee5\u4f7f\u7528\u5b83\u4eec\u6765\u5c06\u4e00\u4e2a\u56fe\u7684\u7279\u5b9a\u90e8\u5206\u653e\u5728\u4e0d\u540c\u7684GPU\u4e2d\u8bad\u7ec3\uff0c\u8fd9\u91cc\u662f\u4e00\u4e2a\u7b80\u5355\u7684\u4f8b\u5b50\uff1a  with tf.device('/gpu:0'):\n    x = tf.placeholder(tf.float32, shape=(None, 20, 64))\n    y = LSTM(32)(x)  # all ops in the LSTM layer will live on GPU:0\n\nwith tf.device('/gpu:1'):\n    x = tf.placeholder(tf.float32, shape=(None, 20, 64))\n    y = LSTM(32)(x)  # all ops in the LSTM layer will live on GPU:1  \u6ce8\u610f\uff0c\u7531LSTM\u5c42\u521b\u5efa\u7684\u53d8\u91cf\u5c06\u4e0d\u4f1a\u751f\u5b58\u5728GPU\u4e0a\uff0c\u4e0d\u7ba1TensorFlow\u53d8\u91cf\u5728\u54ea\u91cc\u521b\u5efa\uff0c\u5b83\u4eec\u603b\u662f\u751f\u5b58\u5728CPU\u4e0a\uff0cTensorFlow\u5c06\u9690\u542b\u7684\u5904\u7406\u8bbe\u5907\u4e4b\u95f4\u7684\u8f6c\u6362  \u5982\u679c\u4f60\u60f3\u5728\u591a\u4e2aGPU\u4e0a\u8bad\u7ec3\u540c\u4e00\u4e2a\u6a21\u578b\u7684\u591a\u4e2a\u526f\u672c\uff0c\u5e76\u5728\u591a\u4e2a\u526f\u672c\u4e2d\u8fdb\u884c\u6743\u91cd\u5171\u4eab\uff0c\u9996\u5148\u4f60\u5e94\u8be5\u5728\u4e00\u4e2a\u8bbe\u5907\u4f5c\u7528\u57df\u4e0b\u5b9e\u4f8b\u5316\u4f60\u7684\u6a21\u578b\u6216\u5c42\uff0c\u7136\u540e\u5728\u4e0d\u540cGPU\u8bbe\u5907\u7684\u4f5c\u7528\u57df\u4e0b\u591a\u6b21\u8c03\u7528\u8be5\u6a21\u578b\u5b9e\u4f8b\uff0c\u5982\uff1a  with tf.device('/cpu:0'):\n    x = tf.placeholder(tf.float32, shape=(None, 784))\n\n    # shared model living on CPU:0\n    # it won't actually be run during training; it acts as an op template\n    # and as a repository for shared variables\n    model = Sequential()\n    model.add(Dense(32, activation='relu', input_dim=784))\n    model.add(Dense(10, activation='softmax'))\n\n# replica 0\nwith tf.device('/gpu:0'):\n    output_0 = model(x)  # all ops in the replica will live on GPU:0\n\n# replica 1\nwith tf.device('/gpu:1'):\n    output_1 = model(x)  # all ops in the replica will live on GPU:1\n\n# merge outputs on CPU\nwith tf.device('/cpu:0'):\n    preds = 0.5 * (output_0 + output_1)\n\n# we only run the `preds` tensor, so that only the two\n# replicas on GPU get run (plus the merge op on CPU)\noutput_value = sess.run([preds], feed_dict={x: data})", 
            "title": "\u5c06Keras\u6a21\u578b\u5206\u6563\u5728\u591a\u4e2aGPU\u4e2d\u8bad\u7ec3"
        }, 
        {
            "location": "/blog/keras_and_tensorflow/#_6", 
            "text": "\u901a\u8fc7\u6ce8\u518cKeras\u4f1a\u8bdd\u5230\u4e00\u4e2a\u96c6\u7fa4\u4e0a\uff0c\u4f60\u53ef\u4ee5\u7b80\u5355\u7684\u5b9e\u73b0\u5206\u5e03\u5f0f\u8bad\u7ec3\uff1a  server = tf.train.Server.create_local_server()\nsess = tf.Session(server.target)\n\nfrom keras import backend as K\nK.set_session(sess)  \u5173\u4e8eTensorFlow\u8fdb\u884c\u5206\u5e03\u5f0f\u8bad\u7ec3\u7684\u914d\u7f6e\u4fe1\u606f\uff0c\u8bf7\u53c2\u8003 \u8fd9\u91cc", 
            "title": "\u5206\u5e03\u5f0f\u8bad\u7ec3"
        }, 
        {
            "location": "/blog/keras_and_tensorflow/#tensorflow-serving", 
            "text": "TensorFlow-Serving \u662f\u7531Google\u5f00\u53d1\u7684\u7528\u4e8e\u5c06TensoFlow\u6a21\u578b\u90e8\u7f72\u4e8e\u751f\u4ea7\u73af\u5883\u7684\u5de5\u5177  \u4efb\u4f55Keras\u6a21\u578b\u90fd\u53ef\u4ee5\u88abTensorFlow-serving\u6240\u5bfc\u51fa\uff08\u53ea\u8981\u5b83\u53ea\u542b\u6709\u4e00\u4e2a\u8f93\u5165\u548c\u4e00\u4e2a\u8f93\u51fa\uff0c\u8fd9\u662fTF-serving\u7684\u9650\u5236\uff09\uff0c\u4e0d\u7ba1\u5b83\u662f\u5426\u4f5c\u4e3aTensroFlow\u5de5\u4f5c\u6d41\u7684\u4e00\u90e8\u5206\u3002\u4e8b\u5b9e\u4e0a\u4f60\u751a\u81f3\u53ef\u4ee5\u4f7f\u7528Theano\u8bad\u7ec3\u4f60\u7684Keras\u6a21\u578b\uff0c\u7136\u540e\u5c06\u5176\u5207\u6362\u5230tensorflow\u540e\u7aef\uff0c\u7136\u540e\u5bfc\u51fa\u6a21\u578b  \u5982\u679c\u4f60\u7684graph\u4f7f\u7528\u4e86Keras\u7684learning phase\uff08\u5728\u8bad\u7ec3\u548c\u6d4b\u8bd5\u4e2d\u884c\u4e3a\u4e0d\u540c\uff09\uff0c\u4f60\u9996\u5148\u8981\u505a\u7684\u4e8b\u5c31\u662f\u5728graph\u4e2d\u786c\u7f16\u7801\u4f60\u7684\u5de5\u4f5c\u6a21\u5f0f\uff08\u8bbe\u4e3a0\uff0c\u5373\u6d4b\u8bd5\u6a21\u5f0f\uff09\uff0c\u8be5\u5de5\u4f5c\u901a\u8fc71\uff09\u4f7f\u7528Keras\u7684\u540e\u7aef\u6ce8\u518c\u4e00\u4e2alearning phase\u5e38\u91cf\uff0c2\uff09\u91cd\u65b0\u6784\u5efa\u6a21\u578b\uff0c\u6765\u5b8c\u6210\u3002  \u8fd9\u91cc\u662f\u5b9e\u8df5\u4e2d\u7684\u793a\u8303\uff1a  from keras import backend as K\n\nK.set_learning_phase(0)  # all new operations will be in test mode from now on\n\n# serialize the model and get its weights, for quick re-building\nconfig = previous_model.get_config()\nweights = previous_model.get_weights()\n\n# re-build a model where the learning phase is now hard-coded to 0\nfrom keras.models import model_from_config\nnew_model = model_from_config(config)\nnew_model.set_weights(weights)  \u73b0\u5728\uff0c\u6211\u4eec\u53ef\u4f7f\u7528Tensorflow-serving\u6765\u5bfc\u51fa\u6a21\u578b\uff0c\u6309\u7167\u5b98\u65b9\u6559\u7a0b\u7684\u6307\u5bfc\uff1a  from tensorflow_serving.session_bundle import exporter\n\nexport_path = ... # where to save the exported graph\nexport_version = ... # version number (integer)\n\nsaver = tf.train.Saver(sharded=True)\nmodel_exporter = exporter.Exporter(saver)\nsignature = exporter.classification_signature(input_tensor=model.input,\n                                              scores_tensor=model.output)\nmodel_exporter.init(sess.graph.as_graph_def(),\n                    default_graph_signature=signature)\nmodel_exporter.export(export_path, tf.constant(export_version), sess)  \u5982\u60f3\u770b\u5230\u5305\u542b\u672c\u6559\u7a0b\u7684\u65b0\u4e3b\u9898\uff0c\u8bf7\u770b \u6211\u7684Twitter", 
            "title": "\u4f7f\u7528TensorFlow-serving\u5bfc\u51fa\u6a21\u578b"
        }, 
        {
            "location": "/acknowledgement/", 
            "text": "\ufeff\n\n\n\u81f4\u8c22\n\n\n\u672c\u9879\u76ee\u7531\u4ee5\u4e0b\u8d21\u732e\u8005\u8d21\u732e\uff1a\n\n\n\u6587\u6863\u8d21\u732e\n\n\n\n\n\n\n\n\n\u8d21\u732e\u8005\n\n\n\u9875\u9762\n\n\n\u7ae0\u8282\n\n\n\u7c7b\u578b\n\n\n\n\n\n\n\n\n\n\nBigmoyan\n\n\nkeras.io\u7684\u5168\u90e8\u6b63\u6587\n\n\n-\n\n\n\u7ffb\u8bd1\n\n\n\n\n\n\nBigmoyan\n\n\n\u6df1\u5ea6\u5b66\u4e60\u4e0eKeras\n\n\nCNN\u773c\u4e2d\u7684\u4e16\u754c\n\n\n\u7ffb\u8bd1\n\n\n\n\n\n\nBigmoyan\n\n\n\u6df1\u5ea6\u5b66\u4e60\u4e0eKeras\n\n\n\u82b1\u5f0f\u81ea\u52a8\u7f16\u7801\u5668\n\n\n\u7ffb\u8bd1\n\n\n\n\n\n\nBigmoyan\n\n\n\u5feb\u901f\u5f00\u59cb\n\n\n\u4e00\u4e9b\u57fa\u672c\u6982\u5ff5\n\n\n\u7f16\u5199\n\n\n\n\n\n\nSCP-173\n\n\n\u5feb\u901f\u5f00\u59cb\n\n\nKeras\u5b89\u88c5\u548c\u914d\u7f6e\u6307\u5357(Linux)\n\n\n\u7f16\u5199\n\n\n\n\n\n\nSCP-173\n\n\n\u5feb\u901f\u5f00\u59cb\n\n\nKeras\u5b89\u88c5\u548c\u914d\u7f6e\u6307\u5357(Windows)\n\n\n\u7f16\u5199\n\n\n\n\n\n\nBigmoyan\n\n\n\u6df1\u5ea6\u5b66\u4e60\u4e0eKeras\n\n\n\u9762\u5411\u5c0f\u6570\u636e\u96c6\u6784\u5efa\u56fe\u50cf\u5206\u7c7b\u6a21\u578b\n\n\n\u7ffb\u8bd1\n\n\n\n\n\n\nleo-nlp\n\n\n\u6df1\u5ea6\u5b66\u4e60\u4e0eKeras\n\n\n\u5728Keras\u6a21\u578b\u4e2d\u4f7f\u7528\u9884\u8bad\u7ec3\u7684\u8bcd\u5411\u91cf\n\n\n\u7ffb\u8bd1\n\n\n\n\n\n\nzhourunlai\n\n\n\u5de5\u5177\n\n\nI/O\u5de5\u5177\n\n\n\u7ffb\u8bd1\n\n\n\n\n\n\n\n\nTips\n\n\n\n\n\n\n\n\n\u8d21\u732e\u8005\n\n\n\u9875\u9762\n\n\n\n\n\n\n\n\n\n\nBigmoyan\n\n\nTips\u5904\u6807\u6ce8\n\n\n\n\n\n\n3rduncle\n\n\nTips\u5904\u6807\u6ce8\n\n\n\n\n\n\n\u767d\u83dc\n\n\nTips\u5904\u6807\u8bb0\n\n\n\n\n\n\n\u6211\u662f\u5c0f\u5c06\n\n\nTips\u5904\u6807\u8bb0\n\n\n\n\n\n\nzhourunlai\n\n\n\u53ef\u89c6\u5316\n\n\n\n\n\n\n\n\nKeras\u9677\u9631\u63d0\u793a\n\n\n\n\n\n\n\n\n\u8d21\u732e\u8005\n\n\n\u9875\u9762\n\n\n\n\n\n\n\n\n\n\nBigmoyan\n\n\ntf\u4e0eth\u5377\u79ef\u6838\u9677\u9631\n\n\n\n\n\n\nBigmoyan\n\n\n\u5411BN\u5c42\u8f7d\u5165\u6743\u91cd\u9677\u9631\n\n\n\n\n\n\nYin\n\n\nvalidation_spilit\u4e0eshuffle\u9677\u9631\n\n\n\n\n\n\nHui Liu\n\n\nmerge\u4e0eMerge\u7684\u533a\u522b\n\n\n\n\n\n\n## Reviewers\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReviewer\n\n\n\u9875\u9762\n\n\n\u7ae0\u8282\n\n\n\n\n\n\n\n\n\n\n\u767d\u83dc\n\n\n\u5feb\u901f\u5f00\u59cb\u6cdb\u578b\u6a21\u578b\n\n\n\u5171\u4eab\u5c42\n\n\n\n\n\n\n\u767d\u83dc\n\n\n\u5e38\u7528\u6570\u636e\u5e93\n\n\nIMDB\u5f71\u8bc4\u503e\u5411\u5206\u7c7b\n\n\n\n\n\n\ndoudou\n\n\n\u5173\u4e8e\u6a21\u578b\n\n\n\u5173\u4e8eKeras\u6a21\u578b\n\n\n\n\n\n\ndoudou\n\n\n\u5e38\u7528\u5c42\n\n\nDense\u5c42\n\n\n\n\n\n\n\u827e\u5b50\n\n\n\u5e38\u7528\u5c42\n\n\nMerge\u5c42\n\n\n\n\n\n\nNUDT-\u5c0f\u8d85\u4eba\u3001\u3001\n\n\n\u5feb\u901f\u5f00\u59cbSequential\u6a21\u578b\n\n\nMerge\u5c42\n\n\n\n\n\n\n\u6bdb\u6bdb\u718a\n\n\n\u5e38\u7528\u6570\u636e\u5e93\n\n\ncifar-10\n\n\n\n\n\n\n\u8ff7\u5ddd\u6d69\u6d69\n\n\n\u56de\u8c03\u51fd\u6570\n\n\ncallback\n\n\n\n\n\n\ntadakey\n\n\n\u4e00\u4e9b\u57fa\u672c\u6982\u5ff5\n\n\n\u5f20\u91cf\n\n\n\n\n\n\n\u65b9\u6e3a\u6e3a\n\n\n\u9012\u5f52\u5c42\n\n\nrecurrent\u5c42\n\n\n\n\n\n\nleo-nlp\n\n\n\u5feb\u901f\u5f00\u59cb\u6cdb\u578b\u6a21\u578b\n\n\n\u5171\u4eab\u5c42\n\n\n\n\n\n\n\u5355\u8f66\n\n\n\u5e38\u7528\u5c42\n\n\nMasking\u5c42\n\n\n\n\n\n\n\u5f20\u6d9b\n\n\n\u5feb\u901f\u5f00\u59cb\u6cdb\u578b\u6a21\u578b\n\n\n\u591a\u8f93\u5165\u548c\u591a\u8f93\u51fa\u6a21\u578b\n\n\n\n\n\n\n\u767d\u83dc\n\n\nFAQ\n\n\n\u5982\u4f55\u89c2\u5bdf\u4e2d\u95f4\u5c42\u7684\u8f93\u51fa\n\n\n\n\n\n\n\u6bd2\u6db2\n\n\n\u6587\u672c\u9884\u5904\u7406\n\n\none-hot\n\n\n\n\n\n\n\u6bd2\u6db2\n\n\n\u56de\u8c03\u51fd\u6570\n\n\nEarlyStopping\n\n\n\n\n\n\n\u6bd2\u6db2\n\n\n\u76ee\u6807\u51fd\u6570\n\n\n\u53ef\u7528\u7684\u76ee\u6807\u51fd\u6570\n\n\n\n\n\n\n\u6bdb\u6bdb\u718a\n\n\n\u6b63\u5219\u9879\n\n\n\u7f29\u5199\n\n\n\n\n\n\n\u6728\u5b50\u5929\u4e00\n\n\n\u5c40\u90e8\u8fde\u63a5\u5c42LocallyConnceted\n\n\nLocallyConnected2D\u5c42\n\n\n\n\n\n\nQiaXi\n\n\nPooling\u5c42\n\n\nGlobalMax/GlobalAve\n\n\n\n\n\n\nshawn\n\n\nCallback\n\n\nModelCheckpoint\n\n\n\n\n\n\nsmallYoki\n\n\n\u5feb\u901f\u5f00\u59cb\n\n\n\u6cdb\u578b\u6a21\u578b\n\n\n\n\n\n\n\n\n\u793a\u4f8b\u7a0b\u5e8f\n\n\n\n\n\u865a\u4f4d\u4ee5\u5f85", 
            "title": "\u81f4\u8c22"
        }, 
        {
            "location": "/acknowledgement/#_1", 
            "text": "\u672c\u9879\u76ee\u7531\u4ee5\u4e0b\u8d21\u732e\u8005\u8d21\u732e\uff1a", 
            "title": "\u81f4\u8c22"
        }, 
        {
            "location": "/acknowledgement/#_2", 
            "text": "\u8d21\u732e\u8005  \u9875\u9762  \u7ae0\u8282  \u7c7b\u578b      Bigmoyan  keras.io\u7684\u5168\u90e8\u6b63\u6587  -  \u7ffb\u8bd1    Bigmoyan  \u6df1\u5ea6\u5b66\u4e60\u4e0eKeras  CNN\u773c\u4e2d\u7684\u4e16\u754c  \u7ffb\u8bd1    Bigmoyan  \u6df1\u5ea6\u5b66\u4e60\u4e0eKeras  \u82b1\u5f0f\u81ea\u52a8\u7f16\u7801\u5668  \u7ffb\u8bd1    Bigmoyan  \u5feb\u901f\u5f00\u59cb  \u4e00\u4e9b\u57fa\u672c\u6982\u5ff5  \u7f16\u5199    SCP-173  \u5feb\u901f\u5f00\u59cb  Keras\u5b89\u88c5\u548c\u914d\u7f6e\u6307\u5357(Linux)  \u7f16\u5199    SCP-173  \u5feb\u901f\u5f00\u59cb  Keras\u5b89\u88c5\u548c\u914d\u7f6e\u6307\u5357(Windows)  \u7f16\u5199    Bigmoyan  \u6df1\u5ea6\u5b66\u4e60\u4e0eKeras  \u9762\u5411\u5c0f\u6570\u636e\u96c6\u6784\u5efa\u56fe\u50cf\u5206\u7c7b\u6a21\u578b  \u7ffb\u8bd1    leo-nlp  \u6df1\u5ea6\u5b66\u4e60\u4e0eKeras  \u5728Keras\u6a21\u578b\u4e2d\u4f7f\u7528\u9884\u8bad\u7ec3\u7684\u8bcd\u5411\u91cf  \u7ffb\u8bd1    zhourunlai  \u5de5\u5177  I/O\u5de5\u5177  \u7ffb\u8bd1", 
            "title": "\u6587\u6863\u8d21\u732e"
        }, 
        {
            "location": "/acknowledgement/#tips", 
            "text": "\u8d21\u732e\u8005  \u9875\u9762      Bigmoyan  Tips\u5904\u6807\u6ce8    3rduncle  Tips\u5904\u6807\u6ce8    \u767d\u83dc  Tips\u5904\u6807\u8bb0    \u6211\u662f\u5c0f\u5c06  Tips\u5904\u6807\u8bb0    zhourunlai  \u53ef\u89c6\u5316", 
            "title": "Tips"
        }, 
        {
            "location": "/acknowledgement/#keras", 
            "text": "\u8d21\u732e\u8005  \u9875\u9762      Bigmoyan  tf\u4e0eth\u5377\u79ef\u6838\u9677\u9631    Bigmoyan  \u5411BN\u5c42\u8f7d\u5165\u6743\u91cd\u9677\u9631    Yin  validation_spilit\u4e0eshuffle\u9677\u9631    Hui Liu  merge\u4e0eMerge\u7684\u533a\u522b    ## Reviewers         Reviewer  \u9875\u9762  \u7ae0\u8282      \u767d\u83dc  \u5feb\u901f\u5f00\u59cb\u6cdb\u578b\u6a21\u578b  \u5171\u4eab\u5c42    \u767d\u83dc  \u5e38\u7528\u6570\u636e\u5e93  IMDB\u5f71\u8bc4\u503e\u5411\u5206\u7c7b    doudou  \u5173\u4e8e\u6a21\u578b  \u5173\u4e8eKeras\u6a21\u578b    doudou  \u5e38\u7528\u5c42  Dense\u5c42    \u827e\u5b50  \u5e38\u7528\u5c42  Merge\u5c42    NUDT-\u5c0f\u8d85\u4eba\u3001\u3001  \u5feb\u901f\u5f00\u59cbSequential\u6a21\u578b  Merge\u5c42    \u6bdb\u6bdb\u718a  \u5e38\u7528\u6570\u636e\u5e93  cifar-10    \u8ff7\u5ddd\u6d69\u6d69  \u56de\u8c03\u51fd\u6570  callback    tadakey  \u4e00\u4e9b\u57fa\u672c\u6982\u5ff5  \u5f20\u91cf    \u65b9\u6e3a\u6e3a  \u9012\u5f52\u5c42  recurrent\u5c42    leo-nlp  \u5feb\u901f\u5f00\u59cb\u6cdb\u578b\u6a21\u578b  \u5171\u4eab\u5c42    \u5355\u8f66  \u5e38\u7528\u5c42  Masking\u5c42    \u5f20\u6d9b  \u5feb\u901f\u5f00\u59cb\u6cdb\u578b\u6a21\u578b  \u591a\u8f93\u5165\u548c\u591a\u8f93\u51fa\u6a21\u578b    \u767d\u83dc  FAQ  \u5982\u4f55\u89c2\u5bdf\u4e2d\u95f4\u5c42\u7684\u8f93\u51fa    \u6bd2\u6db2  \u6587\u672c\u9884\u5904\u7406  one-hot    \u6bd2\u6db2  \u56de\u8c03\u51fd\u6570  EarlyStopping    \u6bd2\u6db2  \u76ee\u6807\u51fd\u6570  \u53ef\u7528\u7684\u76ee\u6807\u51fd\u6570    \u6bdb\u6bdb\u718a  \u6b63\u5219\u9879  \u7f29\u5199    \u6728\u5b50\u5929\u4e00  \u5c40\u90e8\u8fde\u63a5\u5c42LocallyConnceted  LocallyConnected2D\u5c42    QiaXi  Pooling\u5c42  GlobalMax/GlobalAve    shawn  Callback  ModelCheckpoint    smallYoki  \u5feb\u901f\u5f00\u59cb  \u6cdb\u578b\u6a21\u578b", 
            "title": "Keras\u9677\u9631\u63d0\u793a"
        }, 
        {
            "location": "/acknowledgement/#_3", 
            "text": "\u865a\u4f4d\u4ee5\u5f85", 
            "title": "\u793a\u4f8b\u7a0b\u5e8f"
        }
    ]
}