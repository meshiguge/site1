<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <meta name="author" content="BigMoyan">
  <link rel="shortcut icon" href="../../img/favicon.ico">
  <title>将Keras作为tensorflow的精简接口 - Keras中文文档</title>
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" href="../../css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../css/theme_extra.css" type="text/css" />
  <link rel="stylesheet" href="../../css/highlight.css">
  
  <script>
    // Current page data
    var mkdocs_page_name = "\u5c06Keras\u4f5c\u4e3atensorflow\u7684\u7cbe\u7b80\u63a5\u53e3";
    var mkdocs_page_input_path = "blog/keras_and_tensorflow.md";
    var mkdocs_page_url = "/blog/keras_and_tensorflow/";
  </script>
  
  <script src="../../js/jquery-2.1.1.min.js"></script>
  <script src="../../js/modernizr-2.8.3.min.js"></script>
  <script type="text/javascript" src="../../js/highlight.pack.js"></script> 
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
      <div class="wy-side-nav-search">
        <a href="../.." class="icon icon-home"> Keras中文文档</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
	<ul class="current">
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../..">主页</a>
        
    </li>
<li>
          
            <li>
    <ul class="subnav">
    <li><span>快速开始</span></li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../getting_started/concepts/">一些基本概念</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../getting_started/keras_linux/">Keras安装和配置指南(Linux)</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../getting_started/keras_windows/">Keras安装和配置指南(Windows)</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../getting_started/sequential_model/">快速开始Sequential模型</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../getting_started/functional_API/">快速开始泛型模型</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../getting_started/FAQ/">FAQ</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../getting_started/trap/">Keras使用陷阱</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../getting_started/examples/">Keras示例列表</a>
        
    </li>

        
    </ul>
<li>
          
            <li>
    <ul class="subnav">
    <li><span>模型</span></li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../models/about_model/">关于Keras模型</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../models/sequential/">Sequential模型</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../models/model/">泛型模型</a>
        
    </li>

        
    </ul>
<li>
          
            <li>
    <ul class="subnav">
    <li><span>网络层</span></li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../layers/about_layer/">关于Keras层</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../layers/core_layer/">常用层Core</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../layers/convolutional_layer/">卷积层Convolutional</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../layers/pooling_layer/">池化层Pooling</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../layers/locally_connected_layer/">局部连接层Locally-connented</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../layers/recurrent_layer/">递归层Recurrent</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../layers/embedding_layer/">嵌入层Embedding</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../layers/advanced_activation_layer/">高级激活层Advanced Activation</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../layers/normalization_layer/">规范层BatchNormalization</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../layers/noise_layer/">噪声层Noise</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../layers/wrapper/">包装器Wrapper</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../layers/writting_layer/">编写自己的层</a>
        
    </li>

        
    </ul>
<li>
          
            <li>
    <ul class="subnav">
    <li><span>预处理</span></li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../preprocessing/sequence/">序列预处理</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../preprocessing/text/">文本预处理</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../preprocessing/image/">图片预处理</a>
        
    </li>

        
    </ul>
<li>
          
            <li>
    <ul class="subnav">
    <li><span>其他重要模块</span></li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../other/objectives/">目标函数Objective</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../other/optimizers/">优化器Optimizer</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../other/activations/">激活函数Activation</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../other/callbacks/">回调函数Callback</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../other/metrices/">性能评估Metrices</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../other/initializations/">初始化方法Initialization</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../other/regularizers/">正则项Regularizer</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../other/constraints/">约束项Constraint</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../other/application/">预训练模型Application</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../other/datasets/">常用数据库Dataset</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../other/visualization/">可视化Visualization</a>
        
    </li>

        
    </ul>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../../backend/">keras后端Backend</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../../scikit-learn_API/">scikit-learn接口</a>
        
    </li>
<li>
          
            <li>
    <ul class="subnav">
    <li><span>工具</span></li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../utils/data_utils/">数据工具</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../utils/io_utils/">输入输出I/O</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../utils/layer_utils/">Keras层工具</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../utils/np_utils/">numpy工具</a>
        
    </li>

        
    </ul>
<li>
          
            <li>
    <ul class="subnav">
    <li><span>深度学习与Keras</span></li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../cnn_see_world/">CNN眼中的世界</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../autoencoder/">花式自动编码器</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../image_classification_using_very_little_data/">面向小数据集构建图像分类模型</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../word_embedding/">在Keras模型中使用预训练的词向量</a>
        
    </li>

        
            
    <li class="toctree-l1 current">
        <a class="current" href="./">将Keras作为tensorflow的精简接口</a>
        
            <ul>
            
                <li class="toctree-l3"><a href="#kerastensorflow">将Keras作为tensorflow的精简接口</a></li>
                
                    <li><a class="toctree-l4" href="#_1">文章信息</a></li>
                
            
            </ul>
        
    </li>

        
    </ul>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../../acknowledgement/">致谢</a>
        
    </li>
<li>
          
        </ul>
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../..">Keras中文文档</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../..">Docs</a> &raquo;</li>
    
      
        
          <li>深度学习与Keras &raquo;</li>
        
      
    
    <li>将Keras作为tensorflow的精简接口</li>
    <li class="wy-breadcrumbs-aside">
      
    </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <h1 id="kerastensorflow">将Keras作为tensorflow的精简接口</h1>
<h2 id="_1">文章信息</h2>
<p><font color='#FF0000'>本文地址：<a href="https://blog.keras.io/keras-as-a-simplified-interface-to-tensorflow-tutorial.html"><font color='#FF0000'>https://blog.keras.io/keras-as-a-simplified-interface-to-tensorflow-tutorial.html</font></a></p>
<p>本文作者：Francois Chollet
</font></p>
<h3 id="kerastensorflow_1">使用Keras作为TensorFlow工作流的一部分</h3>
<p>如果Tensorflow是你的首选框架，并且你想找一个简化的、高层的模型定义接口来让自己活的不那么累，那么这篇文章就是给你看的</p>
<p>Keras的层和模型与纯TensorFlow的tensor完全兼容，因此，Keras可以作为TensorFlow的模型定义，甚至可以与其他TensoFlow库协同工作。</p>
<p><strong>注意，本文假定你已经把Keras配置为tensorflow后端，如果你不懂怎么配置，请查看<a href="../../backend/"><font color="#FF0000">这里</font></a></strong></p>
<p><img alt="keras-tensorflow-logo" src="../../images/keras-tensorflow-logo.jpg" /></p>
<h3 id="tensorflowkeras">在tensorflow中调用Keras层</h3>
<p>让我们以一个简单的例子开始：MNIST数字分类。我们将以Keras的全连接层堆叠构造一个TensorFlow的分类器，</p>
<pre><code class="python">import tensorflow as tf
sess = tf.Session()

from keras import backend as K
K.set_session(sess)
</code></pre>

<p>然后，我们开始用tensorflow构建模型：</p>
<pre><code class="python"># this placeholder will contain our input digits, as flat vectors
img = tf.placeholder(tf.float32, shape=(None, 784))

</code></pre>

<p>用Keras可以加速模型的定义过程：</p>
<pre><code class="python">from keras.layers import Dense

# Keras layers can be called on TensorFlow tensors:
x = Dense(128, activation='relu')(img)  # fully-connected layer with 128 units and ReLU activation
x = Dense(128, activation='relu')(x)
preds = Dense(10, activation='softmax')(x)  # output layer with 10 units and a softmax activation
</code></pre>

<p>定义标签的占位符和损失函数：</p>
<pre><code class="python">labels = tf.placeholder(tf.float32, shape=(None, 10))

from keras.objectives import categorical_crossentropy
loss = tf.reduce_mean(categorical_crossentropy(labels, preds))
</code></pre>

<p>然后，我们可以用tensorflow的优化器来训练模型：</p>
<pre><code class="python">from tensorflow.examples.tutorials.mnist import input_data
mnist_data = input_data.read_data_sets('MNIST_data', one_hot=True)

train_step = tf.train.GradientDescentOptimizer(0.5).minimize(loss)
with sess.as_default():
    for i in range(100):
        batch = mnist_data.train.next_batch(50)
        train_step.run(feed_dict={img: batch[0],
                                  labels: batch[1]})
</code></pre>

<p>最后我们来评估一下模型性能：</p>
<pre><code class="python">from keras.metrics import categorical_accuracy as accuracy

acc_value = accuracy(labels, preds)
with sess.as_default():
    print acc_value.eval(feed_dict={img: mnist_data.test.images,
                                    labels: mnist_data.test.labels})
</code></pre>

<p>我们只是将Keras作为生成从tensor到tensor的函数（op）的快捷方法而已，优化过程完全采用的原生tensorflow的优化器，而不是Keras优化器，我们压根不需要Keras的Model</p>
<p>关于原生TensorFlow和Keras的优化器的一点注记：虽然有点反直觉，但Keras的优化器要比TensorFlow的优化器快大概5-10%。虽然这种速度的差异基本上没什么差别。</p>
<h4 id="_2">训练和测试行为不同</h4>
<p>有些Keras层，如BN，Dropout，在训练和测试过程中的行为不一致，你可以通过打印layer.uses_learning_phase来确定当前层工作在训练模式还是测试模式。</p>
<p>如果你的模型包含这样的层，你需要指定你希望模型工作在什么模式下，通过Keras的backend你可以了解当前的工作模式：</p>
<pre><code class="python">from keras import backend as K
print K.learning_phase()
</code></pre>

<p>向feed_dict中传递1（训练模式）或0（测试模式）即可指定当前工作模式：</p>
<pre><code class="python"># train mode
train_step.run(feed_dict={x: batch[0], labels: batch[1], K.learning_phase(): 1})
</code></pre>

<p>例如，下面代码示范了如何将Dropout层加入刚才的模型中：</p>
<pre><code class="python">from keras.layers import Dropout
from keras import backend as K

img = tf.placeholder(tf.float32, shape=(None, 784))
labels = tf.placeholder(tf.float32, shape=(None, 10))

x = Dense(128, activation='relu')(img)
x = Dropout(0.5)(x)
x = Dense(128, activation='relu')(x)
x = Dropout(0.5)(x)
preds = Dense(10, activation='softmax')(x)

loss = tf.reduce_mean(categorical_crossentropy(labels, preds))

train_step = tf.train.GradientDescentOptimizer(0.5).minimize(loss)
with sess.as_default():
    for i in range(100):
        batch = mnist_data.train.next_batch(50)
        train_step.run(feed_dict={img: batch[0],
                                  labels: batch[1],
                                  K.learning_phase(): 1})

acc_value = accuracy(labels, preds)
with sess.as_default():
    print acc_value.eval(feed_dict={img: mnist_data.test.images,
                                    labels: mnist_data.test.labels,
                                    K.learning_phase(): 0})
</code></pre>

<h4 id="_3">与变量名作用域和设备作用域的兼容</h4>
<p>Keras的层与模型和tensorflow的命名完全兼容，例如：</p>
<pre><code class="python">x = tf.placeholder(tf.float32, shape=(None, 20, 64))
with tf.name_scope('block1'):
    y = LSTM(32, name='mylstm')(x)
</code></pre>

<p>我们LSTM层的权重将会被命名为block1/mylstm_W_i, block1/mylstm_U, 等..
类似的，设备的命名也会像你期望的一样工作：</p>
<pre><code class="python">with tf.device('/gpu:0'):
    x = tf.placeholder(tf.float32, shape=(None, 20, 64))
    y = LSTM(32)(x)  # all ops / variables in the LSTM layer will live on GPU:0
</code></pre>

<h4 id="graph">与Graph的作用域兼容</h4>
<p>任何在tensorflow的Graph作用域定义的Keras层或模型的所有变量和操作将被生成为该Graph的一个部分，例如，下面的代码将会以你所期望的形式工作</p>
<pre><code class="python">from keras.layers import LSTM
import tensorflow as tf

my_graph = tf.Graph()
with my_graph.as_default():
    x = tf.placeholder(tf.float32, shape=(None, 20, 64))
    y = LSTM(32)(x)  # all ops / variables in the LSTM layer are created as part of our graph
</code></pre>

<h4 id="_4">与变量作用域兼容</h4>
<p>变量共享应通过多次调用同样的Keras层或模型来实现，而不是通过TensorFlow的变量作用域实现。TensorFlow变量作用域将对Keras层或模型没有任何影响。更多Keras权重共享的信息请参考<a href="../../getting_started/functional_API.md/#node"><font color="#FF0000">这里</font></a></p>
<p>Keras通过重用相同层或模型的对象来完成权值共享，这是一个例子：</p>
<pre><code class="python"># instantiate a Keras layer
lstm = LSTM(32)

# instantiate two TF placeholders
x = tf.placeholder(tf.float32, shape=(None, 20, 64))
y = tf.placeholder(tf.float32, shape=(None, 20, 64))

# encode the two tensors with the *same* LSTM weights
x_encoded = lstm(x)
y_encoded = lstm(y)
</code></pre>

<h4 id="_5">收集可训练权重与状态更新</h4>
<p>某些Keras层，如状态RNN和BN层，其内部的更新需要作为训练过程的一步来进行，这些更新被存储在一个tensor tuple里：layer.updates，你应该生成assign操作来使在训练的每一步这些更新能够被运行，这里是例子：</p>
<pre><code class="python">from keras.layers import BatchNormalization

layer = BatchNormalization()(x)

update_ops = []
for old_value, new_value in layer.updates:
    update_ops.append(tf.assign(old_value, new_value))
</code></pre>

<p>注意如果你使用Keras模型，model.updates将与上面的代码作用相同（收集模型中所有更新）</p>
<p>另外，如果你需要显式的收集一个层的可训练权重，你可以通过layer.trainable_weights来实现，对模型而言是model.trainable_weights，它是一个tensorflow变量对象的列表：</p>
<pre><code class="python">from keras.layers import Dense

layer = Dense(32)(x)  # instantiate and call a layer
print layer.trainable_weights  # list of TensorFlow Variables
</code></pre>

<p>这些东西允许你实现你基于TensorFlow优化器实现自己的训练程序</p>
<h3 id="kerastensorflow_2">使用Keras模型与TensorFlow协作</h3>
<h4 id="keras-sequentialtensorflow">将Keras Sequential模型转换到TensorFlow中</h4>
<p>假如你已经有一个训练好的Keras模型，如VGG-16，现在你想将它应用在你的TensorFlow工作中，应该怎么办？</p>
<p>首先，注意如果你的预训练权重含有使用Theano训练的卷积层的话，你需要对这些权重的卷积核进行转换，这是因为Theano和TensorFlow对卷积的实现不同，TensorFlow和Caffe实际上实现的是相关性计算。点击<a href="https://github.com/fchollet/keras/wiki/Converting-convolution-kernels-from-Theano-to-TensorFlow-and-vice-versa"><font color="#FF0000">这里</font></a>查看详细示例。</p>
<p>假设你从下面的Keras模型开始，并希望对其进行修改以使得它可以以一个特定的tensorflow张量my_input_tensor为输入，这个tensor可能是一个数据feeder或别的tensorflow模型的输出</p>
<pre><code class="python"># this is our initial Keras model
model = Sequential()
first_layer = Dense(32, activation='relu', input_dim=784)
model.add(Dense(10, activation='softmax'))
</code></pre>

<p>你只需要在实例化该模型后，使用set_input来修改首层的输入，然后将剩下模型搭建于其上：</p>
<pre><code class="python"># this is our modified Keras model
model = Sequential()
first_layer = Dense(32, activation='relu', input_dim=784)
first_layer.set_input(my_input_tensor)

# build the rest of the model as before
model.add(first_layer)
model.add(Dense(10, activation='softmax'))
</code></pre>

<p>在这个阶段，你可以调用model.load_weights(weights_file)来加载预训练的权重</p>
<p>然后，你或许会收集该模型的输出张量：</p>
<pre><code class="python">output_tensor = model.output
</code></pre>

<h4 id="tensorflowkeras_1">对TensorFlow张量中调用Keras模型</h4>
<p>Keras模型与Keras层的行为一致，因此可以被调用于TensorFlow张量上：</p>
<pre><code class="python">from keras.models import Sequential

model = Sequential()
model.add(Dense(32, activation='relu', input_dim=784))
model.add(Dense(10, activation='softmax'))

# this works! 
x = tf.placeholder(tf.float32, shape=(None, 784))
y = model(x)
</code></pre>

<p>注意，调用模型时你同时使用了模型的结构与权重，当你在一个tensor上调用模型时，你就在该tensor上创造了一些操作，这些操作重用了已经在模型中出现的TensorFlow变量的对象</p>
<h3 id="gpu">多GPU和分布式训练</h3>
<h3 id="kerasgpu">将Keras模型分散在多个GPU中训练</h3>
<p>TensorFlow的设备作用域完全与Keras的层和模型兼容，因此你可以使用它们来将一个图的特定部分放在不同的GPU中训练，这里是一个简单的例子：</p>
<pre><code class="python">with tf.device('/gpu:0'):
    x = tf.placeholder(tf.float32, shape=(None, 20, 64))
    y = LSTM(32)(x)  # all ops in the LSTM layer will live on GPU:0

with tf.device('/gpu:1'):
    x = tf.placeholder(tf.float32, shape=(None, 20, 64))
    y = LSTM(32)(x)  # all ops in the LSTM layer will live on GPU:1
</code></pre>

<p>注意，由LSTM层创建的变量将不会生存在GPU上，不管TensorFlow变量在哪里创建，它们总是生存在CPU上，TensorFlow将隐含的处理设备之间的转换</p>
<p>如果你想在多个GPU上训练同一个模型的多个副本，并在多个副本中进行权重共享，首先你应该在一个设备作用域下实例化你的模型或层，然后在不同GPU设备的作用域下多次调用该模型实例，如：</p>
<pre><code class="python">with tf.device('/cpu:0'):
    x = tf.placeholder(tf.float32, shape=(None, 784))

    # shared model living on CPU:0
    # it won't actually be run during training; it acts as an op template
    # and as a repository for shared variables
    model = Sequential()
    model.add(Dense(32, activation='relu', input_dim=784))
    model.add(Dense(10, activation='softmax'))

# replica 0
with tf.device('/gpu:0'):
    output_0 = model(x)  # all ops in the replica will live on GPU:0

# replica 1
with tf.device('/gpu:1'):
    output_1 = model(x)  # all ops in the replica will live on GPU:1

# merge outputs on CPU
with tf.device('/cpu:0'):
    preds = 0.5 * (output_0 + output_1)

# we only run the `preds` tensor, so that only the two
# replicas on GPU get run (plus the merge op on CPU)
output_value = sess.run([preds], feed_dict={x: data})
</code></pre>

<h4 id="_6">分布式训练</h4>
<p>通过注册Keras会话到一个集群上，你可以简单的实现分布式训练：</p>
<pre><code class="python">server = tf.train.Server.create_local_server()
sess = tf.Session(server.target)

from keras import backend as K
K.set_session(sess)
</code></pre>

<p>关于TensorFlow进行分布式训练的配置信息，请参考<a href="https://www.tensorflow.org/versions/r0.8/how_tos/distributed/index.html"><font color="#FF0000">这里</font></a></p>
<h3 id="tensorflow-serving">使用TensorFlow-serving导出模型</h3>
<p><a href="https://github.com/tensorflow/serving"><font color="#FF0000">TensorFlow-Serving</font></a>是由Google开发的用于将TensoFlow模型部署于生产环境的工具</p>
<p>任何Keras模型都可以被TensorFlow-serving所导出（只要它只含有一个输入和一个输出，这是TF-serving的限制），不管它是否作为TensroFlow工作流的一部分。事实上你甚至可以使用Theano训练你的Keras模型，然后将其切换到tensorflow后端，然后导出模型</p>
<p>如果你的graph使用了Keras的learning phase（在训练和测试中行为不同），你首先要做的事就是在graph中硬编码你的工作模式（设为0，即测试模式），该工作通过1）使用Keras的后端注册一个learning phase常量，2）重新构建模型，来完成。</p>
<p>这里是实践中的示范：</p>
<pre><code class="python">from keras import backend as K

K.set_learning_phase(0)  # all new operations will be in test mode from now on

# serialize the model and get its weights, for quick re-building
config = previous_model.get_config()
weights = previous_model.get_weights()

# re-build a model where the learning phase is now hard-coded to 0
from keras.models import model_from_config
new_model = model_from_config(config)
new_model.set_weights(weights)
</code></pre>

<p>现在，我们可使用Tensorflow-serving来导出模型，按照官方教程的指导：</p>
<pre><code class="python">from tensorflow_serving.session_bundle import exporter

export_path = ... # where to save the exported graph
export_version = ... # version number (integer)

saver = tf.train.Saver(sharded=True)
model_exporter = exporter.Exporter(saver)
signature = exporter.classification_signature(input_tensor=model.input,
                                              scores_tensor=model.output)
model_exporter.init(sess.graph.as_graph_def(),
                    default_graph_signature=signature)
model_exporter.export(export_path, tf.constant(export_version), sess)
</code></pre>

<p>如想看到包含本教程的新主题，请看<a href="https://twitter.com/fchollet"><font color="#FF0000">我的Twitter</font></a></p>
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../../acknowledgement/" class="btn btn-neutral float-right" title="致谢">Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
        <a href="../word_embedding/" class="btn btn-neutral" title="在Keras模型中使用预训练的词向量"><span class="icon icon-circle-arrow-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="http://www.mkdocs.org">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
	  
        </div>
      </div>

    </section>
    
  </div>

  <div class="rst-versions" role="note" style="cursor: pointer">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
      
        <span><a href="../word_embedding/" style="color: #fcfcfc;">&laquo; Previous</a></span>
      
      
        <span style="margin-left: 15px"><a href="../../acknowledgement/" style="color: #fcfcfc">Next &raquo;</a></span>
      
    </span>
</div>
    <script src="../../js/theme.js"></script>

</body>
</html>
