<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <meta name="author" content="BigMoyan">
  <link rel="shortcut icon" href="../../img/favicon.ico">
  <title>递归层Recurrent - Keras中文文档</title>
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" href="../../css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../css/theme_extra.css" type="text/css" />
  <link rel="stylesheet" href="../../css/highlight.css">
  
  <script>
    // Current page data
    var mkdocs_page_name = "\u9012\u5f52\u5c42Recurrent";
    var mkdocs_page_input_path = "layers/recurrent_layer.md";
    var mkdocs_page_url = "/layers/recurrent_layer/";
  </script>
  
  <script src="../../js/jquery-2.1.1.min.js"></script>
  <script src="../../js/modernizr-2.8.3.min.js"></script>
  <script type="text/javascript" src="../../js/highlight.pack.js"></script> 
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
      <div class="wy-side-nav-search">
        <a href="../.." class="icon icon-home"> Keras中文文档</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
	<ul class="current">
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../..">主页</a>
        
    </li>
<li>
          
            <li>
    <ul class="subnav">
    <li><span>快速开始</span></li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../getting_started/concepts/">一些基本概念</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../getting_started/keras_linux/">Keras安装和配置指南(Linux)</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../getting_started/keras_windows/">Keras安装和配置指南(Windows)</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../getting_started/sequential_model/">快速开始Sequential模型</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../getting_started/functional_API/">快速开始泛型模型</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../getting_started/FAQ/">FAQ</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../getting_started/trap/">Keras使用陷阱</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../getting_started/examples/">Keras示例列表</a>
        
    </li>

        
    </ul>
<li>
          
            <li>
    <ul class="subnav">
    <li><span>模型</span></li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../models/about_model/">关于Keras模型</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../models/sequential/">Sequential模型</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../models/model/">泛型模型</a>
        
    </li>

        
    </ul>
<li>
          
            <li>
    <ul class="subnav">
    <li><span>网络层</span></li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../about_layer/">关于Keras层</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../core_layer/">常用层Core</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../convolutional_layer/">卷积层Convolutional</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../pooling_layer/">池化层Pooling</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../locally_connected_layer/">局部连接层Locally-connented</a>
        
    </li>

        
            
    <li class="toctree-l1 current">
        <a class="current" href="./">递归层Recurrent</a>
        
            <ul>
            
                <li class="toctree-l3"><a href="#recurrent">递归层Recurrent</a></li>
                
                    <li><a class="toctree-l4" href="#recurrent_1">Recurrent层</a></li>
                
                    <li><a class="toctree-l4" href="#simplernn">SimpleRNN层</a></li>
                
                    <li><a class="toctree-l4" href="#gru">GRU层</a></li>
                
                    <li><a class="toctree-l4" href="#lstm">LSTM层</a></li>
                
            
            </ul>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../embedding_layer/">嵌入层Embedding</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../advanced_activation_layer/">高级激活层Advanced Activation</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../normalization_layer/">规范层BatchNormalization</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../noise_layer/">噪声层Noise</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../wrapper/">包装器Wrapper</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../writting_layer/">编写自己的层</a>
        
    </li>

        
    </ul>
<li>
          
            <li>
    <ul class="subnav">
    <li><span>预处理</span></li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../preprocessing/sequence/">序列预处理</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../preprocessing/text/">文本预处理</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../preprocessing/image/">图片预处理</a>
        
    </li>

        
    </ul>
<li>
          
            <li>
    <ul class="subnav">
    <li><span>其他重要模块</span></li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../other/objectives/">目标函数Objective</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../other/optimizers/">优化器Optimizer</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../other/activations/">激活函数Activation</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../other/callbacks/">回调函数Callback</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../other/metrices/">性能评估Metrices</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../other/initializations/">初始化方法Initialization</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../other/regularizers/">正则项Regularizer</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../other/constraints/">约束项Constraint</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../other/application/">预训练模型Application</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../other/datasets/">常用数据库Dataset</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../other/visualization/">可视化Visualization</a>
        
    </li>

        
    </ul>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../../backend/">keras后端Backend</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../../scikit-learn_API/">scikit-learn接口</a>
        
    </li>
<li>
          
            <li>
    <ul class="subnav">
    <li><span>工具</span></li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../utils/data_utils/">数据工具</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../utils/io_utils/">输入输出I/O</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../utils/layer_utils/">Keras层工具</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../utils/np_utils/">numpy工具</a>
        
    </li>

        
    </ul>
<li>
          
            <li>
    <ul class="subnav">
    <li><span>深度学习与Keras</span></li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../blog/cnn_see_world/">CNN眼中的世界</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../blog/autoencoder/">花式自动编码器</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../blog/image_classification_using_very_little_data/">面向小数据集构建图像分类模型</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../blog/word_embedding/">在Keras模型中使用预训练的词向量</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../blog/keras_and_tensorflow/">将Keras作为tensorflow的精简接口</a>
        
    </li>

        
    </ul>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../../acknowledgement/">致谢</a>
        
    </li>
<li>
          
        </ul>
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../..">Keras中文文档</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../..">Docs</a> &raquo;</li>
    
      
        
          <li>网络层 &raquo;</li>
        
      
    
    <li>递归层Recurrent</li>
    <li class="wy-breadcrumbs-aside">
      
    </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <h1 id="recurrent">递归层Recurrent</h1>
<h2 id="recurrent_1">Recurrent层</h2>
<pre><code class="python">keras.layers.recurrent.Recurrent(weights=None, return_sequences=False, go_backwards=False, stateful=False, unroll=False, consume_less='cpu', input_dim=None, input_length=None)
</code></pre>

<p>这是递归层的抽象类，请不要在模型中直接应用该层（因为它是抽象类，无法实例化任何对象）。请使用它的子类<code>LSTM</code>或<code>SimpleRNN</code>。</p>
<p>所有的递归层（<code>LSTM</code>,<code>GRU</code>,<code>SimpleRNN</code>）都服从本层的性质，并接受本层指定的所有关键字参数。</p>
<h3 id="_1">参数</h3>
<ul>
<li>
<p>weights：numpy array的list，用以初始化权重。该list形如<code>[(input_dim, output_dim),(output_dim, output_dim),(output_dim,)]</code></p>
</li>
<li>
<p>return_sequences：布尔值，默认<code>False</code>，控制返回类型。若为<code>True</code>则返回整个序列，否则仅返回输出序列的最后一个输出</p>
</li>
<li>
<p>go_backwards：布尔值，默认为<code>False</code>，若为<code>True</code>，则逆向处理输入序列</p>
</li>
<li>
<p>stateful：布尔值，默认为<code>False</code>，若为<code>True</code>，则一个batch中下标为i的样本的最终状态将会用作下一个batch同样下标的样本的初始状态。</p>
</li>
<li>
<p>unroll：布尔值，默认为<code>False</code>，若为<code>True</code>，则递归层将被展开，否则就使用符号化的循环。当使用TensorFlow为后端时，递归网络本来就是展开的，因此该层不做任何事情。层展开会占用更多的内存，但会加速RNN的运算。层展开只适用于短序列。</p>
</li>
<li>
<p>consume_less：‘cpu’或‘mem’之一。若设为‘cpu’，则RNN将使用较少、较大的矩阵乘法来实现，从而在CPU上会运行更快，但会更消耗内存。如果设为‘mem’，则RNN将会较多的小矩阵乘法来实现，从而在GPU并行计算时会运行更快（但在CPU上慢），并占用较少内存。</p>
</li>
<li>
<p>input_dim：输入维度，当使用该层为模型首层时，应指定该值（或等价的指定input_shape)</p>
</li>
<li>
<p>input_length：当输入序列的长度固定时，该参数为输入序列的长度。当需要在该层后连接<code>Flatten</code>层，然后又要连接<code>Dense</code>层时，需要指定该参数，否则全连接的输出无法计算出来。注意，如果递归层不是网络的第一层，你需要在网络的第一层中指定序列的长度，如通过<code>input_shape</code>指定。</p>
</li>
</ul>
<h3 id="shape">输入shape</h3>
<p>形如（samples，timesteps，input_dim）的3D张量</p>
<h3 id="shape_1">输出shape</h3>
<p>如果<code>return_sequences=True</code>：返回形如（samples，timesteps，output_dim）的3D张量</p>
<p>否则，返回形如（samples，output_dim）的2D张量</p>
<h3 id="_2">例子</h3>
<pre><code class="python"># as the first layer in a Sequential model
model = Sequential()
model.add(LSTM(32, input_shape=(10, 64)))
# now model.output_shape == (None, 10, 32)
# note: `None` is the batch dimension.

# the following is identical:
model = Sequential()
model.add(LSTM(32, input_dim=64, input_length=10))

# for subsequent layers, not need to specify the input size:
model.add(LSTM(16))
</code></pre>

<h3 id="masking">屏蔽输入数据（Masking）</h3>
<p>递归层支持通过时间步变量对输入数据进行Masking，如果想将输入数据的一部分屏蔽掉，请使用<a href="../embedding_layer"><font color-'#FF0000'>Embedding</font></a>层并将参数<code>mask_zero</code>设为<code>True</code>。</p>
<h3 id="tensorflow">TensorFlow警告</h3>
<p>目前为止，当使用TensorFlow作为后端时，序列的时间步数目必须在网络中指定。通过<code>input_length</code>（如果网络首层是递归层）或完整的<code>input_shape</code>来指定该值。</p>
<h3 id="rnn">使用状态RNN的注意事项</h3>
<p>可以将RNN设置为‘stateful’，意味着训练时每个batch的状态都会被重用于初始化下一个batch的初始状态。状态RNN假设连续的两个batch之中，相同下标的元素有一一映射关系。</p>
<p>要启用状态RNN，请在实例化层对象时指定参数<code>stateful=True</code>，并指定模型使用固定大小的batch：通过在模型的第一层传入<code>batch_input_shape=(...)</code>来实现。该参数应为包含batch大小的元组，例如（32，10，100）代表每个batch的大小是32.</p>
<p>如果要将递归层的状态重置，请调用<code>.reset_states()</code>，对模型调用将重置模型中所有状态RNN的状态。对单个层调用则只重置该层的状态。</p>
<h3 id="tensorflowdropout">以TensorFlow作为后端时使用dropout的注意事项</h3>
<p>当使用TensorFlow作为后端时，如果要在递归层使用dropout，需要同上面所述的一样指定好固定的batch大小</p>
<hr />
<h2 id="simplernn">SimpleRNN层</h2>
<pre><code class="python">keras.layers.recurrent.SimpleRNN(output_dim, init='glorot_uniform', inner_init='orthogonal', activation='tanh', W_regularizer=None, U_regularizer=None, b_regularizer=None, dropout_W=0.0, dropout_U=0.0)
</code></pre>

<p>全连接RNN网络，RNN的输出会被回馈到输入</p>
<h3 id="_3">参数</h3>
<ul>
<li>
<p>output_dim：内部投影和输出的维度</p>
</li>
<li>
<p>init：初始化方法，为预定义初始化方法名的字符串，或用于初始化权重的Theano函数。</p>
</li>
<li>
<p>inner_init：内部单元的初始化方法</p>
</li>
<li>
<p>activation：激活函数，为预定义的激活函数名（参考<a href="../../other/activations"><font color='#FF0000'>激活函数</font></a>）</p>
</li>
<li>
<p>W_regularizer：施加在权重上的正则项，为<a href="../../other/regularizers"><font color='FF0000'>WeightRegularizer</font></a>对象</p>
</li>
<li>
<p>U_regularizer：施加在递归权重上的正则项，为<a href="../../other/regularizers"><font color='FF0000'>WeightRegularizer</font></a>对象</p>
</li>
<li>
<p>b_regularizer：施加在偏置向量上的正则项，为<a href="../../other/regularizers"><font color='FF0000'>WeightRegularizer</font></a>对象</p>
</li>
<li>
<p>dropout_W：0~1之间的浮点数，控制输入单元到输入门的连接断开比例</p>
</li>
<li>
<p>dropout_U：0~1之间的浮点数，控制输入单元到递归连接的断开比例</p>
</li>
</ul>
<h3 id="_4">参考文献</h3>
<ul>
<li><a href="http://arxiv.org/abs/1512.05287"><font color='FF0000'>A Theoretically Grounded Application of Dropout in Recurrent Neural Networks</font></a></li>
</ul>
<hr />
<h2 id="gru">GRU层</h2>
<pre><code class="python">keras.layers.recurrent.GRU(output_dim, init='glorot_uniform', inner_init='orthogonal', activation='tanh', inner_activation='hard_sigmoid', W_regularizer=None, U_regularizer=None, b_regularizer=None, dropout_W=0.0, dropout_U=0.0)
</code></pre>

<p>门限递归单元（详见参考文献）</p>
<h3 id="_5">参数</h3>
<ul>
<li>
<p>output_dim：内部投影和输出的维度</p>
</li>
<li>
<p>init：初始化方法，为预定义初始化方法名的字符串，或用于初始化权重的Theano函数。</p>
</li>
<li>
<p>inner_init：内部单元的初始化方法</p>
</li>
<li>
<p>activation：激活函数，为预定义的激活函数名（参考<a href="../../other/activations"><font color='#FF0000'>激活函数</font></a>）</p>
</li>
<li>
<p>inner_activation：内部单元激活函数</p>
</li>
<li>
<p>W_regularizer：施加在权重上的正则项，为<a href="../../other/regularizers"><font color='FF0000'>WeightRegularizer</font></a>对象</p>
</li>
<li>
<p>U_regularizer：施加在递归权重上的正则项，为<a href="../../other/regularizers"><font color='FF0000'>WeightRegularizer</font></a>对象</p>
</li>
<li>
<p>b_regularizer：施加在偏置向量上的正则项，为<a href="../../other/regularizers"><font color='FF0000'>WeightRegularizer</font></a>对象</p>
</li>
<li>
<p>dropout_W：0~1之间的浮点数，控制输入单元到输入门的连接断开比例</p>
</li>
<li>
<p>dropout_U：0~1之间的浮点数，控制输入单元到递归连接的断开比例</p>
</li>
</ul>
<h3 id="_6">参考文献</h3>
<ul>
<li>
<p><a href="http://www.aclweb.org/anthology/W14-4012"><font color='FF0000'>On the Properties of Neural Machine Translation: Encoder–Decoder Approaches</font></a></p>
</li>
<li>
<p><a href="http://arxiv.org/pdf/1412.3555v1.pdf"><font color='FF0000'>Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling</font></a></p>
</li>
<li>
<p><a href="http://arxiv.org/abs/1512.05287"><font color='FF0000'>A Theoretically Grounded Application of Dropout in Recurrent Neural Networks</font></a></p>
</li>
</ul>
<hr />
<h2 id="lstm">LSTM层</h2>
<pre><code class="python">keras.layers.recurrent.LSTM(output_dim, init='glorot_uniform', inner_init='orthogonal', forget_bias_init='one', activation='tanh', inner_activation='hard_sigmoid', W_regularizer=None, U_regularizer=None, b_regularizer=None, dropout_W=0.0, dropout_U=0.0)
</code></pre>

<p>Keras长短期记忆模型，关于此算法的详情，请参考<a href="http://deeplearning.net/tutorial/lstm.html"><font color='FF0000'>本教程</font></a></p>
<h3 id="_7">参数</h3>
<ul>
<li>
<p>output_dim：内部投影和输出的维度</p>
</li>
<li>
<p>init：初始化方法，为预定义初始化方法名的字符串，或用于初始化权重的Theano函数。</p>
</li>
<li>
<p>inner_init：内部单元的初始化方法</p>
</li>
<li>
<p>forget_bias_init：遗忘门偏置的初始化函数，<a href="http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf"><font color='FF0000'>Jozefowicz et al.</font></a>建议初始化为全1元素</p>
</li>
<li>
<p>activation：激活函数，为预定义的激活函数名（参考<a href="../../other/activations"><font color='#FF0000'>激活函数</font></a>）</p>
</li>
<li>
<p>inner_activation：内部单元激活函数</p>
</li>
<li>
<p>W_regularizer：施加在权重上的正则项，为<a href="../../other/regularizers"><font color='FF0000'>WeightRegularizer</font></a>对象</p>
</li>
<li>
<p>U_regularizer：施加在递归权重上的正则项，为<a href="../../other/regularizers"><font color='FF0000'>WeightRegularizer</font></a>对象</p>
</li>
<li>
<p>b_regularizer：施加在偏置向量上的正则项，为<a href="../../other/regularizers"><font color='FF0000'>WeightRegularizer</font></a>对象</p>
</li>
<li>
<p>dropout_W：0~1之间的浮点数，控制输入单元到输入门的连接断开比例</p>
</li>
<li>
<p>dropout_U：0~1之间的浮点数，控制输入单元到递归连接的断开比例</p>
</li>
</ul>
<h3 id="_8">参考文献</h3>
<ul>
<li>
<p><a href="http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf"><font color='FF0000'>Long short-term memory </font></a>（original 1997 paper）</p>
</li>
<li>
<p><a href="http://www.mitpressjournals.org/doi/pdf/10.1162/089976600300015015"><font color='FF0000'>Learning to forget: Continual prediction with LSTM</font></a></p>
</li>
<li>
<p><a href="http://www.cs.toronto.edu/~graves/preprint.pdf"><font color='FF0000'>Supervised sequence labelling with recurrent neural networks</font></a></p>
</li>
<li>
<p><a href="http://arxiv.org/abs/1512.05287"><font color='FF0000'>A Theoretically Grounded Application of Dropout in Recurrent Neural Networks</font></a></p>
</li>
</ul>
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../embedding_layer/" class="btn btn-neutral float-right" title="嵌入层Embedding">Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
        <a href="../locally_connected_layer/" class="btn btn-neutral" title="局部连接层Locally-connented"><span class="icon icon-circle-arrow-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="http://www.mkdocs.org">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
	  
        </div>
      </div>

    </section>
    
  </div>

  <div class="rst-versions" role="note" style="cursor: pointer">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
      
        <span><a href="../locally_connected_layer/" style="color: #fcfcfc;">&laquo; Previous</a></span>
      
      
        <span style="margin-left: 15px"><a href="../embedding_layer/" style="color: #fcfcfc">Next &raquo;</a></span>
      
    </span>
</div>
    <script src="../../js/theme.js"></script>

</body>
</html>
